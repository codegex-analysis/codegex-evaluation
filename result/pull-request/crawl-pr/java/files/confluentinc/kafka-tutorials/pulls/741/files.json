[
  {
    "sha": "b9db4fecf50d01d0fb40f5e61eb62d4cc006dbfd",
    "filename": ".semaphore/semaphore.yml",
    "status": "modified",
    "additions": 4,
    "deletions": 0,
    "changes": 4,
    "blob_url": "https://github.com/confluentinc/kafka-tutorials/blob/00a95730609a35e5ec37a40b25c73385a551e263/.semaphore/semaphore.yml",
    "raw_url": "https://github.com/confluentinc/kafka-tutorials/raw/00a95730609a35e5ec37a40b25c73385a551e263/.semaphore/semaphore.yml",
    "contents_url": "https://api.github.com/repos/confluentinc/kafka-tutorials/contents/.semaphore/semaphore.yml?ref=00a95730609a35e5ec37a40b25c73385a551e263",
    "patch": "@@ -360,3 +360,7 @@ blocks:\n           commands:\n             - make -C _includes/tutorials/finding-distinct/kstreams/code tutorial\n             \n+        - name: KStreams Test Kafka Streams uncaught exception handling tests\n+          commands:\n+            - make -C _includes/tutorials/error-handling/kstreams/code tutorial\n+"
  },
  {
    "sha": "816a346f7b5f000541bc405fbe4802d8ee90caf6",
    "filename": "_data/harnesses/error-handling/kstreams.yml",
    "status": "added",
    "additions": 168,
    "deletions": 0,
    "changes": 168,
    "blob_url": "https://github.com/confluentinc/kafka-tutorials/blob/00a95730609a35e5ec37a40b25c73385a551e263/_data/harnesses/error-handling/kstreams.yml",
    "raw_url": "https://github.com/confluentinc/kafka-tutorials/raw/00a95730609a35e5ec37a40b25c73385a551e263/_data/harnesses/error-handling/kstreams.yml",
    "contents_url": "https://api.github.com/repos/confluentinc/kafka-tutorials/contents/_data/harnesses/error-handling/kstreams.yml?ref=00a95730609a35e5ec37a40b25c73385a551e263",
    "patch": "@@ -0,0 +1,168 @@\n+answer:\n+  steps:\n+    - title:\n+      content:\n+        - action: skip\n+          render:\n+            file: tutorials/error-handling/kstreams/markup/answer/error-handling-answer.adoc\n+\n+dev:\n+  steps:\n+    - title: Initialize the project\n+      content:\n+        - action: execute\n+          file: tutorial-steps/dev/init.sh\n+          render:\n+            file: tutorials/error-handling/kstreams/markup/dev/init.adoc\n+\n+    - title: Get Confluent Platform\n+      content:\n+        - action: make_file\n+          file: docker-compose.yml\n+          render:\n+            file: tutorials/error-handling/kstreams/markup/dev/make-docker-compose.adoc\n+\n+        - action: execute_async\n+          file: tutorial-steps/dev/docker-compose-up.sh\n+          render:\n+            file: tutorials/error-handling/kstreams/markup/dev/start-compose.adoc\n+\n+        - action: execute\n+          file: tutorial-steps/dev/wait-for-containers.sh\n+          render:\n+            skip: true\n+\n+    - title: Configure the project\n+      content:\n+        - action: make_file\n+          file: build.gradle\n+          render:\n+            file: tutorials/error-handling/kstreams/markup/dev/make-build-file.adoc\n+\n+        - action: execute\n+          file: tutorial-steps/dev/gradle-wrapper.sh\n+          render:\n+            file: tutorials/error-handling/kstreams/markup/dev/make-gradle-wrapper.adoc\n+\n+        - action: execute\n+          file: tutorial-steps/dev/make-configuration-dir.sh\n+          render:\n+            file: tutorials/error-handling/kstreams/markup/dev/make-config-dir.adoc\n+\n+        - action: make_file\n+          file: configuration/dev.properties\n+          render:\n+            file: tutorials/error-handling/kstreams/markup/dev/make-dev-file.adoc\n+            \n+    - title: Create an exception handler implementation\n+      content:\n+        - action: execute\n+          file: tutorial-steps/dev/make-src-dir.sh\n+          render:\n+            file: tutorials/error-handling/kstreams/markup/dev/make-src-dir.adoc\n+\n+        - action: make_file\n+          file: src/main/java/io/confluent/developer/MaxFailuresUncaughtExceptionHandler.java\n+          render:\n+            file: tutorials/error-handling/kstreams/markup/dev/make-exception-handler.adoc      \n+         \n+    - title: Create the Kafka Streams topology\n+      content:\n+        - action: make_file\n+          file: src/main/java/io/confluent/developer/StreamsUncaughtExceptionHandling.java\n+          render:\n+            file: tutorials/error-handling/kstreams/markup/dev/make-topology.adoc \n+\n+    - title: Compile and run the Kafka Streams program\n+      content:\n+        - action: execute\n+          file: tutorial-steps/dev/build-uberjar.sh\n+          render:\n+            file: tutorials/error-handling/kstreams/markup/dev/build-uberjar.adoc\n+\n+        - action: execute_async\n+          file: tutorial-steps/dev/run-dev-app.sh\n+          render:\n+            file: tutorials/error-handling/kstreams/markup/dev/run-dev-app.adoc\n+\n+    - title: Consume data from the output topic\n+      content:\n+        - action: execute_async\n+          file: tutorial-steps/dev/console-consumer.sh\n+          stdout: tutorial-steps/dev/outputs/actual-output.txt\n+          render:\n+            file: tutorials/error-handling/kstreams/markup/dev/run-consumer.adoc\n+\n+        - name: wait for the consumer to read the messages\n+          action: sleep\n+          ms: 60000\n+          render:\n+            skip: true\n+\n+test:\n+  steps:\n+    - title: Create a test configuration file\n+      content:\n+        - action: make_file\n+          file: configuration/test.properties\n+          render:\n+            file: tutorials/error-handling/kstreams/markup/test/make-test-file.adoc\n+\n+    - title: Write a test\n+      content:\n+        - action: execute\n+          file: tutorial-steps/test/make-test-dir.sh\n+          render:\n+            file: tutorials/error-handling/kstreams/markup/test/make-test-dir.adoc\n+\n+        - action: make_file\n+          file: src/test/java/io/confluent/developer/StreamsUncaughtExceptionHandlingTest.java\n+          render:\n+            file: tutorials/error-handling/kstreams/markup/test/make-topology-test.adoc\n+\n+        - action: make_file\n+          file: src/test/java/io/confluent/developer/MaxFailuresUncaughtExceptionHandlerTest.java\n+          render:\n+            skip: true\n+\n+    - title: Invoke the tests\n+      content:\n+        - action: execute\n+          file: tutorial-steps/test/invoke-tests.sh\n+          stdout: tutorial-steps/dev/outputs/unit-test-output.txt\n+          render:\n+            file: tutorials/error-handling/kstreams/markup/test/invoke-tests.adoc\n+\n+prod:\n+  steps:\n+    - title: Create a production configuration file\n+      content:\n+        - action: make_file\n+          file: configuration/prod.properties\n+          render:\n+            file: tutorials/error-handling/kstreams/markup/prod/make-prod-file.adoc\n+\n+    - title: Build a Docker image\n+      content:\n+        - action: execute\n+          file: tutorial-steps/prod/build-image.sh\n+          render:\n+            file: tutorials/error-handling/kstreams/markup/prod/build-image.adoc\n+\n+    - title: Launch the container\n+      content:\n+        - action: skip\n+          render:\n+            file: tutorials/error-handling/kstreams/markup/prod/launch-container.adoc\n+\n+        - action: execute\n+          file: tutorial-steps/dev/clean-up.sh\n+          render:\n+            skip: true\n+ccloud:\n+  steps:\n+    - title: Run your app to Confluent Cloud\n+      content:\n+        - action: skip\n+          render:\n+            file: shared/markup/ccloud/try-ccloud-properties.adoc"
  },
  {
    "sha": "994440d497be59c43691c4470169e136eb8830ee",
    "filename": "_data/tutorials.yaml",
    "status": "modified",
    "additions": 19,
    "deletions": 0,
    "changes": 19,
    "blob_url": "https://github.com/confluentinc/kafka-tutorials/blob/00a95730609a35e5ec37a40b25c73385a551e263/_data/tutorials.yaml",
    "raw_url": "https://github.com/confluentinc/kafka-tutorials/raw/00a95730609a35e5ec37a40b25c73385a551e263/_data/tutorials.yaml",
    "contents_url": "https://api.github.com/repos/confluentinc/kafka-tutorials/contents/_data/tutorials.yaml?ref=00a95730609a35e5ec37a40b25c73385a551e263",
    "patch": "@@ -673,3 +673,22 @@ sliding-windows:\n     ruby: disabled\n     scala: disabled\n     swift: disabled\n+\n+error-handling:\n+  title: \"Handling uncaught exceptions\"\n+  meta-description: \"Handling uncaught exceptions\"\n+  slug: \"/error-handling\"\n+  question: \"How do I handle uncaught exceptions?\"\n+  introduction: \"You have an event streaming application and you want to make sure it's robust in the face of unexpected errors.  Depending on the situation, you'll either want the application to either continue running or shut down.  In this tutorial you'll learn how to use the `StreamsUncaughtExceptionHandler` to provide this functionality.\"\n+  status:\n+    ksql: disabled\n+    kstreams: enabled\n+    kafka: disabled\n+    c: disabled\n+    go: disabled\n+    groovy: disabled\n+    nodejs: disabled\n+    python: disabled\n+    ruby: disabled\n+    scala: disabled\n+    swift: disabled"
  },
  {
    "sha": "3f4678b3296d45a57734e66284c84a0a0954c923",
    "filename": "_includes/tutorials/error-handling/.gitignore",
    "status": "added",
    "additions": 2,
    "deletions": 0,
    "changes": 2,
    "blob_url": "https://github.com/confluentinc/kafka-tutorials/blob/00a95730609a35e5ec37a40b25c73385a551e263/_includes/tutorials/error-handling/.gitignore",
    "raw_url": "https://github.com/confluentinc/kafka-tutorials/raw/00a95730609a35e5ec37a40b25c73385a551e263/_includes/tutorials/error-handling/.gitignore",
    "contents_url": "https://api.github.com/repos/confluentinc/kafka-tutorials/contents/_includes/tutorials/error-handling/.gitignore?ref=00a95730609a35e5ec37a40b25c73385a551e263",
    "patch": "@@ -0,0 +1,2 @@\n+kstreams/code/tutorial-steps/dev/outputs/\n+"
  },
  {
    "sha": "dea029dc3f642494d4e9c671b556f985683246f7",
    "filename": "_includes/tutorials/error-handling/kstreams/code/Makefile",
    "status": "added",
    "additions": 15,
    "deletions": 0,
    "changes": 15,
    "blob_url": "https://github.com/confluentinc/kafka-tutorials/blob/00a95730609a35e5ec37a40b25c73385a551e263/_includes/tutorials/error-handling/kstreams/code/Makefile",
    "raw_url": "https://github.com/confluentinc/kafka-tutorials/raw/00a95730609a35e5ec37a40b25c73385a551e263/_includes/tutorials/error-handling/kstreams/code/Makefile",
    "contents_url": "https://api.github.com/repos/confluentinc/kafka-tutorials/contents/_includes/tutorials/error-handling/kstreams/code/Makefile?ref=00a95730609a35e5ec37a40b25c73385a551e263",
    "patch": "@@ -0,0 +1,15 @@\n+STEPS_DIR := tutorial-steps\n+DEV_OUTPUTS_DIR := $(STEPS_DIR)/dev/outputs\n+TEMP_DIR := $(shell mktemp -d)\n+SEQUENCE := \"dev, test, prod, ccloud\"\n+LIB_DIR := $(TEMP_DIR)/temp_local_28_repo\n+\n+tutorial:\n+\trm -r $(DEV_OUTPUTS_DIR) || true\n+\tmkdir $(DEV_OUTPUTS_DIR)\n+\tmkdir $(LIB_DIR)\n+\tcp temp_local_28_repo/* $(LIB_DIR)\n+\tharness-runner ../../../../../_data/harnesses/error-handling/kstreams.yml $(TEMP_DIR) $(SEQUENCE)\n+\tbash -c \"diff --strip-trailing-cr  <(tail -n 1 $(STEPS_DIR)/dev/expected-output.txt) <(tail -n 1 $(DEV_OUTPUTS_DIR)/actual-output.txt)\"\n+\tbash -c \"grep 'BUILD SUCCESSFUL' $(DEV_OUTPUTS_DIR)/unit-test-output.txt\"\n+\treset"
  },
  {
    "sha": "d7ffa67237d065093f9d4c5cb3a6827eee5ba06d",
    "filename": "_includes/tutorials/error-handling/kstreams/code/build.gradle",
    "status": "added",
    "additions": 67,
    "deletions": 0,
    "changes": 67,
    "blob_url": "https://github.com/confluentinc/kafka-tutorials/blob/00a95730609a35e5ec37a40b25c73385a551e263/_includes/tutorials/error-handling/kstreams/code/build.gradle",
    "raw_url": "https://github.com/confluentinc/kafka-tutorials/raw/00a95730609a35e5ec37a40b25c73385a551e263/_includes/tutorials/error-handling/kstreams/code/build.gradle",
    "contents_url": "https://api.github.com/repos/confluentinc/kafka-tutorials/contents/_includes/tutorials/error-handling/kstreams/code/build.gradle?ref=00a95730609a35e5ec37a40b25c73385a551e263",
    "patch": "@@ -0,0 +1,67 @@\n+buildscript {\n+    repositories {\n+        jcenter()\n+    }\n+    dependencies {\n+        classpath \"com.commercehub.gradle.plugin:gradle-avro-plugin:0.22.0\"\n+        classpath \"com.github.jengelman.gradle.plugins:shadow:6.0.0\"\n+    }\n+}\n+\n+plugins {\n+    id \"java\"\n+    id \"com.google.cloud.tools.jib\" version \"2.8.0\"\n+    id \"idea\"\n+    id \"eclipse\"\n+}\n+\n+sourceCompatibility = JavaVersion.VERSION_1_8\n+targetCompatibility = JavaVersion.VERSION_1_8\n+version = \"0.0.1\"\n+\n+repositories {\n+    jcenter()\n+\n+    maven {\n+        url \"https://packages.confluent.io/maven\"\n+    }\n+}\n+\n+apply plugin: \"com.commercehub.gradle.plugin.avro\"\n+apply plugin: \"com.github.johnrengelman.shadow\"\n+\n+dependencies {\n+    implementation \"org.apache.avro:avro:1.10.1\"\n+    implementation \"org.slf4j:slf4j-simple:1.7.30\"\n+    //implementation \"org.apache.kafka:kafka-streams:2.8.0\"\n+    implementation files('temp_local_28_repo/kafka-streams-2.8.0-SNAPSHOT.jar')\n+     //implementation \"org.apache.kafka:kafka-clients:2.8.0\"\n+    implementation files('temp_local_28_repo/kafka-clients-2.8.0-SNAPSHOT.jar')\n+    //testImplementation \"org.apache.kafka:kafka-streams-test-utils:2.8.0\"\n+    testImplementation files('temp_local_28_repo/kafka-streams-test-utils-2.8.0-SNAPSHOT.jar')\n+    \n+    testImplementation \"junit:junit:4.13.2\"\n+    testImplementation 'org.hamcrest:hamcrest:2.2'\n+}\n+\n+test {\n+    testLogging {\n+        outputs.upToDateWhen { false }\n+        showStandardStreams = true\n+        exceptionFormat = \"full\"\n+    }\n+}\n+\n+jar {\n+  manifest {\n+    attributes(\n+      \"Class-Path\": configurations.compileClasspath.collect { it.getName() }.join(\" \"),\n+      \"Main-Class\": \"io.confluent.developer.StreamsUncaughtExceptionHandling\"\n+    )\n+  }\n+}\n+\n+shadowJar {\n+    archiveBaseName = \"error-handling-standalone\"\n+    archiveClassifier = ''\n+}"
  },
  {
    "sha": "bced58b581b0e20a733b4bcbaa487dcd63f3bfd3",
    "filename": "_includes/tutorials/error-handling/kstreams/code/configuration/dev.properties",
    "status": "added",
    "additions": 13,
    "deletions": 0,
    "changes": 13,
    "blob_url": "https://github.com/confluentinc/kafka-tutorials/blob/00a95730609a35e5ec37a40b25c73385a551e263/_includes/tutorials/error-handling/kstreams/code/configuration/dev.properties",
    "raw_url": "https://github.com/confluentinc/kafka-tutorials/raw/00a95730609a35e5ec37a40b25c73385a551e263/_includes/tutorials/error-handling/kstreams/code/configuration/dev.properties",
    "contents_url": "https://api.github.com/repos/confluentinc/kafka-tutorials/contents/_includes/tutorials/error-handling/kstreams/code/configuration/dev.properties?ref=00a95730609a35e5ec37a40b25c73385a551e263",
    "patch": "@@ -0,0 +1,13 @@\n+application.id=error-handling\n+bootstrap.servers=localhost:29092\n+\n+input.topic.name=input-topic\n+input.topic.partitions=1\n+input.topic.replication.factor=1\n+\n+output.topic.name=output-topic\n+output.topic.partitions=1\n+output.topic.replication.factor=1\n+\n+max.failures=3\n+max.time.millis=3600000"
  },
  {
    "sha": "cbb27b80c7cd77df083bcf8b1ac749a146d939d2",
    "filename": "_includes/tutorials/error-handling/kstreams/code/configuration/prod.properties",
    "status": "added",
    "additions": 11,
    "deletions": 0,
    "changes": 11,
    "blob_url": "https://github.com/confluentinc/kafka-tutorials/blob/00a95730609a35e5ec37a40b25c73385a551e263/_includes/tutorials/error-handling/kstreams/code/configuration/prod.properties",
    "raw_url": "https://github.com/confluentinc/kafka-tutorials/raw/00a95730609a35e5ec37a40b25c73385a551e263/_includes/tutorials/error-handling/kstreams/code/configuration/prod.properties",
    "contents_url": "https://api.github.com/repos/confluentinc/kafka-tutorials/contents/_includes/tutorials/error-handling/kstreams/code/configuration/prod.properties?ref=00a95730609a35e5ec37a40b25c73385a551e263",
    "patch": "@@ -0,0 +1,11 @@\n+application.id=error-handling\n+bootstrap.servers=<<FILL ME IN>>\n+schema.registry.url=<<FILL ME IN>>\n+\n+input.topic.name=temp-readings\n+input.topic.partitions=<<FILL ME IN>>\n+input.topic.replication.factor=<<FILL ME IN>>\n+\n+output.topic.name=output-topic\n+output.topic.partitions=<<FILL ME IN>>\n+output.topic.replication.factor=<<FILL ME IN>>\n\\ No newline at end of file"
  },
  {
    "sha": "5539a9284246030b36d66a627e4e41c7eeeac65c",
    "filename": "_includes/tutorials/error-handling/kstreams/code/configuration/test.properties",
    "status": "added",
    "additions": 13,
    "deletions": 0,
    "changes": 13,
    "blob_url": "https://github.com/confluentinc/kafka-tutorials/blob/00a95730609a35e5ec37a40b25c73385a551e263/_includes/tutorials/error-handling/kstreams/code/configuration/test.properties",
    "raw_url": "https://github.com/confluentinc/kafka-tutorials/raw/00a95730609a35e5ec37a40b25c73385a551e263/_includes/tutorials/error-handling/kstreams/code/configuration/test.properties",
    "contents_url": "https://api.github.com/repos/confluentinc/kafka-tutorials/contents/_includes/tutorials/error-handling/kstreams/code/configuration/test.properties?ref=00a95730609a35e5ec37a40b25c73385a551e263",
    "patch": "@@ -0,0 +1,13 @@\n+application.id=error-handling-test\n+bootstrap.servers=localhost:29092\n+\n+input.topic.name=input-topic\n+input.topic.partitions=1\n+input.topic.replication.factor=1\n+\n+output.topic.name=output-topic\n+output.topic.partitions=1\n+output.topic.replication.factor=1\n+\n+max.failures=3\n+max.time.millis=120000"
  },
  {
    "sha": "be330af906e4f3eb0da30c444edbfe5d99d5c392",
    "filename": "_includes/tutorials/error-handling/kstreams/code/docker-compose.yml",
    "status": "added",
    "additions": 31,
    "deletions": 0,
    "changes": 31,
    "blob_url": "https://github.com/confluentinc/kafka-tutorials/blob/00a95730609a35e5ec37a40b25c73385a551e263/_includes/tutorials/error-handling/kstreams/code/docker-compose.yml",
    "raw_url": "https://github.com/confluentinc/kafka-tutorials/raw/00a95730609a35e5ec37a40b25c73385a551e263/_includes/tutorials/error-handling/kstreams/code/docker-compose.yml",
    "contents_url": "https://api.github.com/repos/confluentinc/kafka-tutorials/contents/_includes/tutorials/error-handling/kstreams/code/docker-compose.yml?ref=00a95730609a35e5ec37a40b25c73385a551e263",
    "patch": "@@ -0,0 +1,31 @@\n+---\n+version: '2'\n+\n+services:\n+  zookeeper:\n+    image: confluentinc/cp-zookeeper:6.1.0\n+    hostname: zookeeper\n+    container_name: zookeeper\n+    ports:\n+      - \"2181:2181\"\n+    environment:\n+      ZOOKEEPER_CLIENT_PORT: 2181\n+      ZOOKEEPER_TICK_TIME: 2000\n+\n+  broker:\n+    image: confluentinc/cp-kafka:6.1.0\n+    hostname: broker\n+    container_name: broker\n+    depends_on:\n+      - zookeeper\n+    ports:\n+      - \"29092:29092\"\n+    environment:\n+      KAFKA_BROKER_ID: 1\n+      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'\n+      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT\n+      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker:9092,PLAINTEXT_HOST://localhost:29092\n+      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1\n+      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0\n+\n+"
  },
  {
    "sha": "62d4c053550b91381bbd28b1afc82d634bf73a8a",
    "filename": "_includes/tutorials/error-handling/kstreams/code/gradle/wrapper/gradle-wrapper.jar",
    "status": "added",
    "additions": 0,
    "deletions": 0,
    "changes": 0,
    "blob_url": "https://github.com/confluentinc/kafka-tutorials/blob/00a95730609a35e5ec37a40b25c73385a551e263/_includes/tutorials/error-handling/kstreams/code/gradle/wrapper/gradle-wrapper.jar",
    "raw_url": "https://github.com/confluentinc/kafka-tutorials/raw/00a95730609a35e5ec37a40b25c73385a551e263/_includes/tutorials/error-handling/kstreams/code/gradle/wrapper/gradle-wrapper.jar",
    "contents_url": "https://api.github.com/repos/confluentinc/kafka-tutorials/contents/_includes/tutorials/error-handling/kstreams/code/gradle/wrapper/gradle-wrapper.jar?ref=00a95730609a35e5ec37a40b25c73385a551e263"
  },
  {
    "sha": "bb8b2fc26b2e572c79d7212a4f6f11057c6787f7",
    "filename": "_includes/tutorials/error-handling/kstreams/code/gradle/wrapper/gradle-wrapper.properties",
    "status": "added",
    "additions": 5,
    "deletions": 0,
    "changes": 5,
    "blob_url": "https://github.com/confluentinc/kafka-tutorials/blob/00a95730609a35e5ec37a40b25c73385a551e263/_includes/tutorials/error-handling/kstreams/code/gradle/wrapper/gradle-wrapper.properties",
    "raw_url": "https://github.com/confluentinc/kafka-tutorials/raw/00a95730609a35e5ec37a40b25c73385a551e263/_includes/tutorials/error-handling/kstreams/code/gradle/wrapper/gradle-wrapper.properties",
    "contents_url": "https://api.github.com/repos/confluentinc/kafka-tutorials/contents/_includes/tutorials/error-handling/kstreams/code/gradle/wrapper/gradle-wrapper.properties?ref=00a95730609a35e5ec37a40b25c73385a551e263",
    "patch": "@@ -0,0 +1,5 @@\n+distributionBase=GRADLE_USER_HOME\n+distributionPath=wrapper/dists\n+distributionUrl=https\\://services.gradle.org/distributions/gradle-6.5.1-bin.zip\n+zipStoreBase=GRADLE_USER_HOME\n+zipStorePath=wrapper/dists"
  },
  {
    "sha": "fbd7c515832dab7b01092e80db76e5e03fe32d29",
    "filename": "_includes/tutorials/error-handling/kstreams/code/gradlew",
    "status": "added",
    "additions": 185,
    "deletions": 0,
    "changes": 185,
    "blob_url": "https://github.com/confluentinc/kafka-tutorials/blob/00a95730609a35e5ec37a40b25c73385a551e263/_includes/tutorials/error-handling/kstreams/code/gradlew",
    "raw_url": "https://github.com/confluentinc/kafka-tutorials/raw/00a95730609a35e5ec37a40b25c73385a551e263/_includes/tutorials/error-handling/kstreams/code/gradlew",
    "contents_url": "https://api.github.com/repos/confluentinc/kafka-tutorials/contents/_includes/tutorials/error-handling/kstreams/code/gradlew?ref=00a95730609a35e5ec37a40b25c73385a551e263",
    "patch": "@@ -0,0 +1,185 @@\n+#!/usr/bin/env sh\n+\n+#\n+# Copyright 2015 the original author or authors.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#      https://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+##############################################################################\n+##\n+##  Gradle start up script for UN*X\n+##\n+##############################################################################\n+\n+# Attempt to set APP_HOME\n+# Resolve links: $0 may be a link\n+PRG=\"$0\"\n+# Need this for relative symlinks.\n+while [ -h \"$PRG\" ] ; do\n+    ls=`ls -ld \"$PRG\"`\n+    link=`expr \"$ls\" : '.*-> \\(.*\\)$'`\n+    if expr \"$link\" : '/.*' > /dev/null; then\n+        PRG=\"$link\"\n+    else\n+        PRG=`dirname \"$PRG\"`\"/$link\"\n+    fi\n+done\n+SAVED=\"`pwd`\"\n+cd \"`dirname \\\"$PRG\\\"`/\" >/dev/null\n+APP_HOME=\"`pwd -P`\"\n+cd \"$SAVED\" >/dev/null\n+\n+APP_NAME=\"Gradle\"\n+APP_BASE_NAME=`basename \"$0\"`\n+\n+# Add default JVM options here. You can also use JAVA_OPTS and GRADLE_OPTS to pass JVM options to this script.\n+DEFAULT_JVM_OPTS='\"-Xmx64m\" \"-Xms64m\"'\n+\n+# Use the maximum available, or set MAX_FD != -1 to use that value.\n+MAX_FD=\"maximum\"\n+\n+warn () {\n+    echo \"$*\"\n+}\n+\n+die () {\n+    echo\n+    echo \"$*\"\n+    echo\n+    exit 1\n+}\n+\n+# OS specific support (must be 'true' or 'false').\n+cygwin=false\n+msys=false\n+darwin=false\n+nonstop=false\n+case \"`uname`\" in\n+  CYGWIN* )\n+    cygwin=true\n+    ;;\n+  Darwin* )\n+    darwin=true\n+    ;;\n+  MINGW* )\n+    msys=true\n+    ;;\n+  NONSTOP* )\n+    nonstop=true\n+    ;;\n+esac\n+\n+CLASSPATH=$APP_HOME/gradle/wrapper/gradle-wrapper.jar\n+\n+\n+# Determine the Java command to use to start the JVM.\n+if [ -n \"$JAVA_HOME\" ] ; then\n+    if [ -x \"$JAVA_HOME/jre/sh/java\" ] ; then\n+        # IBM's JDK on AIX uses strange locations for the executables\n+        JAVACMD=\"$JAVA_HOME/jre/sh/java\"\n+    else\n+        JAVACMD=\"$JAVA_HOME/bin/java\"\n+    fi\n+    if [ ! -x \"$JAVACMD\" ] ; then\n+        die \"ERROR: JAVA_HOME is set to an invalid directory: $JAVA_HOME\n+\n+Please set the JAVA_HOME variable in your environment to match the\n+location of your Java installation.\"\n+    fi\n+else\n+    JAVACMD=\"java\"\n+    which java >/dev/null 2>&1 || die \"ERROR: JAVA_HOME is not set and no 'java' command could be found in your PATH.\n+\n+Please set the JAVA_HOME variable in your environment to match the\n+location of your Java installation.\"\n+fi\n+\n+# Increase the maximum file descriptors if we can.\n+if [ \"$cygwin\" = \"false\" -a \"$darwin\" = \"false\" -a \"$nonstop\" = \"false\" ] ; then\n+    MAX_FD_LIMIT=`ulimit -H -n`\n+    if [ $? -eq 0 ] ; then\n+        if [ \"$MAX_FD\" = \"maximum\" -o \"$MAX_FD\" = \"max\" ] ; then\n+            MAX_FD=\"$MAX_FD_LIMIT\"\n+        fi\n+        ulimit -n $MAX_FD\n+        if [ $? -ne 0 ] ; then\n+            warn \"Could not set maximum file descriptor limit: $MAX_FD\"\n+        fi\n+    else\n+        warn \"Could not query maximum file descriptor limit: $MAX_FD_LIMIT\"\n+    fi\n+fi\n+\n+# For Darwin, add options to specify how the application appears in the dock\n+if $darwin; then\n+    GRADLE_OPTS=\"$GRADLE_OPTS \\\"-Xdock:name=$APP_NAME\\\" \\\"-Xdock:icon=$APP_HOME/media/gradle.icns\\\"\"\n+fi\n+\n+# For Cygwin or MSYS, switch paths to Windows format before running java\n+if [ \"$cygwin\" = \"true\" -o \"$msys\" = \"true\" ] ; then\n+    APP_HOME=`cygpath --path --mixed \"$APP_HOME\"`\n+    CLASSPATH=`cygpath --path --mixed \"$CLASSPATH\"`\n+    \n+    JAVACMD=`cygpath --unix \"$JAVACMD\"`\n+\n+    # We build the pattern for arguments to be converted via cygpath\n+    ROOTDIRSRAW=`find -L / -maxdepth 1 -mindepth 1 -type d 2>/dev/null`\n+    SEP=\"\"\n+    for dir in $ROOTDIRSRAW ; do\n+        ROOTDIRS=\"$ROOTDIRS$SEP$dir\"\n+        SEP=\"|\"\n+    done\n+    OURCYGPATTERN=\"(^($ROOTDIRS))\"\n+    # Add a user-defined pattern to the cygpath arguments\n+    if [ \"$GRADLE_CYGPATTERN\" != \"\" ] ; then\n+        OURCYGPATTERN=\"$OURCYGPATTERN|($GRADLE_CYGPATTERN)\"\n+    fi\n+    # Now convert the arguments - kludge to limit ourselves to /bin/sh\n+    i=0\n+    for arg in \"$@\" ; do\n+        CHECK=`echo \"$arg\"|egrep -c \"$OURCYGPATTERN\" -`\n+        CHECK2=`echo \"$arg\"|egrep -c \"^-\"`                                 ### Determine if an option\n+\n+        if [ $CHECK -ne 0 ] && [ $CHECK2 -eq 0 ] ; then                    ### Added a condition\n+            eval `echo args$i`=`cygpath --path --ignore --mixed \"$arg\"`\n+        else\n+            eval `echo args$i`=\"\\\"$arg\\\"\"\n+        fi\n+        i=`expr $i + 1`\n+    done\n+    case $i in\n+        0) set -- ;;\n+        1) set -- \"$args0\" ;;\n+        2) set -- \"$args0\" \"$args1\" ;;\n+        3) set -- \"$args0\" \"$args1\" \"$args2\" ;;\n+        4) set -- \"$args0\" \"$args1\" \"$args2\" \"$args3\" ;;\n+        5) set -- \"$args0\" \"$args1\" \"$args2\" \"$args3\" \"$args4\" ;;\n+        6) set -- \"$args0\" \"$args1\" \"$args2\" \"$args3\" \"$args4\" \"$args5\" ;;\n+        7) set -- \"$args0\" \"$args1\" \"$args2\" \"$args3\" \"$args4\" \"$args5\" \"$args6\" ;;\n+        8) set -- \"$args0\" \"$args1\" \"$args2\" \"$args3\" \"$args4\" \"$args5\" \"$args6\" \"$args7\" ;;\n+        9) set -- \"$args0\" \"$args1\" \"$args2\" \"$args3\" \"$args4\" \"$args5\" \"$args6\" \"$args7\" \"$args8\" ;;\n+    esac\n+fi\n+\n+# Escape application args\n+save () {\n+    for i do printf %s\\\\n \"$i\" | sed \"s/'/'\\\\\\\\''/g;1s/^/'/;\\$s/\\$/' \\\\\\\\/\" ; done\n+    echo \" \"\n+}\n+APP_ARGS=`save \"$@\"`\n+\n+# Collect all arguments for the java command, following the shell quoting and substitution rules\n+eval set -- $DEFAULT_JVM_OPTS $JAVA_OPTS $GRADLE_OPTS \"\\\"-Dorg.gradle.appname=$APP_BASE_NAME\\\"\" -classpath \"\\\"$CLASSPATH\\\"\" org.gradle.wrapper.GradleWrapperMain \"$APP_ARGS\"\n+\n+exec \"$JAVACMD\" \"$@\""
  },
  {
    "sha": "5093609d512a96947851d39fa2dc05df2af2248e",
    "filename": "_includes/tutorials/error-handling/kstreams/code/gradlew.bat",
    "status": "added",
    "additions": 104,
    "deletions": 0,
    "changes": 104,
    "blob_url": "https://github.com/confluentinc/kafka-tutorials/blob/00a95730609a35e5ec37a40b25c73385a551e263/_includes/tutorials/error-handling/kstreams/code/gradlew.bat",
    "raw_url": "https://github.com/confluentinc/kafka-tutorials/raw/00a95730609a35e5ec37a40b25c73385a551e263/_includes/tutorials/error-handling/kstreams/code/gradlew.bat",
    "contents_url": "https://api.github.com/repos/confluentinc/kafka-tutorials/contents/_includes/tutorials/error-handling/kstreams/code/gradlew.bat?ref=00a95730609a35e5ec37a40b25c73385a551e263",
    "patch": "@@ -0,0 +1,104 @@\n+@rem\n+@rem Copyright 2015 the original author or authors.\n+@rem\n+@rem Licensed under the Apache License, Version 2.0 (the \"License\");\n+@rem you may not use this file except in compliance with the License.\n+@rem You may obtain a copy of the License at\n+@rem\n+@rem      https://www.apache.org/licenses/LICENSE-2.0\n+@rem\n+@rem Unless required by applicable law or agreed to in writing, software\n+@rem distributed under the License is distributed on an \"AS IS\" BASIS,\n+@rem WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+@rem See the License for the specific language governing permissions and\n+@rem limitations under the License.\n+@rem\n+\n+@if \"%DEBUG%\" == \"\" @echo off\n+@rem ##########################################################################\n+@rem\n+@rem  Gradle startup script for Windows\n+@rem\n+@rem ##########################################################################\n+\n+@rem Set local scope for the variables with windows NT shell\n+if \"%OS%\"==\"Windows_NT\" setlocal\n+\n+set DIRNAME=%~dp0\n+if \"%DIRNAME%\" == \"\" set DIRNAME=.\n+set APP_BASE_NAME=%~n0\n+set APP_HOME=%DIRNAME%\n+\n+@rem Resolve any \".\" and \"..\" in APP_HOME to make it shorter.\n+for %%i in (\"%APP_HOME%\") do set APP_HOME=%%~fi\n+\n+@rem Add default JVM options here. You can also use JAVA_OPTS and GRADLE_OPTS to pass JVM options to this script.\n+set DEFAULT_JVM_OPTS=\"-Xmx64m\" \"-Xms64m\"\n+\n+@rem Find java.exe\n+if defined JAVA_HOME goto findJavaFromJavaHome\n+\n+set JAVA_EXE=java.exe\n+%JAVA_EXE% -version >NUL 2>&1\n+if \"%ERRORLEVEL%\" == \"0\" goto init\n+\n+echo.\n+echo ERROR: JAVA_HOME is not set and no 'java' command could be found in your PATH.\n+echo.\n+echo Please set the JAVA_HOME variable in your environment to match the\n+echo location of your Java installation.\n+\n+goto fail\n+\n+:findJavaFromJavaHome\n+set JAVA_HOME=%JAVA_HOME:\"=%\n+set JAVA_EXE=%JAVA_HOME%/bin/java.exe\n+\n+if exist \"%JAVA_EXE%\" goto init\n+\n+echo.\n+echo ERROR: JAVA_HOME is set to an invalid directory: %JAVA_HOME%\n+echo.\n+echo Please set the JAVA_HOME variable in your environment to match the\n+echo location of your Java installation.\n+\n+goto fail\n+\n+:init\n+@rem Get command-line arguments, handling Windows variants\n+\n+if not \"%OS%\" == \"Windows_NT\" goto win9xME_args\n+\n+:win9xME_args\n+@rem Slurp the command line arguments.\n+set CMD_LINE_ARGS=\n+set _SKIP=2\n+\n+:win9xME_args_slurp\n+if \"x%~1\" == \"x\" goto execute\n+\n+set CMD_LINE_ARGS=%*\n+\n+:execute\n+@rem Setup the command line\n+\n+set CLASSPATH=%APP_HOME%\\gradle\\wrapper\\gradle-wrapper.jar\n+\n+\n+@rem Execute Gradle\n+\"%JAVA_EXE%\" %DEFAULT_JVM_OPTS% %JAVA_OPTS% %GRADLE_OPTS% \"-Dorg.gradle.appname=%APP_BASE_NAME%\" -classpath \"%CLASSPATH%\" org.gradle.wrapper.GradleWrapperMain %CMD_LINE_ARGS%\n+\n+:end\n+@rem End local scope for the variables with windows NT shell\n+if \"%ERRORLEVEL%\"==\"0\" goto mainEnd\n+\n+:fail\n+rem Set variable GRADLE_EXIT_CONSOLE if you need the _script_ return code instead of\n+rem the _cmd.exe /c_ return code!\n+if  not \"\" == \"%GRADLE_EXIT_CONSOLE%\" exit 1\n+exit /b 1\n+\n+:mainEnd\n+if \"%OS%\"==\"Windows_NT\" endlocal\n+\n+:omega"
  },
  {
    "sha": "735a58334f519bc19db561985df03dda5079d7f4",
    "filename": "_includes/tutorials/error-handling/kstreams/code/settings.gradle",
    "status": "added",
    "additions": 10,
    "deletions": 0,
    "changes": 10,
    "blob_url": "https://github.com/confluentinc/kafka-tutorials/blob/00a95730609a35e5ec37a40b25c73385a551e263/_includes/tutorials/error-handling/kstreams/code/settings.gradle",
    "raw_url": "https://github.com/confluentinc/kafka-tutorials/raw/00a95730609a35e5ec37a40b25c73385a551e263/_includes/tutorials/error-handling/kstreams/code/settings.gradle",
    "contents_url": "https://api.github.com/repos/confluentinc/kafka-tutorials/contents/_includes/tutorials/error-handling/kstreams/code/settings.gradle?ref=00a95730609a35e5ec37a40b25c73385a551e263",
    "patch": "@@ -0,0 +1,10 @@\n+/*\n+ * This file was generated by the Gradle 'init' task.\n+ *\n+ * The settings file is used to specify which projects to include in your build.\n+ *\n+ * Detailed information about configuring a multi-project build in Gradle can be found\n+ * in the user manual at https://docs.gradle.org/5.5.1/userguide/multi_project_builds.html\n+ */\n+\n+rootProject.name = 'error-handling'"
  },
  {
    "sha": "9535a717bba52decb65bbe52d728fe81e6075f66",
    "filename": "_includes/tutorials/error-handling/kstreams/code/src/main/avro/clicks.avsc",
    "status": "added",
    "additions": 10,
    "deletions": 0,
    "changes": 10,
    "blob_url": "https://github.com/confluentinc/kafka-tutorials/blob/00a95730609a35e5ec37a40b25c73385a551e263/_includes/tutorials/error-handling/kstreams/code/src/main/avro/clicks.avsc",
    "raw_url": "https://github.com/confluentinc/kafka-tutorials/raw/00a95730609a35e5ec37a40b25c73385a551e263/_includes/tutorials/error-handling/kstreams/code/src/main/avro/clicks.avsc",
    "contents_url": "https://api.github.com/repos/confluentinc/kafka-tutorials/contents/_includes/tutorials/error-handling/kstreams/code/src/main/avro/clicks.avsc?ref=00a95730609a35e5ec37a40b25c73385a551e263",
    "patch": "@@ -0,0 +1,10 @@\n+{\n+  \"namespace\": \"io.confluent.developer.avro\",\n+  \"type\": \"record\",\n+  \"name\": \"Clicks\",\n+  \"fields\": [\n+    { \"name\": \"ip\", \"type\": \"string\" },\n+    { \"name\": \"timestamp\", \"type\": \"long\" } ,\n+    { \"name\": \"url\", \"type\": \"string\" }\n+  ]\n+}"
  },
  {
    "sha": "2234f4e40eab2f2b42335c4ce83217fb9f6f36fc",
    "filename": "_includes/tutorials/error-handling/kstreams/code/src/main/java/io/confluent/developer/MaxFailuresUncaughtExceptionHandler.java",
    "status": "added",
    "additions": 45,
    "deletions": 0,
    "changes": 45,
    "blob_url": "https://github.com/confluentinc/kafka-tutorials/blob/00a95730609a35e5ec37a40b25c73385a551e263/_includes/tutorials/error-handling/kstreams/code/src/main/java/io/confluent/developer/MaxFailuresUncaughtExceptionHandler.java",
    "raw_url": "https://github.com/confluentinc/kafka-tutorials/raw/00a95730609a35e5ec37a40b25c73385a551e263/_includes/tutorials/error-handling/kstreams/code/src/main/java/io/confluent/developer/MaxFailuresUncaughtExceptionHandler.java",
    "contents_url": "https://api.github.com/repos/confluentinc/kafka-tutorials/contents/_includes/tutorials/error-handling/kstreams/code/src/main/java/io/confluent/developer/MaxFailuresUncaughtExceptionHandler.java?ref=00a95730609a35e5ec37a40b25c73385a551e263",
    "patch": "@@ -0,0 +1,45 @@\n+package io.confluent.developer;\n+\n+import org.apache.kafka.streams.errors.StreamsUncaughtExceptionHandler;\n+\n+import java.time.Instant;\n+import java.time.temporal.ChronoUnit;\n+\n+import static org.apache.kafka.streams.errors.StreamsUncaughtExceptionHandler.StreamThreadExceptionResponse.*;\n+\n+\n+public class MaxFailuresUncaughtExceptionHandler implements StreamsUncaughtExceptionHandler {\n+\n+    final int maxFailures;\n+    final long maxTimeIntervalMillis;\n+    private Instant previousErrorTime;\n+    private int currentFailureCount;\n+\n+\n+    public MaxFailuresUncaughtExceptionHandler(final int maxFailures, final long maxTimeIntervalMillis) {\n+        this.maxFailures = maxFailures;\n+        this.maxTimeIntervalMillis = maxTimeIntervalMillis;\n+    }\n+\n+    @Override\n+    public StreamThreadExceptionResponse handle(final Throwable throwable) {\n+        currentFailureCount++;\n+        Instant currentErrorTime = Instant.now();\n+\n+        if (previousErrorTime == null) {\n+            previousErrorTime = currentErrorTime;\n+        }\n+\n+        long millisBetweenFailure = ChronoUnit.MILLIS.between(previousErrorTime, currentErrorTime);\n+        \n+        if (currentFailureCount >= maxFailures) {\n+            if (millisBetweenFailure <= maxTimeIntervalMillis) {\n+                return SHUTDOWN_APPLICATION;\n+            } else {\n+                currentFailureCount = 0;\n+                previousErrorTime = null;\n+            }\n+        }\n+        return REPLACE_THREAD;\n+    }\n+}"
  },
  {
    "sha": "0a253aaafc71e981d57cb342f2b3f80cd7a482aa",
    "filename": "_includes/tutorials/error-handling/kstreams/code/src/main/java/io/confluent/developer/StreamsUncaughtExceptionHandling.java",
    "status": "added",
    "additions": 155,
    "deletions": 0,
    "changes": 155,
    "blob_url": "https://github.com/confluentinc/kafka-tutorials/blob/00a95730609a35e5ec37a40b25c73385a551e263/_includes/tutorials/error-handling/kstreams/code/src/main/java/io/confluent/developer/StreamsUncaughtExceptionHandling.java",
    "raw_url": "https://github.com/confluentinc/kafka-tutorials/raw/00a95730609a35e5ec37a40b25c73385a551e263/_includes/tutorials/error-handling/kstreams/code/src/main/java/io/confluent/developer/StreamsUncaughtExceptionHandling.java",
    "contents_url": "https://api.github.com/repos/confluentinc/kafka-tutorials/contents/_includes/tutorials/error-handling/kstreams/code/src/main/java/io/confluent/developer/StreamsUncaughtExceptionHandling.java?ref=00a95730609a35e5ec37a40b25c73385a551e263",
    "patch": "@@ -0,0 +1,155 @@\n+package io.confluent.developer;\n+\n+import org.apache.kafka.clients.admin.AdminClient;\n+import org.apache.kafka.clients.admin.NewTopic;\n+import org.apache.kafka.clients.producer.KafkaProducer;\n+import org.apache.kafka.clients.producer.Producer;\n+import org.apache.kafka.clients.producer.ProducerConfig;\n+import org.apache.kafka.clients.producer.ProducerRecord;\n+import org.apache.kafka.common.serialization.Serdes;\n+import org.apache.kafka.common.serialization.StringSerializer;\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.apache.kafka.streams.StreamsBuilder;\n+import org.apache.kafka.streams.StreamsConfig;\n+import org.apache.kafka.streams.Topology;\n+import org.apache.kafka.streams.kstream.Consumed;\n+import org.apache.kafka.streams.kstream.Produced;\n+\n+import java.io.FileInputStream;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Properties;\n+\n+public class StreamsUncaughtExceptionHandling {\n+\n+    int counter = 0;\n+\n+    public Properties buildStreamsProperties(Properties envProps) {\n+        Properties props = new Properties();\n+\n+        props.put(StreamsConfig.APPLICATION_ID_CONFIG, envProps.getProperty(\"application.id\"));\n+        props.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, envProps.getProperty(\"bootstrap.servers\"));\n+        props.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.String().getClass());\n+        props.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.String().getClass());\n+        return props;\n+    }\n+\n+    public Topology buildTopology(Properties envProps) {\n+        final StreamsBuilder builder = new StreamsBuilder();\n+        final String inputTopic = envProps.getProperty(\"input.topic.name\");\n+        final String outputTopic = envProps.getProperty(\"output.topic.name\");\n+\n+        builder.stream(inputTopic, Consumed.with(Serdes.String(), Serdes.String()))\n+                .mapValues(value -> {\n+                    counter++;\n+                    if (counter == 2 || counter == 8 || counter == 15) {\n+                        throw new IllegalStateException(\"It works on my box!!!\");\n+                    }\n+                    return value.toUpperCase();\n+                })\n+                .to(outputTopic, Produced.with(Serdes.String(), Serdes.String()));\n+        \n+        return builder.build();\n+    }\n+\n+    public void createTopics(Properties envProps) {\n+        Map<String, Object> config = new HashMap<>();\n+        config.put(\"bootstrap.servers\", envProps.getProperty(\"bootstrap.servers\"));\n+        try (AdminClient client = AdminClient.create(config)) {\n+            List<NewTopic> topicList = new ArrayList<>();\n+\n+            NewTopic sessionInput = new NewTopic(envProps.getProperty(\"input.topic.name\"),\n+                    Integer.parseInt(envProps.getProperty(\"input.topic.partitions\")),\n+                    Short.parseShort(envProps.getProperty(\"input.topic.replication.factor\")));\n+            topicList.add(sessionInput);\n+\n+            NewTopic counts = new NewTopic(envProps.getProperty(\"output.topic.name\"),\n+                    Integer.parseInt(envProps.getProperty(\"output.topic.partitions\")),\n+                    Short.parseShort(envProps.getProperty(\"output.topic.replication.factor\")));\n+\n+            topicList.add(counts);\n+            client.createTopics(topicList);\n+        }\n+    }\n+\n+    public Properties loadEnvProperties(String fileName) throws IOException {\n+        Properties envProps = new Properties();\n+        FileInputStream input = new FileInputStream(fileName);\n+        envProps.load(input);\n+        input.close();\n+\n+        return envProps;\n+    }\n+\n+    public static void main(String[] args) throws Exception {\n+\n+        if (args.length < 1) {\n+            throw new IllegalArgumentException(\"This program takes one argument: the path to an environment configuration file.\");\n+        }\n+\n+        StreamsUncaughtExceptionHandling tw = new StreamsUncaughtExceptionHandling();\n+        Properties envProps = tw.loadEnvProperties(args[0]);\n+        Properties streamProps = tw.buildStreamsProperties(envProps);\n+\n+        // Change this to StreamsConfig.EXACTLY_ONCE to eliminate duplicates\n+        streamProps.put(StreamsConfig.PROCESSING_GUARANTEE_CONFIG, StreamsConfig.AT_LEAST_ONCE);\n+        Topology topology = tw.buildTopology(envProps);\n+\n+        tw.createTopics(envProps);\n+        TutorialDataGenerator dataGenerator = new TutorialDataGenerator(envProps);\n+        dataGenerator.generate();\n+\n+        final int maxFailures = Integer.parseInt(envProps.getProperty(\"max.failures\"));\n+        final long maxTimeInterval = Long.parseLong(envProps.getProperty(\"max.time.millis\"));\n+        final KafkaStreams streams = new KafkaStreams(topology, streamProps);\n+        final MaxFailuresUncaughtExceptionHandler exceptionHandler = new MaxFailuresUncaughtExceptionHandler(maxFailures, maxTimeInterval);\n+        streams.setUncaughtExceptionHandler(exceptionHandler);\n+\n+        // Attach shutdown handler to catch Control-C.\n+        Runtime.getRuntime().addShutdownHook(new Thread(\"streams-shutdown-hook\") {\n+            @Override\n+            public void run() {\n+                streams.close();\n+            }\n+        });\n+\n+        try {\n+            streams.cleanUp();\n+            streams.start();\n+        } catch (Throwable e) {\n+            System.exit(1);\n+        }\n+    }\n+\n+    static class TutorialDataGenerator {\n+        final Properties properties;\n+\n+\n+        public TutorialDataGenerator(final Properties properties) {\n+            this.properties = properties;\n+        }\n+\n+        public void generate() {\n+            properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class);\n+            properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);\n+\n+            try (Producer<String, String> producer = new KafkaProducer<>(properties)) {\n+                String topic = properties.getProperty(\"input.topic.name\");\n+                List<String> messages = Arrays.asList(\"All\", \"streams\", \"lead\", \"to\", \"Confluent\", \"Go\", \"to\", \"Kafka\", \"Summit\");\n+\n+\n+                messages.forEach(message -> producer.send(new ProducerRecord<>(topic, message), (metadata, exception) -> {\n+                        if (exception != null) {\n+                            exception.printStackTrace(System.out);\n+                        } else {\n+                            System.out.printf(\"Produced record at offset %d to topic %s \\n\", metadata.offset(), metadata.topic());\n+                        }\n+                }));\n+            }\n+        }\n+    }\n+}"
  },
  {
    "sha": "787e21cb49075db9b48d89ea544375773fd3e38d",
    "filename": "_includes/tutorials/error-handling/kstreams/code/src/test/java/io/confluent/developer/MaxFailuresUncaughtExceptionHandlerTest.java",
    "status": "added",
    "additions": 35,
    "deletions": 0,
    "changes": 35,
    "blob_url": "https://github.com/confluentinc/kafka-tutorials/blob/00a95730609a35e5ec37a40b25c73385a551e263/_includes/tutorials/error-handling/kstreams/code/src/test/java/io/confluent/developer/MaxFailuresUncaughtExceptionHandlerTest.java",
    "raw_url": "https://github.com/confluentinc/kafka-tutorials/raw/00a95730609a35e5ec37a40b25c73385a551e263/_includes/tutorials/error-handling/kstreams/code/src/test/java/io/confluent/developer/MaxFailuresUncaughtExceptionHandlerTest.java",
    "contents_url": "https://api.github.com/repos/confluentinc/kafka-tutorials/contents/_includes/tutorials/error-handling/kstreams/code/src/test/java/io/confluent/developer/MaxFailuresUncaughtExceptionHandlerTest.java?ref=00a95730609a35e5ec37a40b25c73385a551e263",
    "patch": "@@ -0,0 +1,35 @@\n+package io.confluent.developer;\n+\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import static org.junit.Assert.assertEquals;\n+import static org.apache.kafka.streams.errors.StreamsUncaughtExceptionHandler.StreamThreadExceptionResponse.*;\n+\n+public class MaxFailuresUncaughtExceptionHandlerTest {\n+\n+    private MaxFailuresUncaughtExceptionHandler exceptionHandler;\n+    private final IllegalStateException worksOnMyBoxException = new IllegalStateException(\"Strange, It worked on my box\");\n+\n+    @Before\n+    public void setUp() {\n+        long maxTimeMillis = 100;\n+        int maxFailures = 2;\n+        exceptionHandler = new MaxFailuresUncaughtExceptionHandler(maxFailures, maxTimeMillis);\n+    }\n+\n+    @Test\n+    public void shouldReplaceThreadWhenErrorsNotWithinMaxTime() throws Exception {\n+        for (int i = 0; i < 10; i++) {\n+            assertEquals(REPLACE_THREAD, exceptionHandler.handle(worksOnMyBoxException));\n+            Thread.sleep(200);\n+        }\n+    }\n+\n+    @Test\n+    public void shouldShutdownApplicationWhenErrorsOccurWithinMaxTime() throws Exception {\n+        assertEquals(REPLACE_THREAD, exceptionHandler.handle(worksOnMyBoxException));\n+        Thread.sleep(50);\n+        assertEquals(SHUTDOWN_APPLICATION, exceptionHandler.handle(worksOnMyBoxException));\n+    }\n+}\n\\ No newline at end of file"
  },
  {
    "sha": "56e69d29fe9e1b17dad38e93e2d58f219db117ed",
    "filename": "_includes/tutorials/error-handling/kstreams/code/src/test/java/io/confluent/developer/StreamsUncaughtExceptionHandlingTest.java",
    "status": "added",
    "additions": 74,
    "deletions": 0,
    "changes": 74,
    "blob_url": "https://github.com/confluentinc/kafka-tutorials/blob/00a95730609a35e5ec37a40b25c73385a551e263/_includes/tutorials/error-handling/kstreams/code/src/test/java/io/confluent/developer/StreamsUncaughtExceptionHandlingTest.java",
    "raw_url": "https://github.com/confluentinc/kafka-tutorials/raw/00a95730609a35e5ec37a40b25c73385a551e263/_includes/tutorials/error-handling/kstreams/code/src/test/java/io/confluent/developer/StreamsUncaughtExceptionHandlingTest.java",
    "contents_url": "https://api.github.com/repos/confluentinc/kafka-tutorials/contents/_includes/tutorials/error-handling/kstreams/code/src/test/java/io/confluent/developer/StreamsUncaughtExceptionHandlingTest.java?ref=00a95730609a35e5ec37a40b25c73385a551e263",
    "patch": "@@ -0,0 +1,74 @@\n+package io.confluent.developer;\n+\n+\n+import org.apache.kafka.common.serialization.Deserializer;\n+import org.apache.kafka.common.serialization.Serdes;\n+import org.apache.kafka.common.serialization.Serializer;\n+import org.apache.kafka.streams.TestInputTopic;\n+import org.apache.kafka.streams.TestOutputTopic;\n+import org.apache.kafka.streams.Topology;\n+import org.apache.kafka.streams.TopologyTestDriver;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Properties;\n+import java.util.stream.Collectors;\n+\n+import static junit.framework.TestCase.assertEquals;\n+import static org.junit.Assert.assertThrows;\n+\n+\n+public class StreamsUncaughtExceptionHandlingTest {\n+\n+    private final static String TEST_CONFIG_FILE = \"configuration/test.properties\";\n+\n+    private TestInputTopic<String, String> inputTopic;\n+    private TestOutputTopic<String, String> outputTopic;\n+    private TopologyTestDriver testDriver;\n+\n+\n+    @Before\n+    public void setUp() throws IOException {\n+        final StreamsUncaughtExceptionHandling instance = new StreamsUncaughtExceptionHandling();\n+        final Properties envProps = instance.loadEnvProperties(TEST_CONFIG_FILE);\n+\n+        final Properties streamProps = instance.buildStreamsProperties(envProps);\n+        final String sessionDataInputTopic = envProps.getProperty(\"input.topic.name\");\n+        final String outputTopicName = envProps.getProperty(\"output.topic.name\");\n+\n+        final Topology topology = instance.buildTopology(envProps);\n+        testDriver = new TopologyTestDriver(topology, streamProps);\n+        final Serializer<String> keySerializer = Serdes.String().serializer();\n+        final Serializer<String> exampleSerializer = Serdes.String().serializer();\n+        final Deserializer<String> valueDeserializer = Serdes.String().deserializer();\n+        final Deserializer<String> keyDeserializer = Serdes.String().deserializer();\n+\n+        inputTopic = testDriver.createInputTopic(sessionDataInputTopic, keySerializer, exampleSerializer);\n+        outputTopic = testDriver.createOutputTopic(outputTopicName, keyDeserializer, valueDeserializer);\n+    }\n+\n+    @After\n+    public void tearDown() {\n+        testDriver.close();\n+    }\n+\n+    @Test\n+    public void shouldThrowException() {\n+        assertThrows(org.apache.kafka.streams.errors.StreamsException.class, () -> inputTopic.pipeValueList(Arrays.asList(\"foo\", \"bar\")));\n+    }\n+\n+    @Test\n+    public void shouldProcessValues() {\n+        List<String> validMessages =  Collections.singletonList(\"foo\");\n+        List<String> expectedMessages = validMessages.stream().map(String::toUpperCase).collect(Collectors.toList());\n+        inputTopic.pipeValueList(validMessages);\n+        List<String> actualResults = outputTopic.readValuesToList();\n+        assertEquals(expectedMessages, actualResults);\n+    }\n+\n+}"
  },
  {
    "sha": "d5c3244909e3f72d0615e2e7814d005d4f41d094",
    "filename": "_includes/tutorials/error-handling/kstreams/code/temp_local_28_repo/kafka-clients-2.8.0-SNAPSHOT.jar",
    "status": "added",
    "additions": 0,
    "deletions": 0,
    "changes": 0,
    "blob_url": "https://github.com/confluentinc/kafka-tutorials/blob/00a95730609a35e5ec37a40b25c73385a551e263/_includes/tutorials/error-handling/kstreams/code/temp_local_28_repo/kafka-clients-2.8.0-SNAPSHOT.jar",
    "raw_url": "https://github.com/confluentinc/kafka-tutorials/raw/00a95730609a35e5ec37a40b25c73385a551e263/_includes/tutorials/error-handling/kstreams/code/temp_local_28_repo/kafka-clients-2.8.0-SNAPSHOT.jar",
    "contents_url": "https://api.github.com/repos/confluentinc/kafka-tutorials/contents/_includes/tutorials/error-handling/kstreams/code/temp_local_28_repo/kafka-clients-2.8.0-SNAPSHOT.jar?ref=00a95730609a35e5ec37a40b25c73385a551e263"
  },
  {
    "sha": "3bc2a5dd526aeb9c10a58cbf29e9f6433e2e1995",
    "filename": "_includes/tutorials/error-handling/kstreams/code/temp_local_28_repo/kafka-streams-2.8.0-SNAPSHOT.jar",
    "status": "added",
    "additions": 0,
    "deletions": 0,
    "changes": 0,
    "blob_url": "https://github.com/confluentinc/kafka-tutorials/blob/00a95730609a35e5ec37a40b25c73385a551e263/_includes/tutorials/error-handling/kstreams/code/temp_local_28_repo/kafka-streams-2.8.0-SNAPSHOT.jar",
    "raw_url": "https://github.com/confluentinc/kafka-tutorials/raw/00a95730609a35e5ec37a40b25c73385a551e263/_includes/tutorials/error-handling/kstreams/code/temp_local_28_repo/kafka-streams-2.8.0-SNAPSHOT.jar",
    "contents_url": "https://api.github.com/repos/confluentinc/kafka-tutorials/contents/_includes/tutorials/error-handling/kstreams/code/temp_local_28_repo/kafka-streams-2.8.0-SNAPSHOT.jar?ref=00a95730609a35e5ec37a40b25c73385a551e263"
  },
  {
    "sha": "6092c337c0d8f6cd1ed6b0c32974cd7312733cdf",
    "filename": "_includes/tutorials/error-handling/kstreams/code/temp_local_28_repo/kafka-streams-test-utils-2.8.0-SNAPSHOT.jar",
    "status": "added",
    "additions": 0,
    "deletions": 0,
    "changes": 0,
    "blob_url": "https://github.com/confluentinc/kafka-tutorials/blob/00a95730609a35e5ec37a40b25c73385a551e263/_includes/tutorials/error-handling/kstreams/code/temp_local_28_repo/kafka-streams-test-utils-2.8.0-SNAPSHOT.jar",
    "raw_url": "https://github.com/confluentinc/kafka-tutorials/raw/00a95730609a35e5ec37a40b25c73385a551e263/_includes/tutorials/error-handling/kstreams/code/temp_local_28_repo/kafka-streams-test-utils-2.8.0-SNAPSHOT.jar",
    "contents_url": "https://api.github.com/repos/confluentinc/kafka-tutorials/contents/_includes/tutorials/error-handling/kstreams/code/temp_local_28_repo/kafka-streams-test-utils-2.8.0-SNAPSHOT.jar?ref=00a95730609a35e5ec37a40b25c73385a551e263"
  },
  {
    "sha": "81875953f1362fc1a73e0bbd03d4d9cecfb53b28",
    "filename": "_includes/tutorials/error-handling/kstreams/code/tutorial-steps/dev/build-project.sh",
    "status": "added",
    "additions": 1,
    "deletions": 0,
    "changes": 1,
    "blob_url": "https://github.com/confluentinc/kafka-tutorials/blob/00a95730609a35e5ec37a40b25c73385a551e263/_includes/tutorials/error-handling/kstreams/code/tutorial-steps/dev/build-project.sh",
    "raw_url": "https://github.com/confluentinc/kafka-tutorials/raw/00a95730609a35e5ec37a40b25c73385a551e263/_includes/tutorials/error-handling/kstreams/code/tutorial-steps/dev/build-project.sh",
    "contents_url": "https://api.github.com/repos/confluentinc/kafka-tutorials/contents/_includes/tutorials/error-handling/kstreams/code/tutorial-steps/dev/build-project.sh?ref=00a95730609a35e5ec37a40b25c73385a551e263",
    "patch": "@@ -0,0 +1 @@\n+./gradlew build"
  },
  {
    "sha": "12ffd144a09fde76bfcbdea307c682a169d9c13a",
    "filename": "_includes/tutorials/error-handling/kstreams/code/tutorial-steps/dev/build-uberjar.sh",
    "status": "added",
    "additions": 1,
    "deletions": 0,
    "changes": 1,
    "blob_url": "https://github.com/confluentinc/kafka-tutorials/blob/00a95730609a35e5ec37a40b25c73385a551e263/_includes/tutorials/error-handling/kstreams/code/tutorial-steps/dev/build-uberjar.sh",
    "raw_url": "https://github.com/confluentinc/kafka-tutorials/raw/00a95730609a35e5ec37a40b25c73385a551e263/_includes/tutorials/error-handling/kstreams/code/tutorial-steps/dev/build-uberjar.sh",
    "contents_url": "https://api.github.com/repos/confluentinc/kafka-tutorials/contents/_includes/tutorials/error-handling/kstreams/code/tutorial-steps/dev/build-uberjar.sh?ref=00a95730609a35e5ec37a40b25c73385a551e263",
    "patch": "@@ -0,0 +1 @@\n+./gradlew shadowJar"
  },
  {
    "sha": "685cc772e18df2d73b15e1648a40b6c99480c696",
    "filename": "_includes/tutorials/error-handling/kstreams/code/tutorial-steps/dev/clean-up.sh",
    "status": "added",
    "additions": 1,
    "deletions": 0,
    "changes": 1,
    "blob_url": "https://github.com/confluentinc/kafka-tutorials/blob/00a95730609a35e5ec37a40b25c73385a551e263/_includes/tutorials/error-handling/kstreams/code/tutorial-steps/dev/clean-up.sh",
    "raw_url": "https://github.com/confluentinc/kafka-tutorials/raw/00a95730609a35e5ec37a40b25c73385a551e263/_includes/tutorials/error-handling/kstreams/code/tutorial-steps/dev/clean-up.sh",
    "contents_url": "https://api.github.com/repos/confluentinc/kafka-tutorials/contents/_includes/tutorials/error-handling/kstreams/code/tutorial-steps/dev/clean-up.sh?ref=00a95730609a35e5ec37a40b25c73385a551e263",
    "patch": "@@ -0,0 +1 @@\n+docker-compose down"
  },
  {
    "sha": "51f6c91e9e19aa65e7c15c4d5d53ab164b131670",
    "filename": "_includes/tutorials/error-handling/kstreams/code/tutorial-steps/dev/console-consumer.sh",
    "status": "added",
    "additions": 6,
    "deletions": 0,
    "changes": 6,
    "blob_url": "https://github.com/confluentinc/kafka-tutorials/blob/00a95730609a35e5ec37a40b25c73385a551e263/_includes/tutorials/error-handling/kstreams/code/tutorial-steps/dev/console-consumer.sh",
    "raw_url": "https://github.com/confluentinc/kafka-tutorials/raw/00a95730609a35e5ec37a40b25c73385a551e263/_includes/tutorials/error-handling/kstreams/code/tutorial-steps/dev/console-consumer.sh",
    "contents_url": "https://api.github.com/repos/confluentinc/kafka-tutorials/contents/_includes/tutorials/error-handling/kstreams/code/tutorial-steps/dev/console-consumer.sh?ref=00a95730609a35e5ec37a40b25c73385a551e263",
    "patch": "@@ -0,0 +1,6 @@\n+docker-compose exec broker kafka-console-consumer \\\n+ --bootstrap-server broker:9092 \\\n+ --topic output-topic \\\n+ --from-beginning \\\n+ --max-messages 12\n+"
  },
  {
    "sha": "a8341a634f73647fc73b65f1afc3bb47d31e83de",
    "filename": "_includes/tutorials/error-handling/kstreams/code/tutorial-steps/dev/docker-compose-up.sh",
    "status": "added",
    "additions": 1,
    "deletions": 0,
    "changes": 1,
    "blob_url": "https://github.com/confluentinc/kafka-tutorials/blob/00a95730609a35e5ec37a40b25c73385a551e263/_includes/tutorials/error-handling/kstreams/code/tutorial-steps/dev/docker-compose-up.sh",
    "raw_url": "https://github.com/confluentinc/kafka-tutorials/raw/00a95730609a35e5ec37a40b25c73385a551e263/_includes/tutorials/error-handling/kstreams/code/tutorial-steps/dev/docker-compose-up.sh",
    "contents_url": "https://api.github.com/repos/confluentinc/kafka-tutorials/contents/_includes/tutorials/error-handling/kstreams/code/tutorial-steps/dev/docker-compose-up.sh?ref=00a95730609a35e5ec37a40b25c73385a551e263",
    "patch": "@@ -0,0 +1 @@\n+docker-compose up -d"
  },
  {
    "sha": "401c48f26ab00bed49c346e9eb25deca3fb190d8",
    "filename": "_includes/tutorials/error-handling/kstreams/code/tutorial-steps/dev/expected-output.txt",
    "status": "added",
    "additions": 13,
    "deletions": 0,
    "changes": 13,
    "blob_url": "https://github.com/confluentinc/kafka-tutorials/blob/00a95730609a35e5ec37a40b25c73385a551e263/_includes/tutorials/error-handling/kstreams/code/tutorial-steps/dev/expected-output.txt",
    "raw_url": "https://github.com/confluentinc/kafka-tutorials/raw/00a95730609a35e5ec37a40b25c73385a551e263/_includes/tutorials/error-handling/kstreams/code/tutorial-steps/dev/expected-output.txt",
    "contents_url": "https://api.github.com/repos/confluentinc/kafka-tutorials/contents/_includes/tutorials/error-handling/kstreams/code/tutorial-steps/dev/expected-output.txt?ref=00a95730609a35e5ec37a40b25c73385a551e263",
    "patch": "@@ -0,0 +1,13 @@\n+ALL\n+ALL\n+STREAMS\n+LEAD\n+TO\n+CONFLUENT\n+ALL\n+STREAMS\n+LEAD\n+TO\n+CONFLUENT\n+GO\n+Processed a total of 12 messages"
  },
  {
    "sha": "28d02d7b9c506f57783e0f17dd6acb44ed79d156",
    "filename": "_includes/tutorials/error-handling/kstreams/code/tutorial-steps/dev/gradle-wrapper.sh",
    "status": "added",
    "additions": 1,
    "deletions": 0,
    "changes": 1,
    "blob_url": "https://github.com/confluentinc/kafka-tutorials/blob/00a95730609a35e5ec37a40b25c73385a551e263/_includes/tutorials/error-handling/kstreams/code/tutorial-steps/dev/gradle-wrapper.sh",
    "raw_url": "https://github.com/confluentinc/kafka-tutorials/raw/00a95730609a35e5ec37a40b25c73385a551e263/_includes/tutorials/error-handling/kstreams/code/tutorial-steps/dev/gradle-wrapper.sh",
    "contents_url": "https://api.github.com/repos/confluentinc/kafka-tutorials/contents/_includes/tutorials/error-handling/kstreams/code/tutorial-steps/dev/gradle-wrapper.sh?ref=00a95730609a35e5ec37a40b25c73385a551e263",
    "patch": "@@ -0,0 +1 @@\n+gradle wrapper"
  }
]
