[
  {
    "sha": "a80ab1107a5897ecb98b9532805c6a611689f234",
    "filename": "README.md",
    "status": "modified",
    "additions": 585,
    "deletions": 4,
    "changes": 589,
    "blob_url": "https://github.com/doc-ai/react-native-tensorio-tensorflow/blob/87b362141ceed0611b120243452b3d37b30ea246/README.md",
    "raw_url": "https://github.com/doc-ai/react-native-tensorio-tensorflow/raw/87b362141ceed0611b120243452b3d37b30ea246/README.md",
    "contents_url": "https://api.github.com/repos/doc-ai/react-native-tensorio-tensorflow/contents/README.md?ref=87b362141ceed0611b120243452b3d37b30ea246",
    "patch": "@@ -8,14 +8,112 @@ Tensor/IO for React Native with the TensorFlow backend\n npm install react-native-tensorio-tensorflow\n ```\n \n+### iOS\n+\n+Run pod install in your application's root directory to install the Tensor/IO and TF Lite dependencies.\n+\n+### Android\n+\n+Sync the project's gradle files to install the Tensor/IO and TF Lite dependencies.\n+\n+You may need to increase the amount of heap memory available to the JVM. If you get an error when you build your application with something about the \"Java heap space\" add the following to your *gradle.properties*:\n+\n+```gradle\n+org.gradle.jvmargs=-Xms512M -Xmx4g -XX:MaxPermSize=1024m -XX:MaxMetaspaceSize=1g -Dkotlin.daemon.jvm.options=\"-Xmx1g\"\n+```\n+\n ## Usage\n \n+### Inference\n+\n+Inference with a model is straightforward. You will load the model, run it on some data with special consideration for image data discussed below, handle errors, and read the outputs. When you are finished unload the model.\n+\n ```js\n-import TensorioTensorflow from \"react-native-tensorio-tensorflow\";\n+import TensorioTensorflow from 'react-native-tensorio-tensorflow';\n+\n+// If you're using images acquire the image object constants you need\n+const { imageKeyFormat, imageKeyData, imageTypeAsset } = TensorioTensorflow.getConstants();\n+\n+// In our example we have an image bundled as an image asset on ios and an asset on android\n+const imageAsset = Platform.OS === 'ios' ? 'cat' : 'cat.jpg';\n+\n+// To use the model load it and give it a name. This model is bundled in the application.\n+TensorioTensorflow.load('cats-vs-dogs-predict.tiobundle', 'classifier');\n+    \n+// Call run using the name you gave the model and its expected inputs.\n+// All model functions return promises, so you can use `then` on the result and `catch` for errors\n+    \n+TensorioTensorflow\n+  .run('classifier', {\n+    'image': {\n+      [imageKeyFormat]: imageTypeAsset,\n+      [imageKeyData]: imageAsset\n+    }\n+  })\n+  .then(output => {\n+    // Do something with the output\n+  })\n+  .catch(error => {\n+    // Handle any errors\n+  });\n+\n+// When you're done with the model always unload it to free up the underlying resources\n+TensorioTensorflow.unload('classifier');\n+```\n+\n+### Training\n+\n+Training works like inference except that you must pass labeled training data in batches to the train function. Call train, read the results, handle errors, and unload the model when you are done.\n+\n+```js\n+import TensorioTensorflow from 'react-native-tensorio-tensorflow';\n+\n+// If you're using images acquire the image object constants you need\n+const { imageKeyFormat, imageKeyData, imageTypeAsset } = TensorioTensorflow.getConstants();\n+\n+// In our example we have an image bundled as an image asset on ios and an asset on android\n+const catImage = Platform.OS === 'ios' ? 'cat' : 'cat.jpg';\n+const dogImage = Platform.OS === 'ios' ? 'dog' : 'dog.jpg';\n+const catLabel = 0;\n+const dogLabel = 1;\n+\n+// Prepare a batch of training data. This is just an array of training objects.\n+// Keep batch sizes small due to on-device memory constraints\n+\n+const batch = [\n+  {\n+    'image': {\n+      [imageKeyFormat]: imageTypeAsset,\n+      [imageKeyData]: catImage\n+     },\n+    'labels': catLabel\n+  },\n+  {\n+    'image': {\n+      [imageKeyFormat]: imageTypeAsset,\n+      [imageKeyData]: dogImage\n+    },\n+    'labels': dogLabel\n+  }\n+]\n \n-// ...\n+// Load the trainable model, giving it a name\n+TensorioTensorflow.load('cats-vs-dogs-train.tiobundle', 'trainable');\n \n-const result = await TensorioTensorflow.multiply(3, 7);\n+// Call train using the name you gave the model and its expected inputs.\n+// All model functions return promises, so you can use `then` on the result and `catch` for errors\n+\n+TensorioTensorflow\n+  .train('trainable', batch)\n+  .then(output => {\n+    // Do something with the output\n+  })\n+  .catch(error => {\n+    // Handle any errors\n+  });\n+\n+// When you're done with the model always unload it to free up the underlying resources\n+TensorioTensorflow.unload('trainable');\n ```\n \n ## Contributing\n@@ -24,4 +122,487 @@ See the [contributing guide](CONTRIBUTING.md) to learn how to contribute to the\n \n ## License\n \n-MIT\n+Apache 2\n+\n+## Additional Documentation\n+\n+### About Tensor/IO\n+\n+Tensor/IO uses model bundles to wrap an underlying model and a description of its inputs and outputs along with any assets the model requires, such as text labels for image classification outputs. They are simply folders with the *.tiobundle* extension ([learn more](https://github.com/doc-ai/tensorio)). You will need to add these bundles to your React Native application in order to perform inference with the underlying models.\n+\n+Every Tensor/IO bundle includes a description of the underlying model. Model inputs and outputs are named and indicate what kind of data they expect or produce. You must know these names in order to pass data to the model and extract results from it. From the perspective of a React Native application, you will pass an object to the model whose name-value pairs match the model's input names, and you will receive an object back from the model whose name-value pairs match the model's output names.\n+\n+All this information appears in a bundle's *model.json* file. Let's have a look at the json description of a simple test model that takes a single input and produces a single output. Notice specifically the *inputs* and *outputs* fields:\n+\n+```json\n+{\n+  \"name\": \"1 in 1 out numeric test\",\n+  \"details\": \"Simple model with a single valued input and single valued output\",\n+  \"id\": \"1_in_1_out_number_test\",\n+  \"version\": \"1\",\n+  \"author\": \"doc.ai\",\n+  \"license\": \"\",\n+  \"model\": {\n+    \"file\": \"predict\",\n+    \"quantized\": false,\n+    \"backend\": \"tensorflow\",\n+    \"modes\": [\"predict\"]\n+  },\n+  \"inputs\": [\n+    {\n+      \"name\": \"input\",\n+      \"type\": \"array\",\n+      \"shape\": [1]\n+    }\n+  ],\n+  \"outputs\": [\n+    {\n+      \"name\": \"output\",\n+      \"type\": \"array\",\n+      \"shape\": [1]\n+    }\n+  ]\n+}\n+```\n+\n+The *inputs* and *outputs* fields tell us that this model takes a single input named *\"x\"* whose value is a single number and produces a single output named *\"y\"* whose value is also a single number. We know that the values are a single number from the shape. Let's see how to use a model like this in your own application.\n+\n+### Basic Usage\n+\n+Add a Tensor/IO bundle to your application in Xcode. Simply drag the bundle into the project under the project's primary folder (it will be the folder with the same name as your project). Make sure to check *Copy items if needed*, select *Create folder references*, and that your build target is selected.\n+\n+Then in javascript, import `TensorioTensorflow  from 'react-native-tensorio-tensorflow`. Load the model by providing its name or a fully qualified path, run inference with it, and unload the model when you are done to free the underlying resources.\n+\n+Again, imagine we had a model that takes a single input named *\"x\"* with a single value and produces a singe output named *\"y\"* with a single value:\n+\n+```json\n+\"inputs\": [\n+  {\n+    \"name\": \"x\",\n+    \"type\": \"array\",\n+    \"shape\": [1],\n+  }\n+],\n+\"outputs\": [\n+  {\n+    \"name\": \"y\",\n+    \"type\": \"array\",\n+    \"shape\": [1],\n+  }\n+]\n+```\n+\n+We would use this model as follows. Notice that we pass an object to the run function whose name-value pairs match those of the model's inputs and we extract name-value pairs from the results that match those of the model's outputs:\n+\n+```javascript\n+import TensorioTensorflow from \"react-native-tensorio-tensorflow\";\n+\n+TensorioTensorflow.load('model.tiobundle', 'model');\n+\n+TensorioTensorflow\n+  .run('model', {\n+    'x': [42]\n+  })\n+  .then(output => {\n+    const y = output['y']\n+    console.log(y);\n+  })\n+  .catch(error => {\n+    // Handle error\n+  });\n+\n+TensorioTensorflow.unload('model');\n+```\n+\n+### Image Models\n+\n+React Native represents image data as a base64 encoded string. When you pass that data to a model that has image inputs you must include some additional metadata that describes the encoded image. For example, is it JPEG or PNG data, raw pixel buffer data, or a path to an image on the filesystem?\n+\n+#### About Image Data\n+\n+Models that take image inputs must receive those inputs in a pixel buffer format. A pixel buffer is an unrolled vector of bytes corresponding to the red-green-blue (RGB) values that define the pixel representation of an image. Image models are trained on these kinds of representations and expect them for inputs.\n+\n+React Native represents image data in javascript as a base64 encoded string. In order to perform inference with an image model you must provide this base64 encoded string to the run function as well as a description of the those bytes that may included metadata such as the width, height, and format of the image they represent. To run an image model you'll pack this information into a javascript object and use that object in one of the name-value pairs you provide to the run function.\n+\n+<a name=\"image-classification-example\"></a>\n+#### An Image Classification Example\n+\n+Let's look at a basic image classification model and see how to use it in React Native. The JSON description for a cats vs dogs MobileNet based classification model is as follows. Again, pay special attention to the *inputs* and *outputs* fields:\n+\n+```json\n+{\n+  \"name\": \"Cats vs Dogs MobileNet V2 1.0 128\",\n+  \"details\": \"Cats vs Dogs Kaggle model based on MobileNet V2 architecture with a width multiplier of 1.0 and an input resolution of 128x128.\",\n+  \"id\": \"cats-vs-dogs-v2-100-128-unquantized\",\n+  \"version\": \"1\",\n+  \"author\": \"doc.ai\",\n+  \"license\": \"Apache License. Version 2.0 http://www.apache.org/licenses/LICENSE-2.0\",\n+  \"model\": {\n+    \"file\": \"predict\",\n+    \"quantized\": false,\n+    \"type\": \"image.classification.catsvsdogs\",\n+    \"backend\": \"tensorflow\",\n+    \"modes\": [\"predict\"]\n+  },\n+  \"inputs\": [\n+    {\n+      \"name\": \"image\",\n+      \"type\": \"image\",\n+      \"shape\": [-1,128,128,3],\n+      \"format\": \"RGB\",\n+      \"normalize\": {\n+        \"standard\": \"[0,1]\"\n+      }\n+    }\n+  ],\n+  \"outputs\": [\n+    {\n+      \"name\": \"sigmoid\",\n+      \"type\": \"array\",\n+      \"shape\": [-1,1]\n+    }\n+  ]\n+}\n+```\n+\n+The *inputs* and *outputs* fields tell us that this model expects a single image input whose name is *\"image\"* and produces a single output whose name is *\"classification\"*. You don't need to worry about the image input details. Tensor/IO will take care of preparing an image input for the model using this information. But the output field tells you that the classification output will be a labeled list of 1000 values (1 x 1000 from the shape).\n+\n+Let's see how to use this model in React Native. Assuming we have some base64 encoded JPEG data:\n+\n+\n+```js\n+import TensorioTensorflow from \"react-native-tensorio-tensorflow\";\n+const { imageKeyFormat, imageKeyData, imageKeyOrientation, imageOrientationUp, imageTypeJPEG } = TensorioTensorflow.getConstants();\n+\n+const data = 'data:image/jpeg;base64,' + some.data;\n+const orientation = imageOrientationUp;\n+const format = imageTypeJPEG;\n+\n+TensorioTensorflow.load('mobilenet.tiobundle', 'model');\n+\n+TensorioTensorflow\n+  .run('model', {\n+    'image': {\n+      [imageKeyData]: data,\n+      [imageKeyFormat]: format,\n+      [imageKeyOrientation]: orientation\n+    }\n+  })\n+  .then(output => {\n+    const sigmoid = output['sigmoid'];\n+    console.log(sigmoid);\n+  })\n+  .catch(error => {\n+    // Handle error\n+  });\n+\n+TensorioTensorflow.unload('model');\n+```\n+\n+This time we provide an object for the *\"image\"* name-value pair and this object contains three pieces of information: the base64 encoded string, the format of the underlying data, in this case, JPEG data, and the image's orientation. The names used in this object are exported by the TensorioTensorflow module along with the supported image orientations and image data types. These are all described in more detail below.\n+\n+TensorioTensorflow supports image data in a number of formats. Imagine instead that we have the path to an image on the filesystem. We would run the model as follows, and this time we'll omit the image orientation, which is assumed to be 'Up' by default:\n+\n+```js\n+import TensorioTensorflow from \"react-native-tensorio-tensorflow\";\n+const { imageKeyFormat, imageKeyData, imageTypeFile } = TensorioTensorflow.getConstants();\n+\n+const data = '/path/to/image.png';\n+const format = imageTypeFile;\n+\n+TensorioTensorflow.load('mobilenet.tiobundle', 'model');\n+\n+TensorioTensorflow\n+  .run('model', {\n+    'image': {\n+      [imageKeyData]: data,\n+      [imageKeyFormat]: format\n+    }\n+  })\n+  .then(output => {\n+    const sigmoid = output['sigmoid'];\n+    console.log(sigmoid);\n+  })\n+  .catch(error => {\n+    // Handle error\n+  });\n+\n+TensorioTensorflow.unload('model');\n+```\n+\n+Another use case might be real time pixel buffer data coming from a device camera. In this case, and on iOS, the bytes will represent raw pixel data in the BGRA format. This representation tells us nothing else about the image, so we'll also need to specify its width, height, and orientation. On iOS, pixel buffer data coming from the camera is often 640x480 and will be right oriented. We'd run the model as follows:\n+\n+```js\n+import TensorioTensorflow from \"react-native-tensorio-tensorflow\";\n+const { imageKeyFormat, imageKeyData, imageKeyOrientation, imageKeyWidth, imageKeyHeight, imageTypeBGRA, imageOrientationRight } = TensorioTensorflow.getConstants();\n+\n+const data; // pixel buffer data as a base64 encoded string\n+const format = imageTypeBGRA; // ios camera format\n+const orientation = imageOrientationRight; // ios camera orientation\n+const width = 640;\n+const height = 480;\n+\n+TensorioTensorflow.load('mobilenet.tiobundle', 'model');\n+\n+TensorioTensorflow\n+  .run('model', {\n+    'image': {\n+      [imageKeyData]: data,\n+      [imageKeyFormat]: format,\n+      [imageKeyOrientation]: orientation,\n+      [imageKeyWidth]: width,\n+      [imageKeyHeight]: height\n+    }\n+  })\n+  .then(output => {\n+    const sigmoid = output['sigmoid'];\n+    console.log(sigmoid);\n+  })\n+  .catch(error => {\n+    // Handle error\n+  });\n+  \n+TensorioTensorflow.unload('model');\n+```\n+\n+All image models that take image inputs will be run in this manner.\n+\n+<a name=\"image-outputs\"></a>\n+#### Image Outputs\n+\n+Some models will produce image outputs. In this case the value for that output will be provided to javascript as base64 encoded jpeg data. You'll likely need to prefix it as follows before being able to display it:\n+\n+```js\n+TensorioTensorflow\n+  .run('model', {\n+    'image': {\n+      // ...\n+    }\n+  }) \n+  .then(output => {\n+    const image = output['image'];\n+    const data = 'data:image/jpeg;base64,' + image;\n+  })\n+  .catch(error => {\n+    // Handle error\n+  });\n+```\n+\n+## The TensorioTensorflow Module\n+  \n+Listed below are the functions and constants exported by this module.\n+\n+### Functions\n+\n+All functions execute synchronously and return promises.\n+\n+#### load(path, name): Promise\\<boolean\\>\n+\n+Loads the model at the given path and assigns it the name. If the path is a relative path the model will be loaded from the application bundle on iOS or as an asset on Android. Use the name with the other module functions that interact with models. Returns a boolean promise that resolves to true if the model was loaded and false otherwise.\n+\n+Usage:\n+\n+```js\n+TensorioTensorflow.load('model.tiobundle', 'model');\n+```\n+\n+#### unload(name): Promise\\<boolean\\>\n+\n+Unloads a model and frees the underlying resources. Resolves to true if successful and false otherwise. Always unload models when you are done with them to free the underlying resources associated with them.\n+\n+Usage:\n+\n+```js\n+TensorioTensorflow.unload('model')\n+```\n+\n+\n+#### run(name, input): Promise\\<object\\>\n+\n+Perform inference with the model on the input. \n+\n+The input must be a javascript object whose name-value pairs match the names expected by the underlying model's inputs and which are described in the model bundle's *model.json* file. The resulting promise resolves to an object that contains the model's output with the key-value pairs as they are described in the bundle's *model.json* file.\n+\n+Usage:\n+\n+```js\n+TensorioTensorflow\n+  .run('model', {\n+    'input': [1]\n+  })\n+  .then(output => {\n+    console.log(output);\n+  })\n+  .catch(error => {\n+    // Handle error\n+  });\n+```\n+\n+#### isTrainable(name): Promise\\<boolean\\>\n+\n+Resolve to true or false indicating whether the model is trainable or not.\n+\n+Usage:\n+\n+```js\n+TensorioTensorflow.isTrainable('model')\n+  .then(trains => {\n+    console.log(trains);\n+  })\n+  .catch(error => {\n+    // Handle error\n+  });\n+```\n+\n+#### topN(count, threshold, classifications, callback): Promise\\<object\\>\n+\n+A utility function for image classification models that filters for the results with the highest probabilities above a given threshold. \n+\n+Image classification models are often capable of recognizing hundreds or thousands of items and return what is called a softmax probability distribution that describes the likelihood that a recognizable item appears in the image. Often we do not want to know the entire probabilty distribution but only want to know which items have the highest probability of being in the image. Use this function to filter for those items.\n+\n+Count is the number of items you would like to be returned.\n+\n+Threshold is the minimum probability value an item should have in order to be returned. If there are fewer than count items above this probability, only that many items will be returned.\n+\n+Classifications is the output of a classification model.\n+\n+The promise resolves to an object with the same format as the classifications object passed to the function but only with those key-value pairs which meet the criteria.\n+\n+Usage:\n+\n+*Given the results from a model whose output has the name 'classification', filter for the top five probabilities above a threshold of 0.1:*\n+\n+```js\n+TensorioTensorflow\n+  .run('model', {\n+    'image': {\n+      // ...\n+    }\n+  })\n+  .then(output => {\n+    return TensorioTensorflow.topN(5, 0.1, output['classification'])\n+  })\n+  .then(topN => {\n+    console.log(topN);\n+  })\n+  .catch(error => {\n+    // Handle error\n+  });\n+```\n+\n+### Constants\n+\n+#### Image Input Keys\n+\n+```js\n+imageKeyData\n+imageKeyFormat\n+imageKeyWidth\n+imageKeyHeight\n+imageKeyOrientation\n+```\n+\n+##### imageKeyData\n+\n+The data for the image. Must be a base64 encoded string or the fully qualified path to an image on the filesystem.\n+\n+##### imageKeyFormat\n+\n+The image format. See supported types below. Pixel buffer data coming directly from an iOS camera will usually have the format `imageOrientationRight`.\n+\n+##### imageKeyWidth\n+\n+The width of the underlying image. Only required if the format is `imageTypeARGB` or `imageTypeBGRA`. Pixel buffer data coming directly from an iOS device camera will often have a width of 640.\n+\n+##### imageKeyHeight\n+\n+The height of the underlying image. Only required if the format is `imageTypeARGB` or `imageTypeBGRA`. Pixel buffer data coming directly from an iOS device camera will often have a height of 480.\n+\n+##### imageKeyOrientation\n+\n+The orientation of the image. See supported formats below. Most images will be `imageOrientationUp`, and this is the default value that is used if this field is not specified. However, pixel buffer data coming directly from an iOS device camera will be `imageOrientationRight`.\n+\n+#### Image Data Types\n+\n+```js\n+imageTypeUnknown\n+imageTypeARGB\n+imageTypeBGRA\n+imageTypeJPEG\n+imageTypePNG\n+imageTypeFile\n+imageTypeAsset\n+```\n+\n+##### imageTypeUnknown\n+\n+A placeholder for an unknown image type. TensorioTensorflow will return an error if you specify this format.\n+\n+##### imageTypeARGB\n+\n+Pixel buffer data whose pixels are unrolled into an alpha-red-green-blue byte representation.\n+\n+##### imageTypeBGRA\n+\n+Pixel buffer data whose pixels are unrolled into a blue-green-red-alpha byte representation. Pixel data coming directly from an iOS device camera will usually be in this format.\n+\n+##### imageTypeJPEG\n+\n+JPEG image data. The base64 encoded string must be prefixed with `data:image/jpeg;base64,`.\n+\n+##### imageTypePNG\n+\n+PNG image data. The base64 encoded string must be prefixed with `data:image/png;base64,`.\n+\n+##### imageTypeFile\n+\n+Indicates that the image data will contain the fully qualified path to an image on the filesystem.\n+\n+##### imageTypeAsset\n+\n+Indicates that the image data will contain the name of an image asset on iOS and the relative path to an image asset on Android.\n+\n+#### Image Orientations\n+\n+```js\n+imageOrientationUp\n+imageOrientationUpMirrored\n+imageOrientationDown\n+imageOrientationDownMirrored\n+imageOrientationLeftMirrored\n+imageOrientationRight\n+imageOrientationRightMirrored\n+imageOrientationLeft\n+```\n+\n+##### imageOrientationUp\n+\n+0th row at top, 0th column on left. Default orientation.\n+\n+##### imageOrientationUpMirrored\n+\n+0th row at top, 0th column on right. Horizontal flip.\n+\n+##### imageOrientationDown\n+\n+0th row at bottom, 0th column on right. 180 degree rotation.\n+\n+##### imageOrientationDownMirrored \n+\n+0th row at bottom, 0th column on left. Vertical flip.\n+\n+##### imageOrientationLeftMirrored\n+\n+0th row on left, 0th column at top.\n+\n+##### imageOrientationRight\n+\n+0th row on right, 0th column at top. 90 degree clockwise rotation. Pixel buffer data coming from an iOS device camera will usually have this orientation.\n+\n+##### imageOrientationRightMirrored\n+\n+0th row on right, 0th column on bottom.\n+\n+##### imageOrientationLeft\n+\n+0th row on left, 0th column at bottom. 90 degree counter-clockwise rotation.\n\\ No newline at end of file"
  },
  {
    "sha": "3db5b4ed3d8d8d144e936558b70b907877be0f68",
    "filename": "android/build.gradle",
    "status": "modified",
    "additions": 9,
    "deletions": 4,
    "changes": 13,
    "blob_url": "https://github.com/doc-ai/react-native-tensorio-tensorflow/blob/87b362141ceed0611b120243452b3d37b30ea246/android/build.gradle",
    "raw_url": "https://github.com/doc-ai/react-native-tensorio-tensorflow/raw/87b362141ceed0611b120243452b3d37b30ea246/android/build.gradle",
    "contents_url": "https://api.github.com/repos/doc-ai/react-native-tensorio-tensorflow/contents/android/build.gradle?ref=87b362141ceed0611b120243452b3d37b30ea246",
    "patch": "@@ -8,7 +8,7 @@ buildscript {\n   }\n \n   dependencies {\n-    classpath 'com.android.tools.build:gradle:3.2.1'\n+    classpath 'com.android.tools.build:gradle:4.1.1'\n     // noinspection DifferentKotlinGradleVersion\n     classpath \"org.jetbrains.kotlin:kotlin-gradle-plugin:$kotlin_version\"\n   }\n@@ -29,13 +29,13 @@ android {\n   compileSdkVersion getExtOrIntegerDefault('compileSdkVersion')\n   buildToolsVersion getExtOrDefault('buildToolsVersion')\n   defaultConfig {\n-    minSdkVersion 16\n+    minSdkVersion 22\n     targetSdkVersion getExtOrIntegerDefault('targetSdkVersion')\n     versionCode 1\n     versionName \"1.0\"\n-    \n+\n   }\n-  \n+\n   buildTypes {\n     release {\n       minifyEnabled false\n@@ -45,6 +45,7 @@ android {\n     disable 'GradleCompatible'\n   }\n   compileOptions {\n+    coreLibraryDesugaringEnabled true\n     sourceCompatibility JavaVersion.VERSION_1_8\n     targetCompatibility JavaVersion.VERSION_1_8\n   }\n@@ -127,4 +128,8 @@ dependencies {\n   // noinspection GradleDynamicVersion\n   api 'com.facebook.react:react-native:+'\n   implementation \"org.jetbrains.kotlin:kotlin-stdlib:$kotlin_version\"\n+  coreLibraryDesugaring 'com.android.tools:desugar_jdk_libs:1.1.5'\n+\n+  implementation 'com.github.doc-ai.tensorio-android:core:0.10.1'\n+  implementation 'com.github.doc-ai.tensorio-android:tensorflow:0.10.1'\n }"
  },
  {
    "sha": "b74e7336ec7a2050d3da0bed76fd54deb01a95eb",
    "filename": "android/src/main/java/com/reactnativetensoriotensorflow/ArrayUtil.java",
    "status": "added",
    "additions": 202,
    "deletions": 0,
    "changes": 202,
    "blob_url": "https://github.com/doc-ai/react-native-tensorio-tensorflow/blob/87b362141ceed0611b120243452b3d37b30ea246/android/src/main/java/com/reactnativetensoriotensorflow/ArrayUtil.java",
    "raw_url": "https://github.com/doc-ai/react-native-tensorio-tensorflow/raw/87b362141ceed0611b120243452b3d37b30ea246/android/src/main/java/com/reactnativetensoriotensorflow/ArrayUtil.java",
    "contents_url": "https://api.github.com/repos/doc-ai/react-native-tensorio-tensorflow/contents/android/src/main/java/com/reactnativetensoriotensorflow/ArrayUtil.java?ref=87b362141ceed0611b120243452b3d37b30ea246",
    "patch": "@@ -0,0 +1,202 @@\n+\n+/*\n+  ArrayUtil exposes a set of helper methods for working with\n+  ReadableArray (by React Native), Object[], and JSONArray.\n+\n+  MIT License\n+\n+  Copyright (c) 2020 Marc Mendiola\n+\n+  Permission is hereby granted, free of charge, to any person obtaining a copy\n+  of this software and associated documentation files (the \"Software\"), to deal\n+  in the Software without restriction, including without limitation the rights\n+  to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n+  copies of the Software, and to permit persons to whom the Software is\n+  furnished to do so, subject to the following conditions:\n+\n+  The above copyright notice and this permission notice shall be included in all\n+  copies or substantial portions of the Software.\n+\n+  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n+  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n+  FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n+  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n+  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n+  OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n+  SOFTWARE.\n+ */\n+\n+// See https://gist.github.com/mfmendiola/bb8397162df9f76681325ab9f705748b\n+\n+package com.reactnativetensoriotensorflow;\n+\n+import com.facebook.react.bridge.Arguments;\n+import com.facebook.react.bridge.ReadableArray;\n+import com.facebook.react.bridge.ReadableType;\n+import com.facebook.react.bridge.WritableArray;\n+\n+import java.util.Map;\n+\n+import org.json.JSONArray;\n+import org.json.JSONObject;\n+import org.json.JSONException;\n+\n+public class ArrayUtil {\n+\n+  public static JSONArray toJSONArray(ReadableArray readableArray) throws JSONException {\n+    JSONArray jsonArray = new JSONArray();\n+\n+    for (int i = 0; i < readableArray.size(); i++) {\n+      ReadableType type = readableArray.getType(i);\n+\n+      switch (type) {\n+        case Null:\n+          jsonArray.put(i, null);\n+          break;\n+        case Boolean:\n+          jsonArray.put(i, readableArray.getBoolean(i));\n+          break;\n+        case Number:\n+          jsonArray.put(i, readableArray.getDouble(i));\n+          break;\n+        case String:\n+          jsonArray.put(i, readableArray.getString(i));\n+          break;\n+        case Map:\n+          jsonArray.put(i, MapUtil.toJSONObject(readableArray.getMap(i)));\n+          break;\n+        case Array:\n+          jsonArray.put(i, ArrayUtil.toJSONArray(readableArray.getArray(i)));\n+          break;\n+      }\n+    }\n+\n+    return jsonArray;\n+  }\n+\n+  public static Object[] toArray(JSONArray jsonArray) throws JSONException {\n+    Object[] array = new Object[jsonArray.length()];\n+\n+    for (int i = 0; i < jsonArray.length(); i++) {\n+      Object value = jsonArray.get(i);\n+\n+      if (value instanceof JSONObject) {\n+        value = MapUtil.toMap((JSONObject) value);\n+      }\n+      if (value instanceof JSONArray) {\n+        value = ArrayUtil.toArray((JSONArray) value);\n+      }\n+\n+      array[i] = value;\n+    }\n+\n+    return array;\n+  }\n+\n+  public static Object[] toArray(ReadableArray readableArray) {\n+    Object[] array = new Object[readableArray.size()];\n+\n+    for (int i = 0; i < readableArray.size(); i++) {\n+      ReadableType type = readableArray.getType(i);\n+\n+      switch (type) {\n+        case Null:\n+          array[i] = null;\n+          break;\n+        case Boolean:\n+          array[i] = readableArray.getBoolean(i);\n+          break;\n+        case Number:\n+          array[i] = readableArray.getDouble(i);\n+          break;\n+        case String:\n+          array[i] = readableArray.getString(i);\n+          break;\n+        case Map:\n+          array[i] = MapUtil.toMap(readableArray.getMap(i));\n+          break;\n+        case Array:\n+          array[i] = ArrayUtil.toArray(readableArray.getArray(i));\n+          break;\n+      }\n+    }\n+\n+    return array;\n+  }\n+\n+  // +@pdow\n+  public static WritableArray toWritableArray(boolean[] array) {\n+    WritableArray writableArray = Arguments.createArray();\n+\n+    for (boolean b : array) {\n+      writableArray.pushBoolean(b);\n+    }\n+\n+    return writableArray;\n+  }\n+\n+  // +@pdow\n+  public static WritableArray toWritableArray(double[] array) {\n+    WritableArray writableArray = Arguments.createArray();\n+\n+    for (double v : array) {\n+      writableArray.pushDouble(v);\n+    }\n+\n+    return writableArray;\n+  }\n+\n+  // +@pdow\n+  public static WritableArray toWritableArray(float[] array) {\n+    WritableArray writableArray = Arguments.createArray();\n+\n+    for (float v : array) {\n+      writableArray.pushDouble(((Float) v).doubleValue());\n+    }\n+\n+    return writableArray;\n+  }\n+\n+  // +@pdow\n+  public static WritableArray toWritableArray(int[] array) {\n+    WritableArray writableArray = Arguments.createArray();\n+\n+    for (int value : array) {\n+      writableArray.pushInt(value);\n+    }\n+\n+    return writableArray;\n+  }\n+\n+  public static WritableArray toWritableArray(Object[] array) {\n+    WritableArray writableArray = Arguments.createArray();\n+\n+    for (int i = 0; i < array.length; i++) {\n+      Object value = array[i];\n+\n+      if (value == null) {\n+        writableArray.pushNull();\n+      }\n+      if (value instanceof Boolean) {\n+        writableArray.pushBoolean((Boolean) value);\n+      }\n+      if (value instanceof Double) {\n+        writableArray.pushDouble((Double) value);\n+      }\n+      if (value instanceof Integer) {\n+        writableArray.pushInt((Integer) value);\n+      }\n+      if (value instanceof String) {\n+        writableArray.pushString((String) value);\n+      }\n+      if (value instanceof Map) {\n+        writableArray.pushMap(MapUtil.toWritableMap((Map<String, Object>) value));\n+      }\n+      if (value.getClass().isArray()) {\n+        writableArray.pushArray(ArrayUtil.toWritableArray((Object[]) value));\n+      }\n+    }\n+\n+    return writableArray;\n+  }\n+}"
  },
  {
    "sha": "34652482be683648e168f9869add8c435563e28f",
    "filename": "android/src/main/java/com/reactnativetensoriotensorflow/MapUtil.java",
    "status": "added",
    "additions": 197,
    "deletions": 0,
    "changes": 197,
    "blob_url": "https://github.com/doc-ai/react-native-tensorio-tensorflow/blob/87b362141ceed0611b120243452b3d37b30ea246/android/src/main/java/com/reactnativetensoriotensorflow/MapUtil.java",
    "raw_url": "https://github.com/doc-ai/react-native-tensorio-tensorflow/raw/87b362141ceed0611b120243452b3d37b30ea246/android/src/main/java/com/reactnativetensoriotensorflow/MapUtil.java",
    "contents_url": "https://api.github.com/repos/doc-ai/react-native-tensorio-tensorflow/contents/android/src/main/java/com/reactnativetensoriotensorflow/MapUtil.java?ref=87b362141ceed0611b120243452b3d37b30ea246",
    "patch": "@@ -0,0 +1,197 @@\n+\n+/*\n+  MapUtil exposes a set of helper methods for working with\n+  ReadableMap (by React Native), Map<String, Object>, and JSONObject.\n+\n+  MIT License\n+\n+  Copyright (c) 2020 Marc Mendiola\n+\n+  Permission is hereby granted, free of charge, to any person obtaining a copy\n+  of this software and associated documentation files (the \"Software\"), to deal\n+  in the Software without restriction, including without limitation the rights\n+  to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n+  copies of the Software, and to permit persons to whom the Software is\n+  furnished to do so, subject to the following conditions:\n+\n+  The above copyright notice and this permission notice shall be included in all\n+  copies or substantial portions of the Software.\n+\n+  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n+  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n+  FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n+  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n+  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n+  OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n+  SOFTWARE.\n+ */\n+\n+// See https://gist.github.com/mfmendiola/bb8397162df9f76681325ab9f705748b\n+\n+package com.reactnativetensoriotensorflow;\n+\n+import com.facebook.react.bridge.Arguments;\n+import com.facebook.react.bridge.ReadableMap;\n+import com.facebook.react.bridge.ReadableMapKeySetIterator;\n+import com.facebook.react.bridge.ReadableType;\n+import com.facebook.react.bridge.WritableMap;\n+\n+import java.util.Map;\n+import java.util.HashMap;\n+import java.util.Iterator;\n+\n+import org.json.JSONArray;\n+import org.json.JSONObject;\n+import org.json.JSONException;\n+\n+public class MapUtil {\n+\n+  public static JSONObject toJSONObject(ReadableMap readableMap) throws JSONException {\n+    JSONObject jsonObject = new JSONObject();\n+\n+    ReadableMapKeySetIterator iterator = readableMap.keySetIterator();\n+\n+    while (iterator.hasNextKey()) {\n+      String key = iterator.nextKey();\n+      ReadableType type = readableMap.getType(key);\n+\n+      switch (type) {\n+        case Null:\n+          jsonObject.put(key, null);\n+          break;\n+        case Boolean:\n+          jsonObject.put(key, readableMap.getBoolean(key));\n+          break;\n+        case Number:\n+          jsonObject.put(key, readableMap.getDouble(key));\n+          break;\n+        case String:\n+          jsonObject.put(key, readableMap.getString(key));\n+          break;\n+        case Map:\n+          jsonObject.put(key, MapUtil.toJSONObject(readableMap.getMap(key)));\n+          break;\n+        case Array:\n+          jsonObject.put(key, ArrayUtil.toJSONArray(readableMap.getArray(key)));\n+          break;\n+      }\n+    }\n+\n+    return jsonObject;\n+  }\n+\n+  public static Map<String, Object> toMap(JSONObject jsonObject) throws JSONException {\n+    Map<String, Object> map = new HashMap<>();\n+    Iterator<String> iterator = jsonObject.keys();\n+\n+    while (iterator.hasNext()) {\n+      String key = iterator.next();\n+      Object value = jsonObject.get(key);\n+\n+      if (value instanceof JSONObject) {\n+        value = MapUtil.toMap((JSONObject) value);\n+      }\n+      if (value instanceof JSONArray) {\n+        value = ArrayUtil.toArray((JSONArray) value);\n+      }\n+\n+      map.put(key, value);\n+    }\n+\n+    return map;\n+  }\n+\n+  public static Map<String, Object> toMap(ReadableMap readableMap) {\n+    Map<String, Object> map = new HashMap<>();\n+    ReadableMapKeySetIterator iterator = readableMap.keySetIterator();\n+\n+    while (iterator.hasNextKey()) {\n+      String key = iterator.nextKey();\n+      ReadableType type = readableMap.getType(key);\n+\n+      switch (type) {\n+        case Null:\n+          map.put(key, null);\n+          break;\n+        case Boolean:\n+          map.put(key, readableMap.getBoolean(key));\n+          break;\n+        case Number:\n+          map.put(key, readableMap.getDouble(key));\n+          break;\n+        case String:\n+          map.put(key, readableMap.getString(key));\n+          break;\n+        case Map:\n+          map.put(key, MapUtil.toMap(readableMap.getMap(key)));\n+          break;\n+        case Array:\n+          map.put(key, ArrayUtil.toArray(readableMap.getArray(key)));\n+          break;\n+      }\n+    }\n+\n+    return map;\n+  }\n+\n+  public static WritableMap toWritableMap(Map<String, Object> map) {\n+    WritableMap writableMap = Arguments.createMap();\n+    Iterator iterator = map.entrySet().iterator();\n+\n+    while (iterator.hasNext()) {\n+      Map.Entry pair = (Map.Entry)iterator.next();\n+      Object value = pair.getValue();\n+\n+      if (value == null) {\n+        writableMap.putNull((String) pair.getKey());\n+      } else if (value instanceof Boolean) {\n+        writableMap.putBoolean((String) pair.getKey(), (Boolean) value);\n+      } else if (value instanceof Double) {\n+        writableMap.putDouble((String) pair.getKey(), (Double) value);\n+      } else if (value instanceof Float) {\n+        // +@pdow\n+        writableMap.putDouble((String) pair.getKey(), (Double) ((Float) value).doubleValue());\n+      } else if (value instanceof Integer) {\n+        writableMap.putInt((String) pair.getKey(), (Integer) value);\n+      } else if (value instanceof String) {\n+        writableMap.putString((String) pair.getKey(), (String) value);\n+      } else if (value instanceof Map) {\n+        writableMap.putMap((String) pair.getKey(), MapUtil.toWritableMap((Map<String, Object>) value));\n+      } else if (value instanceof boolean[] ) {\n+         // +@pdow\n+        if ( ((boolean[]) value).length == 1 ) {\n+          writableMap.putBoolean((String) pair.getKey(), ((boolean[]) value)[0]);\n+        } else {\n+          writableMap.putArray((String) pair.getKey(), ArrayUtil.toWritableArray((boolean[]) value));\n+        }\n+      } else if (value instanceof double[] ) {\n+         // +@pdow\n+        if ( ((double[]) value).length == 1 ) {\n+          writableMap.putDouble((String) pair.getKey(), ((double[]) value)[0]);\n+        } else {\n+          writableMap.putArray((String) pair.getKey(), ArrayUtil.toWritableArray((double[]) value));\n+        }\n+      } else if (value instanceof float[] ) {\n+         // +@pdow\n+        if ( ((float[]) value).length == 1 ) {\n+          writableMap.putDouble((String) pair.getKey(), ((float[]) value)[0]);\n+        } else {\n+          writableMap.putArray((String) pair.getKey(), ArrayUtil.toWritableArray((float[]) value));\n+        }\n+      } else if (value instanceof int[] ) {\n+        // +@pdow\n+        if ( ((int[]) value).length == 1 ) {\n+          writableMap.putInt((String) pair.getKey(), ((int[]) value)[0]);\n+        } else {\n+          writableMap.putArray((String) pair.getKey(), ArrayUtil.toWritableArray((int[]) value));\n+        }\n+      } else if (value.getClass() != null && value.getClass().isArray()) {\n+        writableMap.putArray((String) pair.getKey(), ArrayUtil.toWritableArray((Object[]) value));\n+      }\n+\n+      iterator.remove();\n+    }\n+\n+    return writableMap;\n+  }\n+}"
  },
  {
    "sha": "6c6f75c3d889695b5c3066d861141fb7e53c0d85",
    "filename": "android/src/main/java/com/reactnativetensoriotensorflow/TensorioTensorflowModule.kt",
    "status": "modified",
    "additions": 614,
    "deletions": 14,
    "changes": 628,
    "blob_url": "https://github.com/doc-ai/react-native-tensorio-tensorflow/blob/87b362141ceed0611b120243452b3d37b30ea246/android/src/main/java/com/reactnativetensoriotensorflow/TensorioTensorflowModule.kt",
    "raw_url": "https://github.com/doc-ai/react-native-tensorio-tensorflow/raw/87b362141ceed0611b120243452b3d37b30ea246/android/src/main/java/com/reactnativetensoriotensorflow/TensorioTensorflowModule.kt",
    "contents_url": "https://api.github.com/repos/doc-ai/react-native-tensorio-tensorflow/contents/android/src/main/java/com/reactnativetensoriotensorflow/TensorioTensorflowModule.kt?ref=87b362141ceed0611b120243452b3d37b30ea246",
    "patch": "@@ -1,24 +1,624 @@\n package com.reactnativetensoriotensorflow\n \n-import com.facebook.react.bridge.ReactApplicationContext\n-import com.facebook.react.bridge.ReactContextBaseJavaModule\n-import com.facebook.react.bridge.ReactMethod\n-import com.facebook.react.bridge.Promise\n+import ai.doc.tensorio.core.data.Batch\n+import ai.doc.tensorio.core.layerinterface.DataType.*\n+import ai.doc.tensorio.core.layerinterface.LayerDescription\n+import ai.doc.tensorio.core.model.Model\n+import ai.doc.tensorio.core.modelbundle.ModelBundle\n+import ai.doc.tensorio.core.modelbundle.ModelBundle.ModelBundleException\n+import ai.doc.tensorio.core.training.TrainableModel\n+import ai.doc.tensorio.core.utilities.AndroidAssets\n+import ai.doc.tensorio.core.utilities.ClassificationHelper\n+import ai.doc.tensorio.tensorflow.model.TensorFlowModel\n+import android.graphics.Bitmap\n+import android.graphics.BitmapFactory\n+import android.util.Base64\n+import com.facebook.react.bridge.*\n+import java.io.ByteArrayOutputStream\n+import java.io.File\n+import java.io.IOException\n+import java.nio.ByteBuffer\n+\n+const val RNTIOImageKeyData = \"RNTIOImageKeyData\"\n+const val RNTIOImageKeyFormat = \"RNTIOImageKeyFormat\"\n+const val RNTIOImageKeyWidth = \"RNTIOImageKeyWidth\"\n+const val RNTIOImageKeyHeight = \"RNTIOImageKeyHeight\"\n+const val RNTIOImageKeyOrientation = \"RNTIOImageKeyOrientation\"\n \n class TensorioTensorflowModule(reactContext: ReactApplicationContext) : ReactContextBaseJavaModule(reactContext) {\n \n-    override fun getName(): String {\n-        return \"TensorioTensorflow\"\n+    enum class ImageFormat(val value: Int) {\n+    Unknown(0),\n+    ARGB(1),\n+    BGRA(2),\n+    JPEG(3),\n+    PNG(4),\n+    File(5),\n+    Asset(6);\n+\n+    companion object {\n+      fun valueOf(value: Int) = ImageFormat.values().first { it.value == value }\n+    }\n+  }\n+\n+  enum class ImageOrientation(val value: Int) {\n+    Up(1),\n+    UpMirrored(2),\n+    Down(3),\n+    DownMirrored(4),\n+    LeftMirrored(5),\n+    Right(6),\n+    RightMirrored(7),\n+    Left(8);\n+\n+    companion object {\n+      fun valueOf(value: Int) = ImageFormat.values().first { it.value == value }\n+    }\n+  }\n+\n+  /**\n+   * maps path or model names to loaded models, allowing the module to load,\n+   * and use more than one model at a time.\n+   */\n+\n+  private val models: HashMap<String, TensorFlowModel> = HashMap()\n+\n+  /**\n+   * React Native override for the module name\n+   */\n+\n+  override fun getName(): String {\n+    return \"TensorioTensorflow\"\n+  }\n+\n+  /**\n+   * React Native override for exported constants\n+   */\n+\n+  override fun getConstants(): Map<String, Any> {\n+    val constants: HashMap<String, Any> = HashMap()\n+\n+    constants[\"imageKeyData\"]         = RNTIOImageKeyData\n+    constants[\"imageKeyFormat\"]       = RNTIOImageKeyFormat\n+    constants[\"imageKeyWidth\"]        = RNTIOImageKeyWidth\n+    constants[\"imageKeyHeight\"]       = RNTIOImageKeyHeight\n+    constants[\"imageKeyOrientation\"]  = RNTIOImageKeyOrientation\n+\n+    constants[\"imageTypeUnknown\"]     = ImageFormat.Unknown.value\n+    constants[\"imageTypeARGB\"]        = ImageFormat.ARGB.value\n+    constants[\"imageTypeBGRA\"]        = ImageFormat.BGRA.value\n+    constants[\"imageTypeJPEG\"]        = ImageFormat.JPEG.value\n+    constants[\"imageTypePNG\"]         = ImageFormat.PNG.value\n+    constants[\"imageTypeFile\"]        = ImageFormat.File.value\n+    constants[\"imageTypeAsset\"]       = ImageFormat.Asset.value\n+\n+    constants[\"imageOrientationUp\"]             = ImageOrientation.Up.value\n+    constants[\"imageOrientationUpMirrored\"]     = ImageOrientation.UpMirrored.value\n+    constants[\"imageOrientationDown\"]           = ImageOrientation.Down.value\n+    constants[\"imageOrientationDownMirrored\"]   = ImageOrientation.DownMirrored.value\n+    constants[\"imageOrientationLeftMirrored\"]   = ImageOrientation.LeftMirrored.value\n+    constants[\"imageOrientationRight\"]          = ImageOrientation.Right.value\n+    constants[\"imageOrientationRightMirrored\"]  = ImageOrientation.RightMirrored.value\n+    constants[\"imageOrientationLeft\"]           = ImageOrientation.Left.value\n+\n+    return constants\n+  }\n+\n+  /**\n+   * Bridged method that loads a model given a model path. Relative paths will be loaded as assets\n+   * from the application bundle.\n+   */\n+\n+  @ReactMethod\n+  fun load(path: String, name: String?, promise: Promise) {\n+    val hashname = name ?: path\n+\n+    try {\n+\n+      // Reject if model with name is already loaded\n+\n+      if (models[hashname] != null) {\n+        promise.reject(\"ai.doc.tensorio.tensorflow.rn:load:name-in-use\", \"Name already use. Use a different name, and do not reload a model without unloading it first\")\n+        return\n+      }\n+\n+      // Load the model\n+\n+      val bundle = if (isAbsoluteFilepath(path)) {\n+        ModelBundle.bundleWithFile(File(path))\n+      } else {\n+        fileBundleForAsset(path)\n+      }\n+\n+      val model = bundle.newModel() as TensorFlowModel\n+\n+      // Cache it\n+\n+      models[hashname] = model\n+      promise.resolve(true)\n+\n+    } catch (e: ModelBundleException) {\n+      promise.reject(e)\n+    } catch (e: Exception) {\n+      promise.reject(e)\n+    }\n+  }\n+\n+  /**\n+   * Bridged method that unloads a model, freeing the underlying resources.\n+   */\n+\n+  @ReactMethod\n+  fun unload(name: String, promise: Promise) {\n+    if (models[name] == null) {\n+      promise.reject(\"ai.doc.tensorio.tensorflow.rn:unload:model-not-found\", \"No model with this name was found\")\n+      return\n+    }\n+\n+    models[name]?.unload()\n+    models.remove(name)\n+\n+    promise.resolve(true)\n+  }\n+\n+  /**\n+   * Bridged method returns YES if model is trainable, NO otherwise.\n+   * TF Lite models will always return NO\n+   */\n+\n+  @ReactMethod\n+  fun isTrainable(name: String, promise: Promise) {\n+    val trains = models[name]?.bundle?.modes?.trains() ?: false\n+    promise.resolve(trains)\n+  }\n+\n+  /**\n+   * Bridged methods that performs inference with a loaded model and returns the results.\n+   */\n+\n+  @ReactMethod\n+  fun run(name: String, data: ReadableMap, promise: Promise) {\n+    if (models[name] == null) {\n+      promise.reject(\"ai.doc.tensorio.tensorflow.rn:run:model-not-found\", \"No model with this name was found\")\n+      return\n+    }\n+\n+    val model = models[name] as Model\n+    val hashmap = MapUtil.toMap(data)\n+\n+    // Ensure that data is not empty\n+\n+    if (hashmap.count() == 0) {\n+      promise.reject(\"ai.doc.tensorio.tensorflow.rn:run:input-empty\", \"Provided data is empty\")\n+      return\n+    }\n+\n+    // Ensure that the provided keys match the model's expected keys, or return an error\n+\n+    if (!model.io.inputs.keys().equals(hashmap.keys)) {\n+      promise.reject(\"ai.doc.tensorio.tensorflow.rn:run:input-mismatch\", \"Provided inputs do not match expected inputs\")\n+      return\n+    }\n+\n+    // Prepare inputs, converting base64 encoded image data or reading image data from the filesystem\n+\n+    val preparedInputs = preparedInputs(hashmap, model)\n+\n+    if (preparedInputs == null) {\n+      promise.reject(\"ai.doc.tensorio.tensorflow.rn:run:prepared-inputs\", \"Unable to prepare inputs from react native for inference\")\n+      return\n+    }\n+\n+    // Perform inference\n+\n+    val outputs: Map<String, Any>\n+\n+    try {\n+      outputs = model.runOn(preparedInputs)\n+    } catch (e: Exception) {\n+      promise.reject(\"ai.doc.tensorio.tensorflow.rn:run:inference-exception\", e)\n+      return\n+    }\n+\n+    // Prepare outputs, converting pixel buffer outputs to base64 encoded jpeg string data\n+\n+    val preparedOutputs = preparedOutputs(outputs, model)\n+\n+    if (preparedOutputs == null) {\n+      promise.reject(\"ai.doc.tensorio.tensorflow.rn:run:prepared-outputs\", \"Unable to prepare outputs for return to react native\")\n+      return\n+    }\n+\n+    // Return results in React Native format\n+\n+    promise.resolve(MapUtil.toWritableMap(preparedOutputs))\n+  }\n+\n+  /**\n+   * Bridged methods that performs unbatched training with a loaded model and returns the results.\n+   */\n+\n+  // TODO: Output conversion is destroying float value\n+\n+  @ReactMethod\n+  fun train(name: String, data: ReadableArray, promise: Promise) {\n+    if (models[name] == null) {\n+      promise.reject(\"ai.doc.tensorio.tensorflow.rn:run:model-not-found\", \"No model with this name was found\")\n+      return\n+    }\n+\n+    val model = models[name] as Model\n+    val mapArray = ArrayUtil.toArray(data).asList() as List<Map<String, Object>>\n+\n+    // Ensure that data is not empty\n+\n+    if (mapArray.count() == 0) {\n+      promise.reject(\"ai.doc.tensorio.tensorflow.rn:run:input-empty\", \"Provided data is empty\")\n+      return\n+    }\n+\n+    // Ensure that the provided keys match the model's expected keys, or return an error\n+\n+    if (!model.io.inputs.keys().equals(mapArray[0].keys)) {\n+      promise.reject(\"ai.doc.tensorio.tensorflow.rn:run:input-mismatch\", \"Provided inputs do not match expected inputs\")\n+      return\n+    }\n+\n+    // Prepare inputs as batch, converting base64 encoded image data or reading image data from the filesystem\n+\n+    val keys = mapArray[0].keys.toTypedArray()\n+    val batch = Batch(keys)\n+\n+    for (hashmap in mapArray) {\n+      val preparedInputs = preparedInputs(hashmap, model)\n+\n+      if (preparedInputs == null) {\n+        promise.reject(\"ai.doc.tensorio.tensorflow.rn:run:prepared-inputs\", \"Unable to prepare inputs from react native for inference\")\n+        return\n+      }\n+\n+      batch.add(mapToBatchItem(preparedInputs))\n+    }\n+\n+    // Perform training\n+\n+    val outputs: Map<String, Any>\n+\n+    try {\n+      outputs = (model as TrainableModel).trainOn(batch)\n+    } catch (e: Exception) {\n+      promise.reject(\"ai.doc.tensorio.tensorflow.rn:run:train-exception\", e)\n+      return\n+    }\n+\n+    // Prepare outputs, converting pixel buffer outputs to base64 encoded jpeg string data\n+\n+    val preparedOutputs = preparedOutputs(outputs, model)\n+\n+    if (preparedOutputs == null) {\n+      promise.reject(\"ai.doc.tensorio.tensorflow.rn:run:prepared-outputs\", \"Unable to prepare outputs for return to react native\")\n+      return\n+    }\n+\n+    // Return results in React Native format\n+\n+    promise.resolve(MapUtil.toWritableMap(preparedOutputs))\n+  }\n+\n+  /**\n+   * Bridged utility method for image classification models that returns the\n+   * top N probability label-scores.\n+   */\n+\n+  // TODO: Remove and implement in javasript\n+\n+  @ReactMethod\n+  fun topN(count: Int, threshold: Float, classifications: ReadableMap, promise: Promise) {\n+    val hashmap = MapUtil.toMap(classifications) as Map<String, Double>\n+    val floatmap = hashmap.map { it.key to it.value.toFloat() }.toMap()\n+    val topN = ClassificationHelper.topN(floatmap, count, threshold)\n+    val topNMap = HashMap<String, Float>()\n+\n+    for (entry in topN) {\n+      topNMap[entry.key] = entry.value\n+    }\n+\n+    // Return results in React Native format\n+\n+    promise.resolve(MapUtil.toWritableMap(topNMap as Map<String, Any>))\n+  }\n+\n+  // Load Utilities\n+\n+  /** Set up a models directory in cache if loading a model from assets */\n+\n+  // TODO: let consumer know that it is always better to manage model assets themselves\n+\n+  @Throws(Exception::class)\n+  private fun createCacheDir() {\n+    val f: File = File(reactApplicationContext.cacheDir, \"models\")\n+    if (f.exists()) {\n+      return\n+    }\n+    if (!f.mkdirs()) {\n+      throw Exception(\"on create: \" + f.path)\n+    }\n+  }\n+\n+  /** Create a model bundle from a file, copying the asset to models */\n+\n+  @Throws(IOException::class, ModelBundleException::class)\n+  private fun fileBundleForAsset(filename: String): ModelBundle {\n+    createCacheDir()\n+    val dir: File = File(reactApplicationContext.cacheDir, \"models\")\n+    val file = File(dir, filename)\n+    if (!file.exists()) {\n+      AndroidAssets.copyAsset(reactApplicationContext, filename, file)\n+    }\n+    return ModelBundle.bundleWithFile(file)\n+  }\n+\n+  /**\n+   * Returns true if this is an absolute filepath, false otherwise. Filepaths that are not absolute\n+   * will be treated as paths to Assets rather than files on the filesystem.\n+   */\n+\n+  private fun isAbsoluteFilepath(path: String): Boolean {\n+    return path.startsWith(\"file:/\") || path.startsWith(\"/\")\n+  }\n+\n+  // Input/Output Preparation\n+\n+  /**\n+   * Prepares the model inputs sent from javascript for inference. Image inputs are encoded\n+   * as a base64 string and must be decoded and converted to pixel buffers. Other inputs are\n+   * taken as is.\n+   */\n+\n+  private fun preparedInputs(inputs: Map<String, Any>, model: Model): Map<String, Any>? {\n+    val preparedInputs = HashMap<String, Any>()\n+    var error = false\n+\n+    for (layer in model.io.inputs.all()) {\n+      layer.doCase(\n+        {\n+          // Vector layer\n+          preparedInputs[layer.name] = typedInput(it, inputs[layer.name] as Any)\n+        },\n+        {\n+          // Image layer\n+          val bitmap = bitmapForInput(inputs[layer.name] as Map<String, Any>)\n+          if (bitmap != null) {\n+            preparedInputs[layer.name] = bitmap\n+          } else {\n+            error = true\n+          }\n+        },\n+        {\n+          // Bytes layer\n+          preparedInputs[layer.name] = typedInput(it, inputs[layer.name] as Any)\n+        },\n+        {\n+          // Scalar layer\n+          preparedInputs[layer.name] = typedInput(it, inputs[layer.name] as Any)\n+        })\n+    }\n+\n+    if (error) {\n+      return null\n+    }\n+\n+    return preparedInputs\n+  }\n+\n+  /**\n+   * Types Any inputs to the primitive arrays required by Tensor/IO, including float[], byte[],\n+   * int[], and long[]. Barf. Necessary because React Native always gives us doubles but models\n+   * take the above. Holy Jesus Christ this is awful. And primitives vs objects! Why!?!\n+   */\n+\n+  // TODO: Rewrite this whole class in Java.\n+\n+  private fun typedInput(layer: LayerDescription, input: Any): Any {\n+    return when (input) {\n+      is String -> {\n+        input\n+      }\n+      is Boolean -> {\n+        booleanArrayOf(input)\n+      }\n+      is Array<*> -> {\n+        when (input[0]) {\n+          is String -> {\n+            input\n+          }\n+          is Boolean -> {\n+            input\n+          }\n+          is Number -> {\n+            when (layer.dtype) {\n+              UInt8 -> {\n+                input.map { (it as Double).toByte() }.toByteArray()\n+              }\n+              Float32 -> {\n+                input.map { (it as Double).toFloat() }.toFloatArray()\n+              }\n+              Int32 -> {\n+                input.map { (it as Double).toInt() }.toIntArray()\n+              }\n+              Int64 -> {\n+                input.map { (it as Double).toLong() }.toLongArray()\n+              }\n+            }\n+          }\n+          else -> {\n+            print(\"Default typing behavior returns object untyped, which may not be what you want\")\n+            input\n+          }\n+        }\n+      }\n+      is Number -> {\n+        when (layer.dtype) {\n+          UInt8 -> {\n+            byteArrayOf((input as Double).toByte())\n+          }\n+          Float32 -> {\n+            floatArrayOf((input as Double).toFloat())\n+          }\n+          Int32 -> {\n+            intArrayOf((input as Double).toInt())\n+          }\n+          Int64 -> {\n+            longArrayOf((input as Double).toLong())\n+          }\n+        }\n+      }\n+      else -> {\n+        print(\"Default typing behavior returns object untyped, which may not be what you want\")\n+        input\n+      }\n+    }\n+  }\n+\n+  /**\n+   * Prepares the model outputs for consumption by javascript. Pixel buffer outputs are converted\n+   * to base64 strings. Other outputs are taken as is.\n+   */\n+\n+  private fun preparedOutputs(outputs: Map<String, Any>, model: Model): Map<String, Any>? {\n+    val preparedOutputs = HashMap<String, Any>()\n+    var error = false\n+\n+    for (layer in model.io.outputs.all()) {\n+      layer.doCase(\n+        {\n+          // Vector layer\n+          preparedOutputs[layer.name] = outputs[layer.name] as Any\n+        },\n+        {\n+          // Image layer\n+          val encoded = base64JPEGDataForBitmap(outputs[layer.name] as Bitmap)\n+          if (encoded != null) {\n+            preparedOutputs[layer.name] = encoded\n+          } else {\n+            error = true\n+          }\n+        },\n+        {\n+          // Bytes layer\n+          preparedOutputs[layer.name] = outputs[layer.name] as Any\n+        },\n+        {\n+          // Scalar layer\n+          preparedOutputs[layer.name] = outputs[layer.name] as Any\n+        })\n     }\n \n-    // Example method\n-    // See https://facebook.github.io/react-native/docs/native-modules-android\n-    @ReactMethod\n-    fun multiply(a: Int, b: Int, promise: Promise) {\n-    \n-      promise.resolve(a * b)\n-    \n+    if (error) {\n+      return null\n+    }\n+\n+    return preparedOutputs\n+  }\n+\n+  /**\n+   * Utility function for converting a HashMap to a Batch.Item, which extends it\n+   */\n+\n+  private fun mapToBatchItem(map: Map<String,Any>): Batch.Item {\n+    val item = Batch.Item()\n+\n+    for ((k,v) in map) {\n+      item[k] = v\n+    }\n+\n+    return item\n+  }\n+\n+  // Image Utilities\n+\n+  /**\n+   * Converts a pixel buffer output to a base64 encoded string that can be consumed by React Native.\n+   * See https://stackoverflow.com/questions/9224056/android-bitmap-to-base64-string\n+   */\n+\n+  private fun base64JPEGDataForBitmap(bitmap: Bitmap): String? {\n+    val stream = ByteArrayOutputStream()\n+    bitmap.compress(Bitmap.CompressFormat.JPEG, 100, stream)\n+\n+    val bytes = stream.toByteArray()\n+    return Base64.encodeToString(bytes, Base64.DEFAULT)\n+  }\n+\n+  /**\n+   * Converts base64 encoded JPEG or PNG to Bitmap\n+   */\n+\n+  private fun bitmapForBase64Data(string: String): Bitmap? {\n+    val bytes = Base64.decode(string, Base64.DEFAULT)\n+    return BitmapFactory.decodeByteArray(bytes, 0, bytes.size)\n+  }\n+\n+  /**\n+   * Converts base64 encoded pixels to Bitmap\n+   */\n+\n+  private fun bitmapForBase64Pixels(string: String, width: Int, height: Int, format: Bitmap.Config): Bitmap {\n+    val bytes = Base64.decode(string, Base64.DEFAULT)\n+    val bitmap = Bitmap.createBitmap(width, height, Bitmap.Config.ARGB_8888)\n+    val intbuffer = ByteBuffer.wrap(bytes).asIntBuffer()\n+    val ints = IntArray(intbuffer.remaining())\n+\n+    intbuffer.get(ints)\n+    bitmap.setPixels(ints, 0, 0, 0, 0, width, height)\n+\n+    return bitmap\n+  }\n+\n+  /**\n+   * Prepares a pixel buffer input given an image encoding dictionary sent from javascript,\n+   * converting a base64 encoded string or reading data from the file system.\n+   */\n+\n+  // TODO: Test all conversions\n+\n+  private fun bitmapForInput(input: Map<String, Any>): Bitmap? {\n+    val format = ImageFormat.valueOf((input[\"RNTIOImageKeyFormat\"] as Double).toInt())\n+\n+    return when (format) {\n+      ImageFormat.ARGB -> {\n+        val string = input[RNTIOImageKeyData] as String\n+        val width = (input[RNTIOImageKeyWidth] as Double).toInt()\n+        val height = (input[RNTIOImageKeyHeight] as Double).toInt()\n+        bitmapForBase64Pixels(string, width, height, Bitmap.Config.ARGB_8888)\n+      }\n+      ImageFormat.BGRA -> {\n+        val string = input[RNTIOImageKeyData] as String\n+        val width = (input[RNTIOImageKeyWidth] as Double).toInt()\n+        val height = (input[RNTIOImageKeyHeight] as Double).toInt()\n+        bitmapForBase64Pixels(string, width, height, Bitmap.Config.ARGB_8888)\n+      }\n+      ImageFormat.JPEG -> {\n+        val base64 = input[RNTIOImageKeyData] as String\n+        bitmapForBase64Data(base64)\n+      }\n+      ImageFormat.PNG -> {\n+        val base64 = input[RNTIOImageKeyData] as String\n+        bitmapForBase64Data(base64)\n+      }\n+      ImageFormat.File -> {\n+        val filepath = input[RNTIOImageKeyData] as String\n+        BitmapFactory.decodeFile(filepath)\n+      }\n+      ImageFormat.Asset -> {\n+        val name = input[RNTIOImageKeyData] as String\n+        val stream = reactApplicationContext.assets.open(name)\n+        BitmapFactory.decodeStream(stream);\n+      }\n+      ImageFormat.Unknown -> {\n+        null\n+      }\n     }\n+  }\n \n-    \n }"
  },
  {
    "sha": "6a3934e24ac2e943139591b3ca0e6cde06ec5b82",
    "filename": "example/android/app/build.gradle",
    "status": "modified",
    "additions": 5,
    "deletions": 3,
    "changes": 8,
    "blob_url": "https://github.com/doc-ai/react-native-tensorio-tensorflow/blob/87b362141ceed0611b120243452b3d37b30ea246/example/android/app/build.gradle",
    "raw_url": "https://github.com/doc-ai/react-native-tensorio-tensorflow/raw/87b362141ceed0611b120243452b3d37b30ea246/example/android/app/build.gradle",
    "contents_url": "https://api.github.com/repos/doc-ai/react-native-tensorio-tensorflow/contents/example/android/app/build.gradle?ref=87b362141ceed0611b120243452b3d37b30ea246",
    "patch": "@@ -122,6 +122,7 @@ android {\n     compileSdkVersion rootProject.ext.compileSdkVersion\n \n     compileOptions {\n+        coreLibraryDesugaringEnabled true\n         sourceCompatibility JavaVersion.VERSION_1_8\n         targetCompatibility JavaVersion.VERSION_1_8\n     }\n@@ -138,7 +139,7 @@ android {\n             reset()\n             enable enableSeparateBuildPerCPUArchitecture\n             universalApk false  // If true, also generate a universal APK\n-            include \"armeabi-v7a\", \"x86\", \"arm64-v8a\", \"x86_64\"\n+            include \"x86\", \"arm64-v8a\", \"x86_64\"\n         }\n     }\n     signingConfigs {\n@@ -166,7 +167,7 @@ android {\n         variant.outputs.each { output ->\n             // For each separate APK per architecture, set a unique version code as described here:\n             // https://developer.android.com/studio/build/configure-apk-splits.html\n-            def versionCodes = [\"armeabi-v7a\": 1, \"x86\": 2, \"arm64-v8a\": 3, \"x86_64\": 4]\n+            def versionCodes = [\"x86\": 2, \"arm64-v8a\": 3, \"x86_64\": 4]\n             def abi = output.getFilter(OutputFile.ABI)\n             if (abi != null) {  // null for the universal-debug, universal-release variants\n                 output.versionCodeOverride =\n@@ -186,11 +187,12 @@ android {\n \n dependencies {\n     implementation fileTree(dir: \"libs\", include: [\"*.jar\"])\n+  coreLibraryDesugaring 'com.android.tools:desugar_jdk_libs:1.1.5'\n     //noinspection GradleDynamicVersion\n     implementation \"com.facebook.react:react-native:+\"  // From node_modules\n \n \n-    implementation \"androidx.swiperefreshlayout:swiperefreshlayout:1.0.0\"\n+    implementation \"androidx.swiperefreshlayout:swiperefreshlayout:1.1.0\"\n     debugImplementation(\"com.facebook.flipper:flipper:${FLIPPER_VERSION}\") {\n       exclude group:'com.facebook.fbjni'\n     }"
  },
  {
    "sha": "fc5bb88e5ebe55eac8d621fe4aaf969cfa7ce951",
    "filename": "example/android/app/src/main/assets/cat.jpg",
    "status": "added",
    "additions": 0,
    "deletions": 0,
    "changes": 0,
    "blob_url": "https://github.com/doc-ai/react-native-tensorio-tensorflow/blob/87b362141ceed0611b120243452b3d37b30ea246/example/android/app/src/main/assets/cat.jpg",
    "raw_url": "https://github.com/doc-ai/react-native-tensorio-tensorflow/raw/87b362141ceed0611b120243452b3d37b30ea246/example/android/app/src/main/assets/cat.jpg",
    "contents_url": "https://api.github.com/repos/doc-ai/react-native-tensorio-tensorflow/contents/example/android/app/src/main/assets/cat.jpg?ref=87b362141ceed0611b120243452b3d37b30ea246"
  },
  {
    "sha": "1e6b9e17524156e1572367a2a7e326c6900c18dd",
    "filename": "example/android/app/src/main/assets/cats-vs-dogs-predict.tiobundle/model.json",
    "status": "added",
    "additions": 36,
    "deletions": 0,
    "changes": 36,
    "blob_url": "https://github.com/doc-ai/react-native-tensorio-tensorflow/blob/87b362141ceed0611b120243452b3d37b30ea246/example/android/app/src/main/assets/cats-vs-dogs-predict.tiobundle/model.json",
    "raw_url": "https://github.com/doc-ai/react-native-tensorio-tensorflow/raw/87b362141ceed0611b120243452b3d37b30ea246/example/android/app/src/main/assets/cats-vs-dogs-predict.tiobundle/model.json",
    "contents_url": "https://api.github.com/repos/doc-ai/react-native-tensorio-tensorflow/contents/example/android/app/src/main/assets/cats-vs-dogs-predict.tiobundle/model.json?ref=87b362141ceed0611b120243452b3d37b30ea246",
    "patch": "@@ -0,0 +1,36 @@\n+{\n+\t\"name\": \"Cats vs Dogs MobileNet V2 1.0 128\",\n+\t\"details\": \"Cats vs Dogs Kaggle model based on MobileNet V2 architecture with a width multiplier of 1.0 and an input resolution of 128x128.\",\n+\t\"id\": \"cats-vs-dogs-v2-100-128-unquantized\",\n+\t\"version\": \"1\",\n+\t\"author\": \"doc.ai\",\n+\t\"license\": \"Apache License. Version 2.0 http://www.apache.org/licenses/LICENSE-2.0\",\n+\t\"model\": {\n+\t\t\"file\": \"predict\",\n+\t\t\"quantized\": false,\n+\t\t\"type\": \"image.classification.catsvsdogs\",\n+\t\t\"backend\": \"tensorflow\",\n+\t\t\"modes\": [\"predict\"]\n+\t},\n+\t\"inputs\": [\n+\t\t{\n+\t\t\t\"name\": \"image\",\n+\t\t\t\"type\": \"image\",\n+\t\t\t\"shape\": [-1,128,128,3],\n+\t\t\t\"format\": \"RGB\",\n+\t\t\t\"normalize\": {\n+\t\t\t\t\"standard\": \"[0,1]\"\n+\t\t\t}\n+\t\t}\n+\t],\n+\t\"outputs\": [\n+\t\t{\n+\t\t\t\"name\": \"sigmoid\",\n+\t\t\t\"type\": \"array\",\n+\t\t\t\"shape\": [-1,1]\n+\t\t}\n+\t],\n+\t\"options\": {\n+\t\t\"device_position\": \"back\"\n+\t}\n+}"
  },
  {
    "sha": "93acccf4b4c6466380887e6fa42e181a1734e9d3",
    "filename": "example/android/app/src/main/assets/cats-vs-dogs-predict.tiobundle/predict/saved_model.pb",
    "status": "added",
    "additions": 0,
    "deletions": 0,
    "changes": 0,
    "blob_url": "https://github.com/doc-ai/react-native-tensorio-tensorflow/blob/87b362141ceed0611b120243452b3d37b30ea246/example/android/app/src/main/assets/cats-vs-dogs-predict.tiobundle/predict/saved_model.pb",
    "raw_url": "https://github.com/doc-ai/react-native-tensorio-tensorflow/raw/87b362141ceed0611b120243452b3d37b30ea246/example/android/app/src/main/assets/cats-vs-dogs-predict.tiobundle/predict/saved_model.pb",
    "contents_url": "https://api.github.com/repos/doc-ai/react-native-tensorio-tensorflow/contents/example/android/app/src/main/assets/cats-vs-dogs-predict.tiobundle/predict/saved_model.pb?ref=87b362141ceed0611b120243452b3d37b30ea246"
  },
  {
    "sha": "26aae2e7570cc44448ca1b43faf6391e03f83333",
    "filename": "example/android/app/src/main/assets/cats-vs-dogs-predict.tiobundle/predict/variables/variables.data-00000-of-00001",
    "status": "added",
    "additions": 0,
    "deletions": 0,
    "changes": 0,
    "blob_url": "https://github.com/doc-ai/react-native-tensorio-tensorflow/blob/87b362141ceed0611b120243452b3d37b30ea246/example/android/app/src/main/assets/cats-vs-dogs-predict.tiobundle/predict/variables/variables.data-00000-of-00001",
    "raw_url": "https://github.com/doc-ai/react-native-tensorio-tensorflow/raw/87b362141ceed0611b120243452b3d37b30ea246/example/android/app/src/main/assets/cats-vs-dogs-predict.tiobundle/predict/variables/variables.data-00000-of-00001",
    "contents_url": "https://api.github.com/repos/doc-ai/react-native-tensorio-tensorflow/contents/example/android/app/src/main/assets/cats-vs-dogs-predict.tiobundle/predict/variables/variables.data-00000-of-00001?ref=87b362141ceed0611b120243452b3d37b30ea246"
  },
  {
    "sha": "f5d6c37e2532b97574ced6cc4da295946afbd849",
    "filename": "example/android/app/src/main/assets/cats-vs-dogs-predict.tiobundle/predict/variables/variables.index",
    "status": "added",
    "additions": 0,
    "deletions": 0,
    "changes": 0,
    "blob_url": "https://github.com/doc-ai/react-native-tensorio-tensorflow/blob/87b362141ceed0611b120243452b3d37b30ea246/example/android/app/src/main/assets/cats-vs-dogs-predict.tiobundle/predict/variables/variables.index",
    "raw_url": "https://github.com/doc-ai/react-native-tensorio-tensorflow/raw/87b362141ceed0611b120243452b3d37b30ea246/example/android/app/src/main/assets/cats-vs-dogs-predict.tiobundle/predict/variables/variables.index",
    "contents_url": "https://api.github.com/repos/doc-ai/react-native-tensorio-tensorflow/contents/example/android/app/src/main/assets/cats-vs-dogs-predict.tiobundle/predict/variables/variables.index?ref=87b362141ceed0611b120243452b3d37b30ea246"
  },
  {
    "sha": "c614ff08d70ce1a40396fe3e63fb9095fc217f75",
    "filename": "example/android/app/src/main/assets/cats-vs-dogs-train.tiobundle/model.json",
    "status": "added",
    "additions": 42,
    "deletions": 0,
    "changes": 42,
    "blob_url": "https://github.com/doc-ai/react-native-tensorio-tensorflow/blob/87b362141ceed0611b120243452b3d37b30ea246/example/android/app/src/main/assets/cats-vs-dogs-train.tiobundle/model.json",
    "raw_url": "https://github.com/doc-ai/react-native-tensorio-tensorflow/raw/87b362141ceed0611b120243452b3d37b30ea246/example/android/app/src/main/assets/cats-vs-dogs-train.tiobundle/model.json",
    "contents_url": "https://api.github.com/repos/doc-ai/react-native-tensorio-tensorflow/contents/example/android/app/src/main/assets/cats-vs-dogs-train.tiobundle/model.json?ref=87b362141ceed0611b120243452b3d37b30ea246",
    "patch": "@@ -0,0 +1,42 @@\n+{\n+\t\"name\": \"Cats vs Dogs MobileNet V2 1.0 128\",\n+\t\"details\": \"Cats vs Dogs Kaggle model based on MobileNet V2 architecture with a width multiplier of 1.0 and an input resolution of 128x128.\",\n+\t\"id\": \"cats-vs-dogs-v2-100-128-unquantized\",\n+\t\"version\": \"1\",\n+\t\"author\": \"doc.ai\",\n+\t\"license\": \"Apache License. Version 2.0 http://www.apache.org/licenses/LICENSE-2.0\",\n+\t\"model\": {\n+\t\t\"file\": \"train\",\n+\t\t\"quantized\": false,\n+\t\t\"type\": \"image.classification.catsvsdogs\",\n+\t\t\"backend\": \"tensorflow\",\n+\t\t\"modes\": [\"train\"]\n+\t},\n+\t\"inputs\": [\n+\t\t{\n+\t\t\t\"name\": \"image\",\n+\t\t\t\"type\": \"image\",\n+\t\t\t\"shape\": [-1,128,128,3],\n+\t\t\t\"format\": \"RGB\",\n+\t\t\t\"normalize\": { \"standard\": \"[0,1]\" }\n+\t\t},\n+\t\t{\n+\t\t\t\"name\": \"labels\",\n+\t\t\t\"type\": \"array\",\n+\t\t\t\"dtype\": \"int32\",\n+\t\t\t\"shape\": [-1,1]\n+\t\t}\n+\t],\n+\t\"outputs\": [\n+\t\t{\n+\t\t\t\"name\": \"sigmoid_cross_entropy_loss/value\",\n+\t\t\t\"type\": \"array\",\n+\t\t\t\"shape\": [1]\n+\t\t}\n+\t],\n+\t\"train\": {\n+\t\t\"ops\": [\n+\t\t\t\"train\"\n+\t\t]\n+\t}\n+}"
  },
  {
    "sha": "651156b54cad03293f87192da5683866cea8ec7a",
    "filename": "example/android/app/src/main/assets/cats-vs-dogs-train.tiobundle/train/saved_model.pb",
    "status": "added",
    "additions": 0,
    "deletions": 0,
    "changes": 0,
    "blob_url": "https://github.com/doc-ai/react-native-tensorio-tensorflow/blob/87b362141ceed0611b120243452b3d37b30ea246/example/android/app/src/main/assets/cats-vs-dogs-train.tiobundle/train/saved_model.pb",
    "raw_url": "https://github.com/doc-ai/react-native-tensorio-tensorflow/raw/87b362141ceed0611b120243452b3d37b30ea246/example/android/app/src/main/assets/cats-vs-dogs-train.tiobundle/train/saved_model.pb",
    "contents_url": "https://api.github.com/repos/doc-ai/react-native-tensorio-tensorflow/contents/example/android/app/src/main/assets/cats-vs-dogs-train.tiobundle/train/saved_model.pb?ref=87b362141ceed0611b120243452b3d37b30ea246"
  },
  {
    "sha": "a9c497d8f0c10778b65b0f7161079b1536da564e",
    "filename": "example/android/app/src/main/assets/cats-vs-dogs-train.tiobundle/train/variables/variables.data-00000-of-00001",
    "status": "added",
    "additions": 0,
    "deletions": 0,
    "changes": 0,
    "blob_url": "https://github.com/doc-ai/react-native-tensorio-tensorflow/blob/87b362141ceed0611b120243452b3d37b30ea246/example/android/app/src/main/assets/cats-vs-dogs-train.tiobundle/train/variables/variables.data-00000-of-00001",
    "raw_url": "https://github.com/doc-ai/react-native-tensorio-tensorflow/raw/87b362141ceed0611b120243452b3d37b30ea246/example/android/app/src/main/assets/cats-vs-dogs-train.tiobundle/train/variables/variables.data-00000-of-00001",
    "contents_url": "https://api.github.com/repos/doc-ai/react-native-tensorio-tensorflow/contents/example/android/app/src/main/assets/cats-vs-dogs-train.tiobundle/train/variables/variables.data-00000-of-00001?ref=87b362141ceed0611b120243452b3d37b30ea246"
  },
  {
    "sha": "1055b0a2210e530f2715eee05093ea2549c8f326",
    "filename": "example/android/app/src/main/assets/cats-vs-dogs-train.tiobundle/train/variables/variables.index",
    "status": "added",
    "additions": 0,
    "deletions": 0,
    "changes": 0,
    "blob_url": "https://github.com/doc-ai/react-native-tensorio-tensorflow/blob/87b362141ceed0611b120243452b3d37b30ea246/example/android/app/src/main/assets/cats-vs-dogs-train.tiobundle/train/variables/variables.index",
    "raw_url": "https://github.com/doc-ai/react-native-tensorio-tensorflow/raw/87b362141ceed0611b120243452b3d37b30ea246/example/android/app/src/main/assets/cats-vs-dogs-train.tiobundle/train/variables/variables.index",
    "contents_url": "https://api.github.com/repos/doc-ai/react-native-tensorio-tensorflow/contents/example/android/app/src/main/assets/cats-vs-dogs-train.tiobundle/train/variables/variables.index?ref=87b362141ceed0611b120243452b3d37b30ea246"
  },
  {
    "sha": "5a3c944a6b8645b7f26221df22953f936cc22899",
    "filename": "example/android/app/src/main/assets/dog.jpg",
    "status": "added",
    "additions": 0,
    "deletions": 0,
    "changes": 0,
    "blob_url": "https://github.com/doc-ai/react-native-tensorio-tensorflow/blob/87b362141ceed0611b120243452b3d37b30ea246/example/android/app/src/main/assets/dog.jpg",
    "raw_url": "https://github.com/doc-ai/react-native-tensorio-tensorflow/raw/87b362141ceed0611b120243452b3d37b30ea246/example/android/app/src/main/assets/dog.jpg",
    "contents_url": "https://api.github.com/repos/doc-ai/react-native-tensorio-tensorflow/contents/example/android/app/src/main/assets/dog.jpg?ref=87b362141ceed0611b120243452b3d37b30ea246"
  },
  {
    "sha": "459096c1984ac9c7bd385df35c44eeff9f233ffe",
    "filename": "example/android/build.gradle",
    "status": "modified",
    "additions": 2,
    "deletions": 2,
    "changes": 4,
    "blob_url": "https://github.com/doc-ai/react-native-tensorio-tensorflow/blob/87b362141ceed0611b120243452b3d37b30ea246/example/android/build.gradle",
    "raw_url": "https://github.com/doc-ai/react-native-tensorio-tensorflow/raw/87b362141ceed0611b120243452b3d37b30ea246/example/android/build.gradle",
    "contents_url": "https://api.github.com/repos/doc-ai/react-native-tensorio-tensorflow/contents/example/android/build.gradle?ref=87b362141ceed0611b120243452b3d37b30ea246",
    "patch": "@@ -3,7 +3,7 @@\n buildscript {\n     ext {\n         buildToolsVersion = \"28.0.3\"\n-        minSdkVersion = 16\n+        minSdkVersion = 22\n         compileSdkVersion = 28\n         targetSdkVersion = 28\n     }\n@@ -12,7 +12,7 @@ buildscript {\n         jcenter()\n     }\n     dependencies {\n-        classpath(\"com.android.tools.build:gradle:3.5.2\")\n+        classpath(\"com.android.tools.build:gradle:4.1.1\")\n \n         // NOTE: Do not place your application dependencies here; they belong\n         // in the individual module build.gradle files"
  },
  {
    "sha": "9c13980c2d25078cd44865a68873965e3c29bd82",
    "filename": "example/android/gradle.properties",
    "status": "modified",
    "additions": 1,
    "deletions": 0,
    "changes": 1,
    "blob_url": "https://github.com/doc-ai/react-native-tensorio-tensorflow/blob/87b362141ceed0611b120243452b3d37b30ea246/example/android/gradle.properties",
    "raw_url": "https://github.com/doc-ai/react-native-tensorio-tensorflow/raw/87b362141ceed0611b120243452b3d37b30ea246/example/android/gradle.properties",
    "contents_url": "https://api.github.com/repos/doc-ai/react-native-tensorio-tensorflow/contents/example/android/gradle.properties?ref=87b362141ceed0611b120243452b3d37b30ea246",
    "patch": "@@ -17,6 +17,7 @@\n # http://www.gradle.org/docs/current/userguide/multi_project_builds.html#sec:decoupled_projects\n # org.gradle.parallel=true\n \n+org.gradle.jvmargs=-Xms512M -Xmx4g -XX:MaxPermSize=1024m -XX:MaxMetaspaceSize=1g -Dkotlin.daemon.jvm.options=\"-Xmx1g\"\n android.useAndroidX=true\n android.enableJetifier=true\n FLIPPER_VERSION=0.33.1"
  },
  {
    "sha": "622ab64a3cb60378cd29384961554c0b032c9368",
    "filename": "example/android/gradle/wrapper/gradle-wrapper.properties",
    "status": "modified",
    "additions": 1,
    "deletions": 1,
    "changes": 2,
    "blob_url": "https://github.com/doc-ai/react-native-tensorio-tensorflow/blob/87b362141ceed0611b120243452b3d37b30ea246/example/android/gradle/wrapper/gradle-wrapper.properties",
    "raw_url": "https://github.com/doc-ai/react-native-tensorio-tensorflow/raw/87b362141ceed0611b120243452b3d37b30ea246/example/android/gradle/wrapper/gradle-wrapper.properties",
    "contents_url": "https://api.github.com/repos/doc-ai/react-native-tensorio-tensorflow/contents/example/android/gradle/wrapper/gradle-wrapper.properties?ref=87b362141ceed0611b120243452b3d37b30ea246",
    "patch": "@@ -1,5 +1,5 @@\n distributionBase=GRADLE_USER_HOME\n distributionPath=wrapper/dists\n-distributionUrl=https\\://services.gradle.org/distributions/gradle-6.0.1-all.zip\n+distributionUrl=https\\://services.gradle.org/distributions/gradle-6.5-bin.zip\n zipStoreBase=GRADLE_USER_HOME\n zipStorePath=wrapper/dists"
  },
  {
    "sha": "f15087b08bec84b82e9c6eda359cc4c88fe36691",
    "filename": "example/ios/Podfile",
    "status": "modified",
    "additions": 14,
    "deletions": 0,
    "changes": 14,
    "blob_url": "https://github.com/doc-ai/react-native-tensorio-tensorflow/blob/87b362141ceed0611b120243452b3d37b30ea246/example/ios/Podfile",
    "raw_url": "https://github.com/doc-ai/react-native-tensorio-tensorflow/raw/87b362141ceed0611b120243452b3d37b30ea246/example/ios/Podfile",
    "contents_url": "https://api.github.com/repos/doc-ai/react-native-tensorio-tensorflow/contents/example/ios/Podfile?ref=87b362141ceed0611b120243452b3d37b30ea246",
    "patch": "@@ -8,6 +8,10 @@ def add_flipper_pods!\n   pod 'FlipperKit/SKIOSNetworkPlugin', version, :configuration => 'Debug'\n   pod 'FlipperKit/FlipperKitUserDefaultsPlugin', version, :configuration => 'Debug'\n   pod 'FlipperKit/FlipperKitReactPlugin', version, :configuration => 'Debug'\n+\n+  # Flipper seems broken?\n+  # https://github.com/facebook/react-native/issues/30836\n+  pod 'Flipper-Folly', '2.3.0', :configuration => 'Debug'\n end\n # Post Install processing for Flipper\n def flipper_post_install(installer)\n@@ -61,8 +65,18 @@ target 'TensorioTensorflowExample' do\n   #\n   # Note that if you have use_frameworks! enabled, Flipper will not work and\n   # you should disable these next few lines.\n+  \n   add_flipper_pods!\n+  \n   post_install do |installer|\n     flipper_post_install(installer)\n+    \n+    # https://github.com/facebook/react-native/issues/28503#issuecomment-710041013\n+    installer.pods_project.targets.each do |target|\n+      target.build_configurations.each do |config|\n+        config.build_settings['IPHONEOS_DEPLOYMENT_TARGET'] = '12.0'\n+      end\n+    end\n   end\n+\n end"
  },
  {
    "sha": "2ef090d98f632e0d6344c913aa73f430555f2e50",
    "filename": "example/ios/Podfile.lock",
    "status": "modified",
    "additions": 17,
    "deletions": 16,
    "changes": 33,
    "blob_url": "https://github.com/doc-ai/react-native-tensorio-tensorflow/blob/87b362141ceed0611b120243452b3d37b30ea246/example/ios/Podfile.lock",
    "raw_url": "https://github.com/doc-ai/react-native-tensorio-tensorflow/raw/87b362141ceed0611b120243452b3d37b30ea246/example/ios/Podfile.lock",
    "contents_url": "https://api.github.com/repos/doc-ai/react-native-tensorio-tensorflow/contents/example/ios/Podfile.lock?ref=87b362141ceed0611b120243452b3d37b30ea246",
    "patch": "@@ -1,6 +1,6 @@\n PODS:\n   - boost-for-react-native (1.63.0)\n-  - CocoaAsyncSocket (7.6.4)\n+  - CocoaAsyncSocket (7.6.5)\n   - CocoaLibEvent (1.0.0)\n   - DoubleConversion (1.1.6)\n   - DSJSONSchemaValidation (2.0.7)\n@@ -24,8 +24,8 @@ PODS:\n     - OpenSSL-Universal (= 1.0.2.20)\n   - Flipper-Glog (0.3.6)\n   - Flipper-PeerTalk (0.0.4)\n-  - Flipper-RSocket (1.1.0):\n-    - Flipper-Folly (~> 2.2)\n+  - Flipper-RSocket (1.1.1):\n+    - Flipper-Folly (~> 2.3)\n   - FlipperKit (0.33.1):\n     - FlipperKit/Core (= 0.33.1)\n   - FlipperKit/Core (0.33.1):\n@@ -297,16 +297,16 @@ PODS:\n     - React-cxxreact (= 0.62.2)\n     - React-jsi (= 0.62.2)\n     - ReactCommon/callinvoker (= 0.62.2)\n-  - TensorIO (1.2.3):\n+  - TensorIO (1.2.4):\n     - DSJSONSchemaValidation\n-    - TensorIO/Core (= 1.2.3)\n-  - TensorIO/Core (1.2.3):\n+    - TensorIO/Core (= 1.2.4)\n+  - TensorIO/Core (1.2.4):\n     - DSJSONSchemaValidation\n-  - TensorIO/TensorFlow (1.2.3):\n+  - TensorIO/TensorFlow (1.2.4):\n     - DSJSONSchemaValidation\n     - TensorIO/Core\n-    - TensorIOTensorFlow (~> 2.0.3)\n-  - TensorIOTensorFlow (2.0.7)\n+    - TensorIOTensorFlow (~> 2.0.8)\n+  - TensorIOTensorFlow (2.0.8)\n   - Yoga (1.14.0)\n   - YogaKit (1.18.1):\n     - Yoga (~> 1.14)\n@@ -315,6 +315,7 @@ DEPENDENCIES:\n   - DoubleConversion (from `../node_modules/react-native/third-party-podspecs/DoubleConversion.podspec`)\n   - FBLazyVector (from `../node_modules/react-native/Libraries/FBLazyVector`)\n   - FBReactNativeSpec (from `../node_modules/react-native/Libraries/FBReactNativeSpec`)\n+  - Flipper-Folly (= 2.3.0)\n   - FlipperKit (~> 0.33.1)\n   - FlipperKit/FlipperKitLayoutPlugin (~> 0.33.1)\n   - FlipperKit/FlipperKitReactPlugin (~> 0.33.1)\n@@ -421,7 +422,7 @@ EXTERNAL SOURCES:\n \n SPEC CHECKSUMS:\n   boost-for-react-native: 39c7adb57c4e60d6c5479dd8623128eb5b3f0f2c\n-  CocoaAsyncSocket: 694058e7c0ed05a9e217d1b3c7ded962f4180845\n+  CocoaAsyncSocket: 065fd1e645c7abab64f7a6a2007a48038fdc6a99\n   CocoaLibEvent: 2fab71b8bd46dd33ddb959f7928ec5909f838e3f\n   DoubleConversion: 5805e889d232975c086db112ece9ed034df7a0b2\n   DSJSONSchemaValidation: 46e30ccfa9908c49d184f453d556f55aa0aac1ff\n@@ -432,7 +433,7 @@ SPEC CHECKSUMS:\n   Flipper-Folly: e4493b013c02d9347d5e0cb4d128680239f6c78a\n   Flipper-Glog: 1dfd6abf1e922806c52ceb8701a3599a79a200a6\n   Flipper-PeerTalk: 116d8f857dc6ef55c7a5a75ea3ceaafe878aadc9\n-  Flipper-RSocket: 64e7431a55835eb953b0bf984ef3b90ae9fdddd7\n+  Flipper-RSocket: a3acb8812d6adf127deb0a5edae2793b97e6b641\n   FlipperKit: 6dc9b8f4ef60d9e5ded7f0264db299c91f18832e\n   Folly: 30e7936e1c45c08d884aa59369ed951a8e68cf51\n   glog: 1f3da668190260b06b429bb211bfbee5cd790c28\n@@ -446,7 +447,7 @@ SPEC CHECKSUMS:\n   React-jsi: b6dc94a6a12ff98e8877287a0b7620d365201161\n   React-jsiexecutor: 1540d1c01bb493ae3124ed83351b1b6a155db7da\n   React-jsinspector: 512e560d0e985d0e8c479a54a4e5c147a9c83493\n-  react-native-tensorio-tensorflow: a0cdd11e749f762732d88dd8a814ededf48f1e01\n+  react-native-tensorio-tensorflow: f888a7410e5f90737a6666418be481efdb101cfd\n   React-RCTActionSheet: f41ea8a811aac770e0cc6e0ad6b270c644ea8b7c\n   React-RCTAnimation: 49ab98b1c1ff4445148b72a3d61554138565bad0\n   React-RCTBlob: a332773f0ebc413a0ce85942a55b064471587a71\n@@ -457,11 +458,11 @@ SPEC CHECKSUMS:\n   React-RCTText: fae545b10cfdb3d247c36c56f61a94cfd6dba41d\n   React-RCTVibration: 4356114dbcba4ce66991096e51a66e61eda51256\n   ReactCommon: ed4e11d27609d571e7eee8b65548efc191116eb3\n-  TensorIO: cb64c2b34b356d074f5bc403192511a4e2cc9e12\n-  TensorIOTensorFlow: 1a1a7bb4f45fde1bc5fb1b31571f1e1c72b88ad0\n+  TensorIO: 801d07e7d7d20db0b1c617bf6ad54dd8f58e1d7d\n+  TensorIOTensorFlow: e736ed822f872705ff91758e579064614906a3d4\n   Yoga: 3ebccbdd559724312790e7742142d062476b698e\n   YogaKit: f782866e155069a2cca2517aafea43200b01fd5a\n \n-PODFILE CHECKSUM: f1c961033c7edd0a4c251688b32f234763574338\n+PODFILE CHECKSUM: 0585743235845577fd9a6e6845d1e7d8e9be2353\n \n-COCOAPODS: 1.10.0\n+COCOAPODS: 1.10.1"
  },
  {
    "sha": "0954f302fc94be2edc2211aa761a09a8cd2098a0",
    "filename": "example/ios/TensorioTensorflowExample.xcodeproj/project.pbxproj",
    "status": "modified",
    "additions": 15,
    "deletions": 2,
    "changes": 17,
    "blob_url": "https://github.com/doc-ai/react-native-tensorio-tensorflow/blob/87b362141ceed0611b120243452b3d37b30ea246/example/ios/TensorioTensorflowExample.xcodeproj/project.pbxproj",
    "raw_url": "https://github.com/doc-ai/react-native-tensorio-tensorflow/raw/87b362141ceed0611b120243452b3d37b30ea246/example/ios/TensorioTensorflowExample.xcodeproj/project.pbxproj",
    "contents_url": "https://api.github.com/repos/doc-ai/react-native-tensorio-tensorflow/contents/example/ios/TensorioTensorflowExample.xcodeproj/project.pbxproj?ref=87b362141ceed0611b120243452b3d37b30ea246",
    "patch": "@@ -13,6 +13,8 @@\n \t\t13B07FBF1A68108700A75B9A /* Images.xcassets in Resources */ = {isa = PBXBuildFile; fileRef = 13B07FB51A68108700A75B9A /* Images.xcassets */; };\n \t\t13B07FC11A68108700A75B9A /* main.m in Sources */ = {isa = PBXBuildFile; fileRef = 13B07FB71A68108700A75B9A /* main.m */; };\n \t\t20F357B024636CDF00C146DC /* File.swift in Sources */ = {isa = PBXBuildFile; fileRef = 20F357AF24636CDF00C146DC /* File.swift */; };\n+\t\tE3D3A87B25F823B2007410B5 /* cats-vs-dogs-predict.tiobundle in Resources */ = {isa = PBXBuildFile; fileRef = E3D3A87A25F823B2007410B5 /* cats-vs-dogs-predict.tiobundle */; };\n+\t\tE3D3A8CC26012C49007410B5 /* cats-vs-dogs-train.tiobundle in Resources */ = {isa = PBXBuildFile; fileRef = E3D3A8CB26012C49007410B5 /* cats-vs-dogs-train.tiobundle */; };\n /* End PBXBuildFile section */\n \n /* Begin PBXFileReference section */\n@@ -30,6 +32,8 @@\n \t\t4D7192F03A36A017E887435B /* Pods-TensorioTensorflowExample.release.xcconfig */ = {isa = PBXFileReference; includeInIndex = 1; lastKnownFileType = text.xcconfig; name = \"Pods-TensorioTensorflowExample.release.xcconfig\"; path = \"Target Support Files/Pods-TensorioTensorflowExample/Pods-TensorioTensorflowExample.release.xcconfig\"; sourceTree = \"<group>\"; };\n \t\t871719007ECC5EAD276C345C /* Pods-TensorioTensorflowExample.debug.xcconfig */ = {isa = PBXFileReference; includeInIndex = 1; lastKnownFileType = text.xcconfig; name = \"Pods-TensorioTensorflowExample.debug.xcconfig\"; path = \"Target Support Files/Pods-TensorioTensorflowExample/Pods-TensorioTensorflowExample.debug.xcconfig\"; sourceTree = \"<group>\"; };\n \t\tBCEA90A70F4BEAD7E9FA28B2 /* libPods-TensorioTensorflowExample.a */ = {isa = PBXFileReference; explicitFileType = archive.ar; includeInIndex = 0; path = \"libPods-TensorioTensorflowExample.a\"; sourceTree = BUILT_PRODUCTS_DIR; };\n+\t\tE3D3A87A25F823B2007410B5 /* cats-vs-dogs-predict.tiobundle */ = {isa = PBXFileReference; lastKnownFileType = folder; path = \"cats-vs-dogs-predict.tiobundle\"; sourceTree = \"<group>\"; };\n+\t\tE3D3A8CB26012C49007410B5 /* cats-vs-dogs-train.tiobundle */ = {isa = PBXFileReference; lastKnownFileType = folder; path = \"cats-vs-dogs-train.tiobundle\"; sourceTree = \"<group>\"; };\n \t\tED297162215061F000B7C4FE /* JavaScriptCore.framework */ = {isa = PBXFileReference; lastKnownFileType = wrapper.framework; name = JavaScriptCore.framework; path = System/Library/Frameworks/JavaScriptCore.framework; sourceTree = SDKROOT; };\n /* End PBXFileReference section */\n \n@@ -48,6 +52,8 @@\n \t\t13B07FAE1A68108700A75B9A /* TensorioTensorflowExample */ = {\n \t\t\tisa = PBXGroup;\n \t\t\tchildren = (\n+\t\t\t\tE3D3A87A25F823B2007410B5 /* cats-vs-dogs-predict.tiobundle */,\n+\t\t\t\tE3D3A8CB26012C49007410B5 /* cats-vs-dogs-train.tiobundle */,\n \t\t\t\t008F07F21AC5B25A0029DE68 /* main.jsbundle */,\n \t\t\t\t13B07FAF1A68108700A75B9A /* AppDelegate.h */,\n \t\t\t\t13B07FB01A68108700A75B9A /* AppDelegate.m */,\n@@ -143,6 +149,7 @@\n \t\t\t\tORGANIZATIONNAME = Facebook;\n \t\t\t\tTargetAttributes = {\n \t\t\t\t\t13B07F861A680F5B00A75B9A = {\n+\t\t\t\t\t\tDevelopmentTeam = 8DK246H2T6;\n \t\t\t\t\t\tLastSwiftMigration = 1110;\n \t\t\t\t\t};\n \t\t\t\t};\n@@ -171,7 +178,9 @@\n \t\t\tisa = PBXResourcesBuildPhase;\n \t\t\tbuildActionMask = 2147483647;\n \t\t\tfiles = (\n+\t\t\t\tE3D3A87B25F823B2007410B5 /* cats-vs-dogs-predict.tiobundle in Resources */,\n \t\t\t\t13B07FBF1A68108700A75B9A /* Images.xcassets in Resources */,\n+\t\t\t\tE3D3A8CC26012C49007410B5 /* cats-vs-dogs-train.tiobundle in Resources */,\n \t\t\t\t13B07FBD1A68108700A75B9A /* LaunchScreen.xib in Resources */,\n \t\t\t);\n \t\t\trunOnlyForDeploymentPostprocessing = 0;\n@@ -288,7 +297,9 @@\n \t\t\t\tCLANG_ENABLE_MODULES = YES;\n \t\t\t\tCURRENT_PROJECT_VERSION = 1;\n \t\t\t\tDEAD_CODE_STRIPPING = NO;\n+\t\t\t\tDEVELOPMENT_TEAM = 8DK246H2T6;\n \t\t\t\tINFOPLIST_FILE = TensorioTensorflowExample/Info.plist;\n+\t\t\t\tIPHONEOS_DEPLOYMENT_TARGET = 12.0;\n \t\t\t\tLD_RUNPATH_SEARCH_PATHS = \"$(inherited) @executable_path/Frameworks\";\n \t\t\t\tOTHER_CFLAGS = (\n \t\t\t\t\t\"$(inherited)\",\n@@ -315,7 +326,9 @@\n \t\t\t\tASSETCATALOG_COMPILER_APPICON_NAME = AppIcon;\n \t\t\t\tCLANG_ENABLE_MODULES = YES;\n \t\t\t\tCURRENT_PROJECT_VERSION = 1;\n+\t\t\t\tDEVELOPMENT_TEAM = 8DK246H2T6;\n \t\t\t\tINFOPLIST_FILE = TensorioTensorflowExample/Info.plist;\n+\t\t\t\tIPHONEOS_DEPLOYMENT_TARGET = 12.0;\n \t\t\t\tLD_RUNPATH_SEARCH_PATHS = \"$(inherited) @executable_path/Frameworks\";\n \t\t\t\tOTHER_CFLAGS = (\n \t\t\t\t\t\"$(inherited)\",\n@@ -380,7 +393,7 @@\n \t\t\t\tGCC_WARN_UNINITIALIZED_AUTOS = YES_AGGRESSIVE;\n \t\t\t\tGCC_WARN_UNUSED_FUNCTION = YES;\n \t\t\t\tGCC_WARN_UNUSED_VARIABLE = YES;\n-\t\t\t\tIPHONEOS_DEPLOYMENT_TARGET = 9.0;\n+\t\t\t\tIPHONEOS_DEPLOYMENT_TARGET = 12;\n \t\t\t\tMTL_ENABLE_DEBUG_INFO = YES;\n \t\t\t\tONLY_ACTIVE_ARCH = YES;\n \t\t\t\tSDKROOT = iphoneos;\n@@ -426,7 +439,7 @@\n \t\t\t\tGCC_WARN_UNINITIALIZED_AUTOS = YES_AGGRESSIVE;\n \t\t\t\tGCC_WARN_UNUSED_FUNCTION = YES;\n \t\t\t\tGCC_WARN_UNUSED_VARIABLE = YES;\n-\t\t\t\tIPHONEOS_DEPLOYMENT_TARGET = 9.0;\n+\t\t\t\tIPHONEOS_DEPLOYMENT_TARGET = 12;\n \t\t\t\tMTL_ENABLE_DEBUG_INFO = NO;\n \t\t\t\tSDKROOT = iphoneos;\n \t\t\t\tVALIDATE_PRODUCT = YES;"
  },
  {
    "sha": "81213230deb40de5b032ae0e05f5c74196cc1b07",
    "filename": "example/ios/TensorioTensorflowExample/Images.xcassets/AppIcon.appiconset/Contents.json",
    "status": "modified",
    "additions": 30,
    "deletions": 15,
    "changes": 45,
    "blob_url": "https://github.com/doc-ai/react-native-tensorio-tensorflow/blob/87b362141ceed0611b120243452b3d37b30ea246/example/ios/TensorioTensorflowExample/Images.xcassets/AppIcon.appiconset/Contents.json",
    "raw_url": "https://github.com/doc-ai/react-native-tensorio-tensorflow/raw/87b362141ceed0611b120243452b3d37b30ea246/example/ios/TensorioTensorflowExample/Images.xcassets/AppIcon.appiconset/Contents.json",
    "contents_url": "https://api.github.com/repos/doc-ai/react-native-tensorio-tensorflow/contents/example/ios/TensorioTensorflowExample/Images.xcassets/AppIcon.appiconset/Contents.json?ref=87b362141ceed0611b120243452b3d37b30ea246",
    "patch": "@@ -2,37 +2,52 @@\n   \"images\" : [\n     {\n       \"idiom\" : \"iphone\",\n-      \"size\" : \"29x29\",\n-      \"scale\" : \"2x\"\n+      \"scale\" : \"2x\",\n+      \"size\" : \"20x20\"\n     },\n     {\n       \"idiom\" : \"iphone\",\n-      \"size\" : \"29x29\",\n-      \"scale\" : \"3x\"\n+      \"scale\" : \"3x\",\n+      \"size\" : \"20x20\"\n     },\n     {\n       \"idiom\" : \"iphone\",\n-      \"size\" : \"40x40\",\n-      \"scale\" : \"2x\"\n+      \"scale\" : \"2x\",\n+      \"size\" : \"29x29\"\n     },\n     {\n       \"idiom\" : \"iphone\",\n-      \"size\" : \"40x40\",\n-      \"scale\" : \"3x\"\n+      \"scale\" : \"3x\",\n+      \"size\" : \"29x29\"\n     },\n     {\n       \"idiom\" : \"iphone\",\n-      \"size\" : \"60x60\",\n-      \"scale\" : \"2x\"\n+      \"scale\" : \"2x\",\n+      \"size\" : \"40x40\"\n     },\n     {\n       \"idiom\" : \"iphone\",\n-      \"size\" : \"60x60\",\n-      \"scale\" : \"3x\"\n+      \"scale\" : \"3x\",\n+      \"size\" : \"40x40\"\n+    },\n+    {\n+      \"idiom\" : \"iphone\",\n+      \"scale\" : \"2x\",\n+      \"size\" : \"60x60\"\n+    },\n+    {\n+      \"idiom\" : \"iphone\",\n+      \"scale\" : \"3x\",\n+      \"size\" : \"60x60\"\n+    },\n+    {\n+      \"idiom\" : \"ios-marketing\",\n+      \"scale\" : \"1x\",\n+      \"size\" : \"1024x1024\"\n     }\n   ],\n   \"info\" : {\n-    \"version\" : 1,\n-    \"author\" : \"xcode\"\n+    \"author\" : \"xcode\",\n+    \"version\" : 1\n   }\n-}\n\\ No newline at end of file\n+}"
  },
  {
    "sha": "73c00596a7fca3f3d4bdd64053b69d86745f9e10",
    "filename": "example/ios/TensorioTensorflowExample/Images.xcassets/Contents.json",
    "status": "modified",
    "additions": 2,
    "deletions": 2,
    "changes": 4,
    "blob_url": "https://github.com/doc-ai/react-native-tensorio-tensorflow/blob/87b362141ceed0611b120243452b3d37b30ea246/example/ios/TensorioTensorflowExample/Images.xcassets/Contents.json",
    "raw_url": "https://github.com/doc-ai/react-native-tensorio-tensorflow/raw/87b362141ceed0611b120243452b3d37b30ea246/example/ios/TensorioTensorflowExample/Images.xcassets/Contents.json",
    "contents_url": "https://api.github.com/repos/doc-ai/react-native-tensorio-tensorflow/contents/example/ios/TensorioTensorflowExample/Images.xcassets/Contents.json?ref=87b362141ceed0611b120243452b3d37b30ea246",
    "patch": "@@ -1,6 +1,6 @@\n {\n   \"info\" : {\n-    \"version\" : 1,\n-    \"author\" : \"xcode\"\n+    \"author\" : \"xcode\",\n+    \"version\" : 1\n   }\n }"
  },
  {
    "sha": "04206fe6b1a2f80ce0595ca755894e8b159336ca",
    "filename": "example/ios/TensorioTensorflowExample/Images.xcassets/cat.imageset/Contents.json",
    "status": "added",
    "additions": 21,
    "deletions": 0,
    "changes": 21,
    "blob_url": "https://github.com/doc-ai/react-native-tensorio-tensorflow/blob/87b362141ceed0611b120243452b3d37b30ea246/example/ios/TensorioTensorflowExample/Images.xcassets/cat.imageset/Contents.json",
    "raw_url": "https://github.com/doc-ai/react-native-tensorio-tensorflow/raw/87b362141ceed0611b120243452b3d37b30ea246/example/ios/TensorioTensorflowExample/Images.xcassets/cat.imageset/Contents.json",
    "contents_url": "https://api.github.com/repos/doc-ai/react-native-tensorio-tensorflow/contents/example/ios/TensorioTensorflowExample/Images.xcassets/cat.imageset/Contents.json?ref=87b362141ceed0611b120243452b3d37b30ea246",
    "patch": "@@ -0,0 +1,21 @@\n+{\n+  \"images\" : [\n+    {\n+      \"filename\" : \"cat.jpg\",\n+      \"idiom\" : \"universal\",\n+      \"scale\" : \"1x\"\n+    },\n+    {\n+      \"idiom\" : \"universal\",\n+      \"scale\" : \"2x\"\n+    },\n+    {\n+      \"idiom\" : \"universal\",\n+      \"scale\" : \"3x\"\n+    }\n+  ],\n+  \"info\" : {\n+    \"author\" : \"xcode\",\n+    \"version\" : 1\n+  }\n+}"
  },
  {
    "sha": "fc5bb88e5ebe55eac8d621fe4aaf969cfa7ce951",
    "filename": "example/ios/TensorioTensorflowExample/Images.xcassets/cat.imageset/cat.jpg",
    "status": "added",
    "additions": 0,
    "deletions": 0,
    "changes": 0,
    "blob_url": "https://github.com/doc-ai/react-native-tensorio-tensorflow/blob/87b362141ceed0611b120243452b3d37b30ea246/example/ios/TensorioTensorflowExample/Images.xcassets/cat.imageset/cat.jpg",
    "raw_url": "https://github.com/doc-ai/react-native-tensorio-tensorflow/raw/87b362141ceed0611b120243452b3d37b30ea246/example/ios/TensorioTensorflowExample/Images.xcassets/cat.imageset/cat.jpg",
    "contents_url": "https://api.github.com/repos/doc-ai/react-native-tensorio-tensorflow/contents/example/ios/TensorioTensorflowExample/Images.xcassets/cat.imageset/cat.jpg?ref=87b362141ceed0611b120243452b3d37b30ea246"
  },
  {
    "sha": "b3721e2ebba222453a55c906ddcfe93ab13ef32e",
    "filename": "example/ios/TensorioTensorflowExample/Images.xcassets/dog.imageset/Contents.json",
    "status": "added",
    "additions": 21,
    "deletions": 0,
    "changes": 21,
    "blob_url": "https://github.com/doc-ai/react-native-tensorio-tensorflow/blob/87b362141ceed0611b120243452b3d37b30ea246/example/ios/TensorioTensorflowExample/Images.xcassets/dog.imageset/Contents.json",
    "raw_url": "https://github.com/doc-ai/react-native-tensorio-tensorflow/raw/87b362141ceed0611b120243452b3d37b30ea246/example/ios/TensorioTensorflowExample/Images.xcassets/dog.imageset/Contents.json",
    "contents_url": "https://api.github.com/repos/doc-ai/react-native-tensorio-tensorflow/contents/example/ios/TensorioTensorflowExample/Images.xcassets/dog.imageset/Contents.json?ref=87b362141ceed0611b120243452b3d37b30ea246",
    "patch": "@@ -0,0 +1,21 @@\n+{\n+  \"images\" : [\n+    {\n+      \"filename\" : \"dog.jpg\",\n+      \"idiom\" : \"universal\",\n+      \"scale\" : \"1x\"\n+    },\n+    {\n+      \"idiom\" : \"universal\",\n+      \"scale\" : \"2x\"\n+    },\n+    {\n+      \"idiom\" : \"universal\",\n+      \"scale\" : \"3x\"\n+    }\n+  ],\n+  \"info\" : {\n+    \"author\" : \"xcode\",\n+    \"version\" : 1\n+  }\n+}"
  },
  {
    "sha": "5a3c944a6b8645b7f26221df22953f936cc22899",
    "filename": "example/ios/TensorioTensorflowExample/Images.xcassets/dog.imageset/dog.jpg",
    "status": "added",
    "additions": 0,
    "deletions": 0,
    "changes": 0,
    "blob_url": "https://github.com/doc-ai/react-native-tensorio-tensorflow/blob/87b362141ceed0611b120243452b3d37b30ea246/example/ios/TensorioTensorflowExample/Images.xcassets/dog.imageset/dog.jpg",
    "raw_url": "https://github.com/doc-ai/react-native-tensorio-tensorflow/raw/87b362141ceed0611b120243452b3d37b30ea246/example/ios/TensorioTensorflowExample/Images.xcassets/dog.imageset/dog.jpg",
    "contents_url": "https://api.github.com/repos/doc-ai/react-native-tensorio-tensorflow/contents/example/ios/TensorioTensorflowExample/Images.xcassets/dog.imageset/dog.jpg?ref=87b362141ceed0611b120243452b3d37b30ea246"
  },
  {
    "sha": "1e6b9e17524156e1572367a2a7e326c6900c18dd",
    "filename": "example/ios/cats-vs-dogs-predict.tiobundle/model.json",
    "status": "added",
    "additions": 36,
    "deletions": 0,
    "changes": 36,
    "blob_url": "https://github.com/doc-ai/react-native-tensorio-tensorflow/blob/87b362141ceed0611b120243452b3d37b30ea246/example/ios/cats-vs-dogs-predict.tiobundle/model.json",
    "raw_url": "https://github.com/doc-ai/react-native-tensorio-tensorflow/raw/87b362141ceed0611b120243452b3d37b30ea246/example/ios/cats-vs-dogs-predict.tiobundle/model.json",
    "contents_url": "https://api.github.com/repos/doc-ai/react-native-tensorio-tensorflow/contents/example/ios/cats-vs-dogs-predict.tiobundle/model.json?ref=87b362141ceed0611b120243452b3d37b30ea246",
    "patch": "@@ -0,0 +1,36 @@\n+{\n+\t\"name\": \"Cats vs Dogs MobileNet V2 1.0 128\",\n+\t\"details\": \"Cats vs Dogs Kaggle model based on MobileNet V2 architecture with a width multiplier of 1.0 and an input resolution of 128x128.\",\n+\t\"id\": \"cats-vs-dogs-v2-100-128-unquantized\",\n+\t\"version\": \"1\",\n+\t\"author\": \"doc.ai\",\n+\t\"license\": \"Apache License. Version 2.0 http://www.apache.org/licenses/LICENSE-2.0\",\n+\t\"model\": {\n+\t\t\"file\": \"predict\",\n+\t\t\"quantized\": false,\n+\t\t\"type\": \"image.classification.catsvsdogs\",\n+\t\t\"backend\": \"tensorflow\",\n+\t\t\"modes\": [\"predict\"]\n+\t},\n+\t\"inputs\": [\n+\t\t{\n+\t\t\t\"name\": \"image\",\n+\t\t\t\"type\": \"image\",\n+\t\t\t\"shape\": [-1,128,128,3],\n+\t\t\t\"format\": \"RGB\",\n+\t\t\t\"normalize\": {\n+\t\t\t\t\"standard\": \"[0,1]\"\n+\t\t\t}\n+\t\t}\n+\t],\n+\t\"outputs\": [\n+\t\t{\n+\t\t\t\"name\": \"sigmoid\",\n+\t\t\t\"type\": \"array\",\n+\t\t\t\"shape\": [-1,1]\n+\t\t}\n+\t],\n+\t\"options\": {\n+\t\t\"device_position\": \"back\"\n+\t}\n+}"
  },
  {
    "sha": "93acccf4b4c6466380887e6fa42e181a1734e9d3",
    "filename": "example/ios/cats-vs-dogs-predict.tiobundle/predict/saved_model.pb",
    "status": "added",
    "additions": 0,
    "deletions": 0,
    "changes": 0,
    "blob_url": "https://github.com/doc-ai/react-native-tensorio-tensorflow/blob/87b362141ceed0611b120243452b3d37b30ea246/example/ios/cats-vs-dogs-predict.tiobundle/predict/saved_model.pb",
    "raw_url": "https://github.com/doc-ai/react-native-tensorio-tensorflow/raw/87b362141ceed0611b120243452b3d37b30ea246/example/ios/cats-vs-dogs-predict.tiobundle/predict/saved_model.pb",
    "contents_url": "https://api.github.com/repos/doc-ai/react-native-tensorio-tensorflow/contents/example/ios/cats-vs-dogs-predict.tiobundle/predict/saved_model.pb?ref=87b362141ceed0611b120243452b3d37b30ea246"
  }
]
