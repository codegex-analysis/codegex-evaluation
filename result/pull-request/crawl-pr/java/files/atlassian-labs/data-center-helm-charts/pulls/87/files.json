[
  {
    "sha": "d4b8532e8d7d8e7d19b72bfee002ff7f155d7ee4",
    "filename": "README.md",
    "status": "modified",
    "additions": 1,
    "deletions": 1,
    "changes": 2,
    "blob_url": "https://github.com/atlassian-labs/data-center-helm-charts/blob/f9fc320b02169de28f6219a0381da134a5f9b2ac/README.md",
    "raw_url": "https://github.com/atlassian-labs/data-center-helm-charts/raw/f9fc320b02169de28f6219a0381da134a5f9b2ac/README.md",
    "contents_url": "https://api.github.com/repos/atlassian-labs/data-center-helm-charts/contents/README.md?ref=f9fc320b02169de28f6219a0381da134a5f9b2ac",
    "patch": "@@ -13,7 +13,7 @@ whether it be a managed environment such as Amazon EKS, or a custom, on-premise\n 1. `helm repo add atlassian-data-center https://atlassian-labs.github.io/data-center-helm-charts`\n 1. Write a `values.yaml` file to provide your site-specific configuration\n 1. Create the required authentication Secrets in your Kubernetes cluster\n-1. `helm install <release name> --values <values.yaml> atlassian-data-center/jira` (or `/confluence`, `/bitbucket`)\n+1. `helm install <release name> --values <values.yaml> atlassian-data-center/jira` (or `/confluence`, `/crowd`, `/bitbucket`)\n 1. `helm test <release name>`\n 1. Configure an HTTPS ingress for your deployment\n "
  },
  {
    "sha": "0e8a0eb36f4ca2c939201c0d54b5d82a1ea34778",
    "filename": "src/main/charts/crowd/.helmignore",
    "status": "added",
    "additions": 23,
    "deletions": 0,
    "changes": 23,
    "blob_url": "https://github.com/atlassian-labs/data-center-helm-charts/blob/f9fc320b02169de28f6219a0381da134a5f9b2ac/src/main/charts/crowd/.helmignore",
    "raw_url": "https://github.com/atlassian-labs/data-center-helm-charts/raw/f9fc320b02169de28f6219a0381da134a5f9b2ac/src/main/charts/crowd/.helmignore",
    "contents_url": "https://api.github.com/repos/atlassian-labs/data-center-helm-charts/contents/src/main/charts/crowd/.helmignore?ref=f9fc320b02169de28f6219a0381da134a5f9b2ac",
    "patch": "@@ -0,0 +1,23 @@\n+# Patterns to ignore when building packages.\n+# This supports shell glob matching, relative path matching, and\n+# negation (prefixed with !). Only one pattern per line.\n+.DS_Store\n+# Common VCS dirs\n+.git/\n+.gitignore\n+.bzr/\n+.bzrignore\n+.hg/\n+.hgignore\n+.svn/\n+# Common backup files\n+*.swp\n+*.bak\n+*.tmp\n+*.orig\n+*~\n+# Various IDEs\n+.project\n+.idea/\n+*.tmproj\n+.vscode/"
  },
  {
    "sha": "659b525779c7fbd8f39f51563cc95c8bf948e8a4",
    "filename": "src/main/charts/crowd/Chart.yaml",
    "status": "added",
    "additions": 16,
    "deletions": 0,
    "changes": 16,
    "blob_url": "https://github.com/atlassian-labs/data-center-helm-charts/blob/f9fc320b02169de28f6219a0381da134a5f9b2ac/src/main/charts/crowd/Chart.yaml",
    "raw_url": "https://github.com/atlassian-labs/data-center-helm-charts/raw/f9fc320b02169de28f6219a0381da134a5f9b2ac/src/main/charts/crowd/Chart.yaml",
    "contents_url": "https://api.github.com/repos/atlassian-labs/data-center-helm-charts/contents/src/main/charts/crowd/Chart.yaml?ref=f9fc320b02169de28f6219a0381da134a5f9b2ac",
    "patch": "@@ -0,0 +1,16 @@\n+apiVersion: v2\n+name: crowd\n+description: A chart for installing Crowd DC on Kubernetes\n+type: application\n+version: 0.1.0\n+appVersion:\n+kubeVersion: \">=1.17.x-0\"\n+keywords:\n+  - Crowd\n+  - Crowd Server\n+  - Crowd Data Center\n+  - Atlassian\n+home: https://github.com/atlassian-labs/data-center-helm-charts\n+sources:\n+  - https://github.com/atlassian-labs/data-center-helm-charts\n+deprecated: false"
  },
  {
    "sha": "6290894c1f729aebbbe8496aaa8dddc44a757596",
    "filename": "src/main/charts/crowd/README.md",
    "status": "added",
    "additions": 87,
    "deletions": 0,
    "changes": 87,
    "blob_url": "https://github.com/atlassian-labs/data-center-helm-charts/blob/f9fc320b02169de28f6219a0381da134a5f9b2ac/src/main/charts/crowd/README.md",
    "raw_url": "https://github.com/atlassian-labs/data-center-helm-charts/raw/f9fc320b02169de28f6219a0381da134a5f9b2ac/src/main/charts/crowd/README.md",
    "contents_url": "https://api.github.com/repos/atlassian-labs/data-center-helm-charts/contents/src/main/charts/crowd/README.md?ref=f9fc320b02169de28f6219a0381da134a5f9b2ac",
    "patch": "@@ -0,0 +1,87 @@\n+# crowd\n+\n+![Version: 0.1.0](https://img.shields.io/badge/Version-0.1.0-informational?style=flat-square) ![Type: application](https://img.shields.io/badge/Type-application-informational?style=flat-square) ![AppVersion: 7.9.0-jdk11](https://img.shields.io/badge/AppVersion-7.9.0--jdk11-informational?style=flat-square)\n+\n+A chart for installing Crowd DC on Kubernetes\n+\n+**Homepage:** <https://github.com/atlassian-labs/data-center-helm-charts>\n+\n+## Source Code\n+\n+* <https://github.com/atlassian-labs/data-center-helm-charts>\n+\n+## Requirements\n+\n+Kubernetes: `>=1.17.x-0`\n+\n+## Values\n+\n+| Key | Type | Default | Description |\n+|-----|------|---------|-------------|\n+| additionalContainers | list | `[]` | Additional container definitions that will be added to all Crowd pods |\n+| additionalInitContainers | list | `[]` | Additional initContainer definitions that will be added to all Crowd pods |\n+| additionalLabels | object | `{}` | Additional labels that should be applied to all resources |\n+| affinity | object | `{}` | Standard Kubernetes affinities that will be applied to all Crowd pods |\n+| crowd.additionalBundledPlugins | list | `[]` | Specifies a list of additional Crowd plugins that should be added to the Crowd container. These are specified in the same manner as the additionalLibraries field, but the files will be loaded as bundled plugins rather than as libraries. |\n+| crowd.additionalEnvironmentVariables | list | `[]` | Defines any additional environment variables to be passed to the Crowd container. See https://hub.docker.com/r/atlassian/crowd-server for supported variables. |\n+| crowd.additionalJvmArgs | list | `[]` | Specifies a list of additional arguments that can be passed to the Crowd JVM, e.g. system properties |\n+| crowd.additionalLibraries | list | `[]` | Specifies a list of additional Java libraries that should be added to the Crowd container. Each item in the list should specify the name of the volume which contain the library, as well as the name of the library file within that volume's root directory. Optionally, a subDirectory field can be included to specify which directory in the volume contains the library file. |\n+| crowd.additionalVolumeMounts | list | `[]` | Defines any additional volumes mounts for the Crowd container. These can refer to existing volumes, or new volumes can be defined in volumes.additional. |\n+| crowd.clustering.enabled | bool | `false` | Set to true if Data Center clustering should be enabled This will automatically configure cluster peer discovery between cluster nodes. |\n+| crowd.clustering.usePodNameAsClusterNodeName | bool | `true` | Set to true if the Kubernetes pod name should be used as the end-user-visible name of the Data Center cluster node. |\n+| crowd.ports.hazelcast | int | `5701` | The port on which the Crowd container listens for Hazelcast traffic |\n+| crowd.ports.http | int | `8090` | The port on which the Crowd container listens for HTTP traffic |\n+| crowd.readinessProbe.failureThreshold | int | `30` | The number of consecutive failures of the Crowd container readiness probe before the pod fails readiness checks |\n+| crowd.readinessProbe.initialDelaySeconds | int | `10` | The initial delay (in seconds) for the Crowd container readiness probe, after which the probe will start running |\n+| crowd.readinessProbe.periodSeconds | int | `5` | How often (in seconds) the Crowd container readiness robe will run |\n+| crowd.resources.container | object | `{}` | Specifies the standard Kubernetes resource requests and/or limits for the Crowd container. It is important that if the memory resources are specified here, they must allow for the size of the Crowd JVM. That means the maximum heap size, the reserved code cache size, plus other JVM overheads, must be accommodated. Allowing for (maxHeap+codeCache)*1.5 would be an example. |\n+| crowd.resources.jvm.maxHeap | string | `\"1g\"` | The maximum amount of heap memory that will be used by the Crowd JVM |\n+| crowd.resources.jvm.minHeap | string | `\"1g\"` | The minimum amount of heap memory that will be used by the Crowd JVM |\n+| crowd.resources.jvm.reservedCodeCache | string | `\"512m\"` | The memory reserved for the Crowd JVM code cache |\n+| crowd.securityContext | object | `{\"enabled\":true,\"gid\":\"2002\"}` | Enable or disable security context in StatefulSet template spec. Enabled by default with UID 2002. -- Disable when deploying to OpenShift, unless anyuid policy is attached to a service account |\n+| crowd.securityContext.gid | string | `\"2002\"` | The GID used by the Crowd docker image |\n+| crowd.service.port | int | `80` | The port on which the Crowd Kubernetes service will listen |\n+| crowd.service.type | string | `\"ClusterIP\"` | The type of Kubernetes service to use for Crowd |\n+| database.credentials.passwordSecretKey | string | `\"password\"` | The key in the Secret used to store the database login password |\n+| database.credentials.secretName | string | `nil` | The name of the Kubernetes Secret that contains the database login credentials. If specified, then the credentials will be automatically populated during Crowd setup. Otherwise, they will need to be provided via the browser after initial startup. |\n+| database.credentials.usernameSecretKey | string | `\"username\"` | The key in the Secret used to store the database login username |\n+| database.type | string | `nil` | The type of database being used. Valid values include 'postgresql', 'mysql', 'oracle', 'mssql'. If not specified, then it will need to be provided via browser during initial startup. |\n+| database.url | string | `nil` | The JDBC URL of the database to be used by Crowd, e.g. jdbc:postgresql://host:port/database If not specified, then it will need to be provided via browser during initial startup. |\n+| image.pullPolicy | string | `\"IfNotPresent\"` |  |\n+| image.repository | string | `\"atlassian/crowd-server\"` |  |\n+| image.tag | string | `nil` | The docker image tag to be used. Defaults to the Chart appVersion. |\n+| ingress.annotations | object | `{}` | The custom annotations that should be applied to the Ingress. |\n+| ingress.create | bool | `false` | True if an Ingress should be created. |\n+| ingress.host | string | `nil` | The fully-qualified hostname of the Ingress. |\n+| ingress.https | bool | `true` | True if the browser communicates with the application over HTTPS. |\n+| ingress.nginx | bool | `true` | True if the created Ingress is to use the Kubernetes ingress-nginx controller. This will populate the Ingress with annotations for that controller. Set to false if a different controller is to be used, in which case the annotations need to be specified. |\n+| ingress.tlsSecretName | string | `nil` | Secret that contains a TLS private key and certificate. Optional if Ingress Controller is configured to use one secret for all ingresses |\n+| nodeSelector | object | `{}` | Standard Kubernetes node-selectors that will be applied to all Crowd pods |\n+| podAnnotations | object | `{}` | Specify additional annotations to be added to all Crowd pods |\n+| replicaCount | int | `1` | The initial number of pods that should be started at deployment of each of Crowd. Note that because Crowd requires initial manual configuration after the first pod is deployed, and before scaling up to additional pods, this should always be kept as 1. |\n+| serviceAccount.clusterRole.create | bool | `true` | true if a ClusterRole should be created, or false if it already exists |\n+| serviceAccount.clusterRole.name | string | `nil` | Specifies the name of the ClusterRole that will be created if the \"serviceAccount.clusterRole.create\" flag is set. If not specified, a name will be auto-generated. |\n+| serviceAccount.clusterRoleBinding.create | bool | `true` | true if a ClusterRoleBinding should be created, or false if it already exists |\n+| serviceAccount.clusterRoleBinding.name | string | `nil` | Specifies the name of the ClusterRoleBinding that will be created if the \"serviceAccount.clusterRoleBinding.create\" flag is set If not specified, a name will be auto-generated. |\n+| serviceAccount.create | bool | `true` | true if a ServiceAccount should be created, or false if it already exists |\n+| serviceAccount.imagePullSecrets | list | `[]` | The list of image pull secrets that should be added to the created ServiceAccount |\n+| serviceAccount.name | string | `nil` | Specifies the name of the ServiceAccount to be used by the pods. If not specified, but the the \"serviceAccount.create\" flag is set, then the ServiceAccount name will be auto-generated, otherwise the 'default' ServiceAccount will be used. |\n+| tolerations | list | `[]` | Standard Kubernetes tolerations that will be applied to all Crowd pods |\n+| volumes.additional | list | `[]` | Defines additional volumes that should be applied to all Crowd pods. Note that this will not create any corresponding volume mounts; those needs to be defined in crowd.additionalVolumeMounts |\n+| volumes.localHome.customVolume | object | `{}` | When persistentVolumeClaim.create is false, then this value can be used to define a standard Kubernetes volume which will be used for the local-home volumes. If not defined, then defaults to an emptyDir volume. |\n+| volumes.localHome.mountPath | string | `\"/var/atlassian/application-data/crowd\"` |  |\n+| volumes.localHome.persistentVolumeClaim.create | bool | `false` | If true, then a PersistentVolumeClaim will be created for each local-home volume. |\n+| volumes.localHome.persistentVolumeClaim.resources | object | `{\"requests\":{\"storage\":\"1Gi\"}}` | Specifies the standard Kubernetes resource requests and/or limits for the local-home volume claims. |\n+| volumes.localHome.persistentVolumeClaim.storageClassName | string | `nil` | Specifies the name of the storage class that should be used for the local-home volume claim. |\n+| volumes.sharedHome.customVolume | object | `{}` | When persistentVolumeClaim.create is false, then this value can be used to define a standard Kubernetes volume which will be used for the shared-home volume. If not defined, then defaults to an emptyDir (i.e. unshared) volume. |\n+| volumes.sharedHome.mountPath | string | `\"/var/atlassian/application-data/shared-home\"` | Specifies the path in the Crowd container to which the shared-home volume will be mounted. |\n+| volumes.sharedHome.nfsPermissionFixer.command | string | `nil` | By default, the fixer will change the group ownership of the volume's root directory to match the Crowd container's GID (2002), and then ensures the directory is group-writeable. If this is not the desired behaviour, command used can be specified here. |\n+| volumes.sharedHome.nfsPermissionFixer.enabled | bool | `false` | If enabled, this will alter the shared-home volume's root directory so that Crowd can write to it. This is a workaround for a Kubernetes bug affecting NFS volumes: https://github.com/kubernetes/examples/issues/260 |\n+| volumes.sharedHome.nfsPermissionFixer.mountPath | string | `\"/shared-home\"` | The path in the initContainer where the shared-home volume will be mounted |\n+| volumes.sharedHome.persistentVolumeClaim.create | bool | `false` | If true, then a PersistentVolumeClaim will be created for the shared-home volume. |\n+| volumes.sharedHome.persistentVolumeClaim.resources | object | `{\"requests\":{\"storage\":\"1Gi\"}}` | Specifies the standard Kubernetes resource requests and/or limits for the shared-home volume claims. |\n+| volumes.sharedHome.persistentVolumeClaim.storageClassName | string | `nil` | Specifies the name of the storage class that should be used for the shared-home volume claim. |\n+| volumes.sharedHome.subPath | string | `nil` | Specifies the sub-directory of the shared-home volume which will be mounted in to the Crowd container. |\n+\n+----------------------------------------------\n+Autogenerated from chart metadata using [helm-docs v1.5.0](https://github.com/norwoodj/helm-docs/releases/v1.5.0)"
  },
  {
    "sha": "c3e0c7456cd25965fb93f7a90a350a7f3af096cf",
    "filename": "src/main/charts/crowd/templates/NOTES.txt",
    "status": "added",
    "additions": 16,
    "deletions": 0,
    "changes": 16,
    "blob_url": "https://github.com/atlassian-labs/data-center-helm-charts/blob/f9fc320b02169de28f6219a0381da134a5f9b2ac/src/main/charts/crowd/templates/NOTES.txt",
    "raw_url": "https://github.com/atlassian-labs/data-center-helm-charts/raw/f9fc320b02169de28f6219a0381da134a5f9b2ac/src/main/charts/crowd/templates/NOTES.txt",
    "contents_url": "https://api.github.com/repos/atlassian-labs/data-center-helm-charts/contents/src/main/charts/crowd/templates/NOTES.txt?ref=f9fc320b02169de28f6219a0381da134a5f9b2ac",
    "patch": "@@ -0,0 +1,16 @@\n+Thank you for installing {{ .Chart.Name }}.\n+\n+Your release is named {{ .Release.Name }}, and resides in namespace {{ .Release.Namespace }}.\n+\n+Please run sanity tests against the release to verify it's healthy:\n+\n+  $ helm test {{ .Release.Name }} --logs -n {{ .Release.Namespace }}\n+\n+If the Kubernetes resources in the release are still starting up, then the tests may fail, so it\n+is advisable to wait for the tests to pass before continuing.\n+\n+To see the custom values you used for this release:\n+\n+  $ helm get values {{ .Release.Name }} -n {{ .Release.Namespace }}\n+\n+For further documentation, see https://github.com/atlassian-labs/data-center-helm-charts/tree/master/docs\n\\ No newline at end of file"
  },
  {
    "sha": "f33ff87db887d7b4c5ce80300a2bc58ddbd828d2",
    "filename": "src/main/charts/crowd/templates/_fluentd_templates.tpl",
    "status": "added",
    "additions": 37,
    "deletions": 0,
    "changes": 37,
    "blob_url": "https://github.com/atlassian-labs/data-center-helm-charts/blob/f9fc320b02169de28f6219a0381da134a5f9b2ac/src/main/charts/crowd/templates/_fluentd_templates.tpl",
    "raw_url": "https://github.com/atlassian-labs/data-center-helm-charts/raw/f9fc320b02169de28f6219a0381da134a5f9b2ac/src/main/charts/crowd/templates/_fluentd_templates.tpl",
    "contents_url": "https://api.github.com/repos/atlassian-labs/data-center-helm-charts/contents/src/main/charts/crowd/templates/_fluentd_templates.tpl?ref=f9fc320b02169de28f6219a0381da134a5f9b2ac",
    "patch": "@@ -0,0 +1,37 @@\n+{{- define \"fluentd.container\" -}}\n+{{ if .Values.fluentd.enabled }}\n+- name: fluentd\n+  image: {{ .Values.fluentd.imageName }}\n+  command: [\"fluentd\", \"-c\", \"/fluentd/etc/fluent.conf\", \"-v\"]\n+  ports:\n+    - containerPort: {{ .Values.fluentd.httpPort }}\n+      protocol: TCP\n+  volumeMounts:\n+    - name: fluentd-config\n+      mountPath: /fluentd/etc\n+      readOnly: true\n+  env:\n+    - name: POD_NAME\n+      valueFrom:\n+        fieldRef:\n+          fieldPath: metadata.name\n+    - name: POD_NAMESPACE\n+      valueFrom:\n+        fieldRef:\n+          fieldPath: metadata.namespace\n+    - name: POD_IP\n+      valueFrom:\n+        fieldRef:\n+          fieldPath: status.podIP\n+    - name: HELM_RELEASE_NAME\n+      value: {{ include \"confluence.fullname\" . }}\n+{{ end }}\n+{{ end }}\n+\n+{{- define \"fluentd.config.volume\" }}\n+{{ if .Values.fluentd.enabled }}\n+- name: fluentd-config\n+  configMap:\n+    name: {{ include \"confluence.fullname\" . }}-fluentd-config\n+{{ end }}\n+{{ end }}\n\\ No newline at end of file"
  },
  {
    "sha": "af8e8e9dfc6aed437000885796b03e9bb79ac238",
    "filename": "src/main/charts/crowd/templates/_helpers.tpl",
    "status": "added",
    "additions": 268,
    "deletions": 0,
    "changes": 268,
    "blob_url": "https://github.com/atlassian-labs/data-center-helm-charts/blob/f9fc320b02169de28f6219a0381da134a5f9b2ac/src/main/charts/crowd/templates/_helpers.tpl",
    "raw_url": "https://github.com/atlassian-labs/data-center-helm-charts/raw/f9fc320b02169de28f6219a0381da134a5f9b2ac/src/main/charts/crowd/templates/_helpers.tpl",
    "contents_url": "https://api.github.com/repos/atlassian-labs/data-center-helm-charts/contents/src/main/charts/crowd/templates/_helpers.tpl?ref=f9fc320b02169de28f6219a0381da134a5f9b2ac",
    "patch": "@@ -0,0 +1,268 @@\n+{{/* vim: set filetype=mustache: */}}\n+{{/*\n+Expand the name of the chart.\n+*/}}\n+{{- define \"crowd.name\" -}}\n+{{- default .Chart.Name .Values.nameOverride | trunc 63 | trimSuffix \"-\" }}\n+{{- end }}\n+\n+{{/*\n+Create a default fully qualified app name.\n+We truncate at 63 chars because some Kubernetes name fields are limited to this (by the DNS naming spec).\n+If release name contains chart name it will be used as a full name.\n+*/}}\n+{{- define \"crowd.fullname\" -}}\n+{{- if .Values.fullnameOverride }}\n+{{- .Values.fullnameOverride | trunc 63 | trimSuffix \"-\" }}\n+{{- else }}\n+{{- $name := default .Chart.Name .Values.nameOverride }}\n+{{- if contains $name .Release.Name }}\n+{{- .Release.Name | trunc 63 | trimSuffix \"-\" }}\n+{{- else }}\n+{{- printf \"%s-%s\" .Release.Name $name | trunc 63 | trimSuffix \"-\" }}\n+{{- end }}\n+{{- end }}\n+{{- end }}\n+\n+{{/*\n+Create chart name and version as used by the chart label.\n+*/}}\n+{{- define \"crowd.chart\" -}}\n+{{- printf \"%s-%s\" .Chart.Name .Chart.Version | replace \"+\" \"_\" | trunc 63 | trimSuffix \"-\" }}\n+{{- end }}\n+\n+{{/*\n+The name of the service account to be used.\n+If the name is defined in the chart values, then use that,\n+else if we're creating a new service account then use the name of the Helm release,\n+else just use the \"default\" service account.\n+*/}}\n+{{- define \"crowd.serviceAccountName\" -}}\n+{{- if .Values.serviceAccount.name -}}\n+{{- .Values.serviceAccount.name -}}\n+{{- else -}}\n+{{- if .Values.serviceAccount.create -}}\n+{{- include \"crowd.fullname\" . -}}\n+{{- else -}}\n+default\n+{{- end -}}\n+{{- end -}}\n+{{- end }}\n+\n+{{/*\n+The name of the ClusterRole that will be created.\n+If the name is defined in the chart values, then use that,\n+else use the name of the Helm release.\n+*/}}\n+{{- define \"crowd.clusterRoleName\" -}}\n+{{- if .Values.serviceAccount.clusterRole.name }}\n+{{- .Values.serviceAccount.clusterRole.name }}\n+{{- else }}\n+{{- include \"crowd.fullname\" . -}}\n+{{- end }}\n+{{- end }}\n+\n+{{/*\n+The name of the ClusterRoleBinding that will be created.\n+If the name is defined in the chart values, then use that,\n+else use the name of the ClusterRole.\n+*/}}\n+{{- define \"crowd.clusterRoleBindingName\" -}}\n+{{- if .Values.serviceAccount.clusterRoleBinding.name }}\n+{{- .Values.serviceAccount.clusterRoleBinding.name }}\n+{{- else }}\n+{{- include \"crowd.clusterRoleName\" . -}}\n+{{- end }}\n+{{- end }}\n+\n+{{/*\n+These labels will be applied to all Crowd resources in the chart\n+*/}}\n+{{- define \"crowd.labels\" -}}\n+helm.sh/chart: {{ include \"crowd.chart\" . }}\n+{{ include \"crowd.selectorLabels\" . }}\n+{{- if .Chart.AppVersion }}\n+app.kubernetes.io/version: {{ .Chart.AppVersion | quote }}\n+{{- end }}\n+app.kubernetes.io/managed-by: {{ .Release.Service }}\n+{{ with .Values.additionalLabels }}\n+{{- toYaml . }}\n+{{- end }}\n+{{- end }}\n+\n+{{/*\n+Selector labels for finding Crowd resources\n+*/}}\n+{{- define \"crowd.selectorLabels\" -}}\n+app.kubernetes.io/name: {{ include \"crowd.name\" . }}\n+app.kubernetes.io/instance: {{ .Release.Name }}\n+{{- end }}\n+\n+{{- define \"crowd.sysprop.hazelcastListenPort\" -}}\n+-Dcrowd.cluster.hazelcast.listenPort={{ .Values.crowd.ports.hazelcast }}\n+{{- end }}\n+\n+{{- define \"crowd.sysprop.clusterNodeName\" -}}\n+-Dcrowd.clusterNodeName.useHostname={{ .Values.crowd.clustering.usePodNameAsClusterNodeName }}\n+{{- end }}\n+\n+{{- define \"crowd.sysprop.fluentdAppender\" -}}\n+-Datlassian.logging.cloud.enabled={{.Values.fluentd.enabled}}\n+{{- end }}\n+\n+{{/*\n+The command that should be run by the nfs-fixer init container to correct the permissions of the shared-home root directory.\n+*/}}\n+{{- define \"sharedHome.permissionFix.command\" -}}\n+{{- if .Values.volumes.sharedHome.nfsPermissionFixer.command }}\n+{{ .Values.volumes.sharedHome.nfsPermissionFixer.command }}\n+{{- else }}\n+{{- printf \"(chgrp %s %s; chmod g+w %s)\" .Values.crowd.securityContext.gid .Values.volumes.sharedHome.nfsPermissionFixer.mountPath .Values.volumes.sharedHome.nfsPermissionFixer.mountPath }}\n+{{- end }}\n+{{- end }}\n+\n+{{- define \"crowd.image\" -}}\n+{{- if .Values.image.registry -}}\n+{{ .Values.image.registry}}/{{ .Values.image.repository }}:{{ .Values.image.tag | default .Chart.AppVersion }}\n+{{- else -}}\n+{{ .Values.image.repository }}:{{ .Values.image.tag | default .Chart.AppVersion }}\n+{{- end }}\n+{{- end }}\n+\n+{{/*\n+Defines the volume mounts used by the Crowd container.\n+Note that the local-home volume is mounted twice, once for the local-home directory itself, and again\n+on Tomcat's logs directory. THis ensures that Tomcat+Crowd logs get captured in the same volume.\n+*/}}\n+{{ define \"crowd.volumeMounts\" }}\n+- name: local-home\n+  mountPath: {{ .Values.volumes.localHome.mountPath | quote }}\n+- name: local-home\n+  mountPath: {{ .Values.crowd.accessLog.mountPath | quote }}\n+  subPath: {{ .Values.crowd.accessLog.localHomeSubPath | quote }}\n+- name: shared-home\n+  mountPath: {{ .Values.volumes.sharedHome.mountPath | quote }}\n+  {{- if .Values.volumes.sharedHome.subPath }}\n+  subPath: {{ .Values.volumes.sharedHome.subPath | quote }}\n+  {{- end }}\n+{{ end }}\n+\n+{{/*\n+For each additional library declared, generate a volume mount that injects that library into the Crowd lib directory\n+*/}}\n+{{- define \"crowd.additionalLibraries\" -}}\n+{{- range .Values.crowd.additionalLibraries -}}\n+- name: {{ .volumeName }}\n+  mountPath: \"/opt/atlassian/crowd/crowd-webapp/WEB-INF/lib/{{ .fileName }}\"\n+  {{- if .subDirectory }}\n+  subPath: {{ printf \"%s/%s\" .subDirectory .fileName | quote }}\n+  {{- else }}\n+  subPath: {{ .fileName | quote }}\n+  {{- end }}\n+{{- end }}\n+{{- end }}\n+\n+{{/*\n+For each additional plugin declared, generate a volume mount that injects that library into the Crowd plugins directory\n+*/}}\n+{{- define \"crowd.additionalBundledPlugins\" -}}\n+{{- range .Values.crowd.additionalBundledPlugins -}}\n+- name: {{ .volumeName }}\n+  mountPath: \"/opt/atlassian/crowd/crowd-webapp/WEB-INF/atlassian-bundled-plugins/{{ .fileName }}\"\n+  {{- if .subDirectory }}\n+  subPath: {{ printf \"%s/%s\" .subDirectory .fileName | quote }}\n+  {{- else }}\n+  subPath: {{ .fileName | quote }}\n+  {{- end }}\n+{{- end }}\n+{{- end }}\n+\n+{{- define \"crowd.volumes\" -}}\n+{{ if not .Values.volumes.localHome.persistentVolumeClaim.create }}\n+{{ include \"crowd.volumes.localHome\" . }}\n+{{- end }}\n+{{ include \"crowd.volumes.sharedHome\" . }}\n+{{- with .Values.volumes.additional }}\n+{{- toYaml . | nindent 0 }}\n+{{- end }}\n+{{- end }}\n+\n+{{- define \"crowd.volumes.localHome\" -}}\n+{{- if not .Values.volumes.localHome.persistentVolumeClaim.create }}\n+- name: local-home\n+{{ if .Values.volumes.localHome.customVolume }}\n+{{- toYaml .Values.volumes.localHome.customVolume | nindent 2 }}\n+{{ else }}\n+  emptyDir: {}\n+{{- end }}\n+{{- end }}\n+{{- end }}\n+\n+{{- define \"crowd.volumes.sharedHome\" -}}\n+- name: shared-home\n+{{- if .Values.volumes.sharedHome.persistentVolumeClaim.create }}\n+  persistentVolumeClaim:\n+    claimName: {{ include \"crowd.fullname\" . }}-shared-home\n+{{ else }}\n+{{ if .Values.volumes.sharedHome.customVolume }}\n+{{- toYaml .Values.volumes.sharedHome.customVolume | nindent 2 }}\n+{{ else }}\n+  emptyDir: {}\n+{{- end }}\n+{{- end }}\n+{{- end }}\n+\n+{{- define \"crowd.volumeClaimTemplates\" -}}\n+{{ if .Values.volumes.localHome.persistentVolumeClaim.create }}\n+volumeClaimTemplates:\n+- metadata:\n+    name: local-home\n+  spec:\n+    accessModes: [ \"ReadWriteOnce\" ]\n+    {{- if .Values.volumes.localHome.persistentVolumeClaim.storageClassName }}\n+    storageClassName: {{ .Values.volumes.localHome.persistentVolumeClaim.storageClassName | quote }}\n+    {{- end }}\n+    {{- with .Values.volumes.localHome.persistentVolumeClaim.resources }}\n+    resources:\n+      {{- toYaml . | nindent 6 }}\n+    {{- end }}\n+{{- end }}\n+{{- end }}\n+\n+{{- define \"crowd.databaseEnvVars\" -}}\n+{{ with .Values.database.type }}\n+- name: ATL_DB_TYPE\n+  value: {{ . | quote }}\n+{{ end }}\n+{{ with .Values.database.url }}\n+- name: ATL_JDBC_URL\n+  value: {{ . | quote }}\n+{{ end }}\n+{{ with .Values.database.credentials.secretName }}\n+- name: ATL_JDBC_USER\n+  valueFrom:\n+    secretKeyRef:\n+      name: {{ . }}\n+      key: {{ $.Values.database.credentials.usernameSecretKey }}\n+- name: ATL_JDBC_PASSWORD\n+  valueFrom:\n+    secretKeyRef:\n+      name: {{ . }}\n+      key: {{ $.Values.database.credentials.passwordSecretKey }}\n+{{ end }}\n+{{ end }}\n+\n+{{- define \"crowd.clusteringEnvVars\" -}}\n+{{ if .Values.crowd.clustering.enabled }}\n+- name: KUBERNETES_NAMESPACE\n+  valueFrom:\n+    fieldRef:\n+      fieldPath: metadata.namespace\n+- name: HAZELCAST_KUBERNETES_SERVICE_NAME\n+  value: {{ include \"crowd.fullname\" . | quote }}\n+- name: ATL_CLUSTER_TYPE\n+  value: \"kubernetes\"\n+- name: ATL_CLUSTER_NAME\n+  value: {{ include \"crowd.fullname\" . | quote }}\n+{{ end }}\n+{{ end }}"
  },
  {
    "sha": "1e1471e1db7e81312c9305dd66a2499d94dfdf0b",
    "filename": "src/main/charts/crowd/templates/clusterrole.yaml",
    "status": "added",
    "additions": 18,
    "deletions": 0,
    "changes": 18,
    "blob_url": "https://github.com/atlassian-labs/data-center-helm-charts/blob/f9fc320b02169de28f6219a0381da134a5f9b2ac/src/main/charts/crowd/templates/clusterrole.yaml",
    "raw_url": "https://github.com/atlassian-labs/data-center-helm-charts/raw/f9fc320b02169de28f6219a0381da134a5f9b2ac/src/main/charts/crowd/templates/clusterrole.yaml",
    "contents_url": "https://api.github.com/repos/atlassian-labs/data-center-helm-charts/contents/src/main/charts/crowd/templates/clusterrole.yaml?ref=f9fc320b02169de28f6219a0381da134a5f9b2ac",
    "patch": "@@ -0,0 +1,18 @@\n+{{- if and .Values.crowd.clustering.enabled .Values.serviceAccount.clusterRole.create -}}\n+apiVersion: rbac.authorization.k8s.io/v1\n+kind: ClusterRole\n+metadata:\n+  name: {{ template \"crowd.clusterRoleName\" . }}\n+  labels:\n+  {{- include \"crowd.labels\" . | nindent 4 }}\n+rules:\n+  - apiGroups:\n+      - \"\"\n+    resources:\n+      - endpoints\n+      - pods\n+      - nodes\n+    verbs:\n+      - get\n+      - list\n+{{- end -}}"
  },
  {
    "sha": "cd5b49f96897b780fadb5c6a535665e0d80e9530",
    "filename": "src/main/charts/crowd/templates/clusterrolebinding.yaml",
    "status": "added",
    "additions": 16,
    "deletions": 0,
    "changes": 16,
    "blob_url": "https://github.com/atlassian-labs/data-center-helm-charts/blob/f9fc320b02169de28f6219a0381da134a5f9b2ac/src/main/charts/crowd/templates/clusterrolebinding.yaml",
    "raw_url": "https://github.com/atlassian-labs/data-center-helm-charts/raw/f9fc320b02169de28f6219a0381da134a5f9b2ac/src/main/charts/crowd/templates/clusterrolebinding.yaml",
    "contents_url": "https://api.github.com/repos/atlassian-labs/data-center-helm-charts/contents/src/main/charts/crowd/templates/clusterrolebinding.yaml?ref=f9fc320b02169de28f6219a0381da134a5f9b2ac",
    "patch": "@@ -0,0 +1,16 @@\n+{{- if and .Values.crowd.clustering.enabled .Values.serviceAccount.clusterRoleBinding.create -}}\n+apiVersion: rbac.authorization.k8s.io/v1\n+kind: ClusterRoleBinding\n+metadata:\n+  name: {{ include \"crowd.clusterRoleBindingName\" . }}\n+  labels:\n+  {{- include \"crowd.labels\" . | nindent 4 }}\n+roleRef:\n+  apiGroup: rbac.authorization.k8s.io\n+  kind: ClusterRole\n+  name: {{ include \"crowd.clusterRoleName\" . }}\n+subjects:\n+  - kind: ServiceAccount\n+    name: {{ include \"crowd.serviceAccountName\" . }}\n+    namespace: {{ .Release.Namespace }}\n+{{ end }}"
  },
  {
    "sha": "f7ce70609538ecde2a2e5f54d4187f5fcfd9c767",
    "filename": "src/main/charts/crowd/templates/config-jvm.yaml",
    "status": "added",
    "additions": 17,
    "deletions": 0,
    "changes": 17,
    "blob_url": "https://github.com/atlassian-labs/data-center-helm-charts/blob/f9fc320b02169de28f6219a0381da134a5f9b2ac/src/main/charts/crowd/templates/config-jvm.yaml",
    "raw_url": "https://github.com/atlassian-labs/data-center-helm-charts/raw/f9fc320b02169de28f6219a0381da134a5f9b2ac/src/main/charts/crowd/templates/config-jvm.yaml",
    "contents_url": "https://api.github.com/repos/atlassian-labs/data-center-helm-charts/contents/src/main/charts/crowd/templates/config-jvm.yaml?ref=f9fc320b02169de28f6219a0381da134a5f9b2ac",
    "patch": "@@ -0,0 +1,17 @@\n+apiVersion: v1\n+kind: ConfigMap\n+metadata:\n+  name: {{ include \"crowd.fullname\" . }}-jvm-config\n+  labels:\n+    {{- include \"crowd.labels\" . | nindent 4 }}\n+data:\n+  additional_jvm_args: >-\n+    {{ include \"crowd.sysprop.hazelcastListenPort\" . }}\n+    {{ include \"crowd.sysprop.clusterNodeName\" . }}\n+    {{ include \"crowd.sysprop.fluentdAppender\" . }}\n+    {{- range .Values.crowd.additionalJvmArgs }}\n+    {{ . }}\n+    {{- end }}\n+  max_heap: {{ .Values.crowd.resources.jvm.maxHeap }}\n+  min_heap: {{ .Values.crowd.resources.jvm.minHeap }}\n+  reserved_code_cache: {{ .Values.crowd.resources.jvm.reservedCodeCache }}"
  },
  {
    "sha": "9e299157f59b3989e8ff2c3a37cf1050f9f54702",
    "filename": "src/main/charts/crowd/templates/configmap-fluentd.yaml",
    "status": "added",
    "additions": 38,
    "deletions": 0,
    "changes": 38,
    "blob_url": "https://github.com/atlassian-labs/data-center-helm-charts/blob/f9fc320b02169de28f6219a0381da134a5f9b2ac/src/main/charts/crowd/templates/configmap-fluentd.yaml",
    "raw_url": "https://github.com/atlassian-labs/data-center-helm-charts/raw/f9fc320b02169de28f6219a0381da134a5f9b2ac/src/main/charts/crowd/templates/configmap-fluentd.yaml",
    "contents_url": "https://api.github.com/repos/atlassian-labs/data-center-helm-charts/contents/src/main/charts/crowd/templates/configmap-fluentd.yaml?ref=f9fc320b02169de28f6219a0381da134a5f9b2ac",
    "patch": "@@ -0,0 +1,38 @@\n+{{ if .Values.fluentd.enabled }}\n+apiVersion: v1\n+kind: ConfigMap\n+metadata:\n+  name: {{ include \"crowd.fullname\" . }}-fluentd-config\n+  labels:\n+  {{- include \"crowd.labels\" . | nindent 4 }}\n+data:\n+  fluent.conf: |\n+    <source>\n+      @type http\n+      port {{ .Values.fluentd.httpPort }}\n+      bind 0.0.0.0\n+    </source>\n+\n+    <filter **>\n+      @type record_transformer\n+      <record>\n+        podname \"#{ENV['POD_NAME']}\"\n+        podnamespace \"#{ENV['POD_NAMESPACE']}\"\n+        podip \"#{ENV['POD_IP']}\"\n+        helmrelease \"#{ENV['HELM_RELEASE_NAME']}\"\n+      </record>\n+    </filter>\n+\n+    <filter **>\n+      @type stdout\n+    </filter>\n+\n+    {{ if .Values.fluentd.elasticsearch.enabled }}\n+    <match **>\n+      @type elasticsearch\n+      host {{ .Values.fluentd.elasticsearch.hostname }}\n+      logstash_format true\n+      logstash_prefix {{ .Values.fluentd.elasticsearch.indexNamePrefix }}\n+    </match>\n+    {{ end }}\n+{{ end }}"
  },
  {
    "sha": "695bbe5392eb3c06e4cea5a854c90a51c776dd51",
    "filename": "src/main/charts/crowd/templates/ingress.yaml",
    "status": "added",
    "additions": 36,
    "deletions": 0,
    "changes": 36,
    "blob_url": "https://github.com/atlassian-labs/data-center-helm-charts/blob/f9fc320b02169de28f6219a0381da134a5f9b2ac/src/main/charts/crowd/templates/ingress.yaml",
    "raw_url": "https://github.com/atlassian-labs/data-center-helm-charts/raw/f9fc320b02169de28f6219a0381da134a5f9b2ac/src/main/charts/crowd/templates/ingress.yaml",
    "contents_url": "https://api.github.com/repos/atlassian-labs/data-center-helm-charts/contents/src/main/charts/crowd/templates/ingress.yaml?ref=f9fc320b02169de28f6219a0381da134a5f9b2ac",
    "patch": "@@ -0,0 +1,36 @@\n+{{- if .Values.ingress.create }}\n+{{/* Change to networking.k8s.io/v1 when k8s 1.19 is the oldest supported version */}}\n+apiVersion: networking.k8s.io/v1beta1\n+kind: Ingress\n+metadata:\n+  name: {{ include \"crowd.fullname\" . }}\n+  labels:\n+    {{- include \"crowd.labels\" . | nindent 4 }}\n+  annotations:\n+    {{ if .Values.ingress.nginx }}\n+    \"kubernetes.io/ingress.class\": \"nginx\"\n+    \"nginx.ingress.kubernetes.io/affinity\": \"cookie\"\n+    \"nginx.ingress.kubernetes.io/affinity-mode\": \"persistent\"\n+    \"nginx.ingress.kubernetes.io/proxy-connect-timeout\": \"60\"\n+    \"nginx.ingress.kubernetes.io/proxy-read-timeout\": \"60\"\n+    \"nginx.ingress.kubernetes.io/proxy-send-timeout\": \"60\"\n+    {{- end }}\n+    {{- with .Values.ingress.annotations }}\n+  {{- toYaml . | nindent 4 }}\n+  {{- end }}\n+spec:\n+{{ if and (.Values.ingress.tlsSecretName) (.Values.ingress.host) }}\n+  tls:\n+    - hosts:\n+        - {{ .Values.ingress.host }}\n+      secretName: {{ .Values.ingress.tlsSecretName }}\n+{{ end }}\n+  rules:\n+    - host: {{ .Values.ingress.host }}\n+      http:\n+        paths:\n+          - path: \"/\"\n+            backend:\n+              serviceName: {{ include \"crowd.fullname\" . }}\n+              servicePort: {{ $.Values.crowd.service.port }}\n+{{ end }}"
  },
  {
    "sha": "95b9ac5ba94f6103d1fbc67c39ebba13014ad3bc",
    "filename": "src/main/charts/crowd/templates/nfs-permission-fixer.yaml",
    "status": "added",
    "additions": 37,
    "deletions": 0,
    "changes": 37,
    "blob_url": "https://github.com/atlassian-labs/data-center-helm-charts/blob/f9fc320b02169de28f6219a0381da134a5f9b2ac/src/main/charts/crowd/templates/nfs-permission-fixer.yaml",
    "raw_url": "https://github.com/atlassian-labs/data-center-helm-charts/raw/f9fc320b02169de28f6219a0381da134a5f9b2ac/src/main/charts/crowd/templates/nfs-permission-fixer.yaml",
    "contents_url": "https://api.github.com/repos/atlassian-labs/data-center-helm-charts/contents/src/main/charts/crowd/templates/nfs-permission-fixer.yaml?ref=f9fc320b02169de28f6219a0381da134a5f9b2ac",
    "patch": "@@ -0,0 +1,37 @@\n+{{- if .Values.volumes.sharedHome.nfsPermissionFixer.enabled }}\n+apiVersion: batch/v1\n+kind: Job\n+metadata:\n+  name: {{ include \"crowd.fullname\" . }}-nfs-fixer\n+  labels:\n+    {{- include \"crowd.labels\" . | nindent 4 }}\n+  annotations:\n+    \"helm.sh/hook\": pre-install\n+    \"helm.sh/hook-delete-policy\": \"before-hook-creation,hook-succeeded\"\n+spec:\n+  template:\n+    metadata:\n+      name: {{ include \"crowd.fullname\" . }}-nfs-fixer\n+      {{- with .Values.podAnnotations }}\n+      annotations:\n+        {{- toYaml . | nindent 8 }}\n+      {{- end }}\n+      labels:\n+        {{- include \"crowd.labels\" . | nindent 8 }}\n+    spec:\n+      restartPolicy: Never\n+      containers:\n+        - name: nfs-fixer\n+          image: alpine\n+          securityContext:\n+            runAsUser: 0 # make sure we run as root so we get the ability to change the volume permissions\n+          volumeMounts:\n+            - name: shared-home\n+              mountPath: {{ .Values.volumes.sharedHome.nfsPermissionFixer.mountPath | quote }}\n+              {{- if .Values.volumes.sharedHome.subPath }}\n+              subPath: {{ .Values.volumes.sharedHome.subPath | quote }}\n+              {{- end }}\n+          command: [\"sh\", \"-c\", {{ include \"sharedHome.permissionFix.command\" . | quote }}]\n+      volumes:\n+        {{ include \"crowd.volumes.sharedHome\" . | nindent 8 }}\n+{{- end }}"
  },
  {
    "sha": "4e3cff277e388abb6fb93336edda6e51945f3377",
    "filename": "src/main/charts/crowd/templates/service.yaml",
    "status": "added",
    "additions": 19,
    "deletions": 0,
    "changes": 19,
    "blob_url": "https://github.com/atlassian-labs/data-center-helm-charts/blob/f9fc320b02169de28f6219a0381da134a5f9b2ac/src/main/charts/crowd/templates/service.yaml",
    "raw_url": "https://github.com/atlassian-labs/data-center-helm-charts/raw/f9fc320b02169de28f6219a0381da134a5f9b2ac/src/main/charts/crowd/templates/service.yaml",
    "contents_url": "https://api.github.com/repos/atlassian-labs/data-center-helm-charts/contents/src/main/charts/crowd/templates/service.yaml?ref=f9fc320b02169de28f6219a0381da134a5f9b2ac",
    "patch": "@@ -0,0 +1,19 @@\n+apiVersion: v1\n+kind: Service\n+metadata:\n+  name: {{ include \"crowd.fullname\" . }}\n+  labels:\n+    {{- include \"crowd.labels\" . | nindent 4 }}\n+spec:\n+  type: {{ .Values.crowd.service.type }}\n+  ports:\n+    - port: {{ .Values.crowd.service.port }}\n+      targetPort: http\n+      protocol: TCP\n+      name: http\n+    - port: {{ .Values.crowd.ports.hazelcast }}\n+      targetPort: hazelcast\n+      protocol: TCP\n+      name: hazelcast\n+  selector:\n+    {{- include \"crowd.selectorLabels\" . | nindent 4 }}"
  },
  {
    "sha": "5888393d217407cb3def2de70a38b74d5423da26",
    "filename": "src/main/charts/crowd/templates/serviceaccount.yaml",
    "status": "added",
    "additions": 12,
    "deletions": 0,
    "changes": 12,
    "blob_url": "https://github.com/atlassian-labs/data-center-helm-charts/blob/f9fc320b02169de28f6219a0381da134a5f9b2ac/src/main/charts/crowd/templates/serviceaccount.yaml",
    "raw_url": "https://github.com/atlassian-labs/data-center-helm-charts/raw/f9fc320b02169de28f6219a0381da134a5f9b2ac/src/main/charts/crowd/templates/serviceaccount.yaml",
    "contents_url": "https://api.github.com/repos/atlassian-labs/data-center-helm-charts/contents/src/main/charts/crowd/templates/serviceaccount.yaml?ref=f9fc320b02169de28f6219a0381da134a5f9b2ac",
    "patch": "@@ -0,0 +1,12 @@\n+{{- if .Values.serviceAccount.create -}}\n+apiVersion: v1\n+kind: ServiceAccount\n+metadata:\n+  name: {{ include \"crowd.serviceAccountName\" . }}\n+  labels:\n+  {{- include \"crowd.labels\" . | nindent 4 }}\n+{{- with .Values.serviceAccount.imagePullSecrets }}\n+imagePullSecrets:\n+  {{- toYaml . | nindent 2 }}\n+{{- end -}}\n+{{- end -}}"
  },
  {
    "sha": "c2f6dbee618a2ab09e8e4aebb16254ab871f5d9e",
    "filename": "src/main/charts/crowd/templates/shared-home-pvc.yaml",
    "status": "added",
    "additions": 18,
    "deletions": 0,
    "changes": 18,
    "blob_url": "https://github.com/atlassian-labs/data-center-helm-charts/blob/f9fc320b02169de28f6219a0381da134a5f9b2ac/src/main/charts/crowd/templates/shared-home-pvc.yaml",
    "raw_url": "https://github.com/atlassian-labs/data-center-helm-charts/raw/f9fc320b02169de28f6219a0381da134a5f9b2ac/src/main/charts/crowd/templates/shared-home-pvc.yaml",
    "contents_url": "https://api.github.com/repos/atlassian-labs/data-center-helm-charts/contents/src/main/charts/crowd/templates/shared-home-pvc.yaml?ref=f9fc320b02169de28f6219a0381da134a5f9b2ac",
    "patch": "@@ -0,0 +1,18 @@\n+{{- if .Values.volumes.sharedHome.persistentVolumeClaim.create }}\n+apiVersion: v1\n+kind: PersistentVolumeClaim\n+metadata:\n+  name: {{ include \"crowd.fullname\" . }}-shared-home\n+  labels:\n+  {{- include \"crowd.labels\" . | nindent 4 }}\n+spec:\n+  accessModes:\n+    - ReadWriteMany\n+  {{- if .Values.volumes.sharedHome.persistentVolumeClaim.storageClassName }}\n+  storageClassName: {{ .Values.volumes.sharedHome.persistentVolumeClaim.storageClassName | quote }}\n+  {{- end }}\n+  {{- with .Values.volumes.sharedHome.persistentVolumeClaim.resources }}\n+  resources:\n+    {{- toYaml . | nindent 4 }}\n+  {{- end }}\n+{{ end }}"
  },
  {
    "sha": "d46e13ec67a900b8511bfb7de0c161d2a91dbfd1",
    "filename": "src/main/charts/crowd/templates/statefulset.yaml",
    "status": "added",
    "additions": 115,
    "deletions": 0,
    "changes": 115,
    "blob_url": "https://github.com/atlassian-labs/data-center-helm-charts/blob/f9fc320b02169de28f6219a0381da134a5f9b2ac/src/main/charts/crowd/templates/statefulset.yaml",
    "raw_url": "https://github.com/atlassian-labs/data-center-helm-charts/raw/f9fc320b02169de28f6219a0381da134a5f9b2ac/src/main/charts/crowd/templates/statefulset.yaml",
    "contents_url": "https://api.github.com/repos/atlassian-labs/data-center-helm-charts/contents/src/main/charts/crowd/templates/statefulset.yaml?ref=f9fc320b02169de28f6219a0381da134a5f9b2ac",
    "patch": "@@ -0,0 +1,115 @@\n+apiVersion: apps/v1\n+kind: StatefulSet\n+metadata:\n+  name: {{ include \"crowd.fullname\" . }}\n+  labels:\n+    {{- include \"crowd.labels\" . | nindent 4 }}\n+spec:\n+  replicas: {{ .Values.replicaCount }}\n+  serviceName: {{ include \"crowd.fullname\" . }}\n+  selector:\n+    matchLabels:\n+      {{- include \"crowd.selectorLabels\" . | nindent 6 }}\n+  template:\n+    metadata:\n+      {{- with .Values.podAnnotations }}\n+      annotations:\n+        {{- toYaml . | nindent 8 }}\n+      {{- end }}\n+      labels:\n+        {{- include \"crowd.selectorLabels\" . | nindent 8 }}\n+    spec:\n+      serviceAccountName: {{ include \"crowd.serviceAccountName\" . }}\n+      terminationGracePeriodSeconds: 1\n+{{ if .Values.crowd.securityContext.enabled }}\n+      securityContext:\n+        # This is intended to ensure that the shared-home volume is group-writeable by the GID used by the Confluence container.\n+        # However, this doesn't appear to work for NFS volumes due to a K8s bug: https://github.com/kubernetes/examples/issues/260\n+        fsGroup: {{ .Values.crowd.securityContext.gid }}\n+{{ end }}\n+      {{- with .Values.additionalInitContainers }}\n+      initContainers:\n+        {{- toYaml . | nindent 8 }}\n+      {{- end }}\n+      containers:\n+        - name: crowd\n+          image: {{ include \"crowd.image\" . | quote }}\n+          imagePullPolicy: {{ .Values.image.pullPolicy }}\n+          ports:\n+            - name: http\n+              containerPort: {{ .Values.crowd.ports.http }}\n+              protocol: TCP\n+            - name: hazelcast\n+              containerPort: {{ .Values.crowd.ports.hazelcast }}\n+              protocol: TCP\n+          readinessProbe:\n+            httpGet:\n+              port: {{ .Values.crowd.ports.http }}\n+              path: /status\n+            initialDelaySeconds: {{ .Values.crowd.readinessProbe.initialDelaySeconds }}\n+            periodSeconds: {{ .Values.crowd.readinessProbe.periodSeconds }}\n+            failureThreshold: {{ .Values.crowd.readinessProbe.failureThreshold }}\n+          {{- with .Values.crowd.resources.container }}\n+          resources:\n+          {{- toYaml . | nindent 12 }}\n+          {{- end }}\n+          volumeMounts:\n+            {{- include \"crowd.volumeMounts\" . | nindent 12 }}\n+            {{- with .Values.crowd.additionalVolumeMounts }}\n+            {{- toYaml . | nindent 12 }}\n+            {{- end }}\n+            {{- include \"crowd.additionalLibraries\" . | nindent 12 }}\n+            {{- include \"crowd.additionalBundledPlugins\" . | nindent 12 }}\n+          env:\n+            {{ if .Values.ingress.https }}\n+            - name: ATL_TOMCAT_SCHEME\n+              value: \"https\"\n+            - name: ATL_TOMCAT_SECURE\n+              value: \"true\"\n+            {{ end }}\n+            - name: ATL_TOMCAT_ACCESS_LOG\n+              value: {{ .Values.crowd.accessLog.enabled | quote }}\n+            - name: UMASK\n+              value: {{ .Values.crowd.umask | quote }}\n+            - name: SET_PERMISSIONS\n+              value: \"false\"\n+            - name: ATL_PRODUCT_HOME_SHARED\n+              value: {{ .Values.volumes.sharedHome.mountPath | quote }}\n+            - name: JVM_MINIMUM_MEMORY\n+              valueFrom:\n+                configMapKeyRef:\n+                  key: min_heap\n+                  name: {{ include \"crowd.fullname\" . }}-jvm-config\n+            - name: JVM_MAXIMUM_MEMORY\n+              valueFrom:\n+                configMapKeyRef:\n+                  key: max_heap\n+                  name: {{ include \"crowd.fullname\" . }}-jvm-config\n+            - name: JVM_RESERVED_CODE_CACHE_SIZE\n+              valueFrom:\n+                configMapKeyRef:\n+                  key: reserved_code_cache\n+                  name: {{ include \"crowd.fullname\" . }}-jvm-config\n+            {{- with .Values.crowd.additionalEnvironmentVariables }}\n+            {{- toYaml . | nindent 12 }}\n+            {{- end }}\n+        {{- include \"fluentd.container\" . | nindent 8 }}\n+        {{- with .Values.additionalContainers }}\n+        {{- toYaml . | nindent 8 }}\n+        {{- end }}\n+      {{- with .Values.nodeSelector }}\n+      nodeSelector:\n+      {{- toYaml . | nindent 8 }}\n+      {{- end }}\n+      {{- with .Values.affinity }}\n+      affinity:\n+      {{- toYaml . | nindent 8 }}\n+      {{- end }}\n+      {{- with .Values.tolerations }}\n+      tolerations:\n+      {{- toYaml . | nindent 8 }}\n+      {{- end }}\n+      volumes:\n+        {{ include \"crowd.volumes\" . | nindent 8 }}\n+        {{ include \"fluentd.config.volume\" . | nindent 8 }}\n+  {{ include \"crowd.volumeClaimTemplates\" . | nindent 2 }}"
  },
  {
    "sha": "68fbbd3ee9a14037144a51eb386a3d40c5a2974f",
    "filename": "src/main/charts/crowd/templates/tests/test-application-status.yaml",
    "status": "added",
    "additions": 28,
    "deletions": 0,
    "changes": 28,
    "blob_url": "https://github.com/atlassian-labs/data-center-helm-charts/blob/f9fc320b02169de28f6219a0381da134a5f9b2ac/src/main/charts/crowd/templates/tests/test-application-status.yaml",
    "raw_url": "https://github.com/atlassian-labs/data-center-helm-charts/raw/f9fc320b02169de28f6219a0381da134a5f9b2ac/src/main/charts/crowd/templates/tests/test-application-status.yaml",
    "contents_url": "https://api.github.com/repos/atlassian-labs/data-center-helm-charts/contents/src/main/charts/crowd/templates/tests/test-application-status.yaml?ref=f9fc320b02169de28f6219a0381da134a5f9b2ac",
    "patch": "@@ -0,0 +1,28 @@\n+apiVersion: v1\n+kind: Pod\n+metadata:\n+  name: \"{{ include \"crowd.fullname\" . }}-application-status-test\"\n+  annotations:\n+    \"helm.sh/hook\": test\n+    \"helm.sh/hook-delete-policy\": \"before-hook-creation,hook-succeeded\"\n+    {{- with .Values.podAnnotations }}\n+      {{- toYaml . | nindent 4 }}\n+    {{- end }}\n+  labels:\n+    {{- include \"crowd.labels\" . | nindent 4 }}\n+spec:\n+  containers:\n+    - name: test\n+      image: alpine\n+      env:\n+        - name: STATUS_URL\n+          value: \"http://{{ include \"crowd.fullname\" . }}:{{ .Values.crowd.service.port }}/status\"\n+      command:\n+        - /bin/sh\n+        - -ec\n+        - |\n+          apk add -q jq curl\n+          STATUS=$(curl -s \"$STATUS_URL\")\n+          echo \"Verifying application state is RUNNING or FIRST_RUN: $STATUS\"\n+          echo $STATUS | jq -e '.state|test(\"RUNNING|FIRST_RUN\")'\n+  restartPolicy: Never"
  },
  {
    "sha": "2a60876a892f03174ec1de91502e54f9cb82b41f",
    "filename": "src/main/charts/crowd/templates/tests/test-database-connectivity.yaml",
    "status": "added",
    "additions": 54,
    "deletions": 0,
    "changes": 54,
    "blob_url": "https://github.com/atlassian-labs/data-center-helm-charts/blob/f9fc320b02169de28f6219a0381da134a5f9b2ac/src/main/charts/crowd/templates/tests/test-database-connectivity.yaml",
    "raw_url": "https://github.com/atlassian-labs/data-center-helm-charts/raw/f9fc320b02169de28f6219a0381da134a5f9b2ac/src/main/charts/crowd/templates/tests/test-database-connectivity.yaml",
    "contents_url": "https://api.github.com/repos/atlassian-labs/data-center-helm-charts/contents/src/main/charts/crowd/templates/tests/test-database-connectivity.yaml?ref=f9fc320b02169de28f6219a0381da134a5f9b2ac",
    "patch": "@@ -0,0 +1,54 @@\n+{{ if .Values.database.credentials.secretName }}\n+apiVersion: v1\n+kind: Pod\n+metadata:\n+  name: \"{{ include \"crowd.fullname\" . }}-db-connectivity-test\"\n+  annotations:\n+    \"helm.sh/hook\": test\n+    \"helm.sh/hook-delete-policy\": \"before-hook-creation,hook-succeeded\"\n+    {{- with .Values.podAnnotations }}\n+      {{- toYaml . | nindent 4 }}\n+    {{- end }}\n+  labels:\n+    {{- include \"crowd.labels\" . | nindent 4 }}\n+spec:\n+  serviceAccountName: {{ include \"crowd.serviceAccountName\" . }}\n+  containers:\n+    - name: test\n+      image: {{ include \"crowd.image\" . | quote }}\n+      imagePullPolicy: IfNotPresent\n+      env:\n+        - name: JDBC_TYPE\n+          value: {{ .Values.database.type | quote }}\n+        - name: JDBC_URL\n+          value: {{ .Values.database.url | quote }}\n+        - name: JDBC_USER\n+          valueFrom:\n+            secretKeyRef:\n+              name: {{ .Values.database.credentials.secretName }}\n+              key: {{ .Values.database.credentials.usernameSecretKey }}\n+        - name: JDBC_PASSWORD\n+          valueFrom:\n+            secretKeyRef:\n+              name: {{ .Values.database.credentials.secretName }}\n+              key: {{ .Values.database.credentials.passwordSecretKey }}\n+        - name: CLASSPATH\n+          value: \"/opt/atlassian/crowd/crowd/WEB-INF/lib/*\"\n+      command:\n+        - /bin/bash\n+        - -ec\n+        - |\n+          cat <<EOF | jshell - > output.txt\n+          var jdbcUrl = System.getenv(\"JDBC_URL\");\n+          var jdbcUsername = System.getenv(\"JDBC_USER\");\n+          var jdbcPassword = System.getenv(\"JDBC_PASSWORD\");\n+\n+          System.out.println(\"Establishing connection to \" + jdbcUrl);\n+          try (var c = java.sql.DriverManager.getConnection(jdbcUrl, jdbcUsername, jdbcPassword)) {\n+             System.out.println(\"Connection established OK, \" + c.getClass());\n+          }\n+          EOF\n+          cat output.txt\n+          grep -q \"Connection established OK\" output.txt\n+  restartPolicy: Never\n+{{ end }}"
  },
  {
    "sha": "c12eaf26e2d979bd2f953233d101592132781c71",
    "filename": "src/main/charts/crowd/templates/tests/test-shared-home-permissions.yaml",
    "status": "added",
    "additions": 39,
    "deletions": 0,
    "changes": 39,
    "blob_url": "https://github.com/atlassian-labs/data-center-helm-charts/blob/f9fc320b02169de28f6219a0381da134a5f9b2ac/src/main/charts/crowd/templates/tests/test-shared-home-permissions.yaml",
    "raw_url": "https://github.com/atlassian-labs/data-center-helm-charts/raw/f9fc320b02169de28f6219a0381da134a5f9b2ac/src/main/charts/crowd/templates/tests/test-shared-home-permissions.yaml",
    "contents_url": "https://api.github.com/repos/atlassian-labs/data-center-helm-charts/contents/src/main/charts/crowd/templates/tests/test-shared-home-permissions.yaml?ref=f9fc320b02169de28f6219a0381da134a5f9b2ac",
    "patch": "@@ -0,0 +1,39 @@\n+apiVersion: v1\n+kind: Pod\n+metadata:\n+  name: \"{{ include \"crowd.fullname\" . }}-shared-home-permissions-test\"\n+  annotations:\n+    \"helm.sh/hook\": test\n+    \"helm.sh/hook-delete-policy\": \"before-hook-creation,hook-succeeded\"\n+    {{- with .Values.podAnnotations }}\n+      {{- toYaml . | nindent 4 }}\n+    {{- end }}\n+  labels:\n+    {{- include \"crowd.labels\" . | nindent 4 }}\n+spec:\n+  containers:\n+    - name: test\n+      image: debian:stable-slim\n+      imagePullPolicy: IfNotPresent\n+      securityContext:\n+        # Slightly dodgy; we assume that the UID and GID used by the product images are the same, which in practice they are\n+        runAsUser: {{ .Values.crowd.securityContext.gid }}\n+        runAsGroup: {{ .Values.crowd.securityContext.gid }}\n+      volumeMounts:\n+        - name: shared-home\n+          mountPath: /shared-home\n+          {{- if .Values.volumes.sharedHome.subPath }}\n+          subPath: {{ .Values.volumes.sharedHome.subPath | quote }}\n+          {{- end }}\n+      command:\n+        - /bin/sh\n+        - -ec\n+        - |\n+          ls -ld /shared-home\n+          echo \"Creating temporary file in shared home as user $(id -u):$(id -g)\"\n+          touch /shared-home/permissions-test\n+          ls -l /shared-home/permissions-test\n+          rm /shared-home/permissions-test\n+  volumes:\n+    {{ include \"crowd.volumes.sharedHome\" . | nindent 4 }}\n+  restartPolicy: Never"
  },
  {
    "sha": "6c70905ae21d6254f33e2247af2d3e77425f7e23",
    "filename": "src/main/charts/crowd/values.yaml",
    "status": "added",
    "additions": 245,
    "deletions": 0,
    "changes": 245,
    "blob_url": "https://github.com/atlassian-labs/data-center-helm-charts/blob/f9fc320b02169de28f6219a0381da134a5f9b2ac/src/main/charts/crowd/values.yaml",
    "raw_url": "https://github.com/atlassian-labs/data-center-helm-charts/raw/f9fc320b02169de28f6219a0381da134a5f9b2ac/src/main/charts/crowd/values.yaml",
    "contents_url": "https://api.github.com/repos/atlassian-labs/data-center-helm-charts/contents/src/main/charts/crowd/values.yaml?ref=f9fc320b02169de28f6219a0381da134a5f9b2ac",
    "patch": "@@ -0,0 +1,245 @@\n+# -- The initial number of pods that should be started at deployment of each of Crowd.\n+# Note that because Crowd requires initial manual configuration after the first pod is deployed, and before scaling\n+# up to additional pods, this should always be kept as 1.\n+replicaCount: 1\n+\n+image:\n+  repository: atlassian/crowd\n+  pullPolicy: IfNotPresent\n+  # -- The docker image tag to be used. Defaults to the Chart appVersion.\n+  tag: 4.2.2\n+\n+serviceAccount:\n+  # -- Specifies the name of the ServiceAccount to be used by the pods.\n+  # If not specified, but the the \"serviceAccount.create\" flag is set, then the ServiceAccount name will be auto-generated,\n+  # otherwise the 'default' ServiceAccount will be used.\n+  name:\n+  # -- true if a ServiceAccount should be created, or false if it already exists\n+  create: true\n+  # -- The list of image pull secrets that should be added to the created ServiceAccount\n+  imagePullSecrets: []\n+  clusterRole:\n+    # -- Specifies the name of the ClusterRole that will be created if the \"serviceAccount.clusterRole.create\" flag is set.\n+    # If not specified, a name will be auto-generated.\n+    name:\n+    # -- true if a ClusterRole should be created, or false if it already exists\n+    create: true\n+  clusterRoleBinding:\n+    # -- Specifies the name of the ClusterRoleBinding that will be created if the \"serviceAccount.clusterRoleBinding.create\" flag is set\n+    # If not specified, a name will be auto-generated.\n+    name:\n+    # -- true if a ClusterRoleBinding should be created, or false if it already exists\n+    create: true\n+\n+database:\n+  # -- The type of database being used.\n+  # Valid values include 'postgresql', 'mysql', 'oracle', 'mssql'.\n+  # If not specified, then it will need to be provided via browser during initial startup.\n+  type:\n+  # -- The JDBC URL of the database to be used by Crowd, e.g. jdbc:postgresql://host:port/database\n+  # If not specified, then it will need to be provided via browser during initial startup.\n+  url:\n+  credentials:\n+    # -- The name of the Kubernetes Secret that contains the database login credentials.\n+    # If specified, then the credentials will be automatically populated during Crowd setup.\n+    # Otherwise, they will need to be provided via the browser after initial startup.\n+    secretName:\n+    # -- The key in the Secret used to store the database login username\n+    usernameSecretKey: username\n+    # -- The key in the Secret used to store the database login password\n+    passwordSecretKey: password\n+\n+crowd:\n+  service:\n+    # -- The port on which the Crowd Kubernetes service will listen\n+    port: 80\n+    # -- The type of Kubernetes service to use for Crowd\n+    type: ClusterIP\n+  # -- Enable or disable security context in StatefulSet template spec. Enabled by default with UID 2002.\n+  # -- Disable when deploying to OpenShift, unless anyuid policy is attached to a service account\n+  securityContext:\n+    enabled: true\n+    # -- The GID used by the Crowd docker image\n+    gid: \"2004\"\n+  # -- The umask used by the Crowd process when it creates new files.\n+  # Default is 0022, which makes the new files read/writeable by the Crowd user, and readable by everyone else.\n+  umask: \"0022\"\n+  ports:\n+    # -- The port on which the Crowd container listens for HTTP traffic\n+    http: 8095\n+    # -- The port on which the Crowd container listens for Hazelcast traffic\n+    hazelcast: 5701\n+  readinessProbe:\n+    # -- The initial delay (in seconds) for the Crowd container readiness probe, after which the probe will start running\n+    initialDelaySeconds: 10\n+    # -- How often (in seconds) the Crowd container readiness robe will run\n+    periodSeconds: 5\n+    # -- The number of consecutive failures of the Crowd container readiness probe before the pod fails readiness checks\n+    failureThreshold: 30\n+\n+  accessLog:\n+    # -- True if access logging should be enabled.\n+    enabled: true\n+    # -- The path within the Crowd container where the local-home volume should be mounted in order to capture access logs.\n+    mountPath: \"/opt/atlassian/crowd/logs\"\n+    # -- The subdirectory within the local-home volume where access logs should be stored.\n+    localHomeSubPath: \"logs\"\n+\n+  clustering:\n+    # -- Set to true if Data Center clustering should be enabled\n+    # This will automatically configure cluster peer discovery between cluster nodes.\n+    enabled: false\n+    # -- Set to true if the Kubernetes pod name should be used as the end-user-visible name of the Data Center cluster node.\n+    usePodNameAsClusterNodeName: true\n+\n+  resources:\n+    jvm:\n+      # -- The maximum amount of heap memory that will be used by the Crowd JVM\n+      maxHeap: \"1g\"\n+      # -- The minimum amount of heap memory that will be used by the Crowd JVM\n+      minHeap: \"1g\"\n+      # -- The memory reserved for the Crowd JVM code cache\n+      reservedCodeCache: \"512m\"\n+    # -- Specifies the standard Kubernetes resource requests and/or limits for the Crowd container.\n+    # It is important that if the memory resources are specified here, they must allow for the size of the Crowd JVM.\n+    # That means the maximum heap size, the reserved code cache size, plus other JVM overheads, must be accommodated.\n+    # Allowing for (maxHeap+codeCache)*1.5 would be an example.\n+    container: {}\n+    #  limits:\n+    #    cpu: \"4\"\n+    #    memory: \"2G\"\n+    #  requests:\n+    #    cpu: \"4\"\n+    #    memory: \"2G\"\n+\n+  # -- Specifies a list of additional arguments that can be passed to the Crowd JVM, e.g. system properties\n+  additionalJvmArgs: []\n+#    - -Dfoo=bar\n+#    - -Dfruit=lemon\n+\n+  # -- Specifies a list of additional Java libraries that should be added to the Crowd container.\n+  # Each item in the list should specify the name of the volume which contain the library, as well as the name of the\n+  # library file within that volume's root directory. Optionally, a subDirectory field can be included to specify which\n+  # directory in the volume contains the library file.\n+  additionalLibraries: []\n+#    - volumeName:\n+#      subDirectory:\n+#      fileName:\n+\n+  # -- Specifies a list of additional Crowd plugins that should be added to the Crowd container.\n+  # These are specified in the same manner as the additionalLibraries field, but the files will be loaded\n+  # as bundled plugins rather than as libraries.\n+  additionalBundledPlugins: []\n+#    - volumeName:\n+#      subDirectory:\n+#      fileName:\n+\n+  # -- Defines any additional volumes mounts for the Crowd container.\n+  # These can refer to existing volumes, or new volumes can be defined in volumes.additional.\n+  additionalVolumeMounts: []\n+\n+  # -- Defines any additional environment variables to be passed to the Crowd container.\n+  # See https://hub.docker.com/r/atlassian/crowd for supported variables.\n+  additionalEnvironmentVariables: []\n+\n+ingress:\n+  # -- True if an Ingress should be created.\n+  create: false\n+  # -- True if the created Ingress is to use the Kubernetes ingress-nginx controller.\n+  # This will populate the Ingress with annotations for that controller.\n+  # Set to false if a different controller is to be used, in which case the annotations need to be specified.\n+  nginx: true\n+  # -- The fully-qualified hostname of the Ingress.\n+  host:\n+  # -- The custom annotations that should be applied to the Ingress.\n+  annotations: {}\n+  # -- True if the browser communicates with the application over HTTPS.\n+  https: true\n+  # -- Secret that contains a TLS private key and certificate.\n+  # Optional if Ingress Controller is configured to use one secret for all ingresses\n+  tlsSecretName:\n+\n+fluentd:\n+  # -- True if the fluentd sidecar should be added to each pod\n+  enabled: false\n+  # -- The name of the image containing the fluentd sidecar\n+  imageName: fluent/fluentd-kubernetes-daemonset:v1.11.5-debian-elasticsearch7-1.2\n+  # -- The port on which the fluentd sidecar will listen\n+  httpPort: 9880\n+  elasticsearch:\n+    # -- True if fluentd should send all log events to an elasticsearch service.\n+    enabled: true\n+    # -- The hostname of the Elasticsearch service that fluentd should send logs to.\n+    hostname: elasticsearch\n+    # -- The prefix of the elasticsearch index name that will be used\n+    indexNamePrefix: crowd\n+\n+# -- Specify additional annotations to be added to all Crowd pods\n+podAnnotations: {}\n+#  \"name\": \"value\"\n+\n+volumes:\n+  localHome:\n+    persistentVolumeClaim:\n+      # -- If true, then a PersistentVolumeClaim will be created for each local-home volume.\n+      create: false\n+      # -- Specifies the name of the storage class that should be used for the local-home volume claim.\n+      storageClassName:\n+      # -- Specifies the standard Kubernetes resource requests and/or limits for the local-home volume claims.\n+      resources:\n+        requests:\n+          storage: 1Gi\n+    # -- When persistentVolumeClaim.create is false, then this value can be used to define a standard Kubernetes\n+    # volume which will be used for the local-home volumes. If not defined, then defaults to an emptyDir volume.\n+    customVolume: {}\n+    # -- The path within the Crowd container which the local-home volume should be mounted.\n+    mountPath: \"/var/atlassian/application-data/crowd\"\n+  sharedHome:\n+    persistentVolumeClaim:\n+      # -- If true, then a PersistentVolumeClaim will be created for the shared-home volume.\n+      create: false\n+      # -- Specifies the name of the storage class that should be used for the shared-home volume claim.\n+      storageClassName:\n+      # -- Specifies the standard Kubernetes resource requests and/or limits for the shared-home volume claims.\n+      resources:\n+        requests:\n+          storage: 1Gi\n+    # -- When persistentVolumeClaim.create is false, then this value can be used to define a standard Kubernetes\n+    # volume which will be used for the shared-home volume. If not defined, then defaults to an emptyDir (i.e. unshared) volume.\n+    customVolume: {}\n+    # -- Specifies the path in the Crowd container to which the shared-home volume will be mounted.\n+    mountPath: \"/var/atlassian/application-data/crowd/shared\"\n+    # -- Specifies the sub-directory of the shared-home volume which will be mounted in to the Crowd container.\n+    subPath:\n+    nfsPermissionFixer:\n+      # -- If enabled, this will alter the shared volume's root directory so that Crowd can write to it.\n+      # This is a workaround for a Kubernetes bug affecting NFS volumes: https://github.com/kubernetes/examples/issues/260\n+      enabled: false\n+      # -- The path in the initContainer where the shared-home volume will be mounted\n+      mountPath: /shared-home\n+      # -- By default, the fixer will change the group ownership of the volume's root directory to match the Crowd\n+      # container's GID (2002), and then ensures the directory is group-writeable. If this is not the desired behaviour,\n+      # command used can be specified here.\n+      command:\n+  # -- Defines additional volumes that should be applied to all Crowd pods.\n+  # Note that this will not create any corresponding volume mounts;\n+  # those needs to be defined in crowd.additionalVolumeMounts\n+  additional: []\n+\n+# -- Standard Kubernetes node-selectors that will be applied to all Crowd pods\n+nodeSelector: {}\n+\n+# -- Standard Kubernetes tolerations that will be applied to all Crowd pods\n+tolerations: []\n+\n+# -- Standard Kubernetes affinities that will be applied to all Crowd pods\n+affinity: {}\n+\n+# -- Additional container definitions that will be added to all Crowd pods\n+additionalContainers: []\n+\n+# -- Additional initContainer definitions that will be added to all Crowd pods\n+additionalInitContainers: []\n+\n+# -- Additional labels that should be applied to all resources\n+additionalLabels: {}"
  }
]
