[
  {
    "sha": "43530e3d5f0f0f94eb2c54f30214b056d9ed33b0",
    "filename": "src/main/java/org/broadinstitute/hellbender/engine/MultiVariantDataSource.java",
    "status": "modified",
    "additions": 6,
    "deletions": 1,
    "changes": 7,
    "blob_url": "https://github.com/broadinstitute/gatk/blob/af6c823e27e1ecd437a3b045f3dc1b519c855bcf/src/main/java/org/broadinstitute/hellbender/engine/MultiVariantDataSource.java",
    "raw_url": "https://github.com/broadinstitute/gatk/raw/af6c823e27e1ecd437a3b045f3dc1b519c855bcf/src/main/java/org/broadinstitute/hellbender/engine/MultiVariantDataSource.java",
    "contents_url": "https://api.github.com/repos/broadinstitute/gatk/contents/src/main/java/org/broadinstitute/hellbender/engine/MultiVariantDataSource.java?ref=af6c823e27e1ecd437a3b045f3dc1b519c855bcf",
    "patch": "@@ -252,10 +252,15 @@ private VCFHeader getMergedHeader() {\n                 .map(ds -> getHeaderWithUpdatedSequenceDictionary(ds))\n                 .collect(Collectors.toList());\n \n+        final Set<String> allSamples = new LinkedHashSet<>();  //use a set to uniquify samples\n+        for (final VCFHeader h : headers) {\n+            allSamples.addAll(h.getGenotypeSamples());\n+        }\n+\n         // Now merge the headers using htsjdk, which is pretty promiscuous, and which only works properly\n         // because of the cross-dictionary validation done in validateAllSequenceDictionaries.\n         return headers.size() > 1 ?\n-                new VCFHeader(VCFUtils.smartMergeHeaders(headers, true)) :\n+                new VCFHeader(VCFUtils.smartMergeHeaders(headers, true), allSamples) :\n                 headers.get(0);\n     }\n "
  },
  {
    "sha": "4b5528371e7efce784352c76ae4ee3137f3ca0d5",
    "filename": "src/main/java/org/broadinstitute/hellbender/engine/spark/datasources/VariantsSparkSink.java",
    "status": "modified",
    "additions": 1,
    "deletions": 1,
    "changes": 2,
    "blob_url": "https://github.com/broadinstitute/gatk/blob/af6c823e27e1ecd437a3b045f3dc1b519c855bcf/src/main/java/org/broadinstitute/hellbender/engine/spark/datasources/VariantsSparkSink.java",
    "raw_url": "https://github.com/broadinstitute/gatk/raw/af6c823e27e1ecd437a3b045f3dc1b519c855bcf/src/main/java/org/broadinstitute/hellbender/engine/spark/datasources/VariantsSparkSink.java",
    "contents_url": "https://api.github.com/repos/broadinstitute/gatk/contents/src/main/java/org/broadinstitute/hellbender/engine/spark/datasources/VariantsSparkSink.java?ref=af6c823e27e1ecd437a3b045f3dc1b519c855bcf",
    "patch": "@@ -122,7 +122,7 @@ private static void writeVariantsSingle(\n         final JavaRDD<VariantContext> sortedVariants = sortVariantsToHeader ? sortVariants(variants, header, numReducers) : variants;\n         final JavaRDD<VariantContext> variantsToSave;\n         if (writeGvcf) {\n-            GVCFBlockCombiner gvcfBlockCombiner = new GVCFBlockCombiner(gqPartitions, defaultPloidy, false);\n+            GVCFBlockCombiner gvcfBlockCombiner = new GVCFBlockCombiner(gqPartitions, false);\n             gvcfBlockCombiner.addRangesToHeader(header);\n             variantsToSave = sortedVariants.mapPartitions((FlatMapFunction<Iterator<VariantContext>, VariantContext>) v -> new GVCFBlockCombiningIterator(v, gqPartitions, defaultPloidy));\n         } else {"
  },
  {
    "sha": "c56938e9665971c3216613a261b4ca180935a99f",
    "filename": "src/main/java/org/broadinstitute/hellbender/tools/walkers/genotyper/AlleleSubsettingUtils.java",
    "status": "modified",
    "additions": 49,
    "deletions": 6,
    "changes": 55,
    "blob_url": "https://github.com/broadinstitute/gatk/blob/af6c823e27e1ecd437a3b045f3dc1b519c855bcf/src/main/java/org/broadinstitute/hellbender/tools/walkers/genotyper/AlleleSubsettingUtils.java",
    "raw_url": "https://github.com/broadinstitute/gatk/raw/af6c823e27e1ecd437a3b045f3dc1b519c855bcf/src/main/java/org/broadinstitute/hellbender/tools/walkers/genotyper/AlleleSubsettingUtils.java",
    "contents_url": "https://api.github.com/repos/broadinstitute/gatk/contents/src/main/java/org/broadinstitute/hellbender/tools/walkers/genotyper/AlleleSubsettingUtils.java?ref=af6c823e27e1ecd437a3b045f3dc1b519c855bcf",
    "patch": "@@ -285,9 +285,45 @@ else if ( clazz.equals(int[].class) ) {\n      */\n     public static List<Allele> calculateMostLikelyAlleles(final VariantContext vc, final int defaultPloidy,\n                                                           final int numAltAllelesToKeep) {\n+        return calculateMostLikelyAlleles(vc, defaultPloidy, numAltAllelesToKeep, false);\n+    }\n+\n+    /**\n+     * Returns the new set of alleles to use based on a likelihood score: alleles' scores are the sum of their counts in\n+     * sample genotypes, weighted by the confidence in the genotype calls.\n+     *\n+     * In the case of ties, the alleles will be chosen from lowest index to highest index.\n+     *\n+     * @param vc target variant context.\n+     * @param numAltAllelesToKeep number of alt alleles to keep.\n+     * @return the list of alleles to keep, including the reference and {@link Allele#NON_REF_ALLELE} if present\n+     *\n+     */\n+    public static List<Allele> calculateMostLikelyAllelesForMonomorphicSite(final VariantContext vc, final int defaultPloidy,\n+                                                                            final int numAltAllelesToKeep) {\n+        return calculateMostLikelyAlleles(vc, defaultPloidy, numAltAllelesToKeep, true);\n+    }\n+\n+    /**\n+     * Returns the new set of alleles to use based on a likelihood score: alleles' scores are the sum of their counts in\n+     * sample genotypes, weighted by the confidence in the genotype calls.\n+     *\n+     * In the case of ties, the alleles will be chosen from lowest index to highest index.\n+     *\n+     * @param vc target variant context.\n+     * @param numAltAllelesToKeep number of alt alleles to keep.\n+     * @param allHomRefData do likelihood calculations for a monomorphic site\n+     * @return the list of alleles to keep, including the reference and {@link Allele#NON_REF_ALLELE} if present\n+     *\n+     */\n+    private static List<Allele> calculateMostLikelyAlleles(final VariantContext vc, final int defaultPloidy,\n+                                                          final int numAltAllelesToKeep, boolean allHomRefData) {\n         Utils.nonNull(vc, \"vc is null\");\n         Utils.validateArg(defaultPloidy > 0, () -> \"default ploidy must be > 0 but defaultPloidy=\" + defaultPloidy);\n         Utils.validateArg(numAltAllelesToKeep > 0, () -> \"numAltAllelesToKeep must be > 0, but numAltAllelesToKeep=\" + numAltAllelesToKeep);\n+        if (allHomRefData) {\n+            Utils.validate(vc.getGenotypes().stream().allMatch(g -> g.hasPL() && g.getPL()[0] == 0), \"Site contains variant genotypes, but method was called for monorphic site.\");\n+        }\n \n         final boolean hasSymbolicNonRef = vc.hasAllele(Allele.NON_REF_ALLELE);\n         final int numberOfAllelesThatArentProperAlts = hasSymbolicNonRef ? 2 : 1; \n@@ -297,7 +333,7 @@ else if ( clazz.equals(int[].class) ) {\n             return vc.getAlleles();\n         }\n \n-        final double[] likelihoodSums = calculateLikelihoodSums(vc, defaultPloidy);\n+        final double[] likelihoodSums = calculateLikelihoodSums(vc, defaultPloidy, allHomRefData);\n         return filterToMaxNumberOfAltAllelesBasedOnScores(numAltAllelesToKeep, vc.getAlleles(), likelihoodSums);\n     }\n \n@@ -329,25 +365,32 @@ else if ( clazz.equals(int[].class) ) {\n      * SUM_{samples whose likeliest genotype contains this alt allele} log(likelihood alt / likelihood hom ref)\n      */\n     @VisibleForTesting\n-    static double[] calculateLikelihoodSums(final VariantContext vc, final int defaultPloidy) {\n+    static double[] calculateLikelihoodSums(final VariantContext vc, final int defaultPloidy, boolean useHomRefData) {\n         final double[] likelihoodSums = new double[vc.getNAlleles()];\n         for ( final Genotype genotype : vc.getGenotypes().iterateInSampleNameOrder() ) {\n             final GenotypeLikelihoods gls = genotype.getLikelihoods();\n             if (gls == null) {\n                 continue;\n             }\n             final double[] glsVector = gls.getAsVector();\n-            final int indexOfMostLikelyGenotype = MathUtils.maxElementIndex(glsVector);\n-            final double GLDiffBetweenRefAndBest = glsVector[indexOfMostLikelyGenotype] - glsVector[PL_INDEX_OF_HOM_REF];\n+            final int genotypeCallIndex = MathUtils.maxElementIndex(glsVector);\n+            int indexOfMostLikelyVariantGenotype;\n+            final double GLDiffBetweenRefAndBestVariantGenotype;\n+            if (genotypeCallIndex > 0 || !useHomRefData) {\n+                 indexOfMostLikelyVariantGenotype = genotypeCallIndex;\n+            } else {\n+                indexOfMostLikelyVariantGenotype = MathUtils.maxElementIndex(glsVector, 1, glsVector.length-1);\n+            }\n+            GLDiffBetweenRefAndBestVariantGenotype = Math.abs(glsVector[indexOfMostLikelyVariantGenotype] - glsVector[PL_INDEX_OF_HOM_REF]);\n             final int ploidy = genotype.getPloidy() > 0 ? genotype.getPloidy() : defaultPloidy;\n \n             final int[] alleleCounts = new GenotypeLikelihoodCalculators()\n-                    .getInstance(ploidy, vc.getNAlleles()).genotypeAlleleCountsAt(indexOfMostLikelyGenotype)\n+                    .getInstance(ploidy, vc.getNAlleles()).genotypeAlleleCountsAt(indexOfMostLikelyVariantGenotype)\n                     .alleleCountsByIndex(vc.getNAlleles() - 1);\n \n             for (int allele = 1; allele < alleleCounts.length; allele++) {\n                 if (alleleCounts[allele] > 0) {\n-                    likelihoodSums[allele] += GLDiffBetweenRefAndBest;\n+                    likelihoodSums[allele] += GLDiffBetweenRefAndBestVariantGenotype;\n                 }\n             }\n         }"
  },
  {
    "sha": "44b0fb41a3187fbbd446380468a29f2d9cccb38d",
    "filename": "src/main/java/org/broadinstitute/hellbender/tools/walkers/genotyper/GenotypeCalculationArgumentCollection.java",
    "status": "modified",
    "additions": 3,
    "deletions": 1,
    "changes": 4,
    "blob_url": "https://github.com/broadinstitute/gatk/blob/af6c823e27e1ecd437a3b045f3dc1b519c855bcf/src/main/java/org/broadinstitute/hellbender/tools/walkers/genotyper/GenotypeCalculationArgumentCollection.java",
    "raw_url": "https://github.com/broadinstitute/gatk/raw/af6c823e27e1ecd437a3b045f3dc1b519c855bcf/src/main/java/org/broadinstitute/hellbender/tools/walkers/genotyper/GenotypeCalculationArgumentCollection.java",
    "contents_url": "https://api.github.com/repos/broadinstitute/gatk/contents/src/main/java/org/broadinstitute/hellbender/tools/walkers/genotyper/GenotypeCalculationArgumentCollection.java?ref=af6c823e27e1ecd437a3b045f3dc1b519c855bcf",
    "patch": "@@ -16,6 +16,8 @@\n     public static final String SUPPORTING_CALLSET_LONG_NAME = \"population-callset\";\n     public static final String SUPPORTING_CALLSET_SHORT_NAME = \"population\";\n     public static final String NUM_REF_SAMPLES_LONG_NAME = \"num-reference-samples-if-no-call\";\n+    public static final String CALL_CONFIDENCE_LONG_NAME = \"standard-min-confidence-threshold-for-calling\";\n+    public static final String CALL_CONFIDENCE_SHORT_NAME = \"stand-call-conf\";\n     public static final String MAX_ALTERNATE_ALLELES_LONG_NAME = \"max-alternate-alleles\";\n     public static final String MAX_GENOTYPE_COUNT_LONG_NAME = \"max-genotype-count\";\n     public static final String SAMPLE_PLOIDY_SHORT_NAME = \"ploidy\";\n@@ -124,7 +126,7 @@ public GenotypeCalculationArgumentCollection clone() {\n      *\n      * Note that the default was changed from 10.0 to 30.0 in version 4.1.0.0 to accompany the switch to use the the new quality score by default.\n      */\n-    @Argument(fullName = \"standard-min-confidence-threshold-for-calling\", shortName = \"stand-call-conf\", doc = \"The minimum phred-scaled confidence threshold at which variants should be called\", optional = true)\n+    @Argument(fullName = CALL_CONFIDENCE_LONG_NAME, shortName = CALL_CONFIDENCE_SHORT_NAME, doc = \"The minimum phred-scaled confidence threshold at which variants should be called\", optional = true)\n     public double STANDARD_CONFIDENCE_FOR_CALLING = DEFAULT_STANDARD_CONFIDENCE_FOR_CALLING;\n \n     /**"
  },
  {
    "sha": "fc56e46490c0a89eb1e1b839cb2632341fbda66c",
    "filename": "src/main/java/org/broadinstitute/hellbender/tools/walkers/genotyper/GenotypingEngine.java",
    "status": "modified",
    "additions": 5,
    "deletions": 2,
    "changes": 7,
    "blob_url": "https://github.com/broadinstitute/gatk/blob/af6c823e27e1ecd437a3b045f3dc1b519c855bcf/src/main/java/org/broadinstitute/hellbender/tools/walkers/genotyper/GenotypingEngine.java",
    "raw_url": "https://github.com/broadinstitute/gatk/raw/af6c823e27e1ecd437a3b045f3dc1b519c855bcf/src/main/java/org/broadinstitute/hellbender/tools/walkers/genotyper/GenotypingEngine.java",
    "contents_url": "https://api.github.com/repos/broadinstitute/gatk/contents/src/main/java/org/broadinstitute/hellbender/tools/walkers/genotyper/GenotypingEngine.java?ref=af6c823e27e1ecd437a3b045f3dc1b519c855bcf",
    "patch": "@@ -60,13 +60,15 @@\n      *                    sample set will be used instead.\n      * @param doAlleleSpecificCalcs Whether the AS_QUAL key should be calculated and added to newly genotyped variants.\n      *\n-     * @throws IllegalArgumentException if any of {@code samples}, {@code configuration} is {@code null}.\n+     * @throws IllegalArgumentException if any of {@code samples}, {@code configuration} is {@code null} or if {@code samples} is empty.\n      */\n     protected GenotypingEngine(final Config configuration,\n                                final SampleList samples,\n                                final boolean doAlleleSpecificCalcs) {\n         this.configuration = Utils.nonNull(configuration, \"the configuration cannot be null\");\n-        this.samples = Utils.nonNull(samples, \"the sample list cannot be null\");\n+        Utils.nonNull(samples, \"the sample list cannot be null\");\n+        Utils.nonEmpty(samples.asListOfSamples(), \"the sample list cannot be empty\");\n+        this.samples = samples;\n         this.doAlleleSpecificCalcs = doAlleleSpecificCalcs;\n         logger = LogManager.getLogger(getClass());\n         numberOfGenomes = this.samples.numberOfSamples() * configuration.genotypeArgs.samplePloidy;\n@@ -233,6 +235,7 @@ private double extractPNoAlt(final List<Allele> alleles, final Genotype gt, fina\n         }\n     }\n \n+    //TODO: update for DRAGEN GP tag\n     private boolean hasPosteriors(final GenotypesContext gc) {\n         return gc.stream().anyMatch(g -> g.hasExtendedAttribute(VCFConstants.GENOTYPE_POSTERIORS_KEY));\n     }"
  },
  {
    "sha": "d7778e10459d57807f972ea4f262a427d0d35f1f",
    "filename": "src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/HaplotypeCallerEngine.java",
    "status": "modified",
    "additions": 1,
    "deletions": 2,
    "changes": 3,
    "blob_url": "https://github.com/broadinstitute/gatk/blob/af6c823e27e1ecd437a3b045f3dc1b519c855bcf/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/HaplotypeCallerEngine.java",
    "raw_url": "https://github.com/broadinstitute/gatk/raw/af6c823e27e1ecd437a3b045f3dc1b519c855bcf/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/HaplotypeCallerEngine.java",
    "contents_url": "https://api.github.com/repos/broadinstitute/gatk/contents/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/HaplotypeCallerEngine.java?ref=af6c823e27e1ecd437a3b045f3dc1b519c855bcf",
    "patch": "@@ -36,7 +36,6 @@\n import org.broadinstitute.hellbender.utils.genotyper.SampleList;\n import org.broadinstitute.hellbender.utils.haplotype.Haplotype;\n import org.broadinstitute.hellbender.utils.haplotype.HaplotypeBAMWriter;\n-import org.broadinstitute.hellbender.utils.io.IOUtils;\n import org.broadinstitute.hellbender.utils.read.AlignmentUtils;\n import org.broadinstitute.hellbender.utils.read.GATKRead;\n import org.broadinstitute.hellbender.utils.read.ReadUtils;\n@@ -381,7 +380,7 @@ public VariantContextWriter makeVCFWriter( final GATKPath outputVCF, final SAMSe\n \n         if ( hcArgs.emitReferenceConfidence == ReferenceConfidenceMode.GVCF ) {\n             try {\n-                writer = new GVCFWriter(writer, new ArrayList<Number>(hcArgs.GVCFGQBands), hcArgs.standardArgs.genotypeArgs.samplePloidy, hcArgs.floorBlocks);\n+                writer = new GVCFWriter(writer, new ArrayList<Number>(hcArgs.GVCFGQBands), hcArgs.floorBlocks);\n             } catch ( IllegalArgumentException e ) {\n                 throw new CommandLineException.BadArgumentValue(\"GQBands\", \"are malformed: \" + e.getMessage());\n             }"
  },
  {
    "sha": "bbb8aae6bf7291f591f62ef93bc0ef66900cb4de",
    "filename": "src/main/java/org/broadinstitute/hellbender/tools/walkers/variantutils/ReblockGVCF.java",
    "status": "modified",
    "additions": 711,
    "deletions": 241,
    "changes": 952,
    "blob_url": "https://github.com/broadinstitute/gatk/blob/af6c823e27e1ecd437a3b045f3dc1b519c855bcf/src/main/java/org/broadinstitute/hellbender/tools/walkers/variantutils/ReblockGVCF.java",
    "raw_url": "https://github.com/broadinstitute/gatk/raw/af6c823e27e1ecd437a3b045f3dc1b519c855bcf/src/main/java/org/broadinstitute/hellbender/tools/walkers/variantutils/ReblockGVCF.java",
    "contents_url": "https://api.github.com/repos/broadinstitute/gatk/contents/src/main/java/org/broadinstitute/hellbender/tools/walkers/variantutils/ReblockGVCF.java?ref=af6c823e27e1ecd437a3b045f3dc1b519c855bcf",
    "patch": "@@ -8,11 +8,8 @@\n import org.broadinstitute.barclay.help.DocumentedFeature;\n import org.broadinstitute.hellbender.cmdline.*;\n import org.broadinstitute.hellbender.cmdline.argumentcollections.DbsnpArgumentCollection;\n-import org.broadinstitute.hellbender.engine.FeatureContext;\n-import org.broadinstitute.hellbender.engine.ReadsContext;\n-import org.broadinstitute.hellbender.engine.ReferenceContext;\n-import org.broadinstitute.hellbender.engine.GATKPath;\n-import org.broadinstitute.hellbender.engine.VariantWalker;\n+import org.broadinstitute.hellbender.engine.*;\n+import org.broadinstitute.hellbender.exceptions.GATKException;\n import org.broadinstitute.hellbender.exceptions.UserException;\n import org.broadinstitute.hellbender.tools.walkers.annotator.*;\n import org.broadinstitute.hellbender.tools.walkers.annotator.allelespecific.AS_QualByDepth;\n@@ -23,18 +20,25 @@\n import org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerGenotypingEngine;\n import org.broadinstitute.hellbender.tools.walkers.haplotypecaller.ReferenceConfidenceMode;\n import org.broadinstitute.hellbender.utils.MathUtils;\n+import org.broadinstitute.hellbender.utils.SimpleInterval;\n+import org.broadinstitute.hellbender.utils.Utils;\n+import org.broadinstitute.hellbender.utils.collections.Permutation;\n+import org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile;\n+import org.broadinstitute.hellbender.utils.genotyper.IndexedAlleleList;\n import org.broadinstitute.hellbender.utils.genotyper.IndexedSampleList;\n import org.broadinstitute.hellbender.utils.genotyper.SampleList;\n import org.broadinstitute.hellbender.utils.logging.OneShotLogger;\n+import org.broadinstitute.hellbender.utils.reference.ReferenceUtils;\n+import org.broadinstitute.hellbender.utils.variant.*;\n import org.broadinstitute.hellbender.utils.variant.GATKVCFConstants;\n import org.broadinstitute.hellbender.utils.variant.GATKVCFHeaderLines;\n import org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils;\n-import org.broadinstitute.hellbender.utils.variant.HomoSapiensConstants;\n import org.broadinstitute.hellbender.utils.variant.writers.GVCFWriter;\n import picard.cmdline.programgroups.OtherProgramGroup;\n \n import java.util.*;\n import java.util.stream.Collectors;\n+import java.util.stream.IntStream;\n \n /**\n  * Condense homRef blocks in a single-sample GVCF\n@@ -76,8 +80,6 @@\n  *\n  * <h3>Caveats</h3>\n  * <p>Only single-sample GVCF files produced by HaplotypeCaller can be used as input for this tool.</p>\n- * <h3>Special note on ploidy</h3>\n- * <p>This tool assumes diploid genotypes.</p>\n  *\n  */\n @BetaFeature\n@@ -86,12 +88,31 @@\n         programGroup = OtherProgramGroup.class,\n         omitFromCommandLine = true)\n @DocumentedFeature\n-public final class ReblockGVCF extends VariantWalker {\n+public final class ReblockGVCF extends MultiVariantWalker {\n \n     private static final OneShotLogger logger = new OneShotLogger(ReblockGVCF.class);\n \n     private final static int PLOIDY_TWO = 2;  //assume diploid genotypes\n \n+    private int bufferEnd = 0;\n+    private int vcfOutputEnd = 0;\n+\n+    public static final String DROP_LOW_QUALS_ARG_NAME = \"drop-low-quals\";\n+    public static final String RGQ_THRESHOLD_LONG_NAME = \"rgq-threshold-to-no-call\";\n+    public static final String RGQ_THRESHOLD_SHORT_NAME = \"rgq-threshold\";\n+    public static final String KEEP_ALL_ALTS_ARG_NAME = \"keep-all-alts\";\n+    public static final String QUAL_APPROX_LONG_NAME = \"do-qual-score-approximation\";\n+    public static final String QUAL_APPROX_SHORT_NAME = \"do-qual-approx\";\n+    public static final String ALLOW_MISSING_LONG_NAME = \"allow-missing-hom-ref-data\";\n+    public static final String POSTERIORS_KEY_LONG_NAME = \"genotype-posteriors-key\";\n+\n+    private final class VariantContextBuilderComparator implements Comparator<VariantContextBuilder> {\n+        @Override\n+        public int compare(final VariantContextBuilder builder1, final VariantContextBuilder builder2) {\n+            return (int)(builder1.getStart() - builder2.getStart());\n+        }\n+    }\n+\n     @Argument(fullName = StandardArgumentDefinitions.OUTPUT_LONG_NAME, shortName = StandardArgumentDefinitions.OUTPUT_SHORT_NAME,\n             doc=\"File to which variants should be written\")\n     private GATKPath outputFile;\n@@ -115,21 +136,29 @@\n     }\n \n     @Advanced\n-    @Argument(fullName=\"drop-low-quals\", shortName=\"drop-low-quals\", doc=\"Exclude variants and homRef blocks that are GQ0 from the reblocked GVCF to save space; drop low quality/uncalled alleles\")\n+    @Argument(fullName=DROP_LOW_QUALS_ARG_NAME, shortName=DROP_LOW_QUALS_ARG_NAME, doc=\"Exclude variants and homRef blocks that are GQ0 from the reblocked GVCF to save space; drop low quality/uncalled alleles\")\n     protected boolean dropLowQuals = false;\n \n     @Advanced\n-    @Argument(fullName=\"rgq-threshold-to-no-call\", shortName=\"rgq-threshold\", doc=\"Reference genotype quality (PL[0]) value below which variant sites will be converted to GQ0 homRef calls\")\n+    @Argument(fullName=RGQ_THRESHOLD_LONG_NAME, shortName=RGQ_THRESHOLD_SHORT_NAME, doc=\"Reference genotype quality (PL[0]) value below which variant sites will be converted to GQ0 homRef calls\")\n     protected double rgqThreshold = 0.0;\n \n     @Advanced\n-    @Argument(fullName=\"do-qual-score-approximation\", shortName=\"do-qual-approx\", doc=\"Add necessary INFO field annotation to perform QUAL approximation downstream; required for GnarlyGenotyper\")\n+    @Argument(fullName=QUAL_APPROX_LONG_NAME, shortName=QUAL_APPROX_SHORT_NAME, doc=\"Add necessary INFO field annotation to perform QUAL approximation downstream; required for GnarlyGenotyper\")\n     protected boolean doQualApprox = false;\n \n     @Advanced\n-    @Argument(fullName=\"allow-missing-hom-ref-data\", doc=\"Fill in homozygous reference genotypes with no PLs and no GQ with PL=[0,0,0].  Necessary for input from Regeneron's WeCall variant caller.\")\n+    @Argument(fullName=ALLOW_MISSING_LONG_NAME, doc=\"Fill in homozygous reference genotypes with no PLs and no GQ with PL=[0,0,0].  Necessary for input from Regeneron's WeCall variant caller.\")\n     protected boolean allowMissingHomRefData = false;\n \n+    @Advanced\n+    @Argument(fullName=KEEP_ALL_ALTS_ARG_NAME, doc=\"Keep all ALT alleles and full PL array for most accurate GQs\")\n+    protected boolean keepAllAlts = false;\n+\n+    @Advanced\n+    @Argument(fullName=POSTERIORS_KEY_LONG_NAME, doc=\"INFO field key corresponding to the posterior genotype probabilities\", optional = true)\n+    protected String posteriorsKey = null;\n+\n     /**\n      * The rsIDs from this file are used to populate the ID column of the output.  Also, the DB INFO flag will be set when appropriate. Note that dbSNP is not used in any way for the calculations themselves.\n      */\n@@ -143,9 +172,14 @@\n     // the INFO field annotation key names to remove\n     private final List<String> infoFieldAnnotationKeyNamesToRemove = Arrays.asList(GVCFWriter.GVCF_BLOCK, GATKVCFConstants.HAPLOTYPE_SCORE_KEY,\n             GATKVCFConstants.INBREEDING_COEFFICIENT_KEY, GATKVCFConstants.MLE_ALLELE_COUNT_KEY,\n-            GATKVCFConstants.MLE_ALLELE_FREQUENCY_KEY, GATKVCFConstants.EXCESS_HET_KEY);\n+            GATKVCFConstants.MLE_ALLELE_FREQUENCY_KEY, GATKVCFConstants.EXCESS_HET_KEY, GATKVCFConstants.AS_INBREEDING_COEFFICIENT_KEY,\n+            GATKVCFConstants.DOWNSAMPLED_KEY);\n \n+    private final List<VariantContextBuilder> homRefBlockBuffer = new ArrayList<>(10);  //10 is a generous estimate for the number of overlapping deletions\n+    private String currentContig;\n     private VariantContextWriter vcfWriter;\n+    private CachingIndexedFastaSequenceFile referenceReader;\n+    private final VariantContextBuilderComparator refBufferComparator = new VariantContextBuilderComparator();\n \n     @Override\n     public boolean useVariantAnnotations() { return true;}\n@@ -155,12 +189,17 @@\n         return Arrays.asList(StandardAnnotation.class, AS_StandardAnnotation.class);\n     }\n \n+    @Override\n+    public boolean requiresReference() {return true;}\n+\n     @Override\n     public void onTraversalStart() {\n-        VCFHeader inputHeader = getHeaderForVariants();\n-        if (inputHeader.getGenotypeSamples().size() > 1) {\n-            throw new UserException.BadInput(\"ReblockGVCF is a single sample tool, but the input GVCF has more than 1 sample.\");\n+        if (getSamplesForVariants().size() != 1) {\n+            throw new UserException.BadInput(\"ReblockGVCF can take multiple input GVCFs, but they must be \"\n+                    + \"non-overlapping shards from the same sample.  Found samples \" + getSamplesForVariants());\n         }\n+\n+        final VCFHeader inputHeader = getHeaderForVariants();\n         final Set<VCFHeaderLine> inputHeaders = inputHeader.getMetaDataInSortedOrder();\n \n         final Set<VCFHeaderLine> headerLines = new HashSet<>(inputHeaders);\n@@ -191,27 +230,30 @@ public void onTraversalStart() {\n             VCFStandardHeaderLines.addStandardInfoLines(headerLines, true, VCFConstants.DBSNP_KEY);\n         }\n \n-        VariantContextWriter writer = createVCFWriter(outputFile);\n+        final VariantContextWriter writer = createVCFWriter(outputFile);\n \n         try {\n-            vcfWriter = new GVCFWriter(writer, new ArrayList<Number>(GVCFGQBands), PLOIDY_TWO, floorBlocks);\n-        } catch ( IllegalArgumentException e ) {\n+            vcfWriter = new GVCFWriter(writer, new ArrayList<>(GVCFGQBands), floorBlocks);\n+        } catch ( final IllegalArgumentException e ) {\n             throw new IllegalArgumentException(\"GQBands are malformed: \" + e.getMessage(), e);\n         }\n-        vcfWriter.writeHeader(new VCFHeader(headerLines, inputHeader.getGenotypeSamples()));\n+        vcfWriter.writeHeader(new VCFHeader(headerLines, getSamplesForVariants()));  //don't get samples from header -- multi-variant inputHeader doens't have sample names\n \n         if (genotypeArgs.samplePloidy != PLOIDY_TWO) {\n-            throw new UserException.BadInput(\"The -ploidy parameter is ignored in \" + getClass().getSimpleName() + \" tool as this is tool assumes a diploid sample\");\n+            throw new UserException.BadInput(\"The -ploidy parameter is ignored in \" + getClass().getSimpleName() + \" tool as this tool maintains input ploidy for each genotype\");\n         }\n+\n+         referenceReader = ReferenceUtils.createReferenceReader(referenceArguments.getReferenceSpecifier());\n     }\n \n-    private HaplotypeCallerGenotypingEngine createGenotypingEngine(SampleList samples) {\n+    private HaplotypeCallerGenotypingEngine createGenotypingEngine(final SampleList samples) {\n         final HaplotypeCallerArgumentCollection hcArgs = new HaplotypeCallerArgumentCollection();\n         // create the genotyping engine\n-        hcArgs.standardArgs.outputMode = OutputMode.EMIT_ALL_ACTIVE_SITES;\n+        hcArgs.standardArgs.outputMode = OutputMode.EMIT_ALL_CONFIDENT_SITES;  //use confident vs. active mode so we can drop low quality variants\n         hcArgs.standardArgs.annotateAllSitesWithPLs = true;\n         hcArgs.standardArgs.genotypeArgs = genotypeArgs.clone();\n         hcArgs.emitReferenceConfidence = ReferenceConfidenceMode.GVCF;   //this is important to force emission of all alleles at a multiallelic site\n+        hcArgs.standardArgs.genotypeArgs.STANDARD_CONFIDENCE_FOR_CALLING = dropLowQuals ? genotypeArgs.STANDARD_CONFIDENCE_FOR_CALLING : 0.0;\n         return new HaplotypeCallerGenotypingEngine(hcArgs, samples, true, false);\n \n     }\n@@ -224,51 +266,208 @@ protected void createAnnotationEngine() {\n     // get VariantContexts from input gVCFs and regenotype\n     @Override\n     public void apply(VariantContext variant, ReadsContext reads, ReferenceContext ref, FeatureContext features) {\n-        final VariantContext newVC = regenotypeVC(variant);\n+        if (currentContig == null) {\n+            currentContig = variant.getContig(); //variantContexts should have identical start, so choose 0th arbitrarily\n+        } else if (!variant.getContig().equals(currentContig)) {\n+            flushRefBlockBuffer();\n+            currentContig = variant.getContig();\n+            vcfOutputEnd = 0;\n+        }\n+        final VariantContext newVC;\n+        try {\n+            newVC = regenotypeVC(variant);\n+        } catch (final Exception e) {\n+            throw new GATKException(\"Exception thrown at \" + variant.getContig() + \":\" + variant.getStart() + \" \" + variant.toString(), e);\n+        }\n         if (newVC != null) {\n-            vcfWriter.add(newVC);\n+            try {\n+                vcfWriter.add(newVC);\n+                if (newVC.getEnd() > vcfOutputEnd) {\n+                    vcfOutputEnd = newVC.getEnd();\n+                }\n+            } catch (Exception e) {\n+                throw new GATKException(\"Exception thrown at \" + newVC.getContig() + \":\" + newVC.getStart() + \" \" + newVC.toString(), e);\n+            }\n         }\n     }\n \n+    @Override\n+    public Object onTraversalSuccess() {\n+        flushRefBlockBuffer();\n+        return null;\n+    }\n+\n     /**\n      * Re-genotype (and re-annotate) a VariantContext\n      * Note that the GVCF write takes care of the actual homRef block merging based on {@code GVCFGQBands}\n      *\n      * @param originalVC     the combined genomic VC\n-     * @return a new VariantContext or null if the site turned monomorphic and we don't want such sites\n+     * @return a new VariantContext or null if the site turned monomorphic (may have been added to ref block buffer)\n      */\n-     private VariantContext regenotypeVC(final VariantContext originalVC) {\n+    private VariantContext regenotypeVC(final VariantContext originalVC) {\n         VariantContext result = originalVC;\n \n         //Pass back ref-conf homRef sites/blocks to be combined by the GVCFWriter\n         if (isHomRefBlock(result)) {\n-            return filterHomRefBlock(result);\n+            if (result.getEnd() <= vcfOutputEnd) {\n+                return null;\n+            }\n+            final VariantContext filtered = filterHomRefBlock(result);\n+            if (filtered != null) {\n+                updateHomRefBlockBuffer(filtered);\n+            }\n+            return null;\n         }\n \n+        //Use the genotyping engine to do the QUAL thresholding if we're dropping low qual sites\n         //don't need to calculate quals for sites with no data whatsoever or sites already genotyped homRef,\n-        // but if STAND_CALL_CONF > 0 we need to drop low quality alleles and regenotype\n-         //Note that spanning deletion star alleles will be considered low quality\n-        if (result.getAttributeAsInt(VCFConstants.DEPTH_KEY,0) > 0 && !isHomRefCall(result) && dropLowQuals) {\n-            result = genotypingEngine.calculateGenotypes(originalVC);\n+        //but if STAND_CALL_CONF > 0 we need to drop low quality alleles and regenotype\n+        //Note that spanning deletion star alleles will be considered low quality\n+        if (dropLowQuals && result.getAttributeAsInt(VCFConstants.DEPTH_KEY, 0) > 0 && !isMonomorphicCallWithAlts(result)) {\n+            final VariantContext regenotyped = genotypingEngine.calculateGenotypes(originalVC);\n+            if (regenotyped == null) {\n+                return null;\n+            }\n+            //make sure result has annotations so we don't have to keep originalVC around\n+            final Map<String, Object> newAnnotations;\n+            if (regenotyped.getNAlleles() != originalVC.getNAlleles()) {\n+                final Permutation<Allele> allelePermutation = new IndexedAlleleList<>(originalVC.getAlleles()).\n+                        permutation(new IndexedAlleleList<>(regenotyped.getAlleles()));\n+                final int[] relevantIndices = IntStream.range(0, regenotyped.getAlleles().size())\n+                        .map(n -> allelePermutation.fromIndex(n)).toArray();\n+                newAnnotations = new LinkedHashMap<>();\n+                composeUpdatedAnnotations(originalVC, newAnnotations, relevantIndices, regenotyped);\n+            } else {\n+                newAnnotations = originalVC.getAttributes();\n+            }\n+            result = new VariantContextBuilder(regenotyped).attributes(newAnnotations).make();\n         }\n \n-        if (result == null) {\n-            return null;\n-        }\n \n         //variants with PL[0] less than threshold get turned to homRef with PL=[0,0,0], shouldn't get INFO attributes\n         //make sure we can call het variants with GQ >= rgqThreshold in joint calling downstream\n         if(shouldBeReblocked(result)) {\n-            return lowQualVariantToGQ0HomRef(result, originalVC);\n+            if (result.getEnd() <= vcfOutputEnd) {\n+                return null;\n+            }\n+            final VariantContextBuilder newHomRefBuilder = lowQualVariantToGQ0HomRef(result);\n+            if (newHomRefBuilder != null) {\n+                updateHomRefBlockBuffer(newHomRefBuilder.make());\n+            }\n+            return null;  //don't write yet in case new ref block needs to be modified\n         }\n         //high quality variant\n         else {\n-            return cleanUpHighQualityVariant(result, originalVC);\n+            final VariantContext trimmedVariant = cleanUpHighQualityVariant(result);\n+            //handle overlapping deletions so there are no duplicate bases\n+            //this is under the assumption that HaplotypeCaller doesn't give us overlapping bases, which isn't really tru\n+\n+            if (homRefBlockBuffer.size() > 0) {\n+                //Queue the low quality deletions until we hit a high quality variant or the start is past the oldBlockEnd\n+                //Oh no, do we have to split the deletion-ref blocks???\n+                //For variants inside spanning deletion, * likelihood goes to zero?  Or matches ref?\n+                updateHomRefBlockBuffer(trimmedVariant);\n+            }\n+            return trimmedVariant;\n         }\n     }\n \n+    /**\n+     * Write and remove ref blocks that end before the variant\n+     * Trim ref block if the variant occurs in the middle of a block\n+     * @param variantContextToOutput can overlap existing ref blocks in buffer, but should never start before vcfOutputEnd\n+     */\n+    private void updateHomRefBlockBuffer(final VariantContext variantContextToOutput) {\n+        Utils.validate(variantContextToOutput.getStart() <= variantContextToOutput.getEnd(),\n+                \"Input variant context at position \" + currentContig + \":\" + variantContextToOutput.getStart() + \" has negative length: start=\" + variantContextToOutput.getStart() + \" end=\" + variantContextToOutput.getEnd());\n+        if (variantContextToOutput.getGenotype(0).isHomRef() && variantContextToOutput.getStart() < vcfOutputEnd) {\n+            throw new IllegalStateException(\"Reference positions added to buffer should not overlap positions already output to VCF. \"\n+                    + variantContextToOutput.getStart() + \" overlaps position \" + currentContig + \":\" + vcfOutputEnd + \" already emitted.\");\n+        }\n+        final List<VariantContextBuilder> completedBlocks = new ArrayList<>();\n+        final List<VariantContextBuilder> tailBuffer = new ArrayList<>();\n+        for (final VariantContextBuilder builder : homRefBlockBuffer) {\n+            final int blockStart = (int)builder.getStart();\n+            final int variantEnd = variantContextToOutput.getEnd();\n+            if (blockStart > variantEnd) {\n+                break;\n+            }\n+            int blockEnd = (int)builder.getStop();\n+            final int variantStart = variantContextToOutput.getStart();\n+            if (blockEnd >= variantStart) {  //then trim out overlap\n+                if (blockEnd > variantEnd && blockStart <= variantStart) {  //then this block will be split -- add a post-variant block\n+                    final VariantContextBuilder blockTailBuilder = new VariantContextBuilder(builder);\n+                    moveBuilderStart(blockTailBuilder, variantEnd + 1);\n+                    tailBuffer.add(blockTailBuilder);\n+                    builder.stop(variantEnd);\n+                    builder.attribute(VCFConstants.END_KEY, variantEnd);\n+                    blockEnd = variantEnd;\n+                }\n+                if (blockStart < variantStart) { //right trim\n+                    if (blockStart > variantStart - 1) {\n+                        throw new GATKException.ShouldNeverReachHereException(\"ref blocks screwed up; current builder: \" + builder.getStart() + \" to \" + builder.getStop());\n+                    }\n+                    builder.attribute(VCFConstants.END_KEY, variantStart - 1);\n+                    builder.stop(variantStart - 1);\n+                } else {  //left trim\n+                    if (variantContextToOutput.contains(new SimpleInterval(currentContig, blockStart, blockEnd))) {\n+                        completedBlocks.add(builder);\n+                    } else {\n+                        if (blockEnd < variantEnd + 1) {\n+                            throw new GATKException.ShouldNeverReachHereException(\"ref blocks screwed up; current builder: \" + builder.getStart() + \" to \" + builder.getStop());\n+                        }\n+                        moveBuilderStart(builder, variantEnd + 1);\n+                    }\n+                }\n+                if (builder.getStart() > builder.getStop()) {\n+                    throw new GATKException.ShouldNeverReachHereException(\"ref blocks screwed up; current builder: \" + builder.getStart() + \" to \" + builder.getStop());\n+                }\n+            }\n+            //only flush ref blocks if we're outputting a variant, otherwise ref blocks can be out of order\n+            if (builder.getStart() < variantStart && !variantContextToOutput.getGenotype(0).isHomRef()) {\n+                vcfWriter.add(builder.make());\n+                vcfOutputEnd = (int)builder.getStop();\n+                completedBlocks.add(builder);\n+            }\n+            bufferEnd = blockEnd;  //keep track of observed ends\n+        }\n+        homRefBlockBuffer.removeAll(completedBlocks);\n+        final Genotype g = variantContextToOutput.getGenotype(0);\n+        if (g.isHomRef() || (g.hasPL() && g.getPL()[0] == 0)) {\n+            final VariantContextBuilder newHomRefBlock = new VariantContextBuilder(variantContextToOutput);\n+            homRefBlockBuffer.add(newHomRefBlock);\n+        }\n+        homRefBlockBuffer.addAll(tailBuffer);\n+        homRefBlockBuffer.sort(refBufferComparator);  //this may seem lazy, but it's more robust to assumptions about overlap being violated\n+        bufferEnd = Math.max(bufferEnd, variantContextToOutput.getEnd());\n+    }\n+\n+    /**\n+     * Write all the reference blocks in the buffer to the output VCF\n+     */\n+    private void flushRefBlockBuffer() {\n+         for (final VariantContextBuilder builder : homRefBlockBuffer) {\n+             vcfWriter.add(builder.make());\n+             vcfOutputEnd = (int)builder.getStop();\n+         }\n+         homRefBlockBuffer.clear();\n+         bufferEnd = 0;\n+    }\n+\n+    /**\n+     * determine if a VC is a homRef block, i.e. has an end key and does not have filtering annotations\n+     * @param result VariantContext to process\n+     * @return true if VC is a homRef block and not a \"call\" with annotations\n+     */\n     private boolean isHomRefBlock(final VariantContext result) {\n-        return result.getAlternateAlleles().contains(Allele.NON_REF_ALLELE) && result.hasAttribute(VCFConstants.END_KEY);\n+        if (result.getGenotype(0).hasPL()) {\n+            if (result.getGenotype(0).getPL()[0] != 0) {\n+                return false;\n+            }\n+        } else {\n+            return (result.getAttributes().size() == 1) && result.hasAttribute(VCFConstants.END_KEY);\n+        }\n+        return result.getLog10PError() == VariantContext.NO_LOG10_PERROR;\n     }\n \n     /**\n@@ -277,24 +476,47 @@ private boolean isHomRefBlock(final VariantContext result) {\n      * @param result VariantContext to process\n      * @return true if VC is a 0/0 call and not a homRef block\n      */\n-    private boolean isHomRefCall(final VariantContext result) {\n+    private boolean isMonomorphicCallWithAlts(final VariantContext result) {\n         final Genotype genotype = result.getGenotype(0);\n-        return genotype.isHomRef() && result.getLog10PError() != VariantContext.NO_LOG10_PERROR;\n+        return ((genotype.isHomRef() || genotype.isNoCall()) && hasGenotypeValuesArray(genotype) && result.getLog10PError() != VariantContext.NO_LOG10_PERROR);\n     }\n \n+    /**\n+     *\n+     * @param genotype  a genotype that may or may not have likelihood/probability data\n+     * @return true if we can quantify genotype call\n+     */\n+    private boolean hasGenotypeValuesArray(final Genotype genotype) {\n+        return genotype.hasPL() || (posteriorsKey != null && genotype.hasExtendedAttribute(posteriorsKey));\n+    }\n+\n+\n+    /**\n+     * Process a reference block VC:\n+     * Drop if low quality or covered by previous VCF output,\n+     * correct missing data if possible, move ref block start if necessary\n+     * @param result    a reference block\n+     * @return  null if this block is entirely overlapped by positions already written out or\n+     * if the ref block is low quality and we'redropping low quality variants\n+     */\n     private VariantContext filterHomRefBlock(final VariantContext result) {\n         final Genotype genotype = result.getGenotype(0);\n+        final VariantContextBuilder vcBuilder = new VariantContextBuilder(result);\n+        if (result.getStart() <= vcfOutputEnd) {\n+            if (result.getEnd() <= vcfOutputEnd) {\n+                return null;\n+            }\n+            moveBuilderStart(vcBuilder, vcfOutputEnd + 1);\n+        }\n         if (dropLowQuals && (!genotype.hasGQ() || genotype.getGQ() < rgqThreshold || genotype.getGQ() == 0)) {\n             return null;\n-        }\n-        else if (genotype.isCalled() && genotype.isHomRef()) {\n+        } else if (genotype.isCalled() && genotype.isHomRef()) {\n             if (!genotype.hasPL()) {\n                 if (genotype.hasGQ()) {\n                     logger.warn(\"PL is missing for hom ref genotype at at least one position for sample \" + genotype.getSampleName() + \": \" + result.getContig() + \":\" + result.getStart() +\n                             \".  Using GQ to determine quality.\");\n                     final int gq = genotype.getGQ();\n                     final GenotypeBuilder gBuilder = new GenotypeBuilder(genotype);\n-                    final VariantContextBuilder vcBuilder = new VariantContextBuilder(result);\n                     vcBuilder.genotypes(gBuilder.GQ(gq).make());\n                     return vcBuilder.make();\n                 } else {\n@@ -303,221 +525,375 @@ else if (genotype.isCalled() && genotype.isHomRef()) {\n                     if (allowMissingHomRefData) {\n                         logger.warn(message);\n                         final GenotypeBuilder gBuilder = new GenotypeBuilder(genotype);\n-                        final VariantContextBuilder vcBuilder = new VariantContextBuilder(result);\n                         vcBuilder.genotypes(gBuilder.GQ(0).PL(new int[]{0,0,0}).make());\n                         return vcBuilder.make();\n                     } else {\n                         throw new UserException.BadInput(message);\n                     }\n                 }\n             }\n-            return result;\n-        }\n-        else if (!genotype.isCalled() && genotype.hasPL() && genotype.getPL()[0] == 0) {\n-            return result;\n+            return vcBuilder.make();\n+        //some external data has no-called genotypes with good likelihoods\n+        } else if (!genotype.isCalled() && genotype.hasPL() && genotype.getPL()[0] == 0) {\n+            return vcBuilder.make();\n         }\n         else {\n             return null;\n         }\n     }\n \n+    /**\n+     * Should this variant context be turned into a reference block?\n+     * @param vc    a low quality variant or variant called homozygous reference\n+     * @return  true if this VariantContext is eligible to be combined with adjacent reference blocks\n+     */\n     @VisibleForTesting\n-    protected boolean shouldBeReblocked(final VariantContext result) {\n-        final Genotype genotype = result.getGenotype(0);\n-        return !genotype.isCalled() || (genotype.hasPL() && genotype.getPL()[0] < rgqThreshold) || genotype.isHomRef();\n+    boolean shouldBeReblocked(final VariantContext vc) {\n+        if (!vc.hasGenotypes()) {\n+            throw new IllegalStateException(\"Variant contexts must contain genotypes to be reblocked.\");\n+        }\n+        final Genotype genotype = vc.getGenotype(0);\n+        final int[] pls = getGenotypeLikelihoodsOrPosteriors(genotype, posteriorsKey);\n+        return (pls != null && (pls[0] < rgqThreshold || pls[0] == 0)) || genotype.isHomRef()\n+                || !genotypeHasConcreteAlt(genotype)\n+                || genotype.getAlleles().stream().anyMatch(a -> a.equals(Allele.NON_REF_ALLELE))\n+                || (!genotype.hasPL() && !genotype.hasGQ())\n+                || (genotype.hasDP() && genotype.getDP() == 0);\n+    }\n+\n+    /**\n+     * Is there a real ALT allele that's not <NON_REF> or * ?\n+     * @param g called genotype\n+     * @return true if the genotype has a called allele that is a \"real\" alternate\n+     */\n+    private boolean genotypeHasConcreteAlt(final Genotype g) {\n+        return g.getAlleles().stream().anyMatch(a -> !a.isReference() && !a.isSymbolic() && !a.equals(Allele.SPAN_DEL));\n     }\n \n     /**\n      * \"reblock\" a variant by converting its genotype to homRef, changing PLs, adding reblock END tags and other attributes\n-     * @param result  a variant already determined to be low quality\n-     * @param originalVC the variant context with the original, full set of alleles\n-     * @return\n+     * @param lowQualityVariant  a variant already determined to be low quality\n+     * @return a Builder that can be modified later\n      */\n     @VisibleForTesting\n-    public VariantContext lowQualVariantToGQ0HomRef(final VariantContext result, final VariantContext originalVC) {\n-        if(dropLowQuals && (!isHomRefCall(result) || !result.getGenotype(0).isCalled())) {\n+    public VariantContextBuilder lowQualVariantToGQ0HomRef(final VariantContext lowQualityVariant) {\n+        if(dropLowQuals && (!isMonomorphicCallWithAlts(lowQualityVariant) || !lowQualityVariant.getGenotype(0).isCalled())) {\n             return null;\n         }\n-        if (!result.getGenotype(0).isCalled()) {\n-            return new VariantContextBuilder(result).attributes(null).make();\n+\n+        //change no-calls with PL values to ref blocks\n+        if (!lowQualityVariant.getGenotype(0).isCalled() && !lowQualityVariant.getGenotype(0).hasPL()) {\n+            final Map<String, Object> blockAttributes = new LinkedHashMap<>(2);\n+            final GenotypeBuilder gb = changeCallToHomRefVersusNonRef(lowQualityVariant, blockAttributes);\n+            final List<Allele> blockAlleles = Arrays.asList(Allele.create(lowQualityVariant.getReference().getBases()[0], true), Allele.NON_REF_ALLELE);\n+            final VariantContextBuilder vb = new VariantContextBuilder(lowQualityVariant).alleles(blockAlleles).attributes(blockAttributes).genotypes(gb.make())\n+                    .log10PError(VariantContext.NO_LOG10_PERROR);\n+            if (vcfOutputEnd + 1 > lowQualityVariant.getStart()) {\n+                moveBuilderStart(vb, vcfOutputEnd + 1);\n+            }\n+            return vb;   //delete variant annotations and add end key\n         }\n \n         final Map<String, Object> attrMap = new HashMap<>();\n-        final GenotypeBuilder gb = changeCallToGQ0HomRef(result, attrMap);\n \n-        //there are some cases where there are low quality variants with homRef calls AND alt alleles!\n-        //TODO: the best thing would be to take the most likely alt's likelihoods\n-        if (isHomRefCall(originalVC)) {\n-            final Genotype genotype = result.getGenotype(0);\n-            final int[] idxVector = originalVC.getGLIndicesOfAlternateAllele(Allele.NON_REF_ALLELE);   //this is always length 3\n-            if (genotype.hasPL()) {\n-                final int[] multiallelicPLs = genotype.getPL();\n-                final int[] newPLs = new int[3];\n-                newPLs[0] = multiallelicPLs[idxVector[0]];\n-                newPLs[1] = multiallelicPLs[idxVector[1]];\n-                newPLs[2] = multiallelicPLs[idxVector[2]];\n-                gb.PL(newPLs);\n-            }\n-            if (genotype.hasAD()) {\n-                int depth = (int) MathUtils.sum(genotype.getAD());\n-                gb.DP(depth);\n-                gb.attribute(GATKVCFConstants.MIN_DP_FORMAT_KEY, depth);\n-            }\n-        }\n+        //this method does a lot of things, including fixing alleles and adding the END key\n+        final GenotypeBuilder gb = changeCallToHomRefVersusNonRef(lowQualityVariant, attrMap);  //note that gb has all zero PLs\n+\n+        final VariantContextBuilder builder = new VariantContextBuilder(lowQualityVariant);\n \n-        VariantContextBuilder builder = new VariantContextBuilder(result);\n         final Genotype newG = gb.make();\n-        return builder.alleles(Arrays.asList(newG.getAlleles().get(0), Allele.NON_REF_ALLELE)).unfiltered().log10PError(VariantContext.NO_LOG10_PERROR).attributes(attrMap).genotypes(newG).make(); //genotyping engine will add lowQual filter, so strip it off\n+        builder.alleles(Arrays.asList(newG.getAlleles().get(0), Allele.NON_REF_ALLELE)).genotypes(newG);\n+        if (lowQualityVariant.getStart() <= vcfOutputEnd) {\n+            final int newStart = vcfOutputEnd + 1;\n+            moveBuilderStart(builder, newStart);\n+        }\n+        return builder.unfiltered()\n+                .log10PError(VariantContext.NO_LOG10_PERROR).attributes(attrMap); //genotyping engine will add lowQual filter, so strip it off\n     }\n \n     /**\n-     * Note that this modifies {@code attrMap} as a side effect\n-     * @param result a VC to be converted to a GQ0 homRef call\n-     * @param attrMap the new VC attribute map, to update the END tag as necessary\n-     * @return a GenotypeBuilder to make a 0/0 call with PLs=[0,0,0]\n+     * Produce a GenotypeBuilder for a hom-ref call suitable to be merged into a reference block, i.e. set with PLs as\n+     * appropriate for a variant with only reference and <NON_REF> as alleles and END applied as appropriate\n+     * Note that this may modify {@code attrMap} as a side effect for END key\n+     * @param result a VC containing a genotype to be converted to a GQ0 homRef call; needed for alleles that correspond to PLs and other things\n+     * @param attrMap the new VC attribute map, to update the END tag for deletions\n+     * @return a GenotypeBuilder to make a 0/0 call with updated PLs and GQ\n      */\n     @VisibleForTesting\n-    protected GenotypeBuilder changeCallToGQ0HomRef(final VariantContext result, final Map<String, Object> attrMap) {\n-        Genotype genotype = result.getGenotype(0);\n+    protected GenotypeBuilder changeCallToHomRefVersusNonRef(final VariantContext result, final Map<String, Object> attrMap) {\n+        final Genotype genotype = result.getGenotype(0);\n         Allele newRef = result.getReference();\n         GenotypeBuilder gb = new GenotypeBuilder(genotype);\n-        //NB: If we're dropping a deletion allele, then we need to trim the reference and add an END tag with the vc stop position\n-        if (result.getReference().length() > 1) {\n-            attrMap.put(VCFConstants.END_KEY, result.getEnd());\n-            newRef = Allele.create(newRef.getBases()[0], true);\n-            gb.alleles(Collections.nCopies(PLOIDY_TWO, newRef));\n+        //if GT is not homRef, correct it and set GQ=0\n+        if (!isMonomorphicCallWithAlts(result)) {\n+            gb.PL(new int[GenotypeLikelihoods.numLikelihoods(2, genotype.getPloidy())]);  //2 alleles for ref and non-ref\n+            gb.GQ(0).noAD().alleles(Collections.nCopies(genotype.getPloidy(), newRef)).noAttributes();\n+        //for hom-ref variants, drop other ALTs and subset PLs, GQ is recalculated (may be > 0)\n+        } else {\n+            if (genotype.hasExtendedAttribute(posteriorsKey)) {\n+                subsetPosteriorsToRefVersusNonRef(result, gb);\n+            } else {\n+                final List<Allele> bestAlleles = AlleleSubsettingUtils.calculateMostLikelyAllelesForMonomorphicSite(result, PLOIDY_TWO, 1);\n+                final Allele bestAlt = bestAlleles.stream().filter(a -> !a.isReference() && !a.isNonRefAllele()).findFirst().orElse(Allele.NON_REF_ALLELE);  //allow span dels\n+                //here we're assuming that an alt that isn't <NON_REF> will have higher likelihood than non-ref, which should be true\n+                final GenotypesContext context = AlleleSubsettingUtils.subsetAlleles(result.getGenotypes(),\n+                        genotype.getPloidy(), result.getAlleles(), Arrays.asList(result.getReference(), bestAlt),\n+                        null, GenotypeAssignmentMethod.BEST_MATCH_TO_ORIGINAL, result.getAttributeAsInt(VCFConstants.DEPTH_KEY, 0));  //BEST_MATCH to avoid no-calling low qual genotypes\n+                final Genotype subsetG = context.get(0);\n+                gb = new GenotypeBuilder(subsetG).noAttributes();  //remove attributes because hom ref blocks shouldn't have posteriors\n+                //subsetting may strip GQ and PLs for low qual genotypes\n+                if (!subsetG.hasGQ()) {\n+                    gb.GQ(0);\n+                }\n+                if (!subsetG.hasPL()) {\n+                    gb.PL(new int[GenotypeLikelihoods.numLikelihoods(2, genotype.getPloidy())]);  //2 alleles for ref and non-ref\n+                }\n+            }\n+        }\n+        if (result.hasAttribute(VCFConstants.DEPTH_KEY)) {\n+            final int depth = result.getAttributeAsInt(VCFConstants.DEPTH_KEY, 0);\n+            gb.DP(depth);\n+            gb.attribute(GATKVCFConstants.MIN_DP_FORMAT_KEY, depth);\n+        } else if (genotype.hasAD()) {\n+            final int depth = (int) MathUtils.sum(genotype.getAD());\n+            gb.DP(depth);\n+            gb.attribute(GATKVCFConstants.MIN_DP_FORMAT_KEY, depth);\n         }\n-        //if GT is not homRef, correct it\n-        if (!isHomRefCall(result)) {\n-            gb.PL(new int[3]);  //3 for diploid PLs, automatically initializes to zero\n-            gb.GQ(0).noAD().alleles(Collections.nCopies(PLOIDY_TWO, newRef)).noAttributes();\n+        //NOTE: If we're dropping a deletion allele, then we need to trim the reference and add an END tag with the vc stop position\n+        if (result.getReference().length() > 1 || genotype.getAlleles().contains(Allele.SPAN_DEL) || genotype.getAlleles().contains(Allele.NO_CALL)) {\n+            newRef = Allele.create(newRef.getBases()[0], true);\n         }\n+        attrMap.put(VCFConstants.END_KEY, result.getEnd());\n+        gb.alleles(Collections.nCopies(genotype.getPloidy(), newRef));\n         return gb;\n     }\n \n+    /**\n+     * Subset alleles as necessary and apply annotations\n+     * @param variant    VariantContext with full set of annotations (e.g. DP)\n+     * @return  an annotated VariantContext with data only for ref, non-ref and called alts\n+     */\n     @VisibleForTesting\n-    protected VariantContext cleanUpHighQualityVariant(final VariantContext result, final VariantContext originalVC) {\n-        Map<String, Object> attrMap = new HashMap<>();\n-        Map<String, Object> origMap = originalVC.getAttributes();\n-        //copy over info annotations\n-        for(final InfoFieldAnnotation annotation : annotationEngine.getInfoAnnotations()) {\n-            for (final String key : annotation.getKeyNames()) {\n-                if (infoFieldAnnotationKeyNamesToRemove.contains(key)) {\n-                    continue;\n-                }\n-                if (origMap.containsKey(key)) {\n-                    attrMap.put(key, origMap.get(key));\n+    VariantContext cleanUpHighQualityVariant(final VariantContext variant) {\n+        final Map<String, Object> attrMap = new HashMap<>();\n+\n+        final Genotype genotype = getCalledGenotype(variant);\n+        VariantContextBuilder builder = new VariantContextBuilder(variant);  //QUAL from result is carried through\n+        builder.attributes(attrMap);  //clear attributes\n+\n+        final List<Allele> allelesToDrop = getAllelesToDrop(variant, genotype);\n+\n+        final boolean allelesNeedSubsetting = !allelesToDrop.isEmpty();\n+        int[] relevantIndices = new int[variant.getNAlleles()];  //called alleles plus ref and non-ref\n+        final List<Allele> newAlleleSetUntrimmed = new ArrayList<>(variant.getAlleles());\n+        if(allelesNeedSubsetting && !keepAllAlts) {\n+            newAlleleSetUntrimmed.removeAll(allelesToDrop);\n+            final GenotypesContext gc = AlleleSubsettingUtils.subsetAlleles(variant.getGenotypes(), PLOIDY_TWO, variant.getAlleles(),\n+                    newAlleleSetUntrimmed, null, GenotypeAssignmentMethod.USE_PLS_TO_ASSIGN,\n+                    variant.getAttributeAsInt(VCFConstants.DEPTH_KEY, 0));\n+            if (!gc.get(0).hasGQ()) {\n+                logger.warn(\"No GQ returned for genotype at \" + variant.getContig() + \":\"\n+                        + variant.getStart() + \" after subsetting -- is this really a high quality genotype? \" + gc.get(0).toString());\n+                final VariantContextBuilder newHomRefBuilder = lowQualVariantToGQ0HomRef(variant);\n+                if (newHomRefBuilder != null) {\n+                    updateHomRefBlockBuffer(newHomRefBuilder.make());\n                 }\n             }\n-            if (annotation instanceof ReducibleAnnotation) {\n-                for (final String rawKey : ((ReducibleAnnotation)annotation).getRawKeyNames()) {\n-                    if (infoFieldAnnotationKeyNamesToRemove.contains(rawKey)) {\n-                        continue;\n-                    }\n-                    if (origMap.containsKey(rawKey)) {\n-                        attrMap.put(rawKey, origMap.get(rawKey));\n-                    }\n+            //note that subsetting alleles can increase GQ, e.g. with one confident reference allele and a deletion allele that's either 4 or 5 bases long\n+            builder.genotypes(gc).alleles(newAlleleSetUntrimmed);\n+            //if deletions are dropped, alleles may need trimming\n+            final VariantContext newTrimmedAllelesVC = GATKVariantContextUtils.trimAlleles(builder.make(), false, true);\n+            builder = new VariantContextBuilder(newTrimmedAllelesVC);\n+            //save indices of new alleles for annotation processing\n+            relevantIndices = newAlleleSetUntrimmed.stream().mapToInt(a -> variant.getAlleles().indexOf(a)).toArray();\n+            final int refBlockDepth;\n+            if (variant.hasAttribute(VCFConstants.DEPTH_KEY)) {  //prefer INFO depth because HaplotypeCaller GVCF block code uses all reads, not just informative\n+                refBlockDepth = variant.getAttributeAsInt(VCFConstants.DEPTH_KEY, 0);\n+            } else if (genotype.hasDP()) {\n+                refBlockDepth = genotype.getDP();\n+            } else {\n+                refBlockDepth = 0;\n+            }\n+            addRefBlockIfNecessary(variant, allelesToDrop, newTrimmedAllelesVC, refBlockDepth);\n+        }\n+\n+        final VariantContext updatedAllelesVC = builder.make();\n+        final Genotype updatedAllelesGenotype = updatedAllelesVC.getGenotype(0);\n+\n+        //remove any AD reads for the non-ref\n+        final ArrayList<Genotype> genotypesArray = removeNonRefADs(updatedAllelesGenotype, updatedAllelesVC.getAlleleIndex(Allele.NON_REF_ALLELE));\n+        builder.genotypes(genotypesArray);\n+\n+        composeUpdatedAnnotations(variant, attrMap, relevantIndices, updatedAllelesVC);\n+\n+        return builder.attributes(attrMap).unfiltered().make();\n+    }\n+\n+    /**\n+     * Update annotations if alleles were subset and add annotations specific to ReblockGVCF, like QUALapprox and RAW_GT_COUNT\n+     * @param variant   variant context with full annotation data\n+     * @param attrMap   annotation map to modify with new annotations\n+     * @param relevantIndices   indexes of alleles in updatedAllelesVC with respect to variant\n+     * @param updatedAllelesVC  variant context with final set of alleles\n+     */\n+    private void composeUpdatedAnnotations(final VariantContext variant, final Map<String, Object> attrMap,\n+                                           final int[] relevantIndices, final VariantContext updatedAllelesVC) {\n+        updateMQAnnotations(variant, attrMap);\n+\n+        final boolean allelesNeedSubsetting = relevantIndices.length < variant.getNAlleles();\n+        copyInfoAnnotations(variant, attrMap, allelesNeedSubsetting, relevantIndices);\n+\n+        //generate qual annotations after we potentially drop alleles\n+        final Genotype updatedAllelesGenotype = updatedAllelesVC.getGenotype(0);\n+        if (doQualApprox) {\n+            //TODO: update to support DRAGEN posteriors\n+            if (updatedAllelesGenotype.hasPL()) {\n+                addQualAnnotations(attrMap, updatedAllelesVC);\n+            }\n+        } else {  //manually copy annotations that might be from reblocking and aren't part of AnnotationEngine\n+            if (variant.hasAttribute(GATKVCFConstants.AS_VARIANT_DEPTH_KEY)) {\n+                attrMap.put(GATKVCFConstants.AS_VARIANT_DEPTH_KEY, variant.getAttribute(GATKVCFConstants.AS_VARIANT_DEPTH_KEY));\n+            }\n+            if (variant.hasAttribute(GATKVCFConstants.RAW_QUAL_APPROX_KEY)) {\n+                attrMap.put(GATKVCFConstants.RAW_QUAL_APPROX_KEY, variant.getAttribute(GATKVCFConstants.RAW_QUAL_APPROX_KEY));\n+            }\n+        }\n+        attrMap.put(GATKVCFConstants.RAW_GENOTYPE_COUNT_KEY, updatedAllelesGenotype.getAlleles().stream().anyMatch(Allele::isReference) ?\n+                Arrays.asList(0,1,0) : Arrays.asList(0,0,1)); //ExcessHet currently uses rounded/integer genotype counts, so do the same here\n+    }\n+\n+    /**\n+     * Return the genotype from variant, call it if data is present and GT is no-call\n+     * @param variant   VariantContext with genotype data\n+     * @return  a called genotype (if possible)\n+     */\n+    private Genotype getCalledGenotype(final VariantContext variant) {\n+        if (variant.getGenotype(0).isNoCall()) {\n+            final Genotype noCallGT = variant.getGenotype(0);\n+            final GenotypeBuilder builderToCallAlleles = new GenotypeBuilder(noCallGT);\n+            //TODO: update to support DRAGEN posteriors\n+            GATKVariantContextUtils.makeGenotypeCall(noCallGT.getPloidy(), builderToCallAlleles, GenotypeAssignmentMethod.USE_PLS_TO_ASSIGN,\n+                    noCallGT.getLikelihoods().getAsVector(), variant.getAlleles(), null);\n+            return builderToCallAlleles.make();\n+        } else {\n+            return variant.getGenotype(0);\n+        }\n+    }\n+\n+    /**\n+     * Get the list of concrete alternate alleles in variant that were not called in genotype\n+     * @param variant   has full set of alleles, not all of which may be called\n+     * @param calledGenotype    should not be no-call\n+     * @return  a list of (concrete) alt alleles that are not called in calledGenotype\n+     */\n+    private List<Allele> getAllelesToDrop(final VariantContext variant, final Genotype calledGenotype) {\n+        //always drop alleles that aren't called to reduce PL size\n+        final List<Allele> allelesToDrop = new ArrayList<>();\n+        for (final Allele currAlt : variant.getAlternateAlleles()) {\n+            boolean foundMatch = false;\n+            for (final Allele gtAllele : calledGenotype.getAlleles()) {\n+                if (gtAllele.equals(currAlt, false)) {\n+                    foundMatch = true;\n+                    break;\n                 }\n             }\n+            if (!foundMatch && !currAlt.isSymbolic()) {\n+                allelesToDrop.add(currAlt);\n+            }\n         }\n-        final Genotype genotype = result.getGenotype(0);\n-        VariantContextBuilder builder = new VariantContextBuilder(result);  //QUAL from result is carried through\n-        builder.attributes(attrMap);\n-\n-        boolean allelesNeedSubsetting = result.getNAlleles() != originalVC.getNAlleles();\n-        List<Allele> allelesToDrop = new ArrayList<>();\n-        if (dropLowQuals) {\n-            //drop alleles that aren't called iff we're dropping low quality variants (mostly because this can introduce GVCF gaps if deletion alleles are dropped)\n-            for (final Allele currAlt : result.getAlternateAlleles()) {\n-                boolean foundMatch = false;\n-                for (final Allele gtAllele : genotype.getAlleles()) {\n-                    if (gtAllele.equals(currAlt, false)) {\n-                        foundMatch = true;\n-                        break;\n-                    }\n-                    if (gtAllele.equals(Allele.NON_REF_ALLELE)) {\n-                        if (dropLowQuals) { //don't regenotype, just drop it -- this is a GQ 0 case if ever I saw one\n-                            return null;\n-                        } else {\n-                            GenotypeBuilder gb = changeCallToGQ0HomRef(result, attrMap);\n-                            return builder.alleles(Arrays.asList(result.getReference(), Allele.NON_REF_ALLELE)).unfiltered().log10PError(VariantContext.NO_LOG10_PERROR).attributes(attrMap).genotypes(gb.make()).make();\n-                        }\n-                    }\n+        return allelesToDrop;\n+    }\n+\n+    /**\n+     * Add the \"raw\" annotations necessary for calculating QD and AS_QD\n+     * @param attrMap   has qual-related annotations added to it, but also potentially supplies DP value\n+     * @param updatedAllelesVC  variant context without uncalled alts\n+     */\n+    private void addQualAnnotations(final Map<String, Object> attrMap, final VariantContext updatedAllelesVC) {\n+        final Genotype updatedAllelesGenotype = updatedAllelesVC.getGenotype(0);\n+        attrMap.put(GATKVCFConstants.RAW_QUAL_APPROX_KEY, updatedAllelesGenotype.getPL()[0]);\n+        int varDP = QualByDepth.getDepth(updatedAllelesVC.getGenotypes(), null);\n+        if (varDP == 0) {  //prevent QD=Infinity case\n+            //attrMap should have DP already from copyInfoAnnotations call above\n+            varDP = Integer.parseInt(attrMap.getOrDefault(VCFConstants.DEPTH_KEY, 1).toString()); //if there's no VarDP and no DP, just prevent Infs/NaNs and QD will get capped later\n+        }\n+        attrMap.put(GATKVCFConstants.VARIANT_DEPTH_KEY, varDP);\n+        if (annotationEngine.getInfoAnnotations().stream()\n+                .anyMatch(infoFieldAnnotation -> infoFieldAnnotation.getClass().getSimpleName().equals(\"AS_QualByDepth\"))) {\n+            final List<String> quals = new ArrayList<>();\n+            //get allele-specific QUAL approximation by subsetting PLs for each alt\n+            for (final Allele alt : updatedAllelesVC.getAlleles()) {\n+                if (alt.isReference()) {\n+                    //GDB expects an empty field for ref\n+                    continue;\n                 }\n-                if (!foundMatch && !currAlt.isSymbolic()) {\n-                    allelesNeedSubsetting = true;\n-                    allelesToDrop.add(currAlt);\n+                if (alt.equals(Allele.NON_REF_ALLELE) || alt.equals(Allele.SPAN_DEL)) {\n+                    quals.add(\"0\");\n+                    continue;\n                 }\n+                //TODO: this isn't going to work for DRAGEN's genotype posteriors\n+                final GenotypesContext gc = AlleleSubsettingUtils.subsetAlleles(updatedAllelesVC.getGenotypes(),\n+                        updatedAllelesGenotype.getPloidy(), updatedAllelesVC.getAlleles(), Arrays.asList(updatedAllelesVC.getReference(), alt), null,\n+                        GenotypeAssignmentMethod.USE_PLS_TO_ASSIGN, 0);  //don't need depth to get PLs for quals\n+\n+                final Genotype subsettedGenotype = gc.get(0);\n+                final int[] likelihoods = getGenotypeLikelihoodsOrPosteriors(subsettedGenotype, posteriorsKey);\n+                if (likelihoods != null) {\n+                    quals.add(Integer.toString(likelihoods[0]));\n+                }  else {  //AlleleSubsettingUtils can no-call genotypes with super duper low GQs\n+                    quals.add(\"0\");\n+                }\n+            }\n+            attrMap.put(GATKVCFConstants.AS_RAW_QUAL_APPROX_KEY, AnnotationUtils.ALLELE_SPECIFIC_RAW_DELIM + String.join(AnnotationUtils.ALLELE_SPECIFIC_RAW_DELIM, quals));\n+            final List<Integer> as_varDP = AS_QualByDepth.getAlleleDepths(updatedAllelesVC.getGenotypes());\n+            if (as_varDP != null) {\n+                attrMap.put(GATKVCFConstants.AS_VARIANT_DEPTH_KEY, as_varDP.stream().map(n -> Integer.toString(n)).collect(Collectors.joining(AnnotationUtils.ALLELE_SPECIFIC_RAW_DELIM)));\n             }\n         }\n+    }\n \n-        //remove any AD reads for the non-ref\n-        int nonRefInd = result.getAlleleIndex(Allele.NON_REF_ALLELE);\n-        boolean genotypesWereModified = false;\n+    /**\n+     * Any AD counts for the non-ref allele get propagated to every new allele when GVCFs are merged, so zero them out\n+     * @param g a genotype that may or may not contain AD\n+     * @param nonRefInd allele index of the non-ref, -1 if missing\n+     * @return  a Genotype array that can be used by a GenotypeBuilder\n+     */\n+    private ArrayList<Genotype> removeNonRefADs(final Genotype g, final int nonRefInd) {\n         final ArrayList<Genotype> genotypesArray = new ArrayList<>();\n-        GenotypesContext newGenotypes = result.getGenotypes();\n-        Genotype g = genotype;\n-        if(g.hasAD()) {\n-            int[] ad = g.getAD();\n+        if (g.hasAD() && nonRefInd != -1) {\n+            final int[] ad = g.getAD();\n             if (ad.length >= nonRefInd && ad[nonRefInd] > 0) { //only initialize a builder if we have to\n-                genotypesWereModified = true;\n-                GenotypeBuilder gb = new GenotypeBuilder(g);\n+                final GenotypeBuilder gb = new GenotypeBuilder(g);\n                 ad[nonRefInd] = 0;\n                 gb.AD(ad).DP((int) MathUtils.sum(ad));\n                 genotypesArray.add(gb.make());\n-                newGenotypes = GenotypesContext.create(genotypesArray);\n+            } else {\n+                genotypesArray.add(g);\n             }\n-        }\n-        else {\n+        } else {\n             genotypesArray.add(g);\n         }\n+        return genotypesArray;\n+    }\n \n-        //all VCs should get new RAW_MAPPING_QUALITY_WITH_DEPTH_KEY, but preserve deprecated keys if present\n-        if (!originalVC.hasAttribute(GATKVCFConstants.RAW_MAPPING_QUALITY_WITH_DEPTH_KEY)) {\n-            //we're going to approximate depth for MQ calculation with the site-level DP (should be informative and uninformative reads), which is pretty safe because it will only differ if reads are missing MQ\n-            final Integer rawMqValue = originalVC.hasAttribute(GATKVCFConstants.RAW_RMS_MAPPING_QUALITY_DEPRECATED) ?\n-                    (int)Math.round(originalVC.getAttributeAsDouble(GATKVCFConstants.RAW_RMS_MAPPING_QUALITY_DEPRECATED, 0.0)) :\n-                    (int)Math.round(originalVC.getAttributeAsDouble(VCFConstants.RMS_MAPPING_QUALITY_KEY, 60.0) *\n-                            originalVC.getAttributeAsDouble(VCFConstants.RMS_MAPPING_QUALITY_KEY, 60.0) *\n-                            originalVC.getAttributeAsInt(VCFConstants.DEPTH_KEY, 0));\n-            attrMap.put(GATKVCFConstants.RAW_MAPPING_QUALITY_WITH_DEPTH_KEY,\n-                    String.format(\"%d,%d\", rawMqValue, originalVC.getAttributeAsInt(VCFConstants.DEPTH_KEY, 0)));\n-            if (originalVC.hasAttribute(GATKVCFConstants.RAW_RMS_MAPPING_QUALITY_DEPRECATED)) {\n-                attrMap.put(GATKVCFConstants.RAW_RMS_MAPPING_QUALITY_DEPRECATED, originalVC.getAttributeAsDouble(GATKVCFConstants.RAW_RMS_MAPPING_QUALITY_DEPRECATED, 0)); //NOTE: this annotation is deprecated, but keep it here so we don't have to reprocess gnomAD v3 GVCFs again\n-                attrMap.put(GATKVCFConstants.MAPPING_QUALITY_DEPTH_DEPRECATED, originalVC.getAttributeAsInt(VCFConstants.DEPTH_KEY, 0)); //NOTE: this annotation is deprecated, but keep it here so we don't have to reprocess gnomAD v3 GVCFs again\n-            }\n-        }\n-\n-\n-        int[] relevantIndices = new int[result.getNAlleles()];\n-        List<Allele> newAlleleSet = new ArrayList<>();\n-        for(final Allele a : result.getAlleles()) {\n-            newAlleleSet.add(a);\n-        }\n-        if(allelesNeedSubsetting) {\n-            newAlleleSet.removeAll(allelesToDrop);\n-            builder.alleles(newAlleleSet);\n-            final GenotypesContext gc;\n-            if(!genotypesWereModified) {\n-                gc = AlleleSubsettingUtils.subsetAlleles(result.getGenotypes(), PLOIDY_TWO, result.getAlleles(), newAlleleSet, null, GenotypeAssignmentMethod.USE_PLS_TO_ASSIGN, result.getAttributeAsInt(VCFConstants.DEPTH_KEY, 0));\n-                builder.genotypes(gc);\n-            }\n-            else {\n-                gc = AlleleSubsettingUtils.subsetAlleles(newGenotypes, PLOIDY_TWO, result.getAlleles(), newAlleleSet, null, GenotypeAssignmentMethod.USE_PLS_TO_ASSIGN, result.getAttributeAsInt(VCFConstants.DEPTH_KEY, 0));\n-                builder.genotypes(gc);\n-            }\n-            g = gc.get(0);\n-            relevantIndices = newAlleleSet.stream().mapToInt(a -> originalVC.getAlleles().indexOf(a)).toArray();\n-        }\n-\n+    /**\n+     * Add the original annotations to the map for the new VC, subsetting AS annotations as necessary\n+     * @param originalVC    VC with full set of alleles and INFO annotations\n+     * @param newVCAttrMap   map of new annotations, to be modified\n+     * @param allelesNeedSubsetting do we have to subset allele-specific annotations?\n+     * @param relevantIndices   indexes for called alleles within the full alleles set from original VC\n+     */\n+    private void copyInfoAnnotations(final VariantContext originalVC, final Map<String, Object> newVCAttrMap,\n+                                     final boolean allelesNeedSubsetting, final int[] relevantIndices) {\n         //copy over info annotations\n+        final Map<String, Object> origMap = originalVC.getAttributes();\n         for(final InfoFieldAnnotation annotation : annotationEngine.getInfoAnnotations()) {\n             for (final String key : annotation.getKeyNames()) {\n                 if (infoFieldAnnotationKeyNamesToRemove.contains(key)) {\n                     continue;\n                 }\n                 if (origMap.containsKey(key)) {\n-                    attrMap.put(key, origMap.get(key));\n+                    newVCAttrMap.put(key, origMap.get(key));\n                 }\n             }\n             if (annotation instanceof ReducibleAnnotation) {\n@@ -527,71 +903,165 @@ protected VariantContext cleanUpHighQualityVariant(final VariantContext result,\n                     }\n                     if (origMap.containsKey(rawKey)) {\n                         if (allelesNeedSubsetting && AnnotationUtils.isAlleleSpecific(annotation)) {\n-                            List<String> alleleSpecificValues = AnnotationUtils.getAlleleLengthListOfString(originalVC.getAttributeAsString(rawKey, null));\n+                            final List<String> alleleSpecificValues = AnnotationUtils.getAlleleLengthListOfString(originalVC.getAttributeAsString(rawKey, null));\n                             final List<?> subsetList = alleleSpecificValues.size() > 0 ? AlleleSubsettingUtils.remapRLengthList(alleleSpecificValues, relevantIndices, \"\")\n                                     : Collections.nCopies(relevantIndices.length, \"\");\n-                            attrMap.put(rawKey, AnnotationUtils.encodeAnyASListWithRawDelim(subsetList));\n+                            newVCAttrMap.put(rawKey, AnnotationUtils.encodeAnyASListWithRawDelim(subsetList));\n                         } else {\n-                            attrMap.put(rawKey, origMap.get(rawKey));\n+                            newVCAttrMap.put(rawKey, origMap.get(rawKey));\n                         }\n                     }\n                 }\n             }\n         }\n-        //do QUAL calcs after we potentially drop alleles\n-        if (doQualApprox && g.hasPL()) {\n-            attrMap.put(GATKVCFConstants.RAW_QUAL_APPROX_KEY, g.getPL()[0]);\n-            int varDP = QualByDepth.getDepth(result.getGenotypes(), null);\n-            if (varDP == 0) {  //prevent QD=Infinity case\n-                varDP = originalVC.getAttributeAsInt(VCFConstants.DEPTH_KEY, 1); //if there's no VarDP and no DP, just prevent Infs/NaNs and QD will get capped later\n-            }\n-            attrMap.put(GATKVCFConstants.VARIANT_DEPTH_KEY, varDP);\n-            if (annotationEngine.getInfoAnnotations().stream()\n-                    .anyMatch(infoFieldAnnotation -> infoFieldAnnotation.getClass().getSimpleName().equals(\"AS_QualByDepth\"))) {\n-                     final List<String> quals = new ArrayList<>();\n-                for (final Allele alt : newAlleleSet) {\n-                    if (alt.isReference()) {\n-                        //GDB expects an empty field for ref\n-                        continue;\n-                    }\n-                    if (alt.equals(Allele.NON_REF_ALLELE)) {\n-                        quals.add(\"0\");\n-                        continue;\n-                    }\n-                    final GenotypesContext gc = AlleleSubsettingUtils.subsetAlleles(result.getGenotypes(),\n-                            HomoSapiensConstants.DEFAULT_PLOIDY, result.getAlleles(), Arrays.asList(result.getReference(), alt), null,\n-                            GenotypeAssignmentMethod.USE_PLS_TO_ASSIGN, result.getAttributeAsInt(VCFConstants.DEPTH_KEY,0));\n-                    if (gc.get(0).hasPL()) {\n-                        quals.add(Integer.toString(gc.get(0).getPL()[0]));\n-                    } else {  //AlleleSubsettingUtils can no-call genotypes with super duper low GQs\n-                        quals.add(\"0\");\n+    }\n+\n+    /**\n+     * Add the newest raw mapping quality annotations to the annotation map\n+     * @param originalVC    VariantContext that may contain deprecated mapping quality annotations\n+     * @param newVCAttrMap   modified to add mapping quality raw annotations\n+     */\n+    private void updateMQAnnotations(final VariantContext originalVC, final Map<String, Object> newVCAttrMap) {\n+        //all VCs should get new RAW_MAPPING_QUALITY_WITH_DEPTH_KEY, but preserve deprecated keys if present\n+        if (!originalVC.hasAttribute(GATKVCFConstants.RAW_MAPPING_QUALITY_WITH_DEPTH_KEY)) {\n+            //we're going to approximate depth for MQ calculation with the site-level DP (should be informative and uninformative reads),\n+            //which is pretty safe because it will only differ if reads are missing MQ\n+            final Integer rawMqValue = originalVC.hasAttribute(GATKVCFConstants.RAW_RMS_MAPPING_QUALITY_DEPRECATED) ?\n+                    (int)Math.round(originalVC.getAttributeAsDouble(GATKVCFConstants.RAW_RMS_MAPPING_QUALITY_DEPRECATED, 0.0)) :\n+                    (int)Math.round(originalVC.getAttributeAsDouble(VCFConstants.RMS_MAPPING_QUALITY_KEY, 60.0) *\n+                            originalVC.getAttributeAsDouble(VCFConstants.RMS_MAPPING_QUALITY_KEY, 60.0) *\n+                            originalVC.getAttributeAsInt(VCFConstants.DEPTH_KEY, 0));\n+            newVCAttrMap.put(GATKVCFConstants.RAW_MAPPING_QUALITY_WITH_DEPTH_KEY,\n+                    String.format(\"%d,%d\", rawMqValue, originalVC.getAttributeAsInt(VCFConstants.DEPTH_KEY, 0)));\n+\n+            //NOTE: this annotation is deprecated, but keep it here so we don't have to reprocess older GVCFs\n+            if (originalVC.hasAttribute(GATKVCFConstants.RAW_RMS_MAPPING_QUALITY_DEPRECATED)) {\n+                newVCAttrMap.put(GATKVCFConstants.RAW_RMS_MAPPING_QUALITY_DEPRECATED,\n+                        originalVC.getAttributeAsDouble(GATKVCFConstants.RAW_RMS_MAPPING_QUALITY_DEPRECATED, 0));\n+                newVCAttrMap.put(GATKVCFConstants.MAPPING_QUALITY_DEPTH_DEPRECATED,\n+                        originalVC.getAttributeAsInt(VCFConstants.DEPTH_KEY, 0));\n+            }\n+        }\n+    }\n+\n+    /**\n+     * If the ref allele is trimmed after alt deletions are dropped, add a reference block to account for the space covered before trimming\n+     * @param result    VC with full set of alleles that may need to be trimmed\n+     * @param allelesToDrop alleles eligible to become the new non-ref likelihood\n+     * @param newTrimmedAllelesVC   VC with called alleles that may have been trimmed\n+     */\n+    private void addRefBlockIfNecessary(final VariantContext result, final List<Allele> allelesToDrop, final VariantContext newTrimmedAllelesVC, final int refBlockDepth) {\n+        //if deletion needs trimming, fill in the gap with a ref block\n+        final int oldLongestAlleleLength = result.getReference().length();\n+        final int newLongestAlleleLength = newTrimmedAllelesVC.getReference().length();\n+        final Genotype genotype = result.getGenotype(0);\n+        if (newLongestAlleleLength < oldLongestAlleleLength) {\n+            //need to add a ref block to make up for the allele trimming or there will be a hole in the GVCF\n+            final int[] originalLikelihoods = getGenotypeLikelihoodsOrPosteriors(genotype, posteriorsKey);\n+            if (originalLikelihoods != null) {\n+                final Allele oldShortestAltAllele;\n+                try {\n+                    oldShortestAltAllele = allelesToDrop.stream().filter(a -> !a.equals(Allele.SPAN_DEL)).min(Allele::compareTo).orElseThrow(NoSuchElementException::new);\n+                } catch (final Exception e) {\n+                    throw new GATKException(\"No shortest ALT at \" + result.getStart() + \" across alleles: \" + allelesToDrop);\n+                }\n+\n+                //subset PLs to ref and longest dropped allele (longest may not be most likely, but we'll approximate so we don't have to make more than one ref block)\n+                final int[] longestVersusRefPLIndices = AlleleSubsettingUtils.subsettedPLIndices(result.getGenotype(0).getPloidy(),\n+                        result.getAlleles(), Arrays.asList(result.getReference(), oldShortestAltAllele));\n+                final int[] newRefBlockLikelihoods = MathUtils.normalizePLs(Arrays.stream(longestVersusRefPLIndices)\n+                        .map(idx -> originalLikelihoods[idx]).toArray());\n+                if (newRefBlockLikelihoods[0] != 0) {\n+                    for (int i = 0; i < newRefBlockLikelihoods.length; i++) {\n+                        newRefBlockLikelihoods[i] = Math.max(newRefBlockLikelihoods[i] - newRefBlockLikelihoods[0], 0);\n                     }\n                 }\n-                attrMap.put(GATKVCFConstants.AS_RAW_QUAL_APPROX_KEY, AnnotationUtils.ALLELE_SPECIFIC_RAW_DELIM +String.join(AnnotationUtils.ALLELE_SPECIFIC_RAW_DELIM, quals));\n-                List<Integer> as_varDP = AS_QualByDepth.getAlleleDepths(AlleleSubsettingUtils.subsetAlleles(result.getGenotypes(),\n-                        HomoSapiensConstants.DEFAULT_PLOIDY, result.getAlleles(), newAlleleSet, null,\n-                        GenotypeAssignmentMethod.USE_PLS_TO_ASSIGN, result.getAttributeAsInt(VCFConstants.DEPTH_KEY,0)));\n-                if (as_varDP != null) {\n-                    attrMap.put(GATKVCFConstants.AS_VARIANT_DEPTH_KEY, as_varDP.stream().map( n -> Integer.toString(n)).collect(Collectors.joining(AnnotationUtils.ALLELE_SPECIFIC_RAW_DELIM)));\n+\n+                //build the new reference block with updated likelihoods\n+                final GenotypeBuilder refBlockGenotypeBuilder = new GenotypeBuilder();\n+                final int refStart = Math.max(result.getEnd() - (oldLongestAlleleLength - newLongestAlleleLength), vcfOutputEnd) + 1;\n+                final Allele newRef = Allele.create(ReferenceUtils.getRefBaseAtPosition(referenceReader, result.getContig(), refStart), true);\n+                refBlockGenotypeBuilder.PL(newRefBlockLikelihoods)\n+                        .GQ(MathUtils.secondSmallestMinusSmallest(newRefBlockLikelihoods, 0))\n+                        .alleles(Arrays.asList(newRef, newRef)).DP(refBlockDepth);\n+\n+                //add the new block to the buffer if it isn't covered by positions already output\n+                if (refStart > vcfOutputEnd && result.getEnd() > vcfOutputEnd) {\n+                    final VariantContextBuilder trimBlockBuilder = new VariantContextBuilder();\n+                    trimBlockBuilder.chr(currentContig).start(Math.max(refStart, vcfOutputEnd + 1)).stop(result.getEnd()).\n+                            alleles(Arrays.asList(newRef, Allele.NON_REF_ALLELE)).attribute(VCFConstants.END_KEY, result.getEnd())\n+                            .genotypes(refBlockGenotypeBuilder.make());\n+                    updateHomRefBlockBuffer(trimBlockBuilder.make());\n                 }\n             }\n-        } else {  //manually copy annotations that might be from reblocking and aren't part of AnnotationEngine\n-            if (result.hasAttribute(GATKVCFConstants.AS_VARIANT_DEPTH_KEY)) {\n-                attrMap.put(GATKVCFConstants.AS_VARIANT_DEPTH_KEY, result.getAttribute(GATKVCFConstants.AS_VARIANT_DEPTH_KEY));\n-            }\n-            if (result.hasAttribute(GATKVCFConstants.RAW_QUAL_APPROX_KEY)) {\n-                attrMap.put(GATKVCFConstants.RAW_QUAL_APPROX_KEY, result.getAttribute(GATKVCFConstants.RAW_QUAL_APPROX_KEY));\n-            }\n+        }\n+    }\n \n+    /**\n+     * Modifies ref block builder to change start position and update ref allele accordingly in VC and genotypes\n+     * @param builder   a builder for a reference block\n+     * @param newStart  the new position for the reference block\n+     */\n+    private void moveBuilderStart(final VariantContextBuilder builder, final int newStart) {\n+        final byte[] newRef = ReferenceUtils.getRefBaseAtPosition(referenceReader, currentContig, newStart);\n+        final Allele newRefAllele = Allele.create(newRef, true);\n+        final ArrayList<Genotype> genotypesArray = new ArrayList<>();\n+        for (final Genotype g : builder.getGenotypes()) {\n+            final GenotypeBuilder gb = new GenotypeBuilder(g);\n+            final List<Allele> newGTAlleles = g.getAlleles().stream().map(a -> a.isReference() ? newRefAllele : a).collect(Collectors.toList());\n+            gb.alleles(newGTAlleles);\n+            genotypesArray.add(gb.make());\n+        }\n+        final List<Allele> newVCAlleles = builder.getAlleles().stream().map(a -> a.isReference() ? newRefAllele : a).collect(Collectors.toList());\n+        builder.start(newStart).alleles(newVCAlleles).genotypes(genotypesArray);\n+    }\n+\n+    /**\n+     * If genotype posterior probabilities are present, return those; otherwise use likelihoods\n+     * @param genotype  should have PLs\n+     * @param posteriorsKey may be null\n+     * @return may be null\n+     */\n+    private int[] getGenotypeLikelihoodsOrPosteriors(final Genotype genotype, final String posteriorsKey) {\n+        if ((posteriorsKey != null && genotype.hasExtendedAttribute(posteriorsKey))) {\n+            final double[] posteriors = VariantContextGetters.getAttributeAsDoubleArray(genotype, posteriorsKey, () -> null, 0);\n+            return Arrays.stream(posteriors).mapToInt(x -> (int)Math.round(x)).toArray();\n+        } else if (genotype.hasPL()) {\n+            return genotype.getPL();\n+        } else {\n+            return null;\n         }\n-        attrMap.put(GATKVCFConstants.RAW_GENOTYPE_COUNT_KEY, g.getAlleles().stream().anyMatch(Allele::isReference) ? Arrays.asList(0,1,0) : Arrays.asList(0,0,1)); //ExcessHet currently uses rounded/integer genotype counts, so do the same here\n-        builder.attributes(attrMap);\n+    }\n \n-        if (allelesNeedSubsetting) {\n-            //only trim if we're subsetting alleles, and we only subset if we're allowed to drop sites, as per the -drop-low-quals arg\n-            return GATKVariantContextUtils.reverseTrimAlleles(builder.attributes(attrMap).unfiltered().make());\n+    /**\n+     * Given a variant with multi-allelic PLs, modify the GenotypeBuilder to have annotations as for just ref and non-ref\n+     * @param result    a VariantContext containing alternate alleles in addition to non-ref\n+     * @param gb    a reference block GenotypeBuilder to be modified\n+     */\n+    private void subsetPosteriorsToRefVersusNonRef(final VariantContext result, final GenotypeBuilder gb) {\n+        //TODO: bestAlleles needs to be modified for posteriors\n+        final List<Allele> bestAlleles = AlleleSubsettingUtils.calculateMostLikelyAlleles(result, PLOIDY_TWO, 1);\n+        final Allele bestAlt = bestAlleles.stream().filter(a -> !a.isReference() && !a.isNonRefAllele()).findFirst().orElse(Allele.NON_REF_ALLELE);  //allow span dels\n+        //here we're assuming that an alt that isn't <NON_REF> will have higher likelihood than non-ref, which should be true\n+        final int[] idxVector = result.getGLIndicesOfAlternateAllele(bestAlt);\n+        final Genotype genotype = result.getGenotype(0);\n+        final int[] multiallelicPLs = getGenotypeLikelihoodsOrPosteriors(genotype, posteriorsKey);\n+        if (multiallelicPLs != null) {\n+            int[] newPLs = new int[GenotypeLikelihoods.numLikelihoods(2, genotype.getPloidy())];\n+            for (int i = 0; i < idxVector.length; i++) {\n+                newPLs[i] = multiallelicPLs[idxVector[i]];\n+            }\n+            //in the case of *, we need to renormalize to homref\n+            if (newPLs[0] != 0) {\n+                final int[] output = new int[newPLs.length];\n+                for (int i = 0; i < newPLs.length; i++) {\n+                    output[i] = Math.max(newPLs[i] - newPLs[0], 0);\n+                }\n+                newPLs = output;\n+            }\n+            gb.PL(newPLs);\n+            gb.GQ(MathUtils.secondSmallestMinusSmallest(newPLs, 0));\n         }\n-        return builder.attributes(attrMap).genotypes(newGenotypes).unfiltered().make();\n     }\n \n     @Override"
  },
  {
    "sha": "97a8c2d3b8b29ff47b8ce16db77082c7553d1f26",
    "filename": "src/main/java/org/broadinstitute/hellbender/utils/MathUtils.java",
    "status": "modified",
    "additions": 12,
    "deletions": 0,
    "changes": 12,
    "blob_url": "https://github.com/broadinstitute/gatk/blob/af6c823e27e1ecd437a3b045f3dc1b519c855bcf/src/main/java/org/broadinstitute/hellbender/utils/MathUtils.java",
    "raw_url": "https://github.com/broadinstitute/gatk/raw/af6c823e27e1ecd437a3b045f3dc1b519c855bcf/src/main/java/org/broadinstitute/hellbender/utils/MathUtils.java",
    "contents_url": "https://api.github.com/repos/broadinstitute/gatk/contents/src/main/java/org/broadinstitute/hellbender/utils/MathUtils.java?ref=af6c823e27e1ecd437a3b045f3dc1b519c855bcf",
    "patch": "@@ -900,6 +900,18 @@ public static int arrayMin(final int[] array) {\n         return min;\n     }\n \n+    public static int minElementIndex(final int[] array) {\n+        Utils.nonNull(array);\n+        Utils.validateArg(array.length > 0, \"array may not be empty\");\n+\n+        int minI = 0;\n+        for (int i = 1; i < array.length; i++) {\n+            if (array[i] < array[minI])\n+                minI = i;\n+        }\n+        return minI;\n+    }\n+\n     public static boolean isValidLog10Probability(final double result) { return result <= 0.0; }\n \n     public static boolean isValidProbability(final double result) {"
  },
  {
    "sha": "d02521aed1256a4a0a4ee2b8deb4c4b7c26c778d",
    "filename": "src/main/java/org/broadinstitute/hellbender/utils/reference/ReferenceUtils.java",
    "status": "modified",
    "additions": 4,
    "deletions": 0,
    "changes": 4,
    "blob_url": "https://github.com/broadinstitute/gatk/blob/af6c823e27e1ecd437a3b045f3dc1b519c855bcf/src/main/java/org/broadinstitute/hellbender/utils/reference/ReferenceUtils.java",
    "raw_url": "https://github.com/broadinstitute/gatk/raw/af6c823e27e1ecd437a3b045f3dc1b519c855bcf/src/main/java/org/broadinstitute/hellbender/utils/reference/ReferenceUtils.java",
    "contents_url": "https://api.github.com/repos/broadinstitute/gatk/contents/src/main/java/org/broadinstitute/hellbender/utils/reference/ReferenceUtils.java?ref=af6c823e27e1ecd437a3b045f3dc1b519c855bcf",
    "patch": "@@ -103,4 +103,8 @@ public static CachingIndexedFastaSequenceFile createReferenceReader(final GATKPa\n     public static byte[] getRefBaseAtPosition(final ReferenceSequenceFile reference, final String contig, final int start) {\n         return reference.getSubsequenceAt(contig, start, start).getBases();\n     }\n+\n+    public static byte[] getRefBasesAtPosition(final ReferenceSequenceFile reference, final String contig, final int start, final int length) {\n+        return reference.getSubsequenceAt(contig, start, start+length-1).getBases();\n+    }\n }"
  },
  {
    "sha": "8d3483dd651915e625098a2163b9785c876d8d6e",
    "filename": "src/main/java/org/broadinstitute/hellbender/utils/variant/GATKVariantContextUtils.java",
    "status": "modified",
    "additions": 4,
    "deletions": 4,
    "changes": 8,
    "blob_url": "https://github.com/broadinstitute/gatk/blob/af6c823e27e1ecd437a3b045f3dc1b519c855bcf/src/main/java/org/broadinstitute/hellbender/utils/variant/GATKVariantContextUtils.java",
    "raw_url": "https://github.com/broadinstitute/gatk/raw/af6c823e27e1ecd437a3b045f3dc1b519c855bcf/src/main/java/org/broadinstitute/hellbender/utils/variant/GATKVariantContextUtils.java",
    "contents_url": "https://api.github.com/repos/broadinstitute/gatk/contents/src/main/java/org/broadinstitute/hellbender/utils/variant/GATKVariantContextUtils.java?ref=af6c823e27e1ecd437a3b045f3dc1b519c855bcf",
    "patch": "@@ -1349,12 +1349,12 @@ public static VariantContext reverseTrimAlleles( final VariantContext inputVC )\n     public static VariantContext trimAlleles(final VariantContext inputVC, final boolean trimForward, final boolean trimReverse) {\n         Utils.nonNull(inputVC);\n \n-        if ( inputVC.getNAlleles() <= 1 || inputVC.getAlleles().stream().anyMatch(a -> a.length() == 1) ) {\n+        if ( inputVC.getNAlleles() <= 1 || inputVC.getAlleles().stream().anyMatch(a -> a.length() == 1 && !a.equals(Allele.SPAN_DEL)) ) {\n             return inputVC;\n         }\n \n-        final List<byte[]> sequences = inputVC.getAlleles().stream().filter(a -> !a.isSymbolic()).map(Allele::getBases).collect(Collectors.toList());\n-        final List<IndexRange> ranges = inputVC.getAlleles().stream().filter(a -> !a.isSymbolic()).map(a -> new IndexRange(0, a.length())).collect(Collectors.toList());\n+        final List<byte[]> sequences = inputVC.getAlleles().stream().filter(a -> !a.isSymbolic() && !a.equals(Allele.SPAN_DEL)).map(Allele::getBases).collect(Collectors.toList());\n+        final List<IndexRange> ranges = inputVC.getAlleles().stream().filter(a -> !a.isSymbolic() && !a.equals(Allele.SPAN_DEL)).map(a -> new IndexRange(0, a.length())).collect(Collectors.toList());\n \n         final Pair<Integer, Integer> shifts = AlignmentUtils.normalizeAlleles(sequences, ranges, 0, true);\n         final int endTrim = shifts.getRight();\n@@ -1390,7 +1390,7 @@ protected static VariantContext trimAlleles(final VariantContext inputVC,\n         final Map<Allele, Allele> originalToTrimmedAlleleMap = new LinkedHashMap<>();\n \n         for (final Allele a : inputVC.getAlleles()) {\n-            if (a.isSymbolic()) {\n+            if (a.isSymbolic() || a.equals(Allele.SPAN_DEL)) {\n                 alleles.add(a);\n                 originalToTrimmedAlleleMap.put(a, a);\n             } else {"
  },
  {
    "sha": "487cbf607aa8f73deea848679e8101c2e568f7f8",
    "filename": "src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlock.java",
    "status": "modified",
    "additions": 6,
    "deletions": 1,
    "changes": 7,
    "blob_url": "https://github.com/broadinstitute/gatk/blob/af6c823e27e1ecd437a3b045f3dc1b519c855bcf/src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlock.java",
    "raw_url": "https://github.com/broadinstitute/gatk/raw/af6c823e27e1ecd437a3b045f3dc1b519c855bcf/src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlock.java",
    "contents_url": "https://api.github.com/repos/broadinstitute/gatk/contents/src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlock.java?ref=af6c823e27e1ecd437a3b045f3dc1b519c855bcf",
    "patch": "@@ -83,8 +83,13 @@ int getGQLowerBound() {\n         return minGQ;\n     }\n \n+    /**\n+     * Allow overlapping input blocks, as in the case where shards are split with duplicate boundary events\n+     * @param vc\n+     * @return\n+     */\n     public boolean isContiguous(final VariantContext vc) {\n-        return (vc.getStart() == getEnd() + 1) && startingVC.getContig().equals(vc.getContig());\n+        return (vc.getStart() >= getStart()) && (vc.getStart() <= getEnd() + 1) && startingVC.getContig().equals(vc.getContig());\n     }\n \n     public VariantContext getStartingVC() {"
  },
  {
    "sha": "e2ce810853ec04336d4f80ea7af7de8dfd45e8fd",
    "filename": "src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java",
    "status": "modified",
    "additions": 4,
    "deletions": 5,
    "changes": 9,
    "blob_url": "https://github.com/broadinstitute/gatk/blob/af6c823e27e1ecd437a3b045f3dc1b519c855bcf/src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java",
    "raw_url": "https://github.com/broadinstitute/gatk/raw/af6c823e27e1ecd437a3b045f3dc1b519c855bcf/src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java",
    "contents_url": "https://api.github.com/repos/broadinstitute/gatk/contents/src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiner.java?ref=af6c823e27e1ecd437a3b045f3dc1b519c855bcf",
    "patch": "@@ -30,7 +30,6 @@\n  */\n public class GVCFBlockCombiner implements PushPullTransformer<VariantContext> {\n     final RangeMap<Integer, Range<Integer>> gqPartitions;\n-    final int defaultPloidy;\n     final boolean floorBlocks;\n     final Queue<VariantContext> toOutput = new ArrayDeque<>();\n \n@@ -43,9 +42,8 @@\n \n     GVCFBlock currentBlock = null;\n \n-    public GVCFBlockCombiner(List<Number> gqPartitions, int defaultPloidy, boolean floorBlocks) {\n+    public GVCFBlockCombiner(List<Number> gqPartitions, boolean floorBlocks) {\n         this.gqPartitions = parsePartitions(gqPartitions);\n-        this.defaultPloidy = defaultPloidy;\n         this.floorBlocks = floorBlocks;\n     }\n \n@@ -164,7 +162,7 @@ GVCFBlock createNewBlock(final VariantContext vc, final Genotype g) {\n         }\n \n         // create the block, add g to it, and return it for use\n-        final HomRefBlock block = new HomRefBlock(vc, partition.lowerEndpoint(), partition.upperEndpoint(), defaultPloidy);\n+        final HomRefBlock block = new HomRefBlock(vc, partition.lowerEndpoint(), partition.upperEndpoint(), g.getPloidy());\n         block.add(vc.getStart(), vc.getAttributeAsInt(VCFConstants.END_KEY, vc.getStart()), g);\n         return block;\n     }\n@@ -195,7 +193,8 @@ public void submit(VariantContext vc) {\n         }\n \n         final Genotype g = vc.getGenotype(0);\n-        if (g.isHomRef() && vc.hasAlternateAllele(Allele.NON_REF_ALLELE) && vc.isBiallelic()) {\n+        if ((g.isHomRef()\n+                || (g.isNoCall() && g.hasPL() && g.getPL()[0] == 0)) && vc.hasAlternateAllele(Allele.NON_REF_ALLELE) && vc.isBiallelic()) {\n             // create bands\n             final VariantContext maybeCompletedBand = addHomRefSite(vc, g);\n             if (maybeCompletedBand != null) {"
  },
  {
    "sha": "6bb754cf074859f5cdf7bb59b3377e73de3a9446",
    "filename": "src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiningIterator.java",
    "status": "modified",
    "additions": 1,
    "deletions": 1,
    "changes": 2,
    "blob_url": "https://github.com/broadinstitute/gatk/blob/af6c823e27e1ecd437a3b045f3dc1b519c855bcf/src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiningIterator.java",
    "raw_url": "https://github.com/broadinstitute/gatk/raw/af6c823e27e1ecd437a3b045f3dc1b519c855bcf/src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiningIterator.java",
    "contents_url": "https://api.github.com/repos/broadinstitute/gatk/contents/src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFBlockCombiningIterator.java?ref=af6c823e27e1ecd437a3b045f3dc1b519c855bcf",
    "patch": "@@ -11,7 +11,7 @@\n public class GVCFBlockCombiningIterator extends PushToPullIterator<VariantContext> {\n \n     public GVCFBlockCombiningIterator(Iterator<VariantContext> variants, final List<Number> gqPartitions, final int defaultPloidy){\n-       super(variants, new GVCFBlockCombiner(gqPartitions, defaultPloidy, false));\n+       super(variants, new GVCFBlockCombiner(gqPartitions, false));\n     }\n \n }"
  },
  {
    "sha": "97718a421af026d406b8774372d6a692b040c8f0",
    "filename": "src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFWriter.java",
    "status": "modified",
    "additions": 5,
    "deletions": 7,
    "changes": 12,
    "blob_url": "https://github.com/broadinstitute/gatk/blob/af6c823e27e1ecd437a3b045f3dc1b519c855bcf/src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFWriter.java",
    "raw_url": "https://github.com/broadinstitute/gatk/raw/af6c823e27e1ecd437a3b045f3dc1b519c855bcf/src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFWriter.java",
    "contents_url": "https://api.github.com/repos/broadinstitute/gatk/contents/src/main/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFWriter.java?ref=af6c823e27e1ecd437a3b045f3dc1b519c855bcf",
    "patch": "@@ -32,18 +32,16 @@\n      * A <= X < B\n      * B <= X < C\n      * X >= C\n-     *\n-     * @param underlyingWriter the ultimate destination of the GVCF records\n+     *  @param underlyingWriter the ultimate destination of the GVCF records\n      * @param gqPartitions     a list of GQ partitions, this list must be non-empty and every element must be larger than previous element\n-     * @param defaultPloidy    the assumed ploidy for input variant context without one.\n      */\n-    public GVCFWriter(final VariantContextWriter underlyingWriter, final List<Number> gqPartitions, final int defaultPloidy, final boolean floorBlocks) {\n+    public GVCFWriter(final VariantContextWriter underlyingWriter, final List<Number> gqPartitions, final boolean floorBlocks) {\n         this.underlyingWriter = Utils.nonNull(underlyingWriter);\n-        this.gvcfBlockCombiner = new GVCFBlockCombiner(gqPartitions, defaultPloidy, floorBlocks);\n+        this.gvcfBlockCombiner = new GVCFBlockCombiner(gqPartitions, floorBlocks);\n     }\n \n-    public GVCFWriter(final VariantContextWriter underlyingWriter, final List<Number> gqPartitions, final int defaultPloidy) {\n-        this(underlyingWriter, gqPartitions, defaultPloidy, false);\n+    public GVCFWriter(final VariantContextWriter underlyingWriter, final List<Number> gqPartitions) {\n+        this(underlyingWriter, gqPartitions, false);\n     }\n \n "
  },
  {
    "sha": "94a9983c32f347ffa024bafc0b546d2eea3de220",
    "filename": "src/main/java/org/broadinstitute/hellbender/utils/variant/writers/HomRefBlock.java",
    "status": "modified",
    "additions": 2,
    "deletions": 0,
    "changes": 2,
    "blob_url": "https://github.com/broadinstitute/gatk/blob/af6c823e27e1ecd437a3b045f3dc1b519c855bcf/src/main/java/org/broadinstitute/hellbender/utils/variant/writers/HomRefBlock.java",
    "raw_url": "https://github.com/broadinstitute/gatk/raw/af6c823e27e1ecd437a3b045f3dc1b519c855bcf/src/main/java/org/broadinstitute/hellbender/utils/variant/writers/HomRefBlock.java",
    "contents_url": "https://api.github.com/repos/broadinstitute/gatk/contents/src/main/java/org/broadinstitute/hellbender/utils/variant/writers/HomRefBlock.java?ref=af6c823e27e1ecd437a3b045f3dc1b519c855bcf",
    "patch": "@@ -91,6 +91,8 @@ Genotype createHomRefGenotype(final String sampleName, final boolean floorBlocks\n     @Override\n     public void add(final int pos, final int newEnd, final Genotype genotype) {\n         Utils.nonNull(genotype, \"genotype cannot be null\");\n+        //if ( pos > end + 1 ) { throw new IllegalArgumentException(\"adding genotype at pos \" + pos + \" isn't contiguous with previous end \" + end); }\n+        //if ( pos < getStart())  { throw new IllegalArgumentException(\"adding genotype at pos \" + pos + \" isn't contained in block with start \" + getStart()); }\n         if ( pos != end + 1 ) { throw new IllegalArgumentException(\"adding genotype at pos \" + pos + \" isn't contiguous with previous end \" + end); }\n         if ( genotype.getPloidy() != ploidy) { throw new IllegalArgumentException(\"cannot add a genotype with a different ploidy: \" + genotype.getPloidy() + \" != \" + ploidy); }\n         // Make sure the GQ is within the bounds of this band. Treat GQs > 99 as 99."
  },
  {
    "sha": "e8b311f8b4f75a3b1e0b9fcdc5740d0bb01b8323",
    "filename": "src/main/java/org/broadinstitute/hellbender/utils/variant/writers/SomaticGVCFBlockCombiner.java",
    "status": "modified",
    "additions": 2,
    "deletions": 2,
    "changes": 4,
    "blob_url": "https://github.com/broadinstitute/gatk/blob/af6c823e27e1ecd437a3b045f3dc1b519c855bcf/src/main/java/org/broadinstitute/hellbender/utils/variant/writers/SomaticGVCFBlockCombiner.java",
    "raw_url": "https://github.com/broadinstitute/gatk/raw/af6c823e27e1ecd437a3b045f3dc1b519c855bcf/src/main/java/org/broadinstitute/hellbender/utils/variant/writers/SomaticGVCFBlockCombiner.java",
    "contents_url": "https://api.github.com/repos/broadinstitute/gatk/contents/src/main/java/org/broadinstitute/hellbender/utils/variant/writers/SomaticGVCFBlockCombiner.java?ref=af6c823e27e1ecd437a3b045f3dc1b519c855bcf",
    "patch": "@@ -17,11 +17,11 @@\n     protected int partitionPrecision;  //number of decimal places to use for TLOD block ranges\n \n     public SomaticGVCFBlockCombiner(List<Number> gqPartitions, int defaultPloidy) {\n-        super(gqPartitions, defaultPloidy, false);\n+        super(gqPartitions, false);\n     }\n \n     public SomaticGVCFBlockCombiner(List<Number> gqPartitions, int defaultPloidy, final int partitionPrecision) {\n-        super(gqPartitions, defaultPloidy, false);\n+        super(gqPartitions, false);\n         this.partitionPrecision = partitionPrecision;\n     }\n "
  },
  {
    "sha": "8d6504249e595eb63c13027bfe0dede4c3bd01fd",
    "filename": "src/main/java/org/broadinstitute/hellbender/utils/variant/writers/SomaticGVCFWriter.java",
    "status": "modified",
    "additions": 2,
    "deletions": 10,
    "changes": 12,
    "blob_url": "https://github.com/broadinstitute/gatk/blob/af6c823e27e1ecd437a3b045f3dc1b519c855bcf/src/main/java/org/broadinstitute/hellbender/utils/variant/writers/SomaticGVCFWriter.java",
    "raw_url": "https://github.com/broadinstitute/gatk/raw/af6c823e27e1ecd437a3b045f3dc1b519c855bcf/src/main/java/org/broadinstitute/hellbender/utils/variant/writers/SomaticGVCFWriter.java",
    "contents_url": "https://api.github.com/repos/broadinstitute/gatk/contents/src/main/java/org/broadinstitute/hellbender/utils/variant/writers/SomaticGVCFWriter.java?ref=af6c823e27e1ecd437a3b045f3dc1b519c855bcf",
    "patch": "@@ -2,15 +2,7 @@\n \n import com.google.common.annotations.VisibleForTesting;\n import com.google.common.collect.ImmutableList;\n-import com.google.common.collect.Range;\n-import com.google.common.collect.RangeMap;\n-import com.google.common.collect.TreeRangeMap;\n-import htsjdk.variant.variantcontext.Genotype;\n-import htsjdk.variant.variantcontext.VariantContext;\n import htsjdk.variant.variantcontext.writer.VariantContextWriter;\n-import org.broadinstitute.hellbender.exceptions.GATKException;\n-import org.broadinstitute.hellbender.utils.Utils;\n-import org.broadinstitute.hellbender.utils.variant.GATKVCFConstants;\n import org.broadinstitute.hellbender.utils.variant.HomoSapiensConstants;\n \n import java.util.List;\n@@ -39,12 +31,12 @@\n      * @param lodPartitions     a list of TLOD partitions, this list must be non-empty and every element must be larger than previous element\n      */\n     public SomaticGVCFWriter(final VariantContextWriter underlyingWriter, final List<Number> lodPartitions) {\n-        super(underlyingWriter, ImmutableList.of(1, 10, 20), HomoSapiensConstants.DEFAULT_PLOIDY, false);\n+        super(underlyingWriter, ImmutableList.of(1, 10, 20), false);\n         gvcfBlockCombiner = new SomaticGVCFBlockCombiner(lodPartitions, HomoSapiensConstants.DEFAULT_PLOIDY);\n     }\n \n     public SomaticGVCFWriter(final VariantContextWriter underlyingWriter, final List<Number> lodPartitions, final int partitionPrecision) {\n-        super(underlyingWriter, ImmutableList.of(1, 10, 20), HomoSapiensConstants.DEFAULT_PLOIDY, false);\n+        super(underlyingWriter, ImmutableList.of(1, 10, 20), false);\n         gvcfBlockCombiner = new SomaticGVCFBlockCombiner(lodPartitions, HomoSapiensConstants.DEFAULT_PLOIDY, partitionPrecision);\n     }\n "
  },
  {
    "sha": "f4a9983b432f70e1a13e69342e155a8f949c45e6",
    "filename": "src/main/java/org/broadinstitute/hellbender/utils/variant/writers/TLODBlock.java",
    "status": "modified",
    "additions": 1,
    "deletions": 1,
    "changes": 2,
    "blob_url": "https://github.com/broadinstitute/gatk/blob/af6c823e27e1ecd437a3b045f3dc1b519c855bcf/src/main/java/org/broadinstitute/hellbender/utils/variant/writers/TLODBlock.java",
    "raw_url": "https://github.com/broadinstitute/gatk/raw/af6c823e27e1ecd437a3b045f3dc1b519c855bcf/src/main/java/org/broadinstitute/hellbender/utils/variant/writers/TLODBlock.java",
    "contents_url": "https://api.github.com/repos/broadinstitute/gatk/contents/src/main/java/org/broadinstitute/hellbender/utils/variant/writers/TLODBlock.java?ref=af6c823e27e1ecd437a3b045f3dc1b519c855bcf",
    "patch": "@@ -84,7 +84,7 @@ Genotype createHomRefGenotype(final String sampleName, final boolean floorBlock)\n     @Override\n     public void add(final int pos, final int newEnd, final Genotype genotype) {\n         Utils.nonNull(genotype, \"genotype cannot be null\");\n-        Utils.validateArg( pos == end + 1,\"adding genotype at pos \" + pos + \" isn't contiguous with previous end \" + end);\n+        if ( pos > end + 1 ) { throw new IllegalArgumentException(\"adding genotype at pos \" + pos + \" isn't contiguous with previous end \" + end); }\n         // Make sure the LOD is within the bounds of this band\n         final double currentLOD = Double.parseDouble(genotype.getExtendedAttribute(GATKVCFConstants.TUMOR_LOG_10_ODDS_KEY).toString());\n         if ( !withinBounds(currentLOD)) {"
  },
  {
    "sha": "91a908cba8b947a4a808f9fe0d618c752adb9cbc",
    "filename": "src/test/java/org/broadinstitute/hellbender/tools/walkers/genotyper/AlleleSubsettingUtilsUnitTest.java",
    "status": "modified",
    "additions": 3,
    "deletions": 4,
    "changes": 7,
    "blob_url": "https://github.com/broadinstitute/gatk/blob/af6c823e27e1ecd437a3b045f3dc1b519c855bcf/src/test/java/org/broadinstitute/hellbender/tools/walkers/genotyper/AlleleSubsettingUtilsUnitTest.java",
    "raw_url": "https://github.com/broadinstitute/gatk/raw/af6c823e27e1ecd437a3b045f3dc1b519c855bcf/src/test/java/org/broadinstitute/hellbender/tools/walkers/genotyper/AlleleSubsettingUtilsUnitTest.java",
    "contents_url": "https://api.github.com/repos/broadinstitute/gatk/contents/src/test/java/org/broadinstitute/hellbender/tools/walkers/genotyper/AlleleSubsettingUtilsUnitTest.java?ref=af6c823e27e1ecd437a3b045f3dc1b519c855bcf",
    "patch": "@@ -2,7 +2,6 @@\n \n import htsjdk.variant.variantcontext.*;\n import htsjdk.variant.vcf.VCFConstants;\n-import htsjdk.variant.vcf.VCFHeader;\n import org.broadinstitute.hellbender.exceptions.UserException;\n import org.broadinstitute.hellbender.utils.MathUtils;\n import org.broadinstitute.hellbender.GATKBaseTest;\n@@ -366,7 +365,7 @@ public void testCalculateLikelihoodSums() {\n         final VariantContext vc1 = new VariantContextBuilder(\"source\", \"contig\", 1, 1, twoAlleles)\n                 .genotypes(Arrays.asList(g1, g2, g3, gNull)).make();\n \n-        Assert.assertEquals(AlleleSubsettingUtils.calculateLikelihoodSums(vc1, 2)[1], 4.2, 1.0e-8);\n+        Assert.assertEquals(AlleleSubsettingUtils.calculateLikelihoodSums(vc1, 2, false)[1], 4.2, 1.0e-8);\n \n         // diploid, triallelic, two samples\n         final List<Allele> threeAlleles = Arrays.asList(Aref, C, G);\n@@ -390,7 +389,7 @@ public void testCalculateLikelihoodSums() {\n         final VariantContext vc2 = new VariantContextBuilder(\"source\", \"contig\", 1, 1, threeAlleles)\n                 .genotypes(Arrays.asList(g4, g5)).make();\n \n-        final double[] likelihoodSums2 = AlleleSubsettingUtils.calculateLikelihoodSums(vc2, 2);\n+        final double[] likelihoodSums2 = AlleleSubsettingUtils.calculateLikelihoodSums(vc2, 2, false);\n         Assert.assertEquals(likelihoodSums2[1], 4.1, 1.0e-8);\n         Assert.assertEquals(likelihoodSums2[2], 3.1, 1.0e-8);\n \n@@ -405,7 +404,7 @@ public void testCalculateLikelihoodSums() {\n         final VariantContext vc3 = new VariantContextBuilder(\"source\", \"contig\", 1, 1, twoAlleles)\n                 .genotypes(Arrays.asList(g6)).make();\n \n-        Assert.assertEquals(AlleleSubsettingUtils.calculateLikelihoodSums(vc3, 3)[1], 3.5, 1.0e-8);\n+        Assert.assertEquals(AlleleSubsettingUtils.calculateLikelihoodSums(vc3, 3, false)[1], 3.5, 1.0e-8);\n     }\n \n     // This test exists to enforce the behavior that AlleleSubsetting utils can be used to reorder alleles, if a developer"
  },
  {
    "sha": "966bd0501f80e3f6e86de79ba5059abcf0b39051",
    "filename": "src/test/java/org/broadinstitute/hellbender/tools/walkers/mutect/Mutect2IntegrationTest.java",
    "status": "modified",
    "additions": 1,
    "deletions": 1,
    "changes": 2,
    "blob_url": "https://github.com/broadinstitute/gatk/blob/af6c823e27e1ecd437a3b045f3dc1b519c855bcf/src/test/java/org/broadinstitute/hellbender/tools/walkers/mutect/Mutect2IntegrationTest.java",
    "raw_url": "https://github.com/broadinstitute/gatk/raw/af6c823e27e1ecd437a3b045f3dc1b519c855bcf/src/test/java/org/broadinstitute/hellbender/tools/walkers/mutect/Mutect2IntegrationTest.java",
    "contents_url": "https://api.github.com/repos/broadinstitute/gatk/contents/src/test/java/org/broadinstitute/hellbender/tools/walkers/mutect/Mutect2IntegrationTest.java?ref=af6c823e27e1ecd437a3b045f3dc1b519c855bcf",
    "patch": "@@ -316,7 +316,7 @@ public void testDifferentAltsInTumorAndNormal() {\n         Assert.assertTrue(altAllelesByPosition.get(10020042).basesMatch(Allele.ALT_C)); //tumor G->C, normal G->A\n         Assert.assertTrue(altAllelesByPosition.get(10020124).basesMatch(Allele.ALT_G)); //tumor A->G, normal A->T\n     }\n-    \n+\n     // test on an artificial bam with several contrived MNPs\n     @Test\n     public void testMnps() {"
  },
  {
    "sha": "bb7255101f83c91024346a801d25e990b6c3a0bd",
    "filename": "src/test/java/org/broadinstitute/hellbender/tools/walkers/validation/ReferenceBlockConcordanceIntegrationTest.java",
    "status": "modified",
    "additions": 0,
    "deletions": 2,
    "changes": 2,
    "blob_url": "https://github.com/broadinstitute/gatk/blob/af6c823e27e1ecd437a3b045f3dc1b519c855bcf/src/test/java/org/broadinstitute/hellbender/tools/walkers/validation/ReferenceBlockConcordanceIntegrationTest.java",
    "raw_url": "https://github.com/broadinstitute/gatk/raw/af6c823e27e1ecd437a3b045f3dc1b519c855bcf/src/test/java/org/broadinstitute/hellbender/tools/walkers/validation/ReferenceBlockConcordanceIntegrationTest.java",
    "contents_url": "https://api.github.com/repos/broadinstitute/gatk/contents/src/test/java/org/broadinstitute/hellbender/tools/walkers/validation/ReferenceBlockConcordanceIntegrationTest.java?ref=af6c823e27e1ecd437a3b045f3dc1b519c855bcf",
    "patch": "@@ -146,7 +146,6 @@ public void testMultipleContigs() throws Exception {\n         final GVCFWriter truthWriter = new GVCFWriter(\n                 GATKVariantContextUtils.createVCFWriter(truthFile.toPath(), null, false, Options.ALLOW_MISSING_FIELDS_IN_HEADER),\n                 IntStream.range(1, 100).boxed().collect(Collectors.toList()),\n-                2,\n                 true\n                 );\n         final VCFHeader header = new VCFHeader(new HashSet<>(), Collections.singletonList(\"TESTSAMPLE\"));\n@@ -160,7 +159,6 @@ public void testMultipleContigs() throws Exception {\n         final GVCFWriter evalWriter = new GVCFWriter(\n                 GATKVariantContextUtils.createVCFWriter(evalFile.toPath(), null, false, Options.ALLOW_MISSING_FIELDS_IN_HEADER),\n                 IntStream.range(1, 100).boxed().collect(Collectors.toList()),\n-                2,\n                 true\n         );\n         evalWriter.writeHeader(header);"
  },
  {
    "sha": "9b80aa8215f35b3518a16bb3237415eae1dbe598",
    "filename": "src/test/java/org/broadinstitute/hellbender/tools/walkers/variantutils/ReblockGVCFIntegrationTest.java",
    "status": "modified",
    "additions": 131,
    "deletions": 5,
    "changes": 136,
    "blob_url": "https://github.com/broadinstitute/gatk/blob/af6c823e27e1ecd437a3b045f3dc1b519c855bcf/src/test/java/org/broadinstitute/hellbender/tools/walkers/variantutils/ReblockGVCFIntegrationTest.java",
    "raw_url": "https://github.com/broadinstitute/gatk/raw/af6c823e27e1ecd437a3b045f3dc1b519c855bcf/src/test/java/org/broadinstitute/hellbender/tools/walkers/variantutils/ReblockGVCFIntegrationTest.java",
    "contents_url": "https://api.github.com/repos/broadinstitute/gatk/contents/src/test/java/org/broadinstitute/hellbender/tools/walkers/variantutils/ReblockGVCFIntegrationTest.java?ref=af6c823e27e1ecd437a3b045f3dc1b519c855bcf",
    "patch": "@@ -8,19 +8,20 @@\n import org.broadinstitute.hellbender.GATKBaseTest;\n import org.broadinstitute.hellbender.cmdline.StandardArgumentDefinitions;\n import org.broadinstitute.hellbender.engine.FeatureDataSource;\n+import org.broadinstitute.hellbender.exceptions.UserException;\n import org.broadinstitute.hellbender.testutils.ArgumentsBuilder;\n import org.broadinstitute.hellbender.testutils.CommandLineProgramTester;\n import org.broadinstitute.hellbender.testutils.IntegrationTestSpec;\n import org.broadinstitute.hellbender.testutils.VariantContextTestUtils;\n+import org.broadinstitute.hellbender.tools.walkers.genotyper.GenotypeCalculationArgumentCollection;\n+import org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2IntegrationTest;\n import org.broadinstitute.hellbender.utils.variant.GATKVCFConstants;\n import org.testng.Assert;\n import org.testng.annotations.Test;\n \n import java.io.File;\n-import java.util.ArrayList;\n-import java.util.Arrays;\n-import java.util.Collections;\n-import java.util.List;\n+import java.io.IOException;\n+import java.util.*;\n import java.util.stream.Collectors;\n \n public class ReblockGVCFIntegrationTest extends CommandLineProgramTest {\n@@ -83,7 +84,6 @@ public void testOneSampleAsForGnomAD() throws Exception {\n         spec.executeTest(\"testOneSampleDropLows\", this);\n     }\n \n-    //TODO: this isn't actually correcting non-ref GTs because I changed some args around -- separate out dropping low qual alleles and low qual sites?\n     @Test  //covers non-ref AD and non-ref GT corrections\n     public void testNonRefADCorrection() throws Exception {\n         final IntegrationTestSpec spec = new IntegrationTestSpec(\n@@ -107,6 +107,7 @@ public void testRawMQInput() throws Exception {\n     @Test\n     public void testASAnnotationsAndSubsetting() throws Exception {\n         //some subsetting, but never dropping the first alt\n+        //also has multi-allelic that gets trimmed with ref block added\n         final IntegrationTestSpec spec = new IntegrationTestSpec(\n                 \"-O %s -R \" + b37_reference_20_21 +\n                         \" -drop-low-quals -do-qual-approx -V \" + \"src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/NA12878.AS.chr20snippet.g.vcf\" +\n@@ -130,6 +131,7 @@ public void testASAnnotationsAndSubsetting() throws Exception {\n                 .add(\"drop-low-quals\", true)\n                 .add(\"rgq-threshold\", \"10\")\n                 .add(\"L\", \"chr20\")\n+                .addReference(hg38Reference)\n                 .addOutput(output);\n         runCommandLine(args);\n \n@@ -163,11 +165,24 @@ public void testNewCompressionScheme() throws Exception {\n         spec.executeTest(\"testNewCompressionScheme\", this);\n     }\n \n+    @Test\n+    public void testAggressiveQualFiltering() throws Exception {\n+        final IntegrationTestSpec spec = new IntegrationTestSpec(\n+                \"-O %s -R \" + hg38_reference_20_21 +\n+                        \" -drop-low-quals -do-qual-approx -V \" + getToolTestDataDir() + \"gvcfForReblocking.g.vcf\" +\n+                        \" --\" + StandardArgumentDefinitions.ADD_OUTPUT_VCF_COMMANDLINE + \" false\" +\n+                        \" --floor-blocks\" +\n+                        \" --\" + GenotypeCalculationArgumentCollection.CALL_CONFIDENCE_LONG_NAME + \" 65.0\",\n+                Arrays.asList(getToolTestDataDir() + \"expected.aggressiveQualFiltering.g.vcf\"));\n+        spec.executeTest(\"testVariantQualFiltering\", this);\n+    }\n+\n     @Test\n     public void testMQHeadersAreUpdated() throws Exception {\n         final File output = createTempFile(\"reblockedgvcf\", \".vcf\");\n         final ArgumentsBuilder args = new ArgumentsBuilder();\n         args.add(\"V\", getToolTestDataDir() + \"justHeader.g.vcf\")\n+                .addReference(hg38Reference)\n                 .addOutput(output);\n         runCommandLine(args);\n \n@@ -191,6 +206,7 @@ public void testReReblocking() {\n         final File output = createTempFile(\"rereblockedgvcf\", \".vcf\");\n         final ArgumentsBuilder args = new ArgumentsBuilder();\n         args.add(\"V\", input)\n+                .addReference(hg38Reference)\n                 .addOutput(output);\n         runCommandLine(args);\n \n@@ -213,4 +229,114 @@ public void testReReblocking() {\n         //we didn't ask to drop GQ0s, but they might get merged together\n         Assert.assertEquals(inputVCs.stream().anyMatch(vc -> vc.getGenotype(0).getGQ() == 0), outputVCs.stream().anyMatch(vc -> vc.getGenotype(0).getGQ() == 0));\n     }\n+\n+    @Test\n+    public void testOverlappingDeletions() throws IOException {\n+        final IntegrationTestSpec spec = new IntegrationTestSpec(\n+                \"-O %s -R \" + hg38_reference_20_21 +\n+                        \" -V \" + getToolTestDataDir() + \"overlappingDeletions.hc.g.vcf\" +\n+                        \" --\" + StandardArgumentDefinitions.ADD_OUTPUT_VCF_COMMANDLINE + \" false\",\n+                Arrays.asList(getToolTestDataDir() + \"expected.overlappingDeletions.g.vcf\"));\n+        spec.executeTest(\"testOverlappingDeletions\", this);\n+\n+        //Note that there's a star in the output that's not associated with any deletion, which isn't great, but\n+        //it is covered by a lot of deletions, just each deletion by itself is very low quality.\n+        //This could be resolved by this tool, but at the expense of a lot more complexity.\n+    }\n+\n+    @Test\n+    public void testHomRefCalls() throws IOException {\n+        final File input = new File(getToolTestDataDir() + \"dropGQ0Dels.g.vcf\");\n+        final File output = createTempFile(\"dropGQ0Dels.reblocked\", \".g.vcf\");\n+        final ArgumentsBuilder args = new ArgumentsBuilder();\n+        args.add(\"V\", input)\n+                .addReference(hg38Reference)\n+                .addOutput(output);\n+        runCommandLine(args);\n+\n+        final List<VariantContext> inputVCs = VariantContextTestUtils.readEntireVCFIntoMemory(input.getAbsolutePath()).getRight();\n+        final List<VariantContext> outputVCs = VariantContextTestUtils.readEntireVCFIntoMemory(output.getAbsolutePath()).getRight();\n+\n+        Assert.assertEquals(outputVCs.size(), 3);\n+        Assert.assertEquals(outputVCs.get(0).getStart(), inputVCs.get(0).getStart());\n+        Assert.assertEquals(outputVCs.get(outputVCs.size()-1).getEnd(), inputVCs.get(inputVCs.size()-1).getEnd());\n+        Assert.assertEquals(outputVCs.get(1).getGenotype(0).getGQ(), 0);  //there should be a GQ0 block in the middle from a crap variant in the input\n+    }\n+\n+    @Test\n+    public void testMultipleInputs() {\n+        //run with multiple inputs split from chr20:19995000-19998999 of prod.chr20snippet.withRawMQ.g.vcf\n+        //note that an event is duplicated in shard1 and shard2 because it spans the boundary\n+        final File output = createTempFile(\"multi-input\", \".vcf\");\n+        final ArgumentsBuilder args = new ArgumentsBuilder();\n+        args.add(\"V\", getToolTestDataDir() + \"chr20.shard3.g.vcf\")\n+                .add(\"V\", getToolTestDataDir() + \"chr20.shard2.g.vcf\")\n+                .add(\"V\", getToolTestDataDir() + \"chr20.shard1.g.vcf\")\n+                .add(\"V\", getToolTestDataDir() + \"chr20.shard0.g.vcf\")\n+                .addReference(hg38Reference)\n+                .addOutput(output);\n+        runCommandLine(args);\n+\n+        final File output2 = createTempFile(\"single-input\",\".vcf\");\n+        final ArgumentsBuilder args2 = new ArgumentsBuilder();\n+        args2.add(\"V\", getToolTestDataDir() + \"prod.chr20snippet.withRawMQ.g.vcf\")\n+                .add(\"L\", \"chr20:19995000-19998999\")\n+                .addReference(hg38Reference)\n+                .addOutput(output2);\n+        runCommandLine(args2);\n+\n+        try (final FeatureDataSource<VariantContext> actualVcs = new FeatureDataSource<>(output);\n+             final FeatureDataSource<VariantContext> expectedVcs = new FeatureDataSource<>(output2)) {\n+            GATKBaseTest.assertCondition(actualVcs, expectedVcs,\n+                    (a, e) -> VariantContextTestUtils.assertVariantContextsAreEqual(a, e,\n+                            Collections.emptyList(), Collections.emptyList()));\n+        }\n+    }\n+\n+    @Test(expectedExceptions = UserException.class)\n+    public void testMixedSamples() {\n+        final File output = createTempFile(\"reblockedgvcf\", \".vcf\");\n+        final ArgumentsBuilder args = new ArgumentsBuilder();\n+        args.add(\"V\", getToolTestDataDir() + \"justHeader.g.vcf\") //sample \"Sample\"\n+            .add(\"V\", getToolTestDataDir() + \"nonRefAD.g.vcf\") //sample \"HK017-0046\"\n+            .addReference(hg38Reference)\n+            .addOutput(output);\n+        runCommandLine(args);\n+    }\n+\n+    @Test\n+    //we had some external GVCFs that each went through CombineGVCFs for some reason, so GTs all went to ./.\n+    public void testNoCallGenotypes() {\n+        final File output = createTempFile(\"reblockedgvcf\", \".vcf\");\n+        final ArgumentsBuilder args = new ArgumentsBuilder();\n+        args.add(\"V\", getToolTestDataDir() + \"noCallGTs.g.vcf\")\n+                .addReference(hg38Reference)\n+                .addOutput(output);\n+        runCommandLine(args);\n+\n+        Pair<VCFHeader, List<VariantContext>> actual = VariantContextTestUtils.readEntireVCFIntoMemory(output.getAbsolutePath());\n+        final List<VariantContext> variants = actual.getRight();\n+        final List<String> variantKeys = variants.stream().map(VariantContextTestUtils::keyForVariant).collect(Collectors.toList());\n+        final Map<String, VariantContext> resultMap = new LinkedHashMap<>();\n+        for (int i = 0; i < variants.size(); i++) {\n+            resultMap.put(variantKeys.get(i), variants.get(i));\n+        }\n+\n+        final List<String> expectedHomVarKeys = Arrays.asList(\n+                \"chr22:10514994-10514994 G*, [<NON_REF>, A]\",\n+                \"chr22:10515170-10515170 C*, [<NON_REF>, T]\",\n+                \"chr22:10515223-10515223 G*, [<NON_REF>, C]\");\n+\n+        final List<String> expectedHetKeys = Arrays.asList(\n+                \"chr22:10515120-10515120 A*, [<NON_REF>, AAAGC]\",\n+                \"chr22:10515223-10515223 G*, [<NON_REF>, C]\");\n+\n+        final List<String> expectedHomRefKeys = Arrays.asList(\n+                \"chr22:10515118-10515118 G*, [<NON_REF>, GGAAA]\");\n+\n+        Assert.assertTrue(variantKeys.containsAll(expectedHomVarKeys));\n+        Assert.assertTrue(variantKeys.containsAll(expectedHetKeys));\n+        Assert.assertTrue(variantKeys.containsAll(expectedHomRefKeys));\n+        Assert.assertTrue(variants.size() == 22);\n+    }\n }\n\\ No newline at end of file"
  },
  {
    "sha": "60508c8d17ff7b59aa5fe9c0b5a591acac69e4b1",
    "filename": "src/test/java/org/broadinstitute/hellbender/tools/walkers/variantutils/ReblockGVCFUnitTest.java",
    "status": "modified",
    "additions": 223,
    "deletions": 23,
    "changes": 246,
    "blob_url": "https://github.com/broadinstitute/gatk/blob/af6c823e27e1ecd437a3b045f3dc1b519c855bcf/src/test/java/org/broadinstitute/hellbender/tools/walkers/variantutils/ReblockGVCFUnitTest.java",
    "raw_url": "https://github.com/broadinstitute/gatk/raw/af6c823e27e1ecd437a3b045f3dc1b519c855bcf/src/test/java/org/broadinstitute/hellbender/tools/walkers/variantutils/ReblockGVCFUnitTest.java",
    "contents_url": "https://api.github.com/repos/broadinstitute/gatk/contents/src/test/java/org/broadinstitute/hellbender/tools/walkers/variantutils/ReblockGVCFUnitTest.java?ref=af6c823e27e1ecd437a3b045f3dc1b519c855bcf",
    "patch": "@@ -1,17 +1,31 @@\n package org.broadinstitute.hellbender.tools.walkers.variantutils;\n \n+import htsjdk.samtools.SAMSequenceDictionary;\n+import htsjdk.samtools.reference.ReferenceSequenceFile;\n+import htsjdk.variant.utils.SAMSequenceDictionaryExtractor;\n import htsjdk.variant.variantcontext.*;\n+import htsjdk.variant.variantcontext.writer.VariantContextWriter;\n+import htsjdk.variant.variantcontext.writer.VariantContextWriterBuilder;\n+import htsjdk.variant.vcf.*;\n+import org.apache.commons.lang3.tuple.Pair;\n+import org.broadinstitute.hellbender.CommandLineProgramTest;\n+import org.broadinstitute.hellbender.GATKBaseTest;\n+import org.broadinstitute.hellbender.engine.GATKPath;\n+import org.broadinstitute.hellbender.testutils.ArgumentsBuilder;\n+import org.broadinstitute.hellbender.testutils.VariantContextTestUtils;\n+import org.broadinstitute.hellbender.utils.reference.ReferenceUtils;\n import htsjdk.variant.vcf.VCFConstants;\n import org.broadinstitute.hellbender.utils.variant.GATKVCFConstants;\n+import org.broadinstitute.hellbender.utils.variant.writers.GVCFWriter;\n import org.testng.Assert;\n+import org.testng.annotations.DataProvider;\n import org.testng.annotations.Test;\n \n-import java.util.Arrays;\n-import java.util.HashMap;\n-import java.util.List;\n-import java.util.Map;\n+import java.io.File;\n+import java.io.IOException;\n+import java.util.*;\n \n-public class ReblockGVCFUnitTest {\n+public class ReblockGVCFUnitTest extends CommandLineProgramTest {\n     private final static Allele LONG_REF = Allele.create(\"ACTG\", true);\n     private final static Allele DELETION = Allele.create(\"A\", false);\n     private final static Allele SHORT_REF = Allele.create(\"A\", true);\n@@ -25,14 +39,14 @@ public void testCleanUpHighQualityVariant() {\n         reblocker.dropLowQuals = true;\n         reblocker.doQualApprox = true;\n \n-        final Genotype g0 = makeG(\"sample1\", LONG_REF, DELETION, 41, 0, 37, 200, 100, 200, 400, 600, 800, 1200);\n-        final Genotype g = addAD(g0,0,13,17,0);\n+        final Genotype g0 = VariantContextTestUtils.makeG(\"sample1\", LONG_REF, DELETION, 41, 0, 37, 200, 100, 200, 400, 600, 800, 1200);\n+        final Genotype g = addAD(g0,13,17,0,0);\n         final VariantContext extraAlt0 = makeDeletionVC(\"lowQualVar\", Arrays.asList(LONG_REF, DELETION, LONG_SNP, Allele.NON_REF_ALLELE), LONG_REF.length(), g);\n         final Map<String, Object> attr = new HashMap<>();\n         attr.put(VCFConstants.DEPTH_KEY, 32);\n         final VariantContext extraAlt = addAttributes(extraAlt0, attr);\n         //we'll call this with the same VC again under the assumption that STAND_CALL_CONF is zero so no alleles/GTs change\n-        final VariantContext cleaned1 = reblocker.cleanUpHighQualityVariant(extraAlt, extraAlt);\n+        final VariantContext cleaned1 = reblocker.cleanUpHighQualityVariant(extraAlt);\n         Assert.assertTrue(cleaned1.getAlleles().size() == 3);\n         Assert.assertTrue(cleaned1.getAlleles().contains(LONG_REF));\n         Assert.assertTrue(cleaned1.getAlleles().contains(DELETION));\n@@ -44,7 +58,7 @@ public void testCleanUpHighQualityVariant() {\n         Assert.assertTrue(cleaned1.hasAttribute(GATKVCFConstants.RAW_MAPPING_QUALITY_WITH_DEPTH_KEY));\n         Assert.assertTrue(cleaned1.getAttributeAsString(GATKVCFConstants.RAW_MAPPING_QUALITY_WITH_DEPTH_KEY,\"\").split(\",\")[1].equals(\"32\"));\n \n-        final Genotype hetNonRef = makeG(\"sample2\", DELETION, LONG_SNP, 891,879,1128,84,0,30,891,879,84,891);\n+        final Genotype hetNonRef = VariantContextTestUtils.makeG(\"sample2\", DELETION, LONG_SNP, 891,879,1128,84,0,30,891,879,84,891);\n         final VariantContext keepAlts = makeDeletionVC(\"keepAllAlts\", Arrays.asList(LONG_REF, DELETION, LONG_SNP, Allele.NON_REF_ALLELE), LONG_REF.length(), hetNonRef);\n         Assert.assertTrue(keepAlts.getAlleles().size() == 4);\n         Assert.assertTrue(keepAlts.getAlleles().contains(LONG_REF));\n@@ -58,13 +72,13 @@ public void testLowQualVariantToGQ0HomRef() {\n         final ReblockGVCF reblocker = new ReblockGVCF();\n \n         reblocker.dropLowQuals = true;\n-        final Genotype g = makeG(\"sample1\", LONG_REF, Allele.NON_REF_ALLELE, 200, 100, 200, 11, 0, 37);\n+        final Genotype g = VariantContextTestUtils.makeG(\"sample1\", LONG_REF, Allele.NON_REF_ALLELE, 200, 100, 200, 11, 0, 37);\n         final VariantContext toBeNoCalled = makeDeletionVC(\"lowQualVar\", Arrays.asList(LONG_REF, DELETION, Allele.NON_REF_ALLELE), LONG_REF.length(), g);\n-        final VariantContext dropped = reblocker.lowQualVariantToGQ0HomRef(toBeNoCalled, toBeNoCalled);\n+        final VariantContextBuilder dropped = reblocker.lowQualVariantToGQ0HomRef(toBeNoCalled);\n         Assert.assertEquals(dropped, null);\n \n         reblocker.dropLowQuals = false;\n-        final VariantContext modified = reblocker.lowQualVariantToGQ0HomRef(toBeNoCalled, toBeNoCalled);\n+        final VariantContext modified = reblocker.lowQualVariantToGQ0HomRef(toBeNoCalled).make();\n         Assert.assertTrue(modified.getAttributes().containsKey(VCFConstants.END_KEY));\n         Assert.assertTrue(modified.getAttributes().get(VCFConstants.END_KEY).equals(13));\n         Assert.assertTrue(modified.getReference().equals(SHORT_REF));\n@@ -73,20 +87,49 @@ public void testLowQualVariantToGQ0HomRef() {\n         Assert.assertTrue(modified.getLog10PError() == VariantContext.NO_LOG10_PERROR);\n \n         //No-calls were throwing NPEs.  Now they're not.\n-        final Genotype g2 = makeG(\"sample1\", Allele.NO_CALL,Allele.NO_CALL);\n+        final Genotype g2 = VariantContextTestUtils.makeG(\"sample1\", Allele.NO_CALL,Allele.NO_CALL);\n         final VariantContext noData = makeDeletionVC(\"noData\", Arrays.asList(LONG_REF, DELETION, Allele.NON_REF_ALLELE), LONG_REF.length(), g2);\n-        final VariantContext notCrashing = reblocker.lowQualVariantToGQ0HomRef(noData, noData);\n-        Assert.assertTrue(notCrashing.getGenotype(0).isNoCall());\n+        final VariantContext notCrashing = reblocker.lowQualVariantToGQ0HomRef(noData).make();\n+        final Genotype outGenotype = notCrashing.getGenotype(0);\n+        Assert.assertTrue(outGenotype.isHomRef());\n+        Assert.assertEquals(outGenotype.getGQ(), 0);\n+        Assert.assertTrue(Arrays.stream(outGenotype.getPL()).allMatch(x -> x == 0));\n+\n+        //haploid hom ref call\n+        final int[] pls = {0, 35, 72};\n+        final GenotypeBuilder gb = new GenotypeBuilder(\"male_sample\", Arrays.asList(LONG_REF)).PL(pls);\n+        final VariantContextBuilder vb = new VariantContextBuilder();\n+        vb.chr(\"20\").start(10001).stop(10004).alleles(Arrays.asList(LONG_REF, DELETION, Allele.NON_REF_ALLELE)).log10PError(-3.0).genotypes(gb.make());\n+        final VariantContext vc = vb.make();\n+\n+        final VariantContext haploidRefBlock = reblocker.lowQualVariantToGQ0HomRef(vc).make();\n+        final Genotype newG = haploidRefBlock.getGenotype(\"male_sample\");\n+\n+        Assert.assertEquals(newG.getPloidy(), 1);\n+        Assert.assertEquals(newG.getGQ(), 35);\n+    }\n+\n+    @Test\n+    public void testCalledHomRefGetsAltGQ() {\n+        final ReblockGVCF reblocker = new ReblockGVCF();\n+\n+        final Genotype g3 = VariantContextTestUtils.makeG(\"sample1\", LONG_REF, LONG_REF, 0, 11, 37, 100, 200, 400);\n+        final VariantContext twoAltsHomRef = makeDeletionVC(\"lowQualVar\", Arrays.asList(LONG_REF, DELETION, Allele.NON_REF_ALLELE), LONG_REF.length(), g3);\n+        final GenotypeBuilder takeGoodAltGQ = reblocker.changeCallToHomRefVersusNonRef(twoAltsHomRef, new HashMap<>());\n+        final Genotype nowRefBlock = takeGoodAltGQ.make();\n+        Assert.assertEquals(nowRefBlock.getGQ(), 11);\n+        Assert.assertEquals(nowRefBlock.getDP(), 18);\n+        Assert.assertEquals((int)nowRefBlock.getExtendedAttribute(GATKVCFConstants.MIN_DP_FORMAT_KEY), 18);\n     }\n \n     @Test\n     public void testChangeCallToGQ0HomRef() {\n         final ReblockGVCF reblocker = new ReblockGVCF();\n \n-        final Genotype g = makeG(\"sample1\", LONG_REF, Allele.NON_REF_ALLELE, 200, 100, 200, 11, 0, 37);\n+        final Genotype g = VariantContextTestUtils.makeG(\"sample1\", LONG_REF, Allele.NON_REF_ALLELE, 200, 100, 200, 11, 0, 37);\n         final VariantContext toBeNoCalled = makeDeletionVC(\"lowQualVar\", Arrays.asList(LONG_REF, DELETION, Allele.NON_REF_ALLELE), LONG_REF.length(), g);\n         final Map<String, Object> noAttributesMap = new HashMap<>();\n-        final GenotypeBuilder noCalled = reblocker.changeCallToGQ0HomRef(toBeNoCalled, noAttributesMap);\n+        final GenotypeBuilder noCalled = reblocker.changeCallToHomRefVersusNonRef(toBeNoCalled, noAttributesMap);\n         final Genotype newG = noCalled.make();\n         Assert.assertTrue(noAttributesMap.containsKey(VCFConstants.END_KEY));\n         Assert.assertTrue(noAttributesMap.get(VCFConstants.END_KEY).equals(13));\n@@ -96,23 +139,180 @@ public void testChangeCallToGQ0HomRef() {\n     }\n \n     @Test  //no-calls can be dropped or reblocked just like hom-refs, i.e. we don't have to preserve them like variants\n-    public void testNoCalls() {\n+    public void testBadCalls() {\n         final ReblockGVCF reblocker = new ReblockGVCF();\n \n-        final Genotype g2 = makeG(\"sample1\", Allele.NO_CALL,Allele.NO_CALL);\n+        final Genotype g2 = VariantContextTestUtils.makeG(\"sample1\", Allele.NO_CALL,Allele.NO_CALL);\n         final VariantContext noData = makeDeletionVC(\"noData\", Arrays.asList(LONG_REF, DELETION, Allele.NON_REF_ALLELE), LONG_REF.length(), g2);\n         Assert.assertTrue(reblocker.shouldBeReblocked(noData));\n+\n+        final Genotype g3 = VariantContextTestUtils.makeG(\"sample1\", LONG_REF, Allele.NON_REF_ALLELE);\n+        final VariantContext nonRefCall = makeDeletionVC(\"nonRefCall\", Arrays.asList(LONG_REF, DELETION, Allele.NON_REF_ALLELE), LONG_REF.length(), g3);\n+        Assert.assertTrue(reblocker.shouldBeReblocked(nonRefCall));\n+    }\n+\n+    @Test\n+    public void testPosteriors() {\n+        final ReblockGVCF reblocker = new ReblockGVCF();\n+        reblocker.posteriorsKey = \"GP\";\n+\n+        final GenotypeBuilder gb = new GenotypeBuilder(\"sample1\", Arrays.asList(LONG_REF, LONG_REF));\n+        final double[] posteriors = {0,2,5.01,2,4,5.01,2,4,4,5.01};\n+        final int[] pls = {2,0,50,2,289,52,38,325,407,88};\n+        gb.attribute(\"GP\", posteriors).PL(pls).GQ(-2); //I kid you not, DRAGEN output a -2 GQ\n+        final VariantContext vc = makeDeletionVC(\"DRAGEN\", Arrays.asList(LONG_REF, DELETION, LONG_SNP, Allele.NON_REF_ALLELE), LONG_REF.length(), gb.make());\n+//        Assert.assertTrue(reblocker.shouldBeReblocked(vc));\n+//        final VariantContext out = reblocker.lowQualVariantToGQ0HomRef(vc, vc).make();\n+//        Assert.assertTrue(out.getGenotype(0).isHomRef());\n+//        Assert.assertTrue(out.getGenotype(0).getGQ() == 2);\n+\n+        final GenotypeBuilder gb2 = new GenotypeBuilder(\"sample1\", Arrays.asList(LONG_REF, LONG_REF));\n+        final double gqForNoPLs = 34.77;\n+        final int inputGQ = 32;\n+        Assert.assertNotEquals(gqForNoPLs, inputGQ);\n+        final double[] posteriors2 = {0,gqForNoPLs,37.78,39.03,73.8,42.04};\n+        gb2.attribute(\"GP\", posteriors2).GQ(inputGQ);\n+        final VariantContext vc2 = makeDeletionVC(\"DRAGEN\", Arrays.asList(LONG_REF, DELETION, Allele.NON_REF_ALLELE), LONG_REF.length(), gb2.make());\n+        final VariantContext out2 = reblocker.lowQualVariantToGQ0HomRef(vc2).make();\n+        final Genotype gOut2 = out2.getGenotype(0);\n+        Assert.assertTrue(gOut2.isHomRef());\n+        Assert.assertEquals(gOut2.getGQ(), (int)Math.round(gqForNoPLs));\n+        Assert.assertTrue(gOut2.hasPL());\n+        Assert.assertEquals(gOut2.getPL().length, 3);\n+    }\n+\n+    @DataProvider(name = \"overlappingDeletionCases\")\n+    public Object[][] createOverlappingDeletionCases() {\n+        return new Object[][] {\n+                {100000, 10, 100005, 10, 99, 99, 2},\n+                {100000, 10, 100005, 10, 99, 5, 2},\n+                {100000, 10, 100005, 10, 5, 99, 2},\n+                {100000, 10, 100005, 10, 5, 5, 1},\n+                {100000, 15, 100010, 5, 99, 99, 2},\n+                {100000, 15, 100010, 5, 99, 5, 1},\n+                {100000, 15, 100005, 5, 5, 99, 3},\n+                {100000, 15, 100005, 5, 5, 5, 1}\n+        };\n+    }\n+\n+    @Test(dataProvider = \"overlappingDeletionCases\")\n+    public void testOverlappingDeletions(final int del1start, final int del1length,\n+                                         final int del2start, final int del2length,\n+                                         final int del1qual, final int del2qual, final int numExpected) throws IOException {\n+        final String inputPrefix = \"overlappingDeletions\";\n+        final String inputSuffix = \".g.vcf\";\n+        final File inputFile = File.createTempFile(inputPrefix, inputSuffix);\n+        final GVCFWriter gvcfWriter= setUpWriter(inputFile, new File(GATKBaseTest.FULL_HG19_DICT));\n+\n+        final ReferenceSequenceFile ref = ReferenceUtils.createReferenceReader(new GATKPath(GATKBaseTest.b37Reference));\n+        final Allele del1Ref = Allele.create(ReferenceUtils.getRefBasesAtPosition(ref, \"20\", del1start, del1length), true);\n+        final Allele del1Alt = Allele.create(ReferenceUtils.getRefBaseAtPosition(ref, \"20\", del1start), false);\n+        final Allele del2Ref = Allele.create(ReferenceUtils.getRefBasesAtPosition(ref, \"20\", del2start, del2length), true);\n+        final Allele del2Alt = Allele.create(ReferenceUtils.getRefBaseAtPosition(ref, \"20\", del2start), false);\n+        final VariantContextBuilder variantContextBuilder = new VariantContextBuilder();\n+        variantContextBuilder.chr(\"20\").start(del1start).stop(del1start+del1length-1).attribute(VCFConstants.DEPTH_KEY, 10).alleles(Arrays.asList(del1Ref, del1Alt, Allele.NON_REF_ALLELE));\n+        final VariantContext del1 = VariantContextTestUtils.makeGVCFVariantContext(variantContextBuilder, Arrays.asList(del1Ref, del1Alt), del1qual);\n+\n+        variantContextBuilder.chr(\"20\").start(del2start).stop(del2start+del2length-1).attribute(VCFConstants.DEPTH_KEY, 10).alleles(Arrays.asList(del2Ref, del2Alt, Allele.NON_REF_ALLELE));\n+        final VariantContext del2 = VariantContextTestUtils.makeGVCFVariantContext(variantContextBuilder, Arrays.asList(del2Ref, del2Alt), del2qual);\n+\n+        gvcfWriter.add(del1);\n+        gvcfWriter.add(del2);\n+        gvcfWriter.close();\n+\n+        final File outputFile = File.createTempFile(inputPrefix,\".reblocked\" + inputSuffix);\n+        final ArgumentsBuilder args = new ArgumentsBuilder();\n+        args.add(\"V\", inputFile)\n+            .add(ReblockGVCF.RGQ_THRESHOLD_SHORT_NAME, 10.0)\n+            .addReference(b37_reference_20_21)\n+            .addOutput(outputFile);\n+        runCommandLine(args);\n+\n+        final Pair<VCFHeader, List<VariantContext>> outVCs = VariantContextTestUtils.readEntireVCFIntoMemory(outputFile.getAbsolutePath());\n+        Assert.assertEquals(outVCs.getRight().size(), numExpected);\n+    }\n+\n+    //TODO: test for uncalled alts, which we want to always drop\n+    @Test\n+    public void testIndelTrimming() throws IOException {\n+        final String inputPrefix = \"altToTrim\";\n+        final String inputSuffix = \".g.vcf\";\n+        final File inputFile = new File(inputPrefix+inputSuffix);\n+        final GVCFWriter gvcfWriter= setUpWriter(inputFile, new File(GATKBaseTest.FULL_HG19_DICT));\n+\n+        final int longestDelLength = 20;\n+        final int del1start = 200000;\n+        final int goodDelLength = 10;\n+        final ReferenceSequenceFile ref = ReferenceUtils.createReferenceReader(new GATKPath(GATKBaseTest.b37Reference));\n+        final Allele del1Ref = Allele.create(ReferenceUtils.getRefBasesAtPosition(ref, \"20\", del1start, longestDelLength), true);  //+1 for anchor base\n+        final Allele del1Alt2 = Allele.create(ReferenceUtils.getRefBaseAtPosition(ref, \"20\", del1start), false);\n+        final Allele del1Alt1 = Allele.extend(Allele.create(del1Alt2, true), ReferenceUtils.getRefBasesAtPosition(ref, \"20\", del1start+goodDelLength, goodDelLength));\n+        final VariantContextBuilder variantContextBuilder = new VariantContextBuilder();\n+        variantContextBuilder.chr(\"20\").start(del1start).stop(del1start+longestDelLength-1).attribute(VCFConstants.DEPTH_KEY, 10).alleles(Arrays.asList(del1Ref, del1Alt1, del1Alt2, Allele.NON_REF_ALLELE));\n+        final GenotypeBuilder gb = new GenotypeBuilder(VariantContextTestUtils.SAMPLE_NAME, Arrays.asList(del1Ref, del1Alt1));\n+        gb.PL(new int[]{50, 0, 100, 150, 200, 300, 400, 500, 600, 1000});\n+        variantContextBuilder.genotypes(gb.make());\n+        final VariantContext del1 = variantContextBuilder.make();\n+\n+        final int goodStart = del1start + longestDelLength;\n+        final Allele goodRef = Allele.create(ReferenceUtils.getRefBasesAtPosition(ref, \"20\", goodStart, 1), true);\n+        final Allele goodSNP = VariantContextTestUtils.makeAnySNPAlt(goodRef);  //generate valid data, but make it agnostic to position and reference genome\n+        variantContextBuilder.start(goodStart).stop(goodStart).alleles(Arrays.asList(goodRef, goodSNP, Allele.NON_REF_ALLELE));\n+        final GenotypeBuilder gb2 = new GenotypeBuilder(VariantContextTestUtils.SAMPLE_NAME, Arrays.asList(goodRef, goodSNP));\n+        gb2.PL(new int[]{50, 0, 100, 150, 200, 300});\n+        gb2.GQ(50);\n+        variantContextBuilder.genotypes(gb2.make());\n+        final VariantContext keepVar = variantContextBuilder.make();\n+\n+        gvcfWriter.add(del1);\n+        gvcfWriter.add(keepVar);\n+        gvcfWriter.close();\n+\n+        final File outputFile = File.createTempFile(inputPrefix,\".reblocked\" + inputSuffix);\n+        final ArgumentsBuilder args = new ArgumentsBuilder();\n+        args.add(\"V\", inputFile)\n+                .addReference(b37_reference_20_21)\n+                .addOutput(outputFile);\n+        runCommandLine(args);\n+\n+        final List<VariantContext> outVCs = VariantContextTestUtils.readEntireVCFIntoMemory(outputFile.getAbsolutePath()).getRight();\n+        Assert.assertEquals(outVCs.size(), 3);\n+        Assert.assertTrue(outVCs.get(0).isVariant());\n+        Assert.assertTrue(outVCs.get(1).isReferenceBlock());\n+        Assert.assertEquals(outVCs.get(1).getStart(), del1start + goodDelLength);\n+        Assert.assertTrue(outVCs.get(2).isVariant());\n     }\n \n-    //TODO: these are duplicated from PosteriorProbabilitiesUtilsUnitTest but PR #4947 modifies VariantContextTestUtils, so I'll do some refactoring before the second of the two is merged\n-    private Genotype makeG(final String sample, final Allele a1, final Allele a2, final int... pls) {\n-        return new GenotypeBuilder(sample, Arrays.asList(a1, a2)).PL(pls).make();\n+    private GVCFWriter setUpWriter(final File outputFile, final File dictionary) throws IOException {\n+        final VariantContextWriterBuilder builder = new VariantContextWriterBuilder();\n+        builder.setOutputPath(outputFile.toPath());\n+        final SAMSequenceDictionary dict = SAMSequenceDictionaryExtractor.extractDictionary(dictionary.toPath());\n+        builder.setReferenceDictionary(dict);\n+        final VariantContextWriter vcfWriter = builder.build();\n+        final GVCFWriter gvcfWriter= new GVCFWriter(vcfWriter, Arrays.asList(20,100));\n+        final VCFHeader result = new VCFHeader(Collections.emptySet(), Collections.singletonList(VariantContextTestUtils.SAMPLE_NAME));\n+        result.setSequenceDictionary(dict);\n+        result.addMetaDataLine(new VCFFormatHeaderLine(VCFConstants.GENOTYPE_KEY, 1,\n+                VCFHeaderLineType.String,  \"genotype\"));\n+        result.addMetaDataLine(new VCFFormatHeaderLine(VCFConstants.GENOTYPE_ALLELE_DEPTHS, 1,\n+                VCFHeaderLineType.String, \"Allele depth\"));\n+        result.addMetaDataLine(new VCFFormatHeaderLine(VCFConstants.DEPTH_KEY, 1,\n+                VCFHeaderLineType.String, \" depth\"));\n+        result.addMetaDataLine(new VCFInfoHeaderLine(VCFConstants.DEPTH_KEY, 1,\n+                VCFHeaderLineType.String, \" depth\"));\n+        result.addMetaDataLine(new VCFFormatHeaderLine(VCFConstants.GENOTYPE_QUALITY_KEY, 1,\n+                VCFHeaderLineType.String, \"Genotype quality\"));\n+        result.addMetaDataLine(new VCFFormatHeaderLine(VCFConstants.GENOTYPE_PL_KEY, 1,\n+                VCFHeaderLineType.String, \"Phred-scaled likelihoods\"));\n+        gvcfWriter.writeHeader(result);\n+        return gvcfWriter;\n     }\n \n     private VariantContext makeDeletionVC(final String source, final List<Allele> alleles, final int refLength, final Genotype... genotypes) {\n         final int start = 10;\n         final int stop = start+refLength-1;\n-        return new VariantContextBuilder(source, \"1\", start, stop, alleles).genotypes(Arrays.asList(genotypes)).unfiltered().make();\n+        return new VariantContextBuilder(source, \"1\", start, stop, alleles)\n+                .genotypes(Arrays.asList(genotypes)).unfiltered().log10PError(-3.0).attribute(VCFConstants.DEPTH_KEY, 18).make();\n     }\n \n     private Genotype addAD(final Genotype g, final int... ads) {"
  },
  {
    "sha": "c5210a446792206405bb0910bd5cb7ac660ff07f",
    "filename": "src/test/java/org/broadinstitute/hellbender/utils/variant/GATKVariantContextUtilsUnitTest.java",
    "status": "modified",
    "additions": 4,
    "deletions": 1,
    "changes": 5,
    "blob_url": "https://github.com/broadinstitute/gatk/blob/af6c823e27e1ecd437a3b045f3dc1b519c855bcf/src/test/java/org/broadinstitute/hellbender/utils/variant/GATKVariantContextUtilsUnitTest.java",
    "raw_url": "https://github.com/broadinstitute/gatk/raw/af6c823e27e1ecd437a3b045f3dc1b519c855bcf/src/test/java/org/broadinstitute/hellbender/utils/variant/GATKVariantContextUtilsUnitTest.java",
    "contents_url": "https://api.github.com/repos/broadinstitute/gatk/contents/src/test/java/org/broadinstitute/hellbender/utils/variant/GATKVariantContextUtilsUnitTest.java?ref=af6c823e27e1ecd437a3b045f3dc1b519c855bcf",
    "patch": "@@ -947,6 +947,9 @@ public void testRepeatAllele() {\n         List<Object[]> tests = new ArrayList<>();\n \n         // this functionality can be adapted to provide input data for whatever you might want in your data\n+        tests.add(new Object[]{Arrays.asList(\"ACC\", \"AC\", \"<NON_REF>\"), Arrays.asList(\"AC\", \"A\", \"<NON_REF>\"), 0});\n+        tests.add(new Object[]{Arrays.asList(\"ACC\", \"AC\", \"*\"), Arrays.asList(\"AC\", \"A\", \"*\"), 0});\n+\n         tests.add(new Object[]{Arrays.asList(\"ACC\", \"AC\"), Arrays.asList(\"AC\", \"A\"), 0});\n         tests.add(new Object[]{Arrays.asList(\"ACGC\", \"ACG\"), Arrays.asList(\"GC\", \"G\"), 2});\n         tests.add(new Object[]{Arrays.asList(\"ACGC\", \"ACGA\"), Arrays.asList(\"C\", \"A\"), 3});\n@@ -974,7 +977,7 @@ public void testClipAlleles(final List<String> alleleStrings, final List<String>\n         Assert.assertEquals(clipped.getStart(), unclipped.getStart() + numLeftClipped);\n         for ( int i = 0; i < unclipped.getAlleles().size(); i++ ) {\n             final Allele trimmed = clipped.getAlleles().get(i);\n-            Assert.assertEquals(trimmed.getBaseString(), expected.get(i));\n+            Assert.assertEquals(trimmed.getDisplayString(), expected.get(i));  //note that getBaseString doesn't work for <NON_REF>\n         }\n     }\n "
  },
  {
    "sha": "cd82e726a8585d3b751c60082ccfb1892e81dda5",
    "filename": "src/test/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFWriterUnitTest.java",
    "status": "modified",
    "additions": 25,
    "deletions": 26,
    "changes": 51,
    "blob_url": "https://github.com/broadinstitute/gatk/blob/af6c823e27e1ecd437a3b045f3dc1b519c855bcf/src/test/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFWriterUnitTest.java",
    "raw_url": "https://github.com/broadinstitute/gatk/raw/af6c823e27e1ecd437a3b045f3dc1b519c855bcf/src/test/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFWriterUnitTest.java",
    "contents_url": "https://api.github.com/repos/broadinstitute/gatk/contents/src/test/java/org/broadinstitute/hellbender/utils/variant/writers/GVCFWriterUnitTest.java?ref=af6c823e27e1ecd437a3b045f3dc1b519c855bcf",
    "patch": "@@ -17,7 +17,6 @@\n import org.broadinstitute.hellbender.utils.variant.GATKVCFConstants;\n import org.broadinstitute.hellbender.utils.variant.GATKVCFHeaderLines;\n import org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils;\n-import org.broadinstitute.hellbender.utils.variant.HomoSapiensConstants;\n import org.testng.Assert;\n import org.testng.annotations.DataProvider;\n import org.testng.annotations.Test;\n@@ -85,7 +84,7 @@ public void setHeader(VCFHeader header) {\n     @Test\n     public void testHeaderWriting() {\n         final MockWriter mockWriter = new MockWriter();\n-        final GVCFWriter writer = new GVCFWriter(mockWriter, standardPartition, HomoSapiensConstants.DEFAULT_PLOIDY);\n+        final GVCFWriter writer = new GVCFWriter(mockWriter, standardPartition);\n         writer.writeHeader(new VCFHeader());\n         Assert.assertTrue(mockWriter.headerSet);\n         Assert.assertTrue(mockWriter.headerWritten);\n@@ -94,7 +93,7 @@ public void testHeaderWriting() {\n     @Test\n     public void testHeaderSetting(){\n         final MockWriter mockWriter = new MockWriter();\n-        final GVCFWriter writer = new GVCFWriter(mockWriter, standardPartition, HomoSapiensConstants.DEFAULT_PLOIDY);\n+        final GVCFWriter writer = new GVCFWriter(mockWriter, standardPartition);\n         writer.setHeader(new VCFHeader());\n         Assert.assertTrue(mockWriter.headerSet);\n         Assert.assertFalse(mockWriter.headerWritten);\n@@ -103,7 +102,7 @@ public void testHeaderSetting(){\n     @Test\n     public void testClose() {\n         final MockWriter mockWriter = new MockWriter();\n-        final GVCFWriter writer = new GVCFWriter(mockWriter, standardPartition, HomoSapiensConstants.DEFAULT_PLOIDY);\n+        final GVCFWriter writer = new GVCFWriter(mockWriter, standardPartition);\n         writer.close();\n         Assert.assertTrue(mockWriter.closed);\n     }\n@@ -113,7 +112,7 @@ public void testClose() {\n     @Test\n     public void testCloseEmitsLastVariant() {\n         final MockWriter mockWriter = new MockWriter();\n-        final GVCFWriter writer = new GVCFWriter(mockWriter, standardPartition, HomoSapiensConstants.DEFAULT_PLOIDY);\n+        final GVCFWriter writer = new GVCFWriter(mockWriter, standardPartition);\n \n         writer.add(makeHomRef(1));\n         Assert.assertEquals(mockWriter.emitted.size(), 0);\n@@ -126,7 +125,7 @@ public void testCloseEmitsLastVariant() {\n     @Test\n     public void testCloseDoesntEmitsLastVariantWhenNonRef() {\n         final MockWriter mockWriter = new MockWriter();\n-        final GVCFWriter writer = new GVCFWriter(mockWriter, standardPartition, HomoSapiensConstants.DEFAULT_PLOIDY);\n+        final GVCFWriter writer = new GVCFWriter(mockWriter, standardPartition);\n \n         writer.add(makeNonRef(CHR1, 1));\n         Assert.assertEquals(mockWriter.emitted.size(), 1);\n@@ -139,7 +138,7 @@ public void testCloseDoesntEmitsLastVariantWhenNonRef() {\n     @Test\n     public void testCrossingContigBoundaryRef() {\n         final MockWriter mockWriter = new MockWriter();\n-        final GVCFWriter writer = new GVCFWriter(mockWriter, standardPartition, HomoSapiensConstants.DEFAULT_PLOIDY);\n+        final GVCFWriter writer = new GVCFWriter(mockWriter, standardPartition);\n \n         writer.add(makeHomRef(1));\n         writer.add(makeHomRef(2));\n@@ -156,7 +155,7 @@ public void testCrossingContigBoundaryRef() {\n     @Test\n     public void testCrossingContigBoundaryToLowerPositionsRef() {\n         final MockWriter mockWriter = new MockWriter();\n-        final GVCFWriter writer = new GVCFWriter(mockWriter, standardPartition, HomoSapiensConstants.DEFAULT_PLOIDY);\n+        final GVCFWriter writer = new GVCFWriter(mockWriter, standardPartition);\n \n         writer.add(makeHomRef(30));\n         writer.add(makeHomRef(31));\n@@ -173,7 +172,7 @@ public void testCrossingContigBoundaryToLowerPositionsRef() {\n     @Test\n     public void testCrossingContigBoundaryFromNonRefToLowerPositionsRef() {\n         final MockWriter mockWriter = new MockWriter();\n-        final GVCFWriter writer = new GVCFWriter(mockWriter, standardPartition, HomoSapiensConstants.DEFAULT_PLOIDY);\n+        final GVCFWriter writer = new GVCFWriter(mockWriter, standardPartition);\n \n         writer.add(makeNonRef(CHR1, 20));\n         Assert.assertEquals(mockWriter.emitted.size(), 1);\n@@ -189,7 +188,7 @@ public void testCrossingContigBoundaryFromNonRefToLowerPositionsRef() {\n     @Test\n     public void testCrossingContigBoundaryNonRef() {\n         final MockWriter mockWriter = new MockWriter();\n-        final GVCFWriter writer = new GVCFWriter(mockWriter, standardPartition, HomoSapiensConstants.DEFAULT_PLOIDY);\n+        final GVCFWriter writer = new GVCFWriter(mockWriter, standardPartition);\n \n         writer.add(makeHomRef(1));\n         writer.add(makeHomRef(2));\n@@ -203,7 +202,7 @@ public void testCrossingContigBoundaryNonRef() {\n     @Test\n     public void testCrossingContigBoundaryNonRefThenNonRef() {\n         final MockWriter mockWriter = new MockWriter();\n-        final GVCFWriter writer = new GVCFWriter(mockWriter, standardPartition, HomoSapiensConstants.DEFAULT_PLOIDY);\n+        final GVCFWriter writer = new GVCFWriter(mockWriter, standardPartition);\n \n         writer.add(makeNonRef(CHR1, 1));\n         Assert.assertEquals(mockWriter.emitted.size(), 1);\n@@ -252,7 +251,7 @@ private static void assertGoodVC(final VariantContext vc, final String contig, f\n     @Test\n     public void testVariantForcesNonRef() {\n         final MockWriter mockWriter = new MockWriter();\n-        final GVCFWriter writer = new GVCFWriter(mockWriter, standardPartition, HomoSapiensConstants.DEFAULT_PLOIDY);\n+        final GVCFWriter writer = new GVCFWriter(mockWriter, standardPartition);\n \n         writer.add(makeHomRef(1));\n         writer.add(makeHomRef(2));\n@@ -270,7 +269,7 @@ public void testVariantForcesNonRef() {\n     @Test\n     public void testEmittingTwoBands() {\n         final MockWriter mockWriter = new MockWriter();\n-        final GVCFWriter writer = new GVCFWriter(mockWriter, standardPartition, HomoSapiensConstants.DEFAULT_PLOIDY);\n+        final GVCFWriter writer = new GVCFWriter(mockWriter, standardPartition);\n \n         writer.add(makeHomRef(1));\n         writer.add(makeHomRef(2));\n@@ -287,7 +286,7 @@ public void testEmittingTwoBands() {\n     @Test\n     public void testBandingUsingPP() {\n         final MockWriter mockWriter = new MockWriter();\n-        final GVCFWriter writer = new GVCFWriter(mockWriter, standardPartition, HomoSapiensConstants.DEFAULT_PLOIDY);\n+        final GVCFWriter writer = new GVCFWriter(mockWriter, standardPartition);\n \n         int[] PPs1 = {0,63,128};\n         int[] PPs2 = {0,67,145};\n@@ -303,7 +302,7 @@ public void testBandingUsingPP() {\n     @Test\n     public void testNonContiguousBlocks() {\n         final MockWriter mockWriter = new MockWriter();\n-        final GVCFWriter writer = new GVCFWriter(mockWriter, standardPartition, HomoSapiensConstants.DEFAULT_PLOIDY);\n+        final GVCFWriter writer = new GVCFWriter(mockWriter, standardPartition);\n \n         writer.add(makeHomRef(1));\n         writer.add(makeHomRef(2));\n@@ -318,7 +317,7 @@ public void testNonContiguousBlocks() {\n     @Test\n     public void testInputBlocks() {\n         final MockWriter mockWriter = new MockWriter();\n-        final GVCFWriter writer = new GVCFWriter(mockWriter, highConfLowConf, HomoSapiensConstants.DEFAULT_PLOIDY);\n+        final GVCFWriter writer = new GVCFWriter(mockWriter, highConfLowConf);\n \n         writer.add(makeHomRef(\"20\", 1, 16, 600));\n         writer.add(makeHomRef(\"20\", 601, 0, 620));\n@@ -330,7 +329,7 @@ public void testInputBlocks() {\n     @Test\n     public void testDeletion() {\n         final MockWriter mockWriter = new MockWriter();\n-        final GVCFWriter writer = new GVCFWriter(mockWriter, standardPartition, HomoSapiensConstants.DEFAULT_PLOIDY);\n+        final GVCFWriter writer = new GVCFWriter(mockWriter, standardPartition);\n \n         writer.add(makeHomRef(1));\n         writer.add(makeHomRef(2));\n@@ -349,7 +348,7 @@ public void testDeletion() {\n     @Test\n     public void testHomRefAlt() {\n         final MockWriter mockWriter = new MockWriter();\n-        final GVCFWriter writer = new GVCFWriter(mockWriter, standardPartition, HomoSapiensConstants.DEFAULT_PLOIDY);\n+        final GVCFWriter writer = new GVCFWriter(mockWriter, standardPartition);\n \n         writer.add(makeHomRef(1));\n         writer.add(makeHomRef(2));\n@@ -382,7 +381,7 @@ public void testHomRefAlt() {\n \n     @Test(dataProvider = \"GoodBandPartitionData\")\n     public void testGoodPartitions(final List<Number> partitions, List<Range<Integer>> expected) {\n-        final GVCFBlockCombiner combiner = new GVCFBlockCombiner(partitions, HomoSapiensConstants.DEFAULT_PLOIDY, false);\n+        final GVCFBlockCombiner combiner = new GVCFBlockCombiner(partitions, false);\n         Assert.assertEquals(new ArrayList<>(combiner.gqPartitions.asMapOfRanges().values()), expected);\n         Assert.assertEquals(new ArrayList<>(combiner.gqPartitions.asMapOfRanges().keySet()), expected);\n     }\n@@ -402,13 +401,13 @@ public void testGoodPartitions(final List<Number> partitions, List<Range<Integer\n \n     @Test(dataProvider = \"BadBandPartitionData\", expectedExceptions = IllegalArgumentException.class)\n     public void testBadPartitionsThrowException(final List<Number> partitions){\n-        GVCFBlockCombiner combiner = new GVCFBlockCombiner(partitions, HomoSapiensConstants.DEFAULT_PLOIDY, false); // we should explode here\n+        GVCFBlockCombiner combiner = new GVCFBlockCombiner(partitions, false); // we should explode here\n     }\n \n     @Test\n     public void testCheckError(){\n         final MockWriter mockWriter = new MockWriter();\n-        final GVCFWriter gvcfWriter = new GVCFWriter(mockWriter, standardPartition, HomoSapiensConstants.DEFAULT_PLOIDY);\n+        final GVCFWriter gvcfWriter = new GVCFWriter(mockWriter, standardPartition);\n         mockWriter.error = false;\n         Assert.assertEquals(gvcfWriter.checkError(), mockWriter.checkError());\n         mockWriter.error = true;\n@@ -458,7 +457,7 @@ public void writeGVCFToDisk(List<VariantContext> variants, List<MinimalData> exp\n         final File outputFile =  createTempFile(\"generated\", \".g.vcf\");\n \n         try (VariantContextWriter writer = GATKVariantContextUtils.createVCFWriter(outputFile.toPath(), null, false);\n-             GVCFWriter gvcfWriter = new GVCFWriter(writer, gqPartitions, HomoSapiensConstants.DEFAULT_PLOIDY))\n+             GVCFWriter gvcfWriter = new GVCFWriter(writer, gqPartitions))\n         {\n             gvcfWriter.writeHeader(getMinimalVCFHeader());\n             variants.forEach(gvcfWriter::add);\n@@ -576,7 +575,7 @@ public void testAgainstExampleGVCF() throws IOException {\n                 .genotypes(block3genotypeBuilder.make());\n \n         try (VariantContextWriter writer = GATKVariantContextUtils.createVCFWriter(outputFile.toPath(), null, false);\n-             GVCFWriter gvcfWriter = new GVCFWriter(writer, gqPartitions, HomoSapiensConstants.DEFAULT_PLOIDY))\n+             GVCFWriter gvcfWriter = new GVCFWriter(writer, gqPartitions))\n         {\n             gvcfWriter.writeHeader(getMinimalVCFHeader());\n \n@@ -634,11 +633,11 @@ public void testOverlappingDeletions() {\n         final VariantContext origRefBlock = makeHomRef(\"1\", 10026, 60, 10050);\n \n         //Let's say that these \"low quality\" deletions are below the RGQ threshold and get converted to homRefs with all zero PLs\n-        final VariantContext block1 = reblocker.lowQualVariantToGQ0HomRef(deletion1, deletion1);\n-        final VariantContext block2 = reblocker.lowQualVariantToGQ0HomRef(deletion2, deletion2);\n+        final VariantContext block1 = reblocker.lowQualVariantToGQ0HomRef(deletion1).make();\n+        final VariantContext block2 = reblocker.lowQualVariantToGQ0HomRef(deletion2).make();\n \n         final MockWriter mockWriter = new MockWriter();\n-        final GVCFWriter writer = new GVCFWriter(mockWriter, Arrays.asList(20,100), 2);\n+        final GVCFWriter writer = new GVCFWriter(mockWriter, Arrays.asList(20,100));\n         writer.add(deletion1);\n         writer.add(block2);\n         writer.add(origRefBlock);"
  },
  {
    "sha": "22d72266de1ec9c75ea82f46667195c5e1436887",
    "filename": "src/test/java/org/broadinstitute/hellbender/utils/variant/writers/HomRefBlockUnitTest.java",
    "status": "modified",
    "additions": 10,
    "deletions": 3,
    "changes": 13,
    "blob_url": "https://github.com/broadinstitute/gatk/blob/af6c823e27e1ecd437a3b045f3dc1b519c855bcf/src/test/java/org/broadinstitute/hellbender/utils/variant/writers/HomRefBlockUnitTest.java",
    "raw_url": "https://github.com/broadinstitute/gatk/raw/af6c823e27e1ecd437a3b045f3dc1b519c855bcf/src/test/java/org/broadinstitute/hellbender/utils/variant/writers/HomRefBlockUnitTest.java",
    "contents_url": "https://api.github.com/repos/broadinstitute/gatk/contents/src/test/java/org/broadinstitute/hellbender/utils/variant/writers/HomRefBlockUnitTest.java?ref=af6c823e27e1ecd437a3b045f3dc1b519c855bcf",
    "patch": "@@ -19,13 +19,15 @@\n public class HomRefBlockUnitTest extends GATKBaseTest {\n     private static final String SAMPLE_NAME = \"foo\";\n     private static final Allele REF = Allele.create(\"A\", true);\n+    private static final int START = 1001;\n+    private static final int END = START + 1000;\n \n     private static List<Allele> getAlleles() {\n         return Arrays.asList(REF, Allele.create(\"C\"));\n     }\n \n     private static VariantContext getVariantContext() {\n-        return new VariantContextBuilder(SAMPLE_NAME, \"20\", 1, 1, getAlleles()).make();\n+        return new VariantContextBuilder(SAMPLE_NAME, \"20\", START, START, getAlleles()).make();\n     }\n \n     @Test\n@@ -80,6 +82,9 @@ public void testMinMedian() {\n     public static Object[][] badAdditions() {\n         final VariantContext vc = getVariantContext();\n         return new Object[][]{\n+                {vc.getStart(), getValidGenotypeBuilder().PL((int[])null).make()}, //no PLs\n+                {END + 2, getValidGenotypeBuilder().make()}, //bad start\n+                {vc.getStart() - 1, getValidGenotypeBuilder().make()}, //bad start\n                 {vc.getStart() + 1000, getValidGenotypeBuilder().make()}, //bad start\n                 {vc.getStart() - 1000, getValidGenotypeBuilder().make()}, //bad start\n                 {vc.getStart(), getValidGenotypeBuilder().GQ(1).make()}, // GQ out of bounds\n@@ -99,7 +104,9 @@ private static GenotypeBuilder getValidGenotypeBuilder() {\n \n     @Test(dataProvider = \"badAdditions\", expectedExceptions = IllegalArgumentException.class)\n     public void testBadAdd(int start, Genotype gb) {\n-        getHomRefBlock(getVariantContext()).add(start, gb);\n+        final HomRefBlock block = getHomRefBlock(getVariantContext());\n+        block.add(START, END, getValidGenotypeBuilder().make());\n+        block.add(start, gb);\n     }\n \n     @Test(expectedExceptions = GATKException.class)\n@@ -156,7 +163,7 @@ private static void assertValues(final GVCFBlock band, final int minDP, final in\n \n         for ( final String chrMod : Arrays.asList(\"\", \".mismatch\") ) {\n             for ( final int offset : Arrays.asList(-10, -1, 0, 1, 10) ) {\n-                final boolean equals = chrMod.isEmpty() && offset == 0;\n+                final boolean equals = chrMod.isEmpty() && (offset == 0 || offset == 1); //allow adding of VCs with same start or adjacent start\n                 tests.add(new Object[]{vc.getContig() + chrMod, vc.getStart() + offset, equals});\n             }\n         }"
  },
  {
    "sha": "a7710e27f4abad570fe844cadda02e054e90ee6a",
    "filename": "src/test/resources/large/testProductionGVCF.expected.g.vcf",
    "status": "modified",
    "additions": 2,
    "deletions": 2,
    "changes": 4,
    "blob_url": "https://github.com/broadinstitute/gatk/blob/af6c823e27e1ecd437a3b045f3dc1b519c855bcf/src/test/resources/large/testProductionGVCF.expected.g.vcf",
    "raw_url": "https://github.com/broadinstitute/gatk/raw/af6c823e27e1ecd437a3b045f3dc1b519c855bcf/src/test/resources/large/testProductionGVCF.expected.g.vcf",
    "contents_url": "https://api.github.com/repos/broadinstitute/gatk/contents/src/test/resources/large/testProductionGVCF.expected.g.vcf?ref=af6c823e27e1ecd437a3b045f3dc1b519c855bcf",
    "patch": "@@ -1,3 +1,3 @@\n version https://git-lfs.github.com/spec/v1\n-oid sha256:1b53e5f87904c3b9cbb24062c139b2cffbef300efba039bbd379e8d93f448db7\n-size 1399442\n+oid sha256:d0541e84a78753bdf8229c030c5b2007ecce379381b7f6f039d94e47d5cb7014\n+size 1398954"
  },
  {
    "sha": "412ca4c9d14fc076e40ec4b35b0a5ffb270a2d6a",
    "filename": "src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/ReblockGVCF/chr20.shard0.g.vcf",
    "status": "added",
    "additions": 244,
    "deletions": 0,
    "changes": 244,
    "blob_url": "https://github.com/broadinstitute/gatk/blob/af6c823e27e1ecd437a3b045f3dc1b519c855bcf/src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/ReblockGVCF/chr20.shard0.g.vcf",
    "raw_url": "https://github.com/broadinstitute/gatk/raw/af6c823e27e1ecd437a3b045f3dc1b519c855bcf/src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/ReblockGVCF/chr20.shard0.g.vcf",
    "contents_url": "https://api.github.com/repos/broadinstitute/gatk/contents/src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/ReblockGVCF/chr20.shard0.g.vcf?ref=af6c823e27e1ecd437a3b045f3dc1b519c855bcf",
    "patch": "@@ -0,0 +1,244 @@\n+##fileformat=VCFv4.2\n+##ALT=<ID=NON_REF,Description=\"Represents any possible alternative allele at this location\">\n+##FILTER=<ID=LowQual,Description=\"Low quality\">\n+##FORMAT=<ID=AD,Number=R,Type=Integer,Description=\"Allelic depths for the ref and alt alleles in the order listed\">\n+##FORMAT=<ID=DP,Number=1,Type=Integer,Description=\"Approximate read depth (reads with MQ=255 or with bad mates are filtered)\">\n+##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=\"Genotype Quality\">\n+##FORMAT=<ID=GT,Number=1,Type=String,Description=\"Genotype\">\n+##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=\"Minimum DP observed within the GVCF block\">\n+##FORMAT=<ID=PGT,Number=1,Type=String,Description=\"Physical phasing haplotype information, describing how the alternate alleles are phased in relation to one another\">\n+##FORMAT=<ID=PID,Number=1,Type=String,Description=\"Physical phasing ID information, where each unique ID within a given sample (but not across samples) connects records within a phasing group\">\n+##FORMAT=<ID=PL,Number=G,Type=Integer,Description=\"Normalized, Phred-scaled likelihoods for genotypes as defined in the VCF specification\">\n+##FORMAT=<ID=SB,Number=4,Type=Integer,Description=\"Per-sample component statistics which comprise the Fisher's Exact Test to detect strand bias.\">\n+##GATKCommandLine.HaplotypeCaller=<ID=HaplotypeCaller,Version=3.5-0-g36282e4,Date=\"Sun Sep 03 19:04:52 UTC 2017\",Epoch=1504465492413,CommandLineOptions=\"analysis_type=HaplotypeCaller input_file=[/cromwell_root/broad-gotc-prod-cromwell-execution/PairedEndSingleSampleWorkflow/36d6043d-5e15-4a26-9bd0-e28d44d4b052/call-GatherBamFiles/NWD242235.bam] showFullBamList=false read_buffer_size=null phone_home=AWS gatk_key=null tag=NA read_filter=[OverclippedRead] disable_read_filter=[] intervals=[/cromwell_root/broad-gotc-prod-cromwell-execution/PairedEndSingleSampleWorkflow/36d6043d-5e15-4a26-9bd0-e28d44d4b052/call-ScatterIntervalList/glob-cb4648beeaff920acb03de7603c06f98/23scattered.interval_list] excludeIntervals=null interval_set_rule=UNION interval_merging=ALL interval_padding=0 reference_sequence=/cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.fasta nonDeterministicRandomSeed=false disableDithering=false maxRuntime=-1 maxRuntimeUnits=MINUTES downsampling_type=BY_SAMPLE downsample_to_fraction=null downsample_to_coverage=500 baq=OFF baqGapOpenPenalty=40.0 refactor_NDN_cigar_string=false fix_misencoded_quality_scores=false allow_potentially_misencoded_quality_scores=false useOriginalQualities=false defaultBaseQualities=-1 performanceLog=null BQSR=null quantize_quals=0 static_quantized_quals=null round_down_quantized=false disable_indel_quals=false emit_original_quals=false preserve_qscores_less_than=6 globalQScorePrior=-1.0 validation_strictness=SILENT remove_program_records=false keep_program_records=false sample_rename_mapping_file=null unsafe=null disable_auto_index_creation_and_locking_when_reading_rods=false no_cmdline_in_header=false sites_only=false never_trim_vcf_format_field=false bcf=false bam_compression=null simplifyBAM=false disable_bam_indexing=false generate_md5=false num_threads=1 num_cpu_threads_per_data_thread=1 num_io_threads=0 monitorThreadEfficiency=false num_bam_file_handles=null read_group_black_list=null pedigree=[] pedigreeString=[] pedigreeValidationType=STRICT allow_intervals_with_unindexed_bam=false generateShadowBCF=false variant_index_type=LINEAR variant_index_parameter=128000 reference_window_stop=0 logging_level=INFO log_to_file=null help=false version=false likelihoodCalculationEngine=PairHMM heterogeneousKmerSizeResolution=COMBO_MIN dbsnp=(RodBinding name= source=UNBOUND) dontTrimActiveRegions=false maxDiscARExtension=25 maxGGAARExtension=300 paddingAroundIndels=150 paddingAroundSNPs=20 comp=[] annotation=[StrandBiasBySample] excludeAnnotation=[ChromosomeCounts, FisherStrand, StrandOddsRatio, QualByDepth] group=[Standard, StandardHCAnnotation] debug=false useFilteredReadsForAnnotations=false emitRefConfidence=GVCF bamOutput=null bamWriterType=CALLED_HAPLOTYPES disableOptimizations=false annotateNDA=false heterozygosity=0.001 indel_heterozygosity=1.25E-4 standard_min_confidence_threshold_for_calling=-0.0 standard_min_confidence_threshold_for_emitting=-0.0 max_alternate_alleles=3 input_prior=[] sample_ploidy=2 genotyping_mode=DISCOVERY alleles=(RodBinding name= source=UNBOUND) contamination_fraction_to_filter=0.004839373333333333 contamination_fraction_per_sample_file=null p_nonref_model=null exactcallslog=null output_mode=EMIT_VARIANTS_ONLY allSitePLs=true gcpHMM=10 pair_hmm_implementation=VECTOR_LOGLESS_CACHING pair_hmm_sub_implementation=ENABLE_ALL always_load_vector_logless_PairHMM_lib=false phredScaledGlobalReadMismappingRate=45 noFpga=false sample_name=null kmerSize=[10, 25] dontIncreaseKmerSizesForCycles=false allowNonUniqueKmersInRef=false numPruningSamples=1 recoverDanglingHeads=false doNotRecoverDanglingBranches=false minDanglingBranchLength=4 consensus=false maxNumHaplotypesInPopulation=128 errorCorrectKmers=false minPruning=2 debugGraphTransformations=false allowCyclesInKmerGraphToGeneratePaths=false graphOutput=null kmerLengthForReadErrorCorrection=25 minObservationsForKmerToBeSolid=20 GVCFGQBands=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 70, 80, 90, 99] indelSizeToEliminateInRefModel=10 min_base_quality_score=10 includeUmappedReads=false useAllelesTrigger=false doNotRunPhysicalPhasing=false keepRG=null justDetermineActiveRegions=false dontGenotype=false dontUseSoftClippedBases=false captureAssemblyFailureBAM=false errorCorrectReads=false pcr_indel_model=CONSERVATIVE maxReadsInRegionPerSample=10000 minReadsPerAlignmentStart=10 mergeVariantsViaLD=false activityProfileOut=null activeRegionOut=null activeRegionIn=null activeRegionExtension=null forceActive=false activeRegionMaxSize=null bandPassSigma=null maxProbPropagationDistance=50 activeProbabilityThreshold=0.002 filter_is_too_short_value=30 do_not_require_softclips_both_ends=false min_mapping_quality_score=20 filter_reads_with_N_cigar=false filter_mismatching_base_and_quals=false filter_bases_not_stored=false\">\n+##GATKCommandLine=<ID=SelectVariants,CommandLine=\"SelectVariants  --output chr20.shard0.g.vcf --variant prod.chr20snippet.withRawMQ.g.vcf --intervals chr20:19995000-19995999  --invertSelect false --exclude-non-variants false --exclude-filtered false --preserve-alleles false --remove-unused-alternates false --restrict-alleles-to ALL --keep-original-ac false --keep-original-dp false --mendelian-violation false --invert-mendelian-violation false --mendelian-violation-qual-threshold 0.0 --select-random-fraction 0.0 --remove-fraction-genotypes 0.0 --fully-decode false --max-indel-size 2147483647 --min-indel-size 0 --max-filtered-genotypes 2147483647 --min-filtered-genotypes 0 --max-fraction-filtered-genotypes 1.0 --min-fraction-filtered-genotypes 0.0 --max-nocall-number 2147483647 --max-nocall-fraction 1.0 --set-filtered-gt-to-nocall false --allow-nonoverlapping-command-line-samples false --suppress-reference-path false --genomicsdb-use-vcf-codec false --interval-set-rule UNION --interval-padding 0 --interval-exclusion-padding 0 --interval-merging-rule ALL --read-validation-stringency SILENT --seconds-between-progress-updates 10.0 --disable-sequence-dictionary-validation false --create-output-bam-index true --create-output-bam-md5 false --create-output-variant-index true --create-output-variant-md5 false --lenient false --add-output-sam-program-record true --add-output-vcf-command-line true --cloud-prefetch-buffer 40 --cloud-index-prefetch-buffer -1 --disable-bam-index-caching false --sites-only-vcf-output false --help false --version false --showHidden false --verbosity INFO --QUIET false --use-jdk-deflater false --use-jdk-inflater false --gcs-max-retries 20 --gcs-project-for-requester-pays  --disable-tool-default-read-filters false\",Version=\"4.1.7.0-104-g7b42ed9-SNAPSHOT\",Date=\"October 22, 2020 10:15:33 AM EDT\">\n+##GATKCommandLine=<ID=SelectVariants,CommandLine=\"SelectVariants  --output prod.chr20snippet.withRawMQ.g.vcf --variant gs://broad-gotc-prod-storage/pipeline/G97551/gvcfs/NWD242235.bcdd0ebc-17fa-402f-aa7e-ec97ae8669ca.g.vcf.gz --intervals chr20:20000000 --interval-padding 5000 --reference Homo_sapiens_assembly38.fasta  --invertSelect false --exclude-non-variants false --exclude-filtered false --preserve-alleles false --remove-unused-alternates false --restrict-alleles-to ALL --keep-original-ac false --keep-original-dp false --mendelian-violation false --invert-mendelian-violation false --mendelian-violation-qual-threshold 0.0 --select-random-fraction 0.0 --remove-fraction-genotypes 0.0 --fully-decode false --max-indel-size 2147483647 --min-indel-size 0 --max-filtered-genotypes 2147483647 --min-filtered-genotypes 0 --max-fraction-filtered-genotypes 1.0 --min-fraction-filtered-genotypes 0.0 --max-nocall-number 2147483647 --max-nocall-fraction 1.0 --set-filtered-gt-to-nocall false --allow-nonoverlapping-command-line-samples false --suppress-reference-path false --interval-set-rule UNION --interval-exclusion-padding 0 --interval-merging-rule ALL --read-validation-stringency SILENT --seconds-between-progress-updates 10.0 --disable-sequence-dictionary-validation false --create-output-bam-index true --create-output-bam-md5 false --create-output-variant-index true --create-output-variant-md5 false --lenient false --add-output-sam-program-record true --add-output-vcf-command-line true --cloud-prefetch-buffer 40 --cloud-index-prefetch-buffer -1 --disable-bam-index-caching false --sites-only-vcf-output false --help false --version false --showHidden false --verbosity INFO --QUIET false --use-jdk-deflater false --use-jdk-inflater false --gcs-max-retries 20 --gcs-project-for-requester-pays  --disable-tool-default-read-filters false\",Version=4.0.9.0-13-g0f6c729-SNAPSHOT,Date=\"October 4, 2018 10:52:55 AM EDT\">\n+##GVCFBlock0-1=minGQ=0(inclusive),maxGQ=1(exclusive)\n+##GVCFBlock1-2=minGQ=1(inclusive),maxGQ=2(exclusive)\n+##GVCFBlock10-11=minGQ=10(inclusive),maxGQ=11(exclusive)\n+##GVCFBlock11-12=minGQ=11(inclusive),maxGQ=12(exclusive)\n+##GVCFBlock12-13=minGQ=12(inclusive),maxGQ=13(exclusive)\n+##GVCFBlock13-14=minGQ=13(inclusive),maxGQ=14(exclusive)\n+##GVCFBlock14-15=minGQ=14(inclusive),maxGQ=15(exclusive)\n+##GVCFBlock15-16=minGQ=15(inclusive),maxGQ=16(exclusive)\n+##GVCFBlock16-17=minGQ=16(inclusive),maxGQ=17(exclusive)\n+##GVCFBlock17-18=minGQ=17(inclusive),maxGQ=18(exclusive)\n+##GVCFBlock18-19=minGQ=18(inclusive),maxGQ=19(exclusive)\n+##GVCFBlock19-20=minGQ=19(inclusive),maxGQ=20(exclusive)\n+##GVCFBlock2-3=minGQ=2(inclusive),maxGQ=3(exclusive)\n+##GVCFBlock20-21=minGQ=20(inclusive),maxGQ=21(exclusive)\n+##GVCFBlock21-22=minGQ=21(inclusive),maxGQ=22(exclusive)\n+##GVCFBlock22-23=minGQ=22(inclusive),maxGQ=23(exclusive)\n+##GVCFBlock23-24=minGQ=23(inclusive),maxGQ=24(exclusive)\n+##GVCFBlock24-25=minGQ=24(inclusive),maxGQ=25(exclusive)\n+##GVCFBlock25-26=minGQ=25(inclusive),maxGQ=26(exclusive)\n+##GVCFBlock26-27=minGQ=26(inclusive),maxGQ=27(exclusive)\n+##GVCFBlock27-28=minGQ=27(inclusive),maxGQ=28(exclusive)\n+##GVCFBlock28-29=minGQ=28(inclusive),maxGQ=29(exclusive)\n+##GVCFBlock29-30=minGQ=29(inclusive),maxGQ=30(exclusive)\n+##GVCFBlock3-4=minGQ=3(inclusive),maxGQ=4(exclusive)\n+##GVCFBlock30-31=minGQ=30(inclusive),maxGQ=31(exclusive)\n+##GVCFBlock31-32=minGQ=31(inclusive),maxGQ=32(exclusive)\n+##GVCFBlock32-33=minGQ=32(inclusive),maxGQ=33(exclusive)\n+##GVCFBlock33-34=minGQ=33(inclusive),maxGQ=34(exclusive)\n+##GVCFBlock34-35=minGQ=34(inclusive),maxGQ=35(exclusive)\n+##GVCFBlock35-36=minGQ=35(inclusive),maxGQ=36(exclusive)\n+##GVCFBlock36-37=minGQ=36(inclusive),maxGQ=37(exclusive)\n+##GVCFBlock37-38=minGQ=37(inclusive),maxGQ=38(exclusive)\n+##GVCFBlock38-39=minGQ=38(inclusive),maxGQ=39(exclusive)\n+##GVCFBlock39-40=minGQ=39(inclusive),maxGQ=40(exclusive)\n+##GVCFBlock4-5=minGQ=4(inclusive),maxGQ=5(exclusive)\n+##GVCFBlock40-41=minGQ=40(inclusive),maxGQ=41(exclusive)\n+##GVCFBlock41-42=minGQ=41(inclusive),maxGQ=42(exclusive)\n+##GVCFBlock42-43=minGQ=42(inclusive),maxGQ=43(exclusive)\n+##GVCFBlock43-44=minGQ=43(inclusive),maxGQ=44(exclusive)\n+##GVCFBlock44-45=minGQ=44(inclusive),maxGQ=45(exclusive)\n+##GVCFBlock45-46=minGQ=45(inclusive),maxGQ=46(exclusive)\n+##GVCFBlock46-47=minGQ=46(inclusive),maxGQ=47(exclusive)\n+##GVCFBlock47-48=minGQ=47(inclusive),maxGQ=48(exclusive)\n+##GVCFBlock48-49=minGQ=48(inclusive),maxGQ=49(exclusive)\n+##GVCFBlock49-50=minGQ=49(inclusive),maxGQ=50(exclusive)\n+##GVCFBlock5-6=minGQ=5(inclusive),maxGQ=6(exclusive)\n+##GVCFBlock50-51=minGQ=50(inclusive),maxGQ=51(exclusive)\n+##GVCFBlock51-52=minGQ=51(inclusive),maxGQ=52(exclusive)\n+##GVCFBlock52-53=minGQ=52(inclusive),maxGQ=53(exclusive)\n+##GVCFBlock53-54=minGQ=53(inclusive),maxGQ=54(exclusive)\n+##GVCFBlock54-55=minGQ=54(inclusive),maxGQ=55(exclusive)\n+##GVCFBlock55-56=minGQ=55(inclusive),maxGQ=56(exclusive)\n+##GVCFBlock56-57=minGQ=56(inclusive),maxGQ=57(exclusive)\n+##GVCFBlock57-58=minGQ=57(inclusive),maxGQ=58(exclusive)\n+##GVCFBlock58-59=minGQ=58(inclusive),maxGQ=59(exclusive)\n+##GVCFBlock59-60=minGQ=59(inclusive),maxGQ=60(exclusive)\n+##GVCFBlock6-7=minGQ=6(inclusive),maxGQ=7(exclusive)\n+##GVCFBlock60-70=minGQ=60(inclusive),maxGQ=70(exclusive)\n+##GVCFBlock7-8=minGQ=7(inclusive),maxGQ=8(exclusive)\n+##GVCFBlock70-80=minGQ=70(inclusive),maxGQ=80(exclusive)\n+##GVCFBlock8-9=minGQ=8(inclusive),maxGQ=9(exclusive)\n+##GVCFBlock80-90=minGQ=80(inclusive),maxGQ=90(exclusive)\n+##GVCFBlock9-10=minGQ=9(inclusive),maxGQ=10(exclusive)\n+##GVCFBlock90-99=minGQ=90(inclusive),maxGQ=99(exclusive)\n+##GVCFBlock99-2147483647=minGQ=99(inclusive),maxGQ=2147483647(exclusive)\n+##INFO=<ID=AC,Number=A,Type=Integer,Description=\"Allele count in genotypes, for each ALT allele, in the same order as listed\">\n+##INFO=<ID=AF,Number=A,Type=Float,Description=\"Allele Frequency, for each ALT allele, in the same order as listed\">\n+##INFO=<ID=AN,Number=1,Type=Integer,Description=\"Total number of alleles in called genotypes\">\n+##INFO=<ID=BaseQRankSum,Number=1,Type=Float,Description=\"Z-score from Wilcoxon rank sum test of Alt Vs. Ref base qualities\">\n+##INFO=<ID=ClippingRankSum,Number=1,Type=Float,Description=\"Z-score From Wilcoxon rank sum test of Alt vs. Ref number of hard clipped bases\">\n+##INFO=<ID=DP,Number=1,Type=Integer,Description=\"Approximate read depth; some reads may have been filtered\">\n+##INFO=<ID=DS,Number=0,Type=Flag,Description=\"Were any of the samples downsampled?\">\n+##INFO=<ID=END,Number=1,Type=Integer,Description=\"Stop position of the interval\">\n+##INFO=<ID=ExcessHet,Number=1,Type=Float,Description=\"Phred-scaled p-value for exact test of excess heterozygosity\">\n+##INFO=<ID=HaplotypeScore,Number=1,Type=Float,Description=\"Consistency of the site with at most two segregating haplotypes\">\n+##INFO=<ID=InbreedingCoeff,Number=1,Type=Float,Description=\"Inbreeding coefficient as estimated from the genotype likelihoods per-sample when compared against the Hardy-Weinberg expectation\">\n+##INFO=<ID=MLEAC,Number=A,Type=Integer,Description=\"Maximum likelihood expectation (MLE) for the allele counts (not necessarily the same as the AC), for each ALT allele, in the same order as listed\">\n+##INFO=<ID=MLEAF,Number=A,Type=Float,Description=\"Maximum likelihood expectation (MLE) for the allele frequency (not necessarily the same as the AF), for each ALT allele, in the same order as listed\">\n+##INFO=<ID=MQ,Number=1,Type=Float,Description=\"RMS Mapping Quality\">\n+##INFO=<ID=MQRankSum,Number=1,Type=Float,Description=\"Z-score From Wilcoxon rank sum test of Alt vs. Ref read mapping qualities\">\n+##INFO=<ID=RAW_MQ,Number=1,Type=Float,Description=\"Raw data for RMS Mapping Quality\">\n+##INFO=<ID=ReadPosRankSum,Number=1,Type=Float,Description=\"Z-score from Wilcoxon rank sum test of Alt vs. Ref read position bias\">\n+##contig=<ID=chr20,length=64444167>\n+##source=SelectVariants\n+#CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO\tFORMAT\tNWD242235\n+chr20\t19994995\t.\tG\t<NON_REF>\t.\t.\tEND=19995070\tGT:DP:GQ:MIN_DP:PL\t0/0:41:99:35:0,105,1177\n+chr20\t19995071\t.\tG\t<NON_REF>\t.\t.\tEND=19995071\tGT:DP:GQ:MIN_DP:PL\t0/0:35:80:35:0,80,1087\n+chr20\t19995072\t.\tA\t<NON_REF>\t.\t.\tEND=19995073\tGT:DP:GQ:MIN_DP:PL\t0/0:35:99:35:0,102,1530\n+chr20\t19995074\t.\tC\t<NON_REF>\t.\t.\tEND=19995079\tGT:DP:GQ:MIN_DP:PL\t0/0:36:93:35:0,93,1395\n+chr20\t19995080\t.\tG\t<NON_REF>\t.\t.\tEND=19995089\tGT:DP:GQ:MIN_DP:PL\t0/0:36:99:35:0,99,1485\n+chr20\t19995090\t.\tG\t<NON_REF>\t.\t.\tEND=19995101\tGT:DP:GQ:MIN_DP:PL\t0/0:35:90:35:0,90,1350\n+chr20\t19995102\t.\tC\t<NON_REF>\t.\t.\tEND=19995114\tGT:DP:GQ:MIN_DP:PL\t0/0:37:99:36:0,102,1530\n+chr20\t19995115\t.\tA\t<NON_REF>\t.\t.\tEND=19995115\tGT:DP:GQ:MIN_DP:PL\t0/0:40:96:40:0,96,1261\n+chr20\t19995116\t.\tT\t<NON_REF>\t.\t.\tEND=19995138\tGT:DP:GQ:MIN_DP:PL\t0/0:37:99:34:0,102,1122\n+chr20\t19995139\t.\tG\t<NON_REF>\t.\t.\tEND=19995139\tGT:DP:GQ:MIN_DP:PL\t0/0:35:81:35:0,81,1117\n+chr20\t19995140\t.\tG\t<NON_REF>\t.\t.\tEND=19995157\tGT:DP:GQ:MIN_DP:PL\t0/0:38:99:34:0,102,1101\n+chr20\t19995158\t.\tC\t<NON_REF>\t.\t.\tEND=19995158\tGT:DP:GQ:MIN_DP:PL\t0/0:40:96:40:0,96,1281\n+chr20\t19995159\t.\tT\t<NON_REF>\t.\t.\tEND=19995168\tGT:DP:GQ:MIN_DP:PL\t0/0:41:99:40:0,105,1575\n+chr20\t19995169\t.\tG\t<NON_REF>\t.\t.\tEND=19995170\tGT:DP:GQ:MIN_DP:PL\t0/0:40:96:40:0,96,1440\n+chr20\t19995171\t.\tC\t<NON_REF>\t.\t.\tEND=19995171\tGT:DP:GQ:MIN_DP:PL\t0/0:40:99:40:0,99,1485\n+chr20\t19995172\t.\tC\t<NON_REF>\t.\t.\tEND=19995172\tGT:DP:GQ:MIN_DP:PL\t0/0:38:96:38:0,96,1440\n+chr20\t19995173\t.\tC\t<NON_REF>\t.\t.\tEND=19995174\tGT:DP:GQ:MIN_DP:PL\t0/0:39:87:39:0,87,1305\n+chr20\t19995175\t.\tA\t<NON_REF>\t.\t.\tEND=19995189\tGT:DP:GQ:MIN_DP:PL\t0/0:34:90:33:0,90,1350\n+chr20\t19995190\t.\tG\t<NON_REF>\t.\t.\tEND=19995190\tGT:DP:GQ:MIN_DP:PL\t0/0:32:72:32:0,72,1033\n+chr20\t19995191\t.\tC\t<NON_REF>\t.\t.\tEND=19995191\tGT:DP:GQ:MIN_DP:PL\t0/0:33:96:33:0,96,1440\n+chr20\t19995192\t.\tA\t<NON_REF>\t.\t.\tEND=19995195\tGT:DP:GQ:MIN_DP:PL\t0/0:34:99:33:0,99,1117\n+chr20\t19995196\t.\tA\t<NON_REF>\t.\t.\tEND=19995196\tGT:DP:GQ:MIN_DP:PL\t0/0:34:68:34:0,68,1113\n+chr20\t19995197\t.\tA\t<NON_REF>\t.\t.\tEND=19995212\tGT:DP:GQ:MIN_DP:PL\t0/0:35:99:33:0,99,1047\n+chr20\t19995213\t.\tT\t<NON_REF>\t.\t.\tEND=19995213\tGT:DP:GQ:MIN_DP:PL\t0/0:36:83:36:0,83,1132\n+chr20\t19995214\t.\tA\t<NON_REF>\t.\t.\tEND=19995218\tGT:DP:GQ:MIN_DP:PL\t0/0:36:99:35:0,102,1197\n+chr20\t19995219\t.\tC\t<NON_REF>\t.\t.\tEND=19995219\tGT:DP:GQ:MIN_DP:PL\t0/0:37:62:37:0,62,1097\n+chr20\t19995220\t.\tT\t<NON_REF>\t.\t.\tEND=19995228\tGT:DP:GQ:MIN_DP:PL\t0/0:37:99:34:0,102,1152\n+chr20\t19995229\t.\tC\t<NON_REF>\t.\t.\tEND=19995229\tGT:DP:GQ:MIN_DP:PL\t0/0:38:74:38:0,74,1080\n+chr20\t19995230\t.\tA\t<NON_REF>\t.\t.\tEND=19995231\tGT:DP:GQ:MIN_DP:PL\t0/0:38:99:35:0,105,1146\n+chr20\t19995232\t.\tG\t<NON_REF>\t.\t.\tEND=19995232\tGT:DP:GQ:MIN_DP:PL\t0/0:34:43:34:0,43,1013\n+chr20\t19995233\t.\tA\t<NON_REF>\t.\t.\tEND=19995234\tGT:DP:GQ:MIN_DP:PL\t0/0:37:99:37:0,102,1530\n+chr20\t19995235\t.\tT\t<NON_REF>\t.\t.\tEND=19995235\tGT:DP:GQ:MIN_DP:PL\t0/0:37:86:37:0,86,1176\n+chr20\t19995236\t.\tA\t<NON_REF>\t.\t.\tEND=19995236\tGT:DP:GQ:MIN_DP:PL\t0/0:37:99:37:0,99,1485\n+chr20\t19995237\t.\tA\t<NON_REF>\t.\t.\tEND=19995241\tGT:DP:GQ:MIN_DP:PL\t0/0:35:93:34:0,93,1395\n+chr20\t19995242\t.\tC\t<NON_REF>\t.\t.\tEND=19995243\tGT:DP:GQ:MIN_DP:PL\t0/0:34:67:31:0,67,978\n+chr20\t19995244\t.\tA\t<NON_REF>\t.\t.\tEND=19995244\tGT:DP:GQ:MIN_DP:PL\t0/0:34:90:34:0,90,1350\n+chr20\t19995245\t.\tG\t<NON_REF>\t.\t.\tEND=19995248\tGT:DP:GQ:MIN_DP:PL\t0/0:34:87:31:0,87,1305\n+chr20\t19995249\t.\tC\t<NON_REF>\t.\t.\tEND=19995249\tGT:DP:GQ:MIN_DP:PL\t0/0:35:80:35:0,80,1015\n+chr20\t19995250\t.\tT\t<NON_REF>\t.\t.\tEND=19995250\tGT:DP:GQ:MIN_DP:PL\t0/0:36:87:36:0,87,1305\n+chr20\t19995251\t.\tG\t<NON_REF>\t.\t.\tEND=19995251\tGT:DP:GQ:MIN_DP:PL\t0/0:33:50:33:0,50,968\n+chr20\t19995252\t.\tT\t<NON_REF>\t.\t.\tEND=19995253\tGT:DP:GQ:MIN_DP:PL\t0/0:36:81:34:0,81,1215\n+chr20\t19995254\t.\tT\t<NON_REF>\t.\t.\tEND=19995256\tGT:DP:GQ:MIN_DP:PL\t0/0:32:78:32:0,78,1170\n+chr20\t19995257\t.\tT\t<NON_REF>\t.\t.\tEND=19995260\tGT:DP:GQ:MIN_DP:PL\t0/0:33:81:32:0,81,1215\n+chr20\t19995261\t.\tT\t<NON_REF>\t.\t.\tEND=19995261\tGT:DP:GQ:MIN_DP:PL\t0/0:33:50:33:0,50,978\n+chr20\t19995262\t.\tA\t<NON_REF>\t.\t.\tEND=19995262\tGT:DP:GQ:MIN_DP:PL\t0/0:34:53:34:0,53,1043\n+chr20\t19995263\t.\tA\t<NON_REF>\t.\t.\tEND=19995263\tGT:DP:GQ:MIN_DP:PL\t0/0:33:65:33:0,65,1068\n+chr20\t19995264\t.\tA\t<NON_REF>\t.\t.\tEND=19995265\tGT:DP:GQ:MIN_DP:PL\t0/0:32:84:31:0,84,1260\n+chr20\t19995266\t.\tA\t<NON_REF>\t.\t.\tEND=19995276\tGT:DP:GQ:MIN_DP:PL\t0/0:37:90:33:0,90,1350\n+chr20\t19995277\t.\tA\t<NON_REF>\t.\t.\tEND=19995277\tGT:DP:GQ:MIN_DP:PL\t0/0:36:74:36:0,74,1152\n+chr20\t19995278\t.\tA\t<NON_REF>\t.\t.\tEND=19995278\tGT:DP:GQ:MIN_DP:PL\t0/0:36:96:36:0,96,1440\n+chr20\t19995279\t.\tC\t<NON_REF>\t.\t.\tEND=19995279\tGT:DP:GQ:MIN_DP:PL\t0/0:33:64:33:0,64,1048\n+chr20\t19995280\t.\tA\t<NON_REF>\t.\t.\tEND=19995280\tGT:DP:GQ:MIN_DP:PL\t0/0:34:96:34:0,96,1440\n+chr20\t19995281\t.\tA\t<NON_REF>\t.\t.\tEND=19995281\tGT:DP:GQ:MIN_DP:PL\t0/0:37:72:37:0,72,1158\n+chr20\t19995282\t.\tA\t<NON_REF>\t.\t.\tEND=19995283\tGT:DP:GQ:MIN_DP:PL\t0/0:38:99:37:0,99,1485\n+chr20\t19995284\t.\tC\t<NON_REF>\t.\t.\tEND=19995284\tGT:DP:GQ:MIN_DP:PL\t0/0:34:77:34:0,77,1052\n+chr20\t19995285\t.\tA\t<NON_REF>\t.\t.\tEND=19995285\tGT:DP:GQ:MIN_DP:PL\t0/0:36:84:36:0,84,1152\n+chr20\t19995286\t.\tC\t<NON_REF>\t.\t.\tEND=19995286\tGT:DP:GQ:MIN_DP:PL\t0/0:33:74:33:0,74,997\n+chr20\t19995287\t.\tA\t<NON_REF>\t.\t.\tEND=19995287\tGT:DP:GQ:MIN_DP:PL\t0/0:35:91:35:0,91,1168\n+chr20\t19995288\t.\tT\t<NON_REF>\t.\t.\tEND=19995288\tGT:DP:GQ:MIN_DP:PL\t0/0:35:70:35:0,70,1107\n+chr20\t19995289\t.\tT\t<NON_REF>\t.\t.\tEND=19995289\tGT:DP:GQ:MIN_DP:PL\t0/0:34:93:34:0,93,1395\n+chr20\t19995290\t.\tC\t<NON_REF>\t.\t.\tEND=19995290\tGT:DP:GQ:MIN_DP:PL\t0/0:33:64:33:0,64,965\n+chr20\t19995291\t.\tA\t<NON_REF>\t.\t.\tEND=19995300\tGT:DP:GQ:MIN_DP:PL\t0/0:35:90:34:0,90,1350\n+chr20\t19995301\t.\tG\t<NON_REF>\t.\t.\tEND=19995301\tGT:DP:GQ:MIN_DP:PL\t0/0:35:87:35:0,87,1305\n+chr20\t19995302\t.\tG\t<NON_REF>\t.\t.\tEND=19995302\tGT:DP:GQ:MIN_DP:PL\t0/0:34:77:34:0,77,1092\n+chr20\t19995303\t.\tA\t<NON_REF>\t.\t.\tEND=19995306\tGT:DP:GQ:MIN_DP:PL\t0/0:34:84:32:0,84,1260\n+chr20\t19995307\t.\tT\t<NON_REF>\t.\t.\tEND=19995308\tGT:DP:GQ:MIN_DP:PL\t0/0:35:90:35:0,90,1350\n+chr20\t19995309\t.\tG\t<NON_REF>\t.\t.\tEND=19995309\tGT:DP:GQ:MIN_DP:PL\t0/0:34:88:34:0,88,1093\n+chr20\t19995310\t.\tG\t<NON_REF>\t.\t.\tEND=19995311\tGT:DP:GQ:MIN_DP:PL\t0/0:33:90:33:0,90,1350\n+chr20\t19995312\t.\tA\t<NON_REF>\t.\t.\tEND=19995314\tGT:DP:GQ:MIN_DP:PL\t0/0:31:84:28:0,84,973\n+chr20\t19995315\t.\tC\t<NON_REF>\t.\t.\tEND=19995315\tGT:DP:GQ:MIN_DP:PL\t0/0:29:58:29:0,58,890\n+chr20\t19995316\t.\tA\t<NON_REF>\t.\t.\tEND=19995332\tGT:DP:GQ:MIN_DP:PL\t0/0:32:90:31:0,90,1007\n+chr20\t19995333\t.\tA\t<NON_REF>\t.\t.\tEND=19995333\tGT:DP:GQ:MIN_DP:PL\t0/0:32:87:32:0,87,1305\n+chr20\t19995334\t.\tA\t<NON_REF>\t.\t.\tEND=19995345\tGT:DP:GQ:MIN_DP:PL\t0/0:33:90:32:0,90,1082\n+chr20\t19995346\t.\tC\t<NON_REF>\t.\t.\tEND=19995346\tGT:DP:GQ:MIN_DP:PL\t0/0:34:77:34:0,77,1102\n+chr20\t19995347\t.\tT\t<NON_REF>\t.\t.\tEND=19995348\tGT:DP:GQ:MIN_DP:PL\t0/0:34:96:34:0,96,1440\n+chr20\t19995349\t.\tT\t<NON_REF>\t.\t.\tEND=19995355\tGT:DP:GQ:MIN_DP:PL\t0/0:34:99:34:0,99,1172\n+chr20\t19995356\t.\tG\t<NON_REF>\t.\t.\tEND=19995356\tGT:DP:GQ:MIN_DP:PL\t0/0:32:96:32:0,96,1092\n+chr20\t19995357\t.\tT\t<NON_REF>\t.\t.\tEND=19995387\tGT:DP:GQ:MIN_DP:PL\t0/0:35:99:33:0,99,1147\n+chr20\t19995388\t.\tG\t<NON_REF>\t.\t.\tEND=19995388\tGT:DP:GQ:MIN_DP:PL\t0/0:38:79:38:0,79,1201\n+chr20\t19995389\t.\tA\t<NON_REF>\t.\t.\tEND=19995401\tGT:DP:GQ:MIN_DP:PL\t0/0:38:99:37:0,102,1266\n+chr20\t19995402\t.\tC\t<NON_REF>\t.\t.\tEND=19995402\tGT:DP:GQ:MIN_DP:PL\t0/0:38:90:38:0,90,1242\n+chr20\t19995403\t.\tT\t<NON_REF>\t.\t.\tEND=19995412\tGT:DP:GQ:MIN_DP:PL\t0/0:41:99:38:0,102,1530\n+chr20\t19995413\t.\tA\t<NON_REF>\t.\t.\tEND=19995413\tGT:DP:GQ:MIN_DP:PL\t0/0:40:96:40:0,96,1291\n+chr20\t19995414\t.\tT\t<NON_REF>\t.\t.\tEND=19995424\tGT:DP:GQ:MIN_DP:PL\t0/0:37:99:36:0,100,1211\n+chr20\t19995425\t.\tC\t<NON_REF>\t.\t.\tEND=19995426\tGT:DP:GQ:MIN_DP:PL\t0/0:38:83:36:0,83,1132\n+chr20\t19995427\t.\tA\t<NON_REF>\t.\t.\tEND=19995479\tGT:DP:GQ:MIN_DP:PL\t0/0:39:99:35:0,102,1126\n+chr20\t19995480\t.\tA\t<NON_REF>\t.\t.\tEND=19995480\tGT:DP:GQ:MIN_DP:PL\t0/0:37:96:37:0,96,1440\n+chr20\t19995481\t.\tG\t<NON_REF>\t.\t.\tEND=19995483\tGT:DP:GQ:MIN_DP:PL\t0/0:38:99:38:0,99,1485\n+chr20\t19995484\t.\tA\t<NON_REF>\t.\t.\tEND=19995487\tGT:DP:GQ:MIN_DP:PL\t0/0:37:96:36:0,96,1440\n+chr20\t19995488\t.\tT\t<NON_REF>\t.\t.\tEND=19995489\tGT:DP:GQ:MIN_DP:PL\t0/0:38:99:37:0,99,1485\n+chr20\t19995490\t.\tA\t<NON_REF>\t.\t.\tEND=19995502\tGT:DP:GQ:MIN_DP:PL\t0/0:34:93:33:0,93,1395\n+chr20\t19995503\t.\tG\t<NON_REF>\t.\t.\tEND=19995505\tGT:DP:GQ:MIN_DP:PL\t0/0:34:99:34:0,99,1485\n+chr20\t19995506\t.\tC\t<NON_REF>\t.\t.\tEND=19995506\tGT:DP:GQ:MIN_DP:PL\t0/0:34:68:34:0,68,1092\n+chr20\t19995507\t.\tC\t<NON_REF>\t.\t.\tEND=19995515\tGT:DP:GQ:MIN_DP:PL\t0/0:36:99:33:0,99,1117\n+chr20\t19995516\t.\tT\t<NON_REF>\t.\t.\tEND=19995516\tGT:DP:GQ:MIN_DP:PL\t0/0:36:94:36:0,94,1192\n+chr20\t19995517\t.\tG\t<NON_REF>\t.\t.\tEND=19995518\tGT:DP:GQ:MIN_DP:PL\t0/0:36:99:36:0,108,1221\n+chr20\t19995519\t.\tT\t<NON_REF>\t.\t.\tEND=19995519\tGT:DP:GQ:MIN_DP:PL\t0/0:36:94:36:0,94,1172\n+chr20\t19995520\t.\tA\t<NON_REF>\t.\t.\tEND=19995524\tGT:DP:GQ:MIN_DP:PL\t0/0:36:99:35:0,99,1232\n+chr20\t19995525\t.\tA\t<NON_REF>\t.\t.\tEND=19995544\tGT:DP:GQ:MIN_DP:PL\t0/0:35:90:31:0,90,1037\n+chr20\t19995545\t.\tT\t<NON_REF>\t.\t.\tEND=19995550\tGT:DP:GQ:MIN_DP:PL\t0/0:34:84:33:0,84,1260\n+chr20\t19995551\t.\tT\t<NON_REF>\t.\t.\tEND=19995560\tGT:DP:GQ:MIN_DP:PL\t0/0:35:90:32:0,90,1350\n+chr20\t19995561\t.\tT\t<NON_REF>\t.\t.\tEND=19995568\tGT:DP:GQ:MIN_DP:PL\t0/0:32:84:30:0,84,1260\n+chr20\t19995569\t.\tC\t<NON_REF>\t.\t.\tEND=19995569\tGT:DP:GQ:MIN_DP:PL\t0/0:32:72:32:0,72,1023\n+chr20\t19995570\t.\tC\t<NON_REF>\t.\t.\tEND=19995572\tGT:DP:GQ:MIN_DP:PL\t0/0:31:87:31:0,87,1305\n+chr20\t19995573\t.\tT\t<NON_REF>\t.\t.\tEND=19995575\tGT:DP:GQ:MIN_DP:PL\t0/0:33:93:33:0,93,1395\n+chr20\t19995576\t.\tA\t<NON_REF>\t.\t.\tEND=19995576\tGT:DP:GQ:MIN_DP:PL\t0/0:33:87:33:0,87,1305\n+chr20\t19995577\t.\tC\t<NON_REF>\t.\t.\tEND=19995577\tGT:DP:GQ:MIN_DP:PL\t0/0:32:90:32:0,90,1350\n+chr20\t19995578\t.\tA\t<NON_REF>\t.\t.\tEND=19995590\tGT:DP:GQ:MIN_DP:PL\t0/0:32:84:30:0,84,1078\n+chr20\t19995591\t.\tA\t<NON_REF>\t.\t.\tEND=19995591\tGT:DP:GQ:MIN_DP:PL\t0/0:34:90:34:0,90,1350\n+chr20\t19995592\t.\tT\t<NON_REF>\t.\t.\tEND=19995592\tGT:DP:GQ:MIN_DP:PL\t0/0:34:88:34:0,88,1113\n+chr20\t19995593\t.\tA\t<NON_REF>\t.\t.\tEND=19995593\tGT:DP:GQ:MIN_DP:PL\t0/0:34:90:34:0,90,1350\n+chr20\t19995594\t.\tA\t<NON_REF>\t.\t.\tEND=19995609\tGT:DP:GQ:MIN_DP:PL\t0/0:32:84:30:0,84,1260\n+chr20\t19995610\t.\tT\t<NON_REF>\t.\t.\tEND=19995610\tGT:DP:GQ:MIN_DP:PL\t0/0:31:90:31:0,90,1350\n+chr20\t19995611\t.\tA\t<NON_REF>\t.\t.\tEND=19995616\tGT:DP:GQ:MIN_DP:PL\t0/0:31:84:31:0,84,1260\n+chr20\t19995617\t.\tT\t<NON_REF>\t.\t.\tEND=19995623\tGT:DP:GQ:MIN_DP:PL\t0/0:33:90:32:0,90,1350\n+chr20\t19995624\t.\tA\t<NON_REF>\t.\t.\tEND=19995624\tGT:DP:GQ:MIN_DP:PL\t0/0:34:67:34:0,67,1072\n+chr20\t19995625\t.\tA\t<NON_REF>\t.\t.\tEND=19995631\tGT:DP:GQ:MIN_DP:PL\t0/0:33:96:33:0,96,1440\n+chr20\t19995632\t.\tT\t<NON_REF>\t.\t.\tEND=19995641\tGT:DP:GQ:MIN_DP:PL\t0/0:35:99:34:0,99,1132\n+chr20\t19995642\t.\tA\t<NON_REF>\t.\t.\tEND=19995651\tGT:DP:GQ:MIN_DP:PL\t0/0:35:93:34:0,93,1395\n+chr20\t19995652\t.\tC\t<NON_REF>\t.\t.\tEND=19995662\tGT:DP:GQ:MIN_DP:PL\t0/0:37:99:35:0,99,1246\n+chr20\t19995663\t.\tG\t<NON_REF>\t.\t.\tEND=19995663\tGT:DP:GQ:MIN_DP:PL\t0/0:37:86:37:0,86,1176\n+chr20\t19995664\t.\tA\t<NON_REF>\t.\t.\tEND=19995789\tGT:DP:GQ:MIN_DP:PL\t0/0:43:99:34:0,102,1131\n+chr20\t19995790\t.\tA\t<NON_REF>\t.\t.\tEND=19995790\tGT:DP:GQ:MIN_DP:PL\t0/0:45:86:45:0,86,1425\n+chr20\t19995791\t.\tA\t<NON_REF>\t.\t.\tEND=19995826\tGT:DP:GQ:MIN_DP:PL\t0/0:42:99:39:0,105,1351\n+chr20\t19995827\t.\tA\t<NON_REF>\t.\t.\tEND=19995827\tGT:DP:GQ:MIN_DP:PL\t0/0:41:89:41:0,89,1336\n+chr20\t19995828\t.\tA\t<NON_REF>\t.\t.\tEND=19995831\tGT:DP:GQ:MIN_DP:PL\t0/0:40:99:39:0,102,1530\n+chr20\t19995832\t.\tA\t<NON_REF>\t.\t.\tEND=19995832\tGT:DP:GQ:MIN_DP:PL\t0/0:38:80:38:0,80,1201\n+chr20\t19995833\t.\tA\t<NON_REF>\t.\t.\tEND=19995837\tGT:DP:GQ:MIN_DP:PL\t0/0:39:99:37:0,99,1485\n+chr20\t19995838\t.\tT\t<NON_REF>\t.\t.\tEND=19995842\tGT:DP:GQ:MIN_DP:PL\t0/0:36:91:34:0,91,1148\n+chr20\t19995843\t.\tA\t<NON_REF>\t.\t.\tEND=19995843\tGT:DP:GQ:MIN_DP:PL\t0/0:36:84:36:0,84,1162\n+chr20\t19995844\t.\tT\t<NON_REF>\t.\t.\tEND=19995848\tGT:DP:GQ:MIN_DP:PL\t0/0:35:99:34:0,99,1485\n+chr20\t19995849\t.\tG\t<NON_REF>\t.\t.\tEND=19995851\tGT:DP:GQ:MIN_DP:PL\t0/0:32:93:31:0,93,1058\n+chr20\t19995852\t.\tA\t<NON_REF>\t.\t.\tEND=19995852\tGT:DP:GQ:MIN_DP:PL\t0/0:33:87:33:0,87,1305\n+chr20\t19995853\t.\tG\t<NON_REF>\t.\t.\tEND=19995853\tGT:DP:GQ:MIN_DP:PL\t0/0:34:77:34:0,77,1072\n+chr20\t19995854\t.\tA\t<NON_REF>\t.\t.\tEND=19995863\tGT:DP:GQ:MIN_DP:PL\t0/0:34:90:32:0,90,1350\n+chr20\t19995864\t.\tT\t<NON_REF>\t.\t.\tEND=19995869\tGT:DP:GQ:MIN_DP:PL\t0/0:32:84:32:0,84,1260\n+chr20\t19995870\t.\tA\t<NON_REF>\t.\t.\tEND=19995889\tGT:DP:GQ:MIN_DP:PL\t0/0:34:90:31:0,90,1350\n+chr20\t19995890\t.\tG\t<NON_REF>\t.\t.\tEND=19995891\tGT:DP:GQ:MIN_DP:PL\t0/0:35:99:35:0,99,1485\n+chr20\t19995892\t.\tG\t<NON_REF>\t.\t.\tEND=19995893\tGT:DP:GQ:MIN_DP:PL\t0/0:35:96:35:0,96,1440\n+chr20\t19995894\t.\tT\t<NON_REF>\t.\t.\tEND=19995927\tGT:DP:GQ:MIN_DP:PL\t0/0:35:99:33:0,99,1101\n+chr20\t19995928\t.\tC\t<NON_REF>\t.\t.\tEND=19995936\tGT:DP:GQ:MIN_DP:PL\t0/0:36:90:33:0,90,1350\n+chr20\t19995937\t.\tA\t<NON_REF>\t.\t.\tEND=19995937\tGT:DP:GQ:MIN_DP:PL\t0/0:33:75:33:0,75,1088\n+chr20\t19995938\t.\tC\t<NON_REF>\t.\t.\tEND=19995939\tGT:DP:GQ:MIN_DP:PL\t0/0:32:90:32:0,90,1350\n+chr20\t19995940\t.\tT\t<NON_REF>\t.\t.\tEND=19995999\tGT:DP:GQ:MIN_DP:PL\t0/0:41:99:34:0,99,1207"
  },
  {
    "sha": "aa6896e19097302d5f0ff1fc200a9a998598c36b",
    "filename": "src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/ReblockGVCF/chr20.shard0.g.vcf.idx",
    "status": "added",
    "additions": 0,
    "deletions": 0,
    "changes": 0,
    "blob_url": "https://github.com/broadinstitute/gatk/blob/af6c823e27e1ecd437a3b045f3dc1b519c855bcf/src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/ReblockGVCF/chr20.shard0.g.vcf.idx",
    "raw_url": "https://github.com/broadinstitute/gatk/raw/af6c823e27e1ecd437a3b045f3dc1b519c855bcf/src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/ReblockGVCF/chr20.shard0.g.vcf.idx",
    "contents_url": "https://api.github.com/repos/broadinstitute/gatk/contents/src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/ReblockGVCF/chr20.shard0.g.vcf.idx?ref=af6c823e27e1ecd437a3b045f3dc1b519c855bcf"
  },
  {
    "sha": "c49cc4b424ba6953270664fb7dda6d0f69f1c176",
    "filename": "src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/ReblockGVCF/chr20.shard1.g.vcf",
    "status": "added",
    "additions": 212,
    "deletions": 0,
    "changes": 212,
    "blob_url": "https://github.com/broadinstitute/gatk/blob/af6c823e27e1ecd437a3b045f3dc1b519c855bcf/src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/ReblockGVCF/chr20.shard1.g.vcf",
    "raw_url": "https://github.com/broadinstitute/gatk/raw/af6c823e27e1ecd437a3b045f3dc1b519c855bcf/src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/ReblockGVCF/chr20.shard1.g.vcf",
    "contents_url": "https://api.github.com/repos/broadinstitute/gatk/contents/src/test/resources/org/broadinstitute/hellbender/tools/walkers/variantutils/ReblockGVCF/chr20.shard1.g.vcf?ref=af6c823e27e1ecd437a3b045f3dc1b519c855bcf",
    "patch": "@@ -0,0 +1,212 @@\n+##fileformat=VCFv4.2\n+##ALT=<ID=NON_REF,Description=\"Represents any possible alternative allele at this location\">\n+##FILTER=<ID=LowQual,Description=\"Low quality\">\n+##FORMAT=<ID=AD,Number=R,Type=Integer,Description=\"Allelic depths for the ref and alt alleles in the order listed\">\n+##FORMAT=<ID=DP,Number=1,Type=Integer,Description=\"Approximate read depth (reads with MQ=255 or with bad mates are filtered)\">\n+##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=\"Genotype Quality\">\n+##FORMAT=<ID=GT,Number=1,Type=String,Description=\"Genotype\">\n+##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=\"Minimum DP observed within the GVCF block\">\n+##FORMAT=<ID=PGT,Number=1,Type=String,Description=\"Physical phasing haplotype information, describing how the alternate alleles are phased in relation to one another\">\n+##FORMAT=<ID=PID,Number=1,Type=String,Description=\"Physical phasing ID information, where each unique ID within a given sample (but not across samples) connects records within a phasing group\">\n+##FORMAT=<ID=PL,Number=G,Type=Integer,Description=\"Normalized, Phred-scaled likelihoods for genotypes as defined in the VCF specification\">\n+##FORMAT=<ID=SB,Number=4,Type=Integer,Description=\"Per-sample component statistics which comprise the Fisher's Exact Test to detect strand bias.\">\n+##GATKCommandLine.HaplotypeCaller=<ID=HaplotypeCaller,Version=3.5-0-g36282e4,Date=\"Sun Sep 03 19:04:52 UTC 2017\",Epoch=1504465492413,CommandLineOptions=\"analysis_type=HaplotypeCaller input_file=[/cromwell_root/broad-gotc-prod-cromwell-execution/PairedEndSingleSampleWorkflow/36d6043d-5e15-4a26-9bd0-e28d44d4b052/call-GatherBamFiles/NWD242235.bam] showFullBamList=false read_buffer_size=null phone_home=AWS gatk_key=null tag=NA read_filter=[OverclippedRead] disable_read_filter=[] intervals=[/cromwell_root/broad-gotc-prod-cromwell-execution/PairedEndSingleSampleWorkflow/36d6043d-5e15-4a26-9bd0-e28d44d4b052/call-ScatterIntervalList/glob-cb4648beeaff920acb03de7603c06f98/23scattered.interval_list] excludeIntervals=null interval_set_rule=UNION interval_merging=ALL interval_padding=0 reference_sequence=/cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.fasta nonDeterministicRandomSeed=false disableDithering=false maxRuntime=-1 maxRuntimeUnits=MINUTES downsampling_type=BY_SAMPLE downsample_to_fraction=null downsample_to_coverage=500 baq=OFF baqGapOpenPenalty=40.0 refactor_NDN_cigar_string=false fix_misencoded_quality_scores=false allow_potentially_misencoded_quality_scores=false useOriginalQualities=false defaultBaseQualities=-1 performanceLog=null BQSR=null quantize_quals=0 static_quantized_quals=null round_down_quantized=false disable_indel_quals=false emit_original_quals=false preserve_qscores_less_than=6 globalQScorePrior=-1.0 validation_strictness=SILENT remove_program_records=false keep_program_records=false sample_rename_mapping_file=null unsafe=null disable_auto_index_creation_and_locking_when_reading_rods=false no_cmdline_in_header=false sites_only=false never_trim_vcf_format_field=false bcf=false bam_compression=null simplifyBAM=false disable_bam_indexing=false generate_md5=false num_threads=1 num_cpu_threads_per_data_thread=1 num_io_threads=0 monitorThreadEfficiency=false num_bam_file_handles=null read_group_black_list=null pedigree=[] pedigreeString=[] pedigreeValidationType=STRICT allow_intervals_with_unindexed_bam=false generateShadowBCF=false variant_index_type=LINEAR variant_index_parameter=128000 reference_window_stop=0 logging_level=INFO log_to_file=null help=false version=false likelihoodCalculationEngine=PairHMM heterogeneousKmerSizeResolution=COMBO_MIN dbsnp=(RodBinding name= source=UNBOUND) dontTrimActiveRegions=false maxDiscARExtension=25 maxGGAARExtension=300 paddingAroundIndels=150 paddingAroundSNPs=20 comp=[] annotation=[StrandBiasBySample] excludeAnnotation=[ChromosomeCounts, FisherStrand, StrandOddsRatio, QualByDepth] group=[Standard, StandardHCAnnotation] debug=false useFilteredReadsForAnnotations=false emitRefConfidence=GVCF bamOutput=null bamWriterType=CALLED_HAPLOTYPES disableOptimizations=false annotateNDA=false heterozygosity=0.001 indel_heterozygosity=1.25E-4 standard_min_confidence_threshold_for_calling=-0.0 standard_min_confidence_threshold_for_emitting=-0.0 max_alternate_alleles=3 input_prior=[] sample_ploidy=2 genotyping_mode=DISCOVERY alleles=(RodBinding name= source=UNBOUND) contamination_fraction_to_filter=0.004839373333333333 contamination_fraction_per_sample_file=null p_nonref_model=null exactcallslog=null output_mode=EMIT_VARIANTS_ONLY allSitePLs=true gcpHMM=10 pair_hmm_implementation=VECTOR_LOGLESS_CACHING pair_hmm_sub_implementation=ENABLE_ALL always_load_vector_logless_PairHMM_lib=false phredScaledGlobalReadMismappingRate=45 noFpga=false sample_name=null kmerSize=[10, 25] dontIncreaseKmerSizesForCycles=false allowNonUniqueKmersInRef=false numPruningSamples=1 recoverDanglingHeads=false doNotRecoverDanglingBranches=false minDanglingBranchLength=4 consensus=false maxNumHaplotypesInPopulation=128 errorCorrectKmers=false minPruning=2 debugGraphTransformations=false allowCyclesInKmerGraphToGeneratePaths=false graphOutput=null kmerLengthForReadErrorCorrection=25 minObservationsForKmerToBeSolid=20 GVCFGQBands=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 70, 80, 90, 99] indelSizeToEliminateInRefModel=10 min_base_quality_score=10 includeUmappedReads=false useAllelesTrigger=false doNotRunPhysicalPhasing=false keepRG=null justDetermineActiveRegions=false dontGenotype=false dontUseSoftClippedBases=false captureAssemblyFailureBAM=false errorCorrectReads=false pcr_indel_model=CONSERVATIVE maxReadsInRegionPerSample=10000 minReadsPerAlignmentStart=10 mergeVariantsViaLD=false activityProfileOut=null activeRegionOut=null activeRegionIn=null activeRegionExtension=null forceActive=false activeRegionMaxSize=null bandPassSigma=null maxProbPropagationDistance=50 activeProbabilityThreshold=0.002 filter_is_too_short_value=30 do_not_require_softclips_both_ends=false min_mapping_quality_score=20 filter_reads_with_N_cigar=false filter_mismatching_base_and_quals=false filter_bases_not_stored=false\">\n+##GATKCommandLine=<ID=SelectVariants,CommandLine=\"SelectVariants  --output chr20.shard1.g.vcf --variant prod.chr20snippet.withRawMQ.g.vcf --intervals chr20:19996000-19996999  --invertSelect false --exclude-non-variants false --exclude-filtered false --preserve-alleles false --remove-unused-alternates false --restrict-alleles-to ALL --keep-original-ac false --keep-original-dp false --mendelian-violation false --invert-mendelian-violation false --mendelian-violation-qual-threshold 0.0 --select-random-fraction 0.0 --remove-fraction-genotypes 0.0 --fully-decode false --max-indel-size 2147483647 --min-indel-size 0 --max-filtered-genotypes 2147483647 --min-filtered-genotypes 0 --max-fraction-filtered-genotypes 1.0 --min-fraction-filtered-genotypes 0.0 --max-nocall-number 2147483647 --max-nocall-fraction 1.0 --set-filtered-gt-to-nocall false --allow-nonoverlapping-command-line-samples false --suppress-reference-path false --genomicsdb-use-vcf-codec false --interval-set-rule UNION --interval-padding 0 --interval-exclusion-padding 0 --interval-merging-rule ALL --read-validation-stringency SILENT --seconds-between-progress-updates 10.0 --disable-sequence-dictionary-validation false --create-output-bam-index true --create-output-bam-md5 false --create-output-variant-index true --create-output-variant-md5 false --lenient false --add-output-sam-program-record true --add-output-vcf-command-line true --cloud-prefetch-buffer 40 --cloud-index-prefetch-buffer -1 --disable-bam-index-caching false --sites-only-vcf-output false --help false --version false --showHidden false --verbosity INFO --QUIET false --use-jdk-deflater false --use-jdk-inflater false --gcs-max-retries 20 --gcs-project-for-requester-pays  --disable-tool-default-read-filters false\",Version=\"4.1.7.0-104-g7b42ed9-SNAPSHOT\",Date=\"October 22, 2020 10:15:47 AM EDT\">\n+##GATKCommandLine=<ID=SelectVariants,CommandLine=\"SelectVariants  --output prod.chr20snippet.withRawMQ.g.vcf --variant gs://broad-gotc-prod-storage/pipeline/G97551/gvcfs/NWD242235.bcdd0ebc-17fa-402f-aa7e-ec97ae8669ca.g.vcf.gz --intervals chr20:20000000 --interval-padding 5000 --reference Homo_sapiens_assembly38.fasta  --invertSelect false --exclude-non-variants false --exclude-filtered false --preserve-alleles false --remove-unused-alternates false --restrict-alleles-to ALL --keep-original-ac false --keep-original-dp false --mendelian-violation false --invert-mendelian-violation false --mendelian-violation-qual-threshold 0.0 --select-random-fraction 0.0 --remove-fraction-genotypes 0.0 --fully-decode false --max-indel-size 2147483647 --min-indel-size 0 --max-filtered-genotypes 2147483647 --min-filtered-genotypes 0 --max-fraction-filtered-genotypes 1.0 --min-fraction-filtered-genotypes 0.0 --max-nocall-number 2147483647 --max-nocall-fraction 1.0 --set-filtered-gt-to-nocall false --allow-nonoverlapping-command-line-samples false --suppress-reference-path false --interval-set-rule UNION --interval-exclusion-padding 0 --interval-merging-rule ALL --read-validation-stringency SILENT --seconds-between-progress-updates 10.0 --disable-sequence-dictionary-validation false --create-output-bam-index true --create-output-bam-md5 false --create-output-variant-index true --create-output-variant-md5 false --lenient false --add-output-sam-program-record true --add-output-vcf-command-line true --cloud-prefetch-buffer 40 --cloud-index-prefetch-buffer -1 --disable-bam-index-caching false --sites-only-vcf-output false --help false --version false --showHidden false --verbosity INFO --QUIET false --use-jdk-deflater false --use-jdk-inflater false --gcs-max-retries 20 --gcs-project-for-requester-pays  --disable-tool-default-read-filters false\",Version=4.0.9.0-13-g0f6c729-SNAPSHOT,Date=\"October 4, 2018 10:52:55 AM EDT\">\n+##GVCFBlock0-1=minGQ=0(inclusive),maxGQ=1(exclusive)\n+##GVCFBlock1-2=minGQ=1(inclusive),maxGQ=2(exclusive)\n+##GVCFBlock10-11=minGQ=10(inclusive),maxGQ=11(exclusive)\n+##GVCFBlock11-12=minGQ=11(inclusive),maxGQ=12(exclusive)\n+##GVCFBlock12-13=minGQ=12(inclusive),maxGQ=13(exclusive)\n+##GVCFBlock13-14=minGQ=13(inclusive),maxGQ=14(exclusive)\n+##GVCFBlock14-15=minGQ=14(inclusive),maxGQ=15(exclusive)\n+##GVCFBlock15-16=minGQ=15(inclusive),maxGQ=16(exclusive)\n+##GVCFBlock16-17=minGQ=16(inclusive),maxGQ=17(exclusive)\n+##GVCFBlock17-18=minGQ=17(inclusive),maxGQ=18(exclusive)\n+##GVCFBlock18-19=minGQ=18(inclusive),maxGQ=19(exclusive)\n+##GVCFBlock19-20=minGQ=19(inclusive),maxGQ=20(exclusive)\n+##GVCFBlock2-3=minGQ=2(inclusive),maxGQ=3(exclusive)\n+##GVCFBlock20-21=minGQ=20(inclusive),maxGQ=21(exclusive)\n+##GVCFBlock21-22=minGQ=21(inclusive),maxGQ=22(exclusive)\n+##GVCFBlock22-23=minGQ=22(inclusive),maxGQ=23(exclusive)\n+##GVCFBlock23-24=minGQ=23(inclusive),maxGQ=24(exclusive)\n+##GVCFBlock24-25=minGQ=24(inclusive),maxGQ=25(exclusive)\n+##GVCFBlock25-26=minGQ=25(inclusive),maxGQ=26(exclusive)\n+##GVCFBlock26-27=minGQ=26(inclusive),maxGQ=27(exclusive)\n+##GVCFBlock27-28=minGQ=27(inclusive),maxGQ=28(exclusive)\n+##GVCFBlock28-29=minGQ=28(inclusive),maxGQ=29(exclusive)\n+##GVCFBlock29-30=minGQ=29(inclusive),maxGQ=30(exclusive)\n+##GVCFBlock3-4=minGQ=3(inclusive),maxGQ=4(exclusive)\n+##GVCFBlock30-31=minGQ=30(inclusive),maxGQ=31(exclusive)\n+##GVCFBlock31-32=minGQ=31(inclusive),maxGQ=32(exclusive)\n+##GVCFBlock32-33=minGQ=32(inclusive),maxGQ=33(exclusive)\n+##GVCFBlock33-34=minGQ=33(inclusive),maxGQ=34(exclusive)\n+##GVCFBlock34-35=minGQ=34(inclusive),maxGQ=35(exclusive)\n+##GVCFBlock35-36=minGQ=35(inclusive),maxGQ=36(exclusive)\n+##GVCFBlock36-37=minGQ=36(inclusive),maxGQ=37(exclusive)\n+##GVCFBlock37-38=minGQ=37(inclusive),maxGQ=38(exclusive)\n+##GVCFBlock38-39=minGQ=38(inclusive),maxGQ=39(exclusive)\n+##GVCFBlock39-40=minGQ=39(inclusive),maxGQ=40(exclusive)\n+##GVCFBlock4-5=minGQ=4(inclusive),maxGQ=5(exclusive)\n+##GVCFBlock40-41=minGQ=40(inclusive),maxGQ=41(exclusive)\n+##GVCFBlock41-42=minGQ=41(inclusive),maxGQ=42(exclusive)\n+##GVCFBlock42-43=minGQ=42(inclusive),maxGQ=43(exclusive)\n+##GVCFBlock43-44=minGQ=43(inclusive),maxGQ=44(exclusive)\n+##GVCFBlock44-45=minGQ=44(inclusive),maxGQ=45(exclusive)\n+##GVCFBlock45-46=minGQ=45(inclusive),maxGQ=46(exclusive)\n+##GVCFBlock46-47=minGQ=46(inclusive),maxGQ=47(exclusive)\n+##GVCFBlock47-48=minGQ=47(inclusive),maxGQ=48(exclusive)\n+##GVCFBlock48-49=minGQ=48(inclusive),maxGQ=49(exclusive)\n+##GVCFBlock49-50=minGQ=49(inclusive),maxGQ=50(exclusive)\n+##GVCFBlock5-6=minGQ=5(inclusive),maxGQ=6(exclusive)\n+##GVCFBlock50-51=minGQ=50(inclusive),maxGQ=51(exclusive)\n+##GVCFBlock51-52=minGQ=51(inclusive),maxGQ=52(exclusive)\n+##GVCFBlock52-53=minGQ=52(inclusive),maxGQ=53(exclusive)\n+##GVCFBlock53-54=minGQ=53(inclusive),maxGQ=54(exclusive)\n+##GVCFBlock54-55=minGQ=54(inclusive),maxGQ=55(exclusive)\n+##GVCFBlock55-56=minGQ=55(inclusive),maxGQ=56(exclusive)\n+##GVCFBlock56-57=minGQ=56(inclusive),maxGQ=57(exclusive)\n+##GVCFBlock57-58=minGQ=57(inclusive),maxGQ=58(exclusive)\n+##GVCFBlock58-59=minGQ=58(inclusive),maxGQ=59(exclusive)\n+##GVCFBlock59-60=minGQ=59(inclusive),maxGQ=60(exclusive)\n+##GVCFBlock6-7=minGQ=6(inclusive),maxGQ=7(exclusive)\n+##GVCFBlock60-70=minGQ=60(inclusive),maxGQ=70(exclusive)\n+##GVCFBlock7-8=minGQ=7(inclusive),maxGQ=8(exclusive)\n+##GVCFBlock70-80=minGQ=70(inclusive),maxGQ=80(exclusive)\n+##GVCFBlock8-9=minGQ=8(inclusive),maxGQ=9(exclusive)\n+##GVCFBlock80-90=minGQ=80(inclusive),maxGQ=90(exclusive)\n+##GVCFBlock9-10=minGQ=9(inclusive),maxGQ=10(exclusive)\n+##GVCFBlock90-99=minGQ=90(inclusive),maxGQ=99(exclusive)\n+##GVCFBlock99-2147483647=minGQ=99(inclusive),maxGQ=2147483647(exclusive)\n+##INFO=<ID=AC,Number=A,Type=Integer,Description=\"Allele count in genotypes, for each ALT allele, in the same order as listed\">\n+##INFO=<ID=AF,Number=A,Type=Float,Description=\"Allele Frequency, for each ALT allele, in the same order as listed\">\n+##INFO=<ID=AN,Number=1,Type=Integer,Description=\"Total number of alleles in called genotypes\">\n+##INFO=<ID=BaseQRankSum,Number=1,Type=Float,Description=\"Z-score from Wilcoxon rank sum test of Alt Vs. Ref base qualities\">\n+##INFO=<ID=ClippingRankSum,Number=1,Type=Float,Description=\"Z-score From Wilcoxon rank sum test of Alt vs. Ref number of hard clipped bases\">\n+##INFO=<ID=DP,Number=1,Type=Integer,Description=\"Approximate read depth; some reads may have been filtered\">\n+##INFO=<ID=DS,Number=0,Type=Flag,Description=\"Were any of the samples downsampled?\">\n+##INFO=<ID=END,Number=1,Type=Integer,Description=\"Stop position of the interval\">\n+##INFO=<ID=ExcessHet,Number=1,Type=Float,Description=\"Phred-scaled p-value for exact test of excess heterozygosity\">\n+##INFO=<ID=HaplotypeScore,Number=1,Type=Float,Description=\"Consistency of the site with at most two segregating haplotypes\">\n+##INFO=<ID=InbreedingCoeff,Number=1,Type=Float,Description=\"Inbreeding coefficient as estimated from the genotype likelihoods per-sample when compared against the Hardy-Weinberg expectation\">\n+##INFO=<ID=MLEAC,Number=A,Type=Integer,Description=\"Maximum likelihood expectation (MLE) for the allele counts (not necessarily the same as the AC), for each ALT allele, in the same order as listed\">\n+##INFO=<ID=MLEAF,Number=A,Type=Float,Description=\"Maximum likelihood expectation (MLE) for the allele frequency (not necessarily the same as the AF), for each ALT allele, in the same order as listed\">\n+##INFO=<ID=MQ,Number=1,Type=Float,Description=\"RMS Mapping Quality\">\n+##INFO=<ID=MQRankSum,Number=1,Type=Float,Description=\"Z-score From Wilcoxon rank sum test of Alt vs. Ref read mapping qualities\">\n+##INFO=<ID=RAW_MQ,Number=1,Type=Float,Description=\"Raw data for RMS Mapping Quality\">\n+##INFO=<ID=ReadPosRankSum,Number=1,Type=Float,Description=\"Z-score from Wilcoxon rank sum test of Alt vs. Ref read position bias\">\n+##contig=<ID=chr20,length=64444167>\n+##source=SelectVariants\n+#CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO\tFORMAT\tNWD242235\n+chr20\t19996000\t.\tC\t<NON_REF>\t.\t.\tEND=19996000\tGT:DP:GQ:MIN_DP:PL\t0/0:43:95:43:0,95,1395\n+chr20\t19996001\t.\tA\t<NON_REF>\t.\t.\tEND=19996043\tGT:DP:GQ:MIN_DP:PL\t0/0:42:99:39:0,105,1575\n+chr20\t19996044\t.\tG\t<NON_REF>\t.\t.\tEND=19996044\tGT:DP:GQ:MIN_DP:PL\t0/0:41:88:41:0,88,1315\n+chr20\t19996045\t.\tG\t<NON_REF>\t.\t.\tEND=19996105\tGT:DP:GQ:MIN_DP:PL\t0/0:41:99:36:0,101,1221\n+chr20\t19996106\t.\tA\tG,<NON_REF>\t484.77\t.\tBaseQRankSum=0.086;ClippingRankSum=-0.604;DP=35;ExcessHet=3.0103;MLEAC=1,0;MLEAF=0.500,0.00;MQRankSum=1.225;RAW_MQ=125316.00;ReadPosRankSum=-1.190\tGT:AD:DP:GQ:PL:SB\t0/1:16,18,0:34:99:513,0,454,562,508,1070:10,6,8,10\n+chr20\t19996107\t.\tG\t<NON_REF>\t.\t.\tEND=19996108\tGT:DP:GQ:MIN_DP:PL\t0/0:38:99:38:0,102,1530\n+chr20\t19996109\t.\tT\t<NON_REF>\t.\t.\tEND=19996109\tGT:DP:GQ:MIN_DP:PL\t0/0:37:62:37:0,62,1127\n+chr20\t19996110\t.\tT\t<NON_REF>\t.\t.\tEND=19996110\tGT:DP:GQ:MIN_DP:PL\t0/0:37:99:37:0,99,1485\n+chr20\t19996111\t.\tC\t<NON_REF>\t.\t.\tEND=19996121\tGT:DP:GQ:MIN_DP:PL\t0/0:37:90:34:0,90,1350\n+chr20\t19996122\t.\tT\t<NON_REF>\t.\t.\tEND=19996123\tGT:DP:GQ:MIN_DP:PL\t0/0:34:87:34:0,87,1305\n+chr20\t19996124\t.\tG\t<NON_REF>\t.\t.\tEND=19996130\tGT:DP:GQ:MIN_DP:PL\t0/0:34:90:34:0,90,1350\n+chr20\t19996131\t.\tT\t<NON_REF>\t.\t.\tEND=19996131\tGT:DP:GQ:MIN_DP:PL\t0/0:32:82:32:0,82,1033\n+chr20\t19996132\t.\tG\t<NON_REF>\t.\t.\tEND=19996136\tGT:DP:GQ:MIN_DP:PL\t0/0:31:90:31:0,90,1058\n+chr20\t19996137\t.\tA\t<NON_REF>\t.\t.\tEND=19996137\tGT:DP:GQ:MIN_DP:PL\t0/0:31:68:31:0,68,988\n+chr20\t19996138\t.\tA\t<NON_REF>\t.\t.\tEND=19996160\tGT:DP:GQ:MIN_DP:PL\t0/0:30:84:29:0,84,988\n+chr20\t19996161\t.\tA\t<NON_REF>\t.\t.\tEND=19996172\tGT:DP:GQ:MIN_DP:PL\t0/0:32:90:32:0,90,1072\n+chr20\t19996173\t.\tG\t<NON_REF>\t.\t.\tEND=19996226\tGT:DP:GQ:MIN_DP:PL\t0/0:41:99:37:0,102,1286\n+chr20\t19996227\t.\tT\t<NON_REF>\t.\t.\tEND=19996227\tGT:DP:GQ:MIN_DP:PL\t0/0:45:86:45:0,86,1365\n+chr20\t19996228\t.\tC\t<NON_REF>\t.\t.\tEND=19996368\tGT:DP:GQ:MIN_DP:PL\t0/0:51:99:42:0,99,1485\n+chr20\t19996369\t.\tC\t<NON_REF>\t.\t.\tEND=19996377\tGT:DP:GQ:MIN_DP:PL\t0/0:36:93:33:0,93,1395\n+chr20\t19996378\t.\tG\t<NON_REF>\t.\t.\tEND=19996378\tGT:DP:GQ:MIN_DP:PL\t0/0:34:77:34:0,77,1032\n+chr20\t19996379\t.\tC\t<NON_REF>\t.\t.\tEND=19996382\tGT:DP:GQ:MIN_DP:PL\t0/0:34:99:33:0,99,1097\n+chr20\t19996383\t.\tA\t<NON_REF>\t.\t.\tEND=19996387\tGT:DP:GQ:MIN_DP:PL\t0/0:33:90:33:0,90,1350\n+chr20\t19996388\t.\tG\t<NON_REF>\t.\t.\tEND=19996390\tGT:DP:GQ:MIN_DP:PL\t0/0:33:84:33:0,84,1260\n+chr20\t19996391\t.\tA\t<NON_REF>\t.\t.\tEND=19996394\tGT:DP:GQ:MIN_DP:PL\t0/0:36:90:34:0,90,1350\n+chr20\t19996395\t.\tC\t<NON_REF>\t.\t.\tEND=19996397\tGT:DP:GQ:MIN_DP:PL\t0/0:35:87:34:0,87,1305\n+chr20\t19996398\t.\tT\t<NON_REF>\t.\t.\tEND=19996401\tGT:DP:GQ:MIN_DP:PL\t0/0:34:90:32:0,90,1350\n+chr20\t19996402\t.\tT\t<NON_REF>\t.\t.\tEND=19996405\tGT:DP:GQ:MIN_DP:PL\t0/0:32:82:30:0,82,1013\n+chr20\t19996406\t.\tA\t<NON_REF>\t.\t.\tEND=19996408\tGT:DP:GQ:MIN_DP:PL\t0/0:30:75:30:0,75,1125\n+chr20\t19996409\t.\tC\t<NON_REF>\t.\t.\tEND=19996409\tGT:DP:GQ:MIN_DP:PL\t0/0:32:61:32:0,61,1023\n+chr20\t19996410\t.\tA\t<NON_REF>\t.\t.\tEND=19996412\tGT:DP:GQ:MIN_DP:PL\t0/0:33:81:32:0,81,1215\n+chr20\t19996413\t.\tA\t<NON_REF>\t.\t.\tEND=19996414\tGT:DP:GQ:MIN_DP:PL\t0/0:32:78:32:0,78,1170\n+chr20\t19996415\t.\tC\t<NON_REF>\t.\t.\tEND=19996417\tGT:DP:GQ:MIN_DP:PL\t0/0:30:81:29:0,81,1215\n+chr20\t19996418\t.\tT\t<NON_REF>\t.\t.\tEND=19996418\tGT:DP:GQ:MIN_DP:PL\t0/0:29:78:29:0,78,1170\n+chr20\t19996419\t.\tG\t<NON_REF>\t.\t.\tEND=19996423\tGT:DP:GQ:MIN_DP:PL\t0/0:30:81:29:0,81,1215\n+chr20\t19996424\t.\tC\t<NON_REF>\t.\t.\tEND=19996424\tGT:DP:GQ:MIN_DP:PL\t0/0:29:78:29:0,78,1170\n+chr20\t19996425\t.\tC\t<NON_REF>\t.\t.\tEND=19996433\tGT:DP:GQ:MIN_DP:PL\t0/0:31:81:28:0,81,1215\n+chr20\t19996434\t.\tC\t<NON_REF>\t.\t.\tEND=19996442\tGT:DP:GQ:MIN_DP:PL\t0/0:32:90:31:0,90,1072\n+chr20\t19996443\t.\tC\t<NON_REF>\t.\t.\tEND=19996444\tGT:DP:GQ:MIN_DP:PL\t0/0:34:99:34:0,99,1485\n+chr20\t19996445\t.\tT\t<NON_REF>\t.\t.\tEND=19996445\tGT:DP:GQ:MIN_DP:PL\t0/0:34:88:34:0,88,1083\n+chr20\t19996446\t.\tG\t<NON_REF>\t.\t.\tEND=19996446\tGT:DP:GQ:MIN_DP:PL\t0/0:34:99:34:0,99,1485\n+chr20\t19996447\t.\tG\t<NON_REF>\t.\t.\tEND=19996452\tGT:DP:GQ:MIN_DP:PL\t0/0:33:90:32:0,90,1350\n+chr20\t19996453\t.\tC\t<NON_REF>\t.\t.\tEND=19996454\tGT:DP:GQ:MIN_DP:PL\t0/0:33:87:32:0,87,1305\n+chr20\t19996455\t.\tC\t<NON_REF>\t.\t.\tEND=19996461\tGT:DP:GQ:MIN_DP:PL\t0/0:34:90:30:0,90,982\n+chr20\t19996462\t.\tG\t<NON_REF>\t.\t.\tEND=19996467\tGT:DP:GQ:MIN_DP:PL\t0/0:35:99:33:0,99,1077\n+chr20\t19996468\t.\tC\t<NON_REF>\t.\t.\tEND=19996470\tGT:DP:GQ:MIN_DP:PL\t0/0:35:96:35:0,96,1440\n+chr20\t19996471\t.\tC\t<NON_REF>\t.\t.\tEND=19996495\tGT:DP:GQ:MIN_DP:PL\t0/0:36:99:35:0,99,1197\n+chr20\t19996496\t.\tT\t<NON_REF>\t.\t.\tEND=19996496\tGT:DP:GQ:MIN_DP:PL\t0/0:35:91:35:0,91,1128\n+chr20\t19996497\t.\tG\t<NON_REF>\t.\t.\tEND=19996551\tGT:DP:GQ:MIN_DP:PL\t0/0:36:99:34:0,102,1142\n+chr20\t19996552\t.\tC\t<NON_REF>\t.\t.\tEND=19996552\tGT:DP:GQ:MIN_DP:PL\t0/0:37:97:37:0,97,1227\n+chr20\t19996553\t.\tC\t<NON_REF>\t.\t.\tEND=19996554\tGT:DP:GQ:MIN_DP:PL\t0/0:39:99:38:0,102,1530\n+chr20\t19996555\t.\tC\t<NON_REF>\t.\t.\tEND=19996563\tGT:DP:GQ:MIN_DP:PL\t0/0:39:96:36:0,96,1440\n+chr20\t19996564\t.\tG\t<NON_REF>\t.\t.\tEND=19996565\tGT:DP:GQ:MIN_DP:PL\t0/0:37:99:36:0,99,1485\n+chr20\t19996566\t.\tA\t<NON_REF>\t.\t.\tEND=19996568\tGT:DP:GQ:MIN_DP:PL\t0/0:35:96:34:0,96,1440\n+chr20\t19996569\t.\tT\t<NON_REF>\t.\t.\tEND=19996574\tGT:DP:GQ:MIN_DP:PL\t0/0:37:99:35:0,102,1530\n+chr20\t19996575\t.\tA\t<NON_REF>\t.\t.\tEND=19996577\tGT:DP:GQ:MIN_DP:PL\t0/0:38:90:37:0,90,1350\n+chr20\t19996578\t.\tT\t<NON_REF>\t.\t.\tEND=19996594\tGT:DP:GQ:MIN_DP:PL\t0/0:37:99:35:0,99,1485\n+chr20\t19996595\t.\tA\t<NON_REF>\t.\t.\tEND=19996595\tGT:DP:GQ:MIN_DP:PL\t0/0:35:96:35:0,96,1440\n+chr20\t19996596\t.\tT\t<NON_REF>\t.\t.\tEND=19996596\tGT:DP:GQ:MIN_DP:PL\t0/0:35:81:35:0,81,1147\n+chr20\t19996597\t.\tG\t<NON_REF>\t.\t.\tEND=19996612\tGT:DP:GQ:MIN_DP:PL\t0/0:37:99:35:0,99,1181\n+chr20\t19996613\t.\tA\t<NON_REF>\t.\t.\tEND=19996613\tGT:DP:GQ:MIN_DP:PL\t0/0:36:94:36:0,94,1203\n+chr20\t19996614\t.\tT\t<NON_REF>\t.\t.\tEND=19996625\tGT:DP:GQ:MIN_DP:PL\t0/0:40:99:36:0,99,1271\n+chr20\t19996626\t.\tA\t<NON_REF>\t.\t.\tEND=19996626\tGT:DP:GQ:MIN_DP:PL\t0/0:38:90:38:0,90,1242\n+chr20\t19996627\t.\tC\t<NON_REF>\t.\t.\tEND=19996658\tGT:DP:GQ:MIN_DP:PL\t0/0:37:99:35:0,105,1187\n+chr20\t19996659\t.\tA\t<NON_REF>\t.\t.\tEND=19996659\tGT:DP:GQ:MIN_DP:PL\t0/0:37:97:37:0,97,1197\n+chr20\t19996660\t.\tC\t<NON_REF>\t.\t.\tEND=19996671\tGT:DP:GQ:MIN_DP:PL\t0/0:37:99:37:0,105,1575\n+chr20\t19996672\t.\tT\t<NON_REF>\t.\t.\tEND=19996672\tGT:DP:GQ:MIN_DP:PL\t0/0:36:84:36:0,84,1182\n+chr20\t19996673\t.\tT\t<NON_REF>\t.\t.\tEND=19996680\tGT:DP:GQ:MIN_DP:PL\t0/0:37:99:35:0,99,1485\n+chr20\t19996681\t.\tG\t<NON_REF>\t.\t.\tEND=19996683\tGT:DP:GQ:MIN_DP:PL\t0/0:35:96:33:0,96,1440\n+chr20\t19996684\t.\tT\t<NON_REF>\t.\t.\tEND=19996684\tGT:DP:GQ:MIN_DP:PL\t0/0:35:99:35:0,99,1485\n+chr20\t19996685\t.\tA\t<NON_REF>\t.\t.\tEND=19996685\tGT:DP:GQ:MIN_DP:PL\t0/0:36:74:36:0,74,1162\n+chr20\t19996686\t.\tT\t<NON_REF>\t.\t.\tEND=19996687\tGT:DP:GQ:MIN_DP:PL\t0/0:36:99:36:0,99,1485\n+chr20\t19996688\t.\tA\t<NON_REF>\t.\t.\tEND=19996692\tGT:DP:GQ:MIN_DP:PL\t0/0:35:93:34:0,93,1395\n+chr20\t19996693\t.\tA\t<NON_REF>\t.\t.\tEND=19996693\tGT:DP:GQ:MIN_DP:PL\t0/0:35:66:35:0,66,1108\n+chr20\t19996694\t.\tC\t<NON_REF>\t.\t.\tEND=19996694\tGT:DP:GQ:MIN_DP:PL\t0/0:36:99:36:0,99,1485\n+chr20\t19996695\t.\tA\t<NON_REF>\t.\t.\tEND=19996709\tGT:DP:GQ:MIN_DP:PL\t0/0:34:90:32:0,90,1350\n+chr20\t19996710\t.\tA\t<NON_REF>\t.\t.\tEND=19996714\tGT:DP:GQ:MIN_DP:PL\t0/0:33:81:32:0,81,1215\n+chr20\t19996715\t.\tC\t<NON_REF>\t.\t.\tEND=19996725\tGT:DP:GQ:MIN_DP:PL\t0/0:32:72:31:0,72,1080\n+chr20\t19996726\t.\tA\t<NON_REF>\t.\t.\tEND=19996728\tGT:DP:GQ:MIN_DP:PL\t0/0:33:84:32:0,84,1260\n+chr20\t19996729\t.\tT\t<NON_REF>\t.\t.\tEND=19996730\tGT:DP:GQ:MIN_DP:PL\t0/0:31:65:30:0,65,963\n+chr20\t19996731\t.\tC\t<NON_REF>\t.\t.\tEND=19996737\tGT:DP:GQ:MIN_DP:PL\t0/0:30:84:30:0,84,1260\n+chr20\t19996738\t.\tG\t<NON_REF>\t.\t.\tEND=19996738\tGT:DP:GQ:MIN_DP:PL\t0/0:30:90:30:0,90,1033\n+chr20\t19996739\t.\tA\t<NON_REF>\t.\t.\tEND=19996743\tGT:DP:GQ:MIN_DP:PL\t0/0:31:84:30:0,84,1260\n+chr20\t19996744\t.\tG\t<NON_REF>\t.\t.\tEND=19996756\tGT:DP:GQ:MIN_DP:PL\t0/0:30:72:26:0,72,1080\n+chr20\t19996757\t.\tT\t<NON_REF>\t.\t.\tEND=19996767\tGT:DP:GQ:MIN_DP:PL\t0/0:27:66:24:0,66,990\n+chr20\t19996768\t.\tA\t<NON_REF>\t.\t.\tEND=19996768\tGT:DP:GQ:MIN_DP:PL\t0/0:24:58:24:0,58,765\n+chr20\t19996769\t.\tC\t<NON_REF>\t.\t.\tEND=19996775\tGT:DP:GQ:MIN_DP:PL\t0/0:23:66:23:0,66,990\n+chr20\t19996776\t.\tC\t<NON_REF>\t.\t.\tEND=19996785\tGT:DP:GQ:MIN_DP:PL\t0/0:25:72:24:0,72,814\n+chr20\t19996786\t.\tC\t<NON_REF>\t.\t.\tEND=19996799\tGT:DP:GQ:MIN_DP:PL\t0/0:24:69:23:0,69,780\n+chr20\t19996800\t.\tG\t<NON_REF>\t.\t.\tEND=19996824\tGT:DP:GQ:MIN_DP:PL\t0/0:26:72:24:0,72,834\n+chr20\t19996825\t.\tT\t<NON_REF>\t.\t.\tEND=19996825\tGT:DP:GQ:MIN_DP:PL\t0/0:27:56:27:0,56,849\n+chr20\t19996826\t.\tC\t<NON_REF>\t.\t.\tEND=19996833\tGT:DP:GQ:MIN_DP:PL\t0/0:26:72:25:0,72,1080\n+chr20\t19996834\t.\tG\t<NON_REF>\t.\t.\tEND=19996841\tGT:DP:GQ:MIN_DP:PL\t0/0:24:69:23:0,69,800\n+chr20\t19996842\t.\tG\t<NON_REF>\t.\t.\tEND=19996859\tGT:DP:GQ:MIN_DP:PL\t0/0:27:72:25:0,72,859\n+chr20\t19996860\t.\tC\t<NON_REF>\t.\t.\tEND=19996867\tGT:DP:GQ:MIN_DP:PL\t0/0:27:60:26:0,60,900\n+chr20\t19996868\t.\tT\t<NON_REF>\t.\t.\tEND=19996868\tGT:DP:GQ:MIN_DP:PL\t0/0:26:57:26:0,57,855\n+chr20\t19996869\t.\tC\t<NON_REF>\t.\t.\tEND=19996905\tGT:DP:GQ:MIN_DP:PL\t0/0:23:60:21:0,60,680\n+chr20\t19996906\t.\tC\t<NON_REF>\t.\t.\tEND=19996906\tGT:DP:GQ:MIN_DP:PL\t0/0:22:41:22:0,41,675\n+chr20\t19996907\t.\tA\t<NON_REF>\t.\t.\tEND=19996933\tGT:DP:GQ:MIN_DP:PL\t0/0:23:60:21:0,60,690\n+chr20\t19996934\t.\tG\t<NON_REF>\t.\t.\tEND=19996934\tGT:DP:GQ:MIN_DP:PL\t0/0:22:52:22:0,52,716\n+chr20\t19996935\t.\tT\t<NON_REF>\t.\t.\tEND=19996946\tGT:DP:GQ:MIN_DP:PL\t0/0:23:69:23:0,69,759\n+chr20\t19996947\t.\tG\t<NON_REF>\t.\t.\tEND=19996952\tGT:DP:GQ:MIN_DP:PL\t0/0:25:72:25:0,72,1080\n+chr20\t19996953\t.\tA\t<NON_REF>\t.\t.\tEND=19996963\tGT:DP:GQ:MIN_DP:PL\t0/0:25:66:24:0,66,990\n+chr20\t19996964\t.\tC\t<NON_REF>\t.\t.\tEND=19996965\tGT:DP:GQ:MIN_DP:PL\t0/0:26:72:25:0,72,1080\n+chr20\t19996966\t.\tA\t<NON_REF>\t.\t.\tEND=19996966\tGT:DP:GQ:MIN_DP:PL\t0/0:25:61:25:0,61,790\n+chr20\t19996967\t.\tA\t<NON_REF>\t.\t.\tEND=19996969\tGT:DP:GQ:MIN_DP:PL\t0/0:24:72:24:0,72,774\n+chr20\t19996970\t.\tA\t<NON_REF>\t.\t.\tEND=19996970\tGT:DP:GQ:MIN_DP:PL\t0/0:23:69:23:0,69,780\n+chr20\t19996971\t.\tC\t<NON_REF>\t.\t.\tEND=19996979\tGT:DP:GQ:MIN_DP:PL\t0/0:25:72:25:0,72,808\n+chr20\t19996980\t.\tC\t<NON_REF>\t.\t.\tEND=19996988\tGT:DP:GQ:MIN_DP:PL\t0/0:26:66:25:0,66,990\n+chr20\t19996989\t.\tC\t<NON_REF>\t.\t.\tEND=19996991\tGT:DP:GQ:MIN_DP:PL\t0/0:26:72:26:0,72,1080\n+chr20\t19996992\t.\tA\t<NON_REF>\t.\t.\tEND=19996996\tGT:DP:GQ:MIN_DP:PL\t0/0:25:66:25:0,66,990\n+chr20\t19996997\t.\tT\t<NON_REF>\t.\t.\tEND=19997009\tGT:DP:GQ:MIN_DP:PL\t0/0:26:72:25:0,72,1080"
  }
]
