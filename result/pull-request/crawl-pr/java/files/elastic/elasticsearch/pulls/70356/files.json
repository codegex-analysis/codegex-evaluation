[
  {
    "sha": "b51ae0e2fb82c2ec1eed57644cd4fb7fd0691337",
    "filename": "buildSrc/src/main/resources/checkstyle_suppressions.xml",
    "status": "modified",
    "additions": 1,
    "deletions": 0,
    "changes": 1,
    "blob_url": "https://github.com/elastic/elasticsearch/blob/d0893e5ae135f0ac881e86cf558fe67a9c65268d/buildSrc/src/main/resources/checkstyle_suppressions.xml",
    "raw_url": "https://github.com/elastic/elasticsearch/raw/d0893e5ae135f0ac881e86cf558fe67a9c65268d/buildSrc/src/main/resources/checkstyle_suppressions.xml",
    "contents_url": "https://api.github.com/repos/elastic/elasticsearch/contents/buildSrc/src/main/resources/checkstyle_suppressions.xml?ref=d0893e5ae135f0ac881e86cf558fe67a9c65268d",
    "patch": "@@ -9,6 +9,7 @@\n   <!-- These files are generated by ANTLR so its silly to hold them to our rules. -->\n   <suppress files=\"modules[/\\\\]lang-painless[/\\\\]src[/\\\\]main[/\\\\]java[/\\\\]org[/\\\\]elasticsearch[/\\\\]painless[/\\\\]antlr[/\\\\]PainlessLexer\\.java\" checks=\".\" />\n   <suppress files=\"modules[/\\\\]lang-painless[/\\\\]src[/\\\\]main[/\\\\]java[/\\\\]org[/\\\\]elasticsearch[/\\\\]painless[/\\\\]antlr[/\\\\]PainlessParser(|BaseVisitor|Visitor)\\.java\" checks=\".\" />\n+  <suppress files=\"modules[/\\\\]lang-painless[/\\\\]src[/\\\\]main[/\\\\]java[/\\\\]org[/\\\\]elasticsearch[/\\\\]painless[/\\\\]antlr[/\\\\]SuggestLexer\\.java\" checks=\".\" />\n   <suppress files=\"plugin[/\\\\]sql[/\\\\]src[/\\\\]main[/\\\\]java[/\\\\]org[/\\\\]elasticsearch[/\\\\]xpack[/\\\\]sql[/\\\\]parser[/\\\\]SqlBase(Base(Listener|Visitor)|Lexer|Listener|Parser|Visitor).java\" checks=\".\" />\n   <suppress files=\"plugin[/\\\\]eql[/\\\\]src[/\\\\]main[/\\\\]java[/\\\\]org[/\\\\]elasticsearch[/\\\\]xpack[/\\\\]eql[/\\\\]parser[/\\\\]EqlBase(Base(Listener|Visitor)|Lexer|Listener|Parser|Visitor).java\" checks=\".\" />\n "
  },
  {
    "sha": "8e728a5bf6f4fda15c680c2466affbd137c3c4e9",
    "filename": "modules/lang-painless/build.gradle",
    "status": "modified",
    "additions": 67,
    "deletions": 1,
    "changes": 68,
    "blob_url": "https://github.com/elastic/elasticsearch/blob/d0893e5ae135f0ac881e86cf558fe67a9c65268d/modules/lang-painless/build.gradle",
    "raw_url": "https://github.com/elastic/elasticsearch/raw/d0893e5ae135f0ac881e86cf558fe67a9c65268d/modules/lang-painless/build.gradle",
    "contents_url": "https://api.github.com/repos/elastic/elasticsearch/contents/modules/lang-painless/build.gradle?ref=d0893e5ae135f0ac881e86cf558fe67a9c65268d",
    "patch": "@@ -146,7 +146,7 @@ String outputPath = 'src/main/java/org/elasticsearch/painless/antlr'\n \n tasks.register(\"cleanGenerated\", Delete) {\n   delete fileTree(grammarPath) {\n-    include '*.tokens'\n+    include '*Painless*.tokens'\n   }\n   delete fileTree(outputPath) {\n     include 'Painless*.java'\n@@ -218,3 +218,69 @@ tasks.register(\"regen\") {\n     }\n   }\n }\n+\n+/**********************************************\n+ *         Suggest lexer regeneration          *\n+ **********************************************/\n+\n+configurations {\n+    suggestRegenerate\n+}\n+\n+dependencies {\n+    regenerate 'org.antlr:antlr4:4.5.3'\n+}\n+\n+String suggestGrammarPath = 'src/main/antlr'\n+String suggestOutputPath = 'src/main/java/org/elasticsearch/painless/antlr'\n+\n+tasks.register(\"cleanSuggestGenerated\", Delete) {\n+    delete fileTree(grammarPath) {\n+        include 'SuggestLexer.tokens'\n+    }\n+    delete fileTree(outputPath) {\n+        include 'Suggest*.java'\n+    }\n+}\n+\n+tasks.register(\"regenSuggestLexer\", JavaExec) {\n+    dependsOn \"cleanSuggestGenerated\"\n+    main = 'org.antlr.v4.Tool'\n+    classpath = configurations.regenerate\n+    systemProperty 'file.encoding', 'UTF-8'\n+    systemProperty 'user.language', 'en'\n+    systemProperty 'user.country', 'US'\n+    systemProperty 'user.variant', ''\n+    args '-Werror',\n+            '-package', 'org.elasticsearch.painless.antlr',\n+            '-o', outputPath,\n+            \"${file(grammarPath)}/SuggestLexer.g4\"\n+}\n+\n+tasks.register(\"regenSuggest\") {\n+    dependsOn \"regenSuggestLexer\"\n+    doLast {\n+        // moves token files to grammar directory for use with IDE's\n+        ant.move(file: \"${outputPath}/SuggestLexer.tokens\", toDir: grammarPath)\n+        // make the lexer abstract\n+        ant.replaceregexp(match: '(class \\\\QSuggest\\\\ELexer)',\n+                replace: 'abstract \\\\1',\n+                encoding: 'UTF-8') {\n+            fileset(dir: outputPath, includes: 'SuggestLexer.java')\n+        }\n+        // nuke timestamps/filenames in generated files\n+        ant.replaceregexp(match: '\\\\Q// Generated from \\\\E.*',\n+                replace: '\\\\/\\\\/ ANTLR GENERATED CODE: DO NOT EDIT',\n+                encoding: 'UTF-8') {\n+            fileset(dir: outputPath, includes: 'Suggest*.java')\n+        }\n+        // remove tabs in antlr generated files\n+        ant.replaceregexp(match: '\\t', flags: 'g', replace: '  ', encoding: 'UTF-8') {\n+            fileset(dir: outputPath, includes: 'Suggest*.java')\n+        }\n+        // fix line endings\n+        ant.fixcrlf(srcdir: outputPath, eol: 'lf') {\n+            patternset(includes: 'Suggest*.java')\n+        }\n+    }\n+}\n\\ No newline at end of file"
  },
  {
    "sha": "ff068df7008207250893dda4fa546ce22d1d8add",
    "filename": "modules/lang-painless/src/main/antlr/SuggestLexer.g4",
    "status": "added",
    "additions": 118,
    "deletions": 0,
    "changes": 118,
    "blob_url": "https://github.com/elastic/elasticsearch/blob/d0893e5ae135f0ac881e86cf558fe67a9c65268d/modules/lang-painless/src/main/antlr/SuggestLexer.g4",
    "raw_url": "https://github.com/elastic/elasticsearch/raw/d0893e5ae135f0ac881e86cf558fe67a9c65268d/modules/lang-painless/src/main/antlr/SuggestLexer.g4",
    "contents_url": "https://api.github.com/repos/elastic/elasticsearch/contents/modules/lang-painless/src/main/antlr/SuggestLexer.g4?ref=d0893e5ae135f0ac881e86cf558fe67a9c65268d",
    "patch": "@@ -0,0 +1,118 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License\n+ * 2.0 and the Server Side Public License, v 1; you may not use this file except\n+ * in compliance with, at your election, the Elastic License 2.0 or the Server\n+ * Side Public License, v 1.\n+ */\n+\n+lexer grammar SuggestLexer;\n+\n+@members {\n+/** Is the preceding {@code /} a the beginning of a regex (true) or a division (false). */\n+protected abstract boolean isSlashRegex();\n+protected abstract boolean isType(String text);\n+}\n+\n+WS: [ \\t\\n\\r]+ -> skip;\n+COMMENT: ( '//' .*? [\\n\\r] | '/*' .*? '*/' ) -> skip;\n+\n+LBRACK:    '{';\n+RBRACK:    '}';\n+LBRACE:    '[';\n+RBRACE:    ']';\n+LP:        '(';\n+RP:        ')';\n+// We switch modes after a dot to ensure there are not conflicts\n+// between shortcuts and decimal values.  Without the mode switch\n+// shortcuts such as id.0.0 will fail because 0.0 will be interpreted\n+// as a decimal value instead of two individual list-style shortcuts.\n+DOT:       '.'  -> mode(AFTER_DOT);\n+NSDOT:     '?.' -> mode(AFTER_DOT);\n+COMMA:     ',';\n+SEMICOLON: ';';\n+IF:        'if';\n+IN:        'in';\n+ELSE:      'else';\n+WHILE:     'while';\n+DO:        'do';\n+FOR:       'for';\n+CONTINUE:  'continue';\n+BREAK:     'break';\n+RETURN:    'return';\n+NEW:       'new';\n+TRY:       'try';\n+CATCH:     'catch';\n+THROW:     'throw';\n+THIS:      'this';\n+INSTANCEOF: 'instanceof';\n+\n+BOOLNOT: '!';\n+BWNOT:   '~';\n+MUL:     '*';\n+DIV:     '/' { isSlashRegex() == false }?;\n+REM:     '%';\n+ADD:     '+';\n+SUB:     '-';\n+LSH:     '<<';\n+RSH:     '>>';\n+USH:     '>>>';\n+LT:      '<';\n+LTE:     '<=';\n+GT:      '>';\n+GTE:     '>=';\n+EQ:      '==';\n+EQR:     '===';\n+NE:      '!=';\n+NER:     '!==';\n+BWAND:   '&';\n+XOR:     '^';\n+BWOR:    '|';\n+BOOLAND: '&&';\n+BOOLOR:  '||';\n+COND:    '?';\n+COLON:   ':';\n+ELVIS:   '?:';\n+REF:     '::';\n+ARROW:   '->';\n+FIND:    '=~';\n+MATCH:   '==~';\n+INCR:    '++';\n+DECR:    '--';\n+\n+ASSIGN: '=';\n+AADD:   '+=';\n+ASUB:   '-=';\n+AMUL:   '*=';\n+ADIV:   '/=';\n+AREM:   '%=';\n+AAND:   '&=';\n+AXOR:   '^=';\n+AOR:    '|=';\n+ALSH:   '<<=';\n+ARSH:   '>>=';\n+AUSH:   '>>>=';\n+\n+OCTAL: '0' [0-7]+ [lL]?;\n+HEX: '0' [xX] [0-9a-fA-F]+ [lL]?;\n+INTEGER: ( '0' | [1-9] [0-9]* ) [lLfFdD]?;\n+DECIMAL: ( '0' | [1-9] [0-9]* ) (DOT [0-9]+)? ( [eE] [+\\-]? [0-9]+ )? [fFdD]?;\n+\n+STRING: ( '\"' ( '\\\\\"' | '\\\\\\\\' | ~[\\\\\"] )*? '\"' ) | ( '\\'' ( '\\\\\\'' | '\\\\\\\\' | ~[\\\\'] )*? '\\'' );\n+REGEX: '/' ( '\\\\' ~'\\n' | ~('/' | '\\n') )+? '/' [cilmsUux]* { isSlashRegex() }?;\n+\n+TRUE:  'true';\n+FALSE: 'false';\n+\n+NULL: 'null';\n+\n+ATYPE: TYPE (LBRACE RBRACE)+;\n+TYPE: ID (DOT ID)* { isType(getText()) }?;\n+ID: [_a-zA-Z] [_a-zA-Z0-9]*;\n+\n+UNKNOWN: . -> skip;\n+\n+mode AFTER_DOT;\n+\n+DOTINTEGER: ( '0' | [1-9] [0-9]* ) -> mode(DEFAULT_MODE);\n+DOTID: [_a-zA-Z] [_a-zA-Z0-9]*     -> mode(DEFAULT_MODE);"
  },
  {
    "sha": "bcad6e54e2d549c2827ea10c3fe66aa236e3cd1a",
    "filename": "modules/lang-painless/src/main/antlr/SuggestLexer.tokens",
    "status": "added",
    "additions": 158,
    "deletions": 0,
    "changes": 158,
    "blob_url": "https://github.com/elastic/elasticsearch/blob/d0893e5ae135f0ac881e86cf558fe67a9c65268d/modules/lang-painless/src/main/antlr/SuggestLexer.tokens",
    "raw_url": "https://github.com/elastic/elasticsearch/raw/d0893e5ae135f0ac881e86cf558fe67a9c65268d/modules/lang-painless/src/main/antlr/SuggestLexer.tokens",
    "contents_url": "https://api.github.com/repos/elastic/elasticsearch/contents/modules/lang-painless/src/main/antlr/SuggestLexer.tokens?ref=d0893e5ae135f0ac881e86cf558fe67a9c65268d",
    "patch": "@@ -0,0 +1,158 @@\n+WS=1\n+COMMENT=2\n+LBRACK=3\n+RBRACK=4\n+LBRACE=5\n+RBRACE=6\n+LP=7\n+RP=8\n+DOT=9\n+NSDOT=10\n+COMMA=11\n+SEMICOLON=12\n+IF=13\n+IN=14\n+ELSE=15\n+WHILE=16\n+DO=17\n+FOR=18\n+CONTINUE=19\n+BREAK=20\n+RETURN=21\n+NEW=22\n+TRY=23\n+CATCH=24\n+THROW=25\n+THIS=26\n+INSTANCEOF=27\n+BOOLNOT=28\n+BWNOT=29\n+MUL=30\n+DIV=31\n+REM=32\n+ADD=33\n+SUB=34\n+LSH=35\n+RSH=36\n+USH=37\n+LT=38\n+LTE=39\n+GT=40\n+GTE=41\n+EQ=42\n+EQR=43\n+NE=44\n+NER=45\n+BWAND=46\n+XOR=47\n+BWOR=48\n+BOOLAND=49\n+BOOLOR=50\n+COND=51\n+COLON=52\n+ELVIS=53\n+REF=54\n+ARROW=55\n+FIND=56\n+MATCH=57\n+INCR=58\n+DECR=59\n+ASSIGN=60\n+AADD=61\n+ASUB=62\n+AMUL=63\n+ADIV=64\n+AREM=65\n+AAND=66\n+AXOR=67\n+AOR=68\n+ALSH=69\n+ARSH=70\n+AUSH=71\n+OCTAL=72\n+HEX=73\n+INTEGER=74\n+DECIMAL=75\n+STRING=76\n+REGEX=77\n+TRUE=78\n+FALSE=79\n+NULL=80\n+ATYPE=81\n+TYPE=82\n+ID=83\n+UNKNOWN=84\n+DOTINTEGER=85\n+DOTID=86\n+'{'=3\n+'}'=4\n+'['=5\n+']'=6\n+'('=7\n+')'=8\n+'.'=9\n+'?.'=10\n+','=11\n+';'=12\n+'if'=13\n+'in'=14\n+'else'=15\n+'while'=16\n+'do'=17\n+'for'=18\n+'continue'=19\n+'break'=20\n+'return'=21\n+'new'=22\n+'try'=23\n+'catch'=24\n+'throw'=25\n+'this'=26\n+'instanceof'=27\n+'!'=28\n+'~'=29\n+'*'=30\n+'/'=31\n+'%'=32\n+'+'=33\n+'-'=34\n+'<<'=35\n+'>>'=36\n+'>>>'=37\n+'<'=38\n+'<='=39\n+'>'=40\n+'>='=41\n+'=='=42\n+'==='=43\n+'!='=44\n+'!=='=45\n+'&'=46\n+'^'=47\n+'|'=48\n+'&&'=49\n+'||'=50\n+'?'=51\n+':'=52\n+'?:'=53\n+'::'=54\n+'->'=55\n+'=~'=56\n+'==~'=57\n+'++'=58\n+'--'=59\n+'='=60\n+'+='=61\n+'-='=62\n+'*='=63\n+'/='=64\n+'%='=65\n+'&='=66\n+'^='=67\n+'|='=68\n+'<<='=69\n+'>>='=70\n+'>>>='=71\n+'true'=78\n+'false'=79\n+'null'=80"
  },
  {
    "sha": "4e8f713e28af3000cdd8bcde58ae78b159751225",
    "filename": "modules/lang-painless/src/main/java/org/elasticsearch/painless/PainlessPlugin.java",
    "status": "modified",
    "additions": 3,
    "deletions": 0,
    "changes": 3,
    "blob_url": "https://github.com/elastic/elasticsearch/blob/d0893e5ae135f0ac881e86cf558fe67a9c65268d/modules/lang-painless/src/main/java/org/elasticsearch/painless/PainlessPlugin.java",
    "raw_url": "https://github.com/elastic/elasticsearch/raw/d0893e5ae135f0ac881e86cf558fe67a9c65268d/modules/lang-painless/src/main/java/org/elasticsearch/painless/PainlessPlugin.java",
    "contents_url": "https://api.github.com/repos/elastic/elasticsearch/contents/modules/lang-painless/src/main/java/org/elasticsearch/painless/PainlessPlugin.java?ref=d0893e5ae135f0ac881e86cf558fe67a9c65268d",
    "patch": "@@ -27,6 +27,7 @@\n import org.elasticsearch.env.NodeEnvironment;\n import org.elasticsearch.painless.action.PainlessContextAction;\n import org.elasticsearch.painless.action.PainlessExecuteAction;\n+import org.elasticsearch.painless.action.PainlessSuggestAction;\n import org.elasticsearch.painless.spi.PainlessExtension;\n import org.elasticsearch.painless.spi.Whitelist;\n import org.elasticsearch.painless.spi.WhitelistLoader;\n@@ -178,6 +179,7 @@ public void loadExtensions(ExtensionLoader loader) {\n         List<ActionHandler<? extends ActionRequest, ? extends ActionResponse>> actions = new ArrayList<>();\n         actions.add(new ActionHandler<>(PainlessExecuteAction.INSTANCE, PainlessExecuteAction.TransportAction.class));\n         actions.add(new ActionHandler<>(PainlessContextAction.INSTANCE, PainlessContextAction.TransportAction.class));\n+        actions.add(new ActionHandler<>(PainlessSuggestAction.INSTANCE, PainlessSuggestAction.TransportAction.class));\n         return actions;\n     }\n \n@@ -189,6 +191,7 @@ public void loadExtensions(ExtensionLoader loader) {\n         List<RestHandler> handlers = new ArrayList<>();\n         handlers.add(new PainlessExecuteAction.RestAction());\n         handlers.add(new PainlessContextAction.RestAction());\n+        handlers.add(new PainlessSuggestAction.RestAction());\n         return handlers;\n     }\n }"
  },
  {
    "sha": "c4c848a185943ae45b44435a6053ff8476742362",
    "filename": "modules/lang-painless/src/main/java/org/elasticsearch/painless/action/PainlessSuggest.java",
    "status": "added",
    "additions": 1451,
    "deletions": 0,
    "changes": 1451,
    "blob_url": "https://github.com/elastic/elasticsearch/blob/d0893e5ae135f0ac881e86cf558fe67a9c65268d/modules/lang-painless/src/main/java/org/elasticsearch/painless/action/PainlessSuggest.java",
    "raw_url": "https://github.com/elastic/elasticsearch/raw/d0893e5ae135f0ac881e86cf558fe67a9c65268d/modules/lang-painless/src/main/java/org/elasticsearch/painless/action/PainlessSuggest.java",
    "contents_url": "https://api.github.com/repos/elastic/elasticsearch/contents/modules/lang-painless/src/main/java/org/elasticsearch/painless/action/PainlessSuggest.java?ref=d0893e5ae135f0ac881e86cf558fe67a9c65268d",
    "patch": "@@ -0,0 +1,1451 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License\n+ * 2.0 and the Server Side Public License, v 1; you may not use this file except\n+ * in compliance with, at your election, the Elastic License 2.0 or the Server\n+ * Side Public License, v 1.\n+ */\n+\n+package org.elasticsearch.painless.action;\n+\n+import org.antlr.v4.runtime.ANTLRInputStream;\n+import org.antlr.v4.runtime.Token;\n+import org.elasticsearch.painless.ScriptClassInfo;\n+import org.elasticsearch.painless.antlr.EnhancedSuggestLexer;\n+import org.elasticsearch.painless.antlr.SuggestLexer;\n+import org.elasticsearch.painless.lookup.PainlessClass;\n+import org.elasticsearch.painless.lookup.PainlessClassBinding;\n+import org.elasticsearch.painless.lookup.PainlessConstructor;\n+import org.elasticsearch.painless.lookup.PainlessField;\n+import org.elasticsearch.painless.lookup.PainlessInstanceBinding;\n+import org.elasticsearch.painless.lookup.PainlessLookup;\n+import org.elasticsearch.painless.lookup.PainlessLookupUtility;\n+import org.elasticsearch.painless.lookup.PainlessMethod;\n+import org.elasticsearch.painless.lookup.def;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.function.Function;\n+\n+/**\n+ * PainlessSuggest generates suggestions for partially completed scripts\n+ * based on context and source. The parsing for suggestions is\n+ * extremely lenient and never issues an error outright. The parser attempts\n+ * to recover given extraneous or unknown input. If an error is unrecoverable,\n+ * no suggestions are given. Also note that no suggestions are given if\n+ * a type is resolved as def as there is no way to know what def represents.\n+ */\n+public class PainlessSuggest {\n+\n+    public static List<Suggestion> suggest(PainlessLookup lookup, ScriptClassInfo info, String source) {\n+        ANTLRInputStream stream = new ANTLRInputStream(source);\n+        SuggestLexer lexer = new EnhancedSuggestLexer(stream, lookup);\n+        lexer.removeErrorListeners();\n+\n+        return new PainlessSuggest(lookup, info, lexer.getAllTokens()).suggest();\n+    }\n+\n+    protected final PainlessLookup lookup;\n+    protected final ScriptClassInfo info;\n+    protected final List<? extends Token> tokens;\n+\n+    protected PainlessSuggest(PainlessLookup lookup, ScriptClassInfo info, List<? extends Token> tokens) {\n+        this.lookup = Objects.requireNonNull(lookup);\n+        this.info = Objects.requireNonNull(info);\n+        this.tokens = Collections.unmodifiableList(Objects.requireNonNull(tokens));\n+    }\n+\n+    protected List<Suggestion> suggest() {\n+        // collect data on user-defined functions\n+        FunctionMachine.FunctionState fs = new FunctionMachine.FunctionState(this.tokens);\n+        FunctionMachine.walk(fs);\n+\n+        // setup which function we are in based on the end of the token stream\n+        // to allow for appropriate top-level parameters to be added to the suggestions\n+        FunctionMachine.FunctionData fd = fs.functions.isEmpty() ? null : fs.functions.get(fs.functions.size() - 1);\n+\n+        // set our starting token at the beginning of the stream\n+        // and this does not change unless there are user-defined functions\n+        int start = 0;\n+\n+        if (fd != null) {\n+            if (fd.bodyEndToken == -1) {\n+                // cursor ended in a function, so set the starting token for the other\n+                // state machines to the beginning of the function\n+                start = fd.bodyStartToken;\n+            } else {\n+                // cursor ended in the execute body, so set the starting token to outside\n+                // the last\n+                start = fd.bodyEndToken + 2;\n+            }\n+        }\n+\n+        // cut the tokens to just our method body up to the cursor\n+        List<? extends Token> tokens = this.tokens.subList(start, this.tokens.size());\n+\n+        // collect data on lambdas\n+        LambdaMachine.LambdaState ls = new LambdaMachine.LambdaState(tokens);\n+        LambdaMachine.walk(ls);\n+\n+        Map<Integer, LambdaMachine.LambdaData> mld = new HashMap<>();\n+\n+        // set up our lambda at the starting token for use in the block machine\n+        for (LambdaMachine.LambdaData ld : ls.lambdas) {\n+            mld.put(ld.headerStartToken, ld);\n+        }\n+\n+        // collect data on declarations within the scope the cursor is in\n+        BlockMachine.BlockState bs = new BlockMachine.BlockState(tokens, mld);\n+        BlockMachine.walk(bs);\n+\n+        // collect a list of type resolvable pieces along with a piece to generate\n+        // suggestion from\n+        AccessMachine.AccessState as = new AccessMachine.AccessState(tokens);\n+        AccessMachine.walk(as);\n+\n+        List<Suggestion> suggestions = new ArrayList<>();\n+\n+        if (as.target == -2) {\n+            // the access machine had a result that allows for suggestion generation\n+            Map<String, String> functions = new HashMap<>();\n+\n+            // collect user-defined functions that may be provided as suggestions\n+            for (FunctionMachine.FunctionData function : fs.functions) {\n+                functions.put(function.functionName + \"/\" + function.parameterTypes.size(), function.returnType);\n+            }\n+\n+            // collect variables that may be provided as suggestions\n+            Map<String, String> variables = bs.scope.getVariables();\n+\n+            // add top-level parameters as variables that may be provided as suggestions\n+            if (fd == null || fd.bodyEndToken != -1) {\n+                // adds execute method parameters\n+                for (ScriptClassInfo.MethodArgument argument : info.getExecuteArguments()) {\n+                    variables.put(argument.getName(), PainlessLookupUtility.typeToCanonicalTypeName(argument.getClazz()));\n+                }\n+\n+                for (int parameter = 0; parameter < info.getGetMethods().size(); ++parameter) {\n+                    String type = PainlessLookupUtility.typeToCanonicalTypeName(info.getGetReturns().get(parameter));\n+                    org.objectweb.asm.commons.Method method = info.getGetMethods().get(parameter);\n+                    String name = method.getName().substring(3);\n+                    name = Character.toLowerCase(name.charAt(0)) + name.substring(1);\n+                    variables.put(name, type);\n+                }\n+            } else {\n+                // adds user-defined function parameters\n+                if (fd.parameterNames.size() == fd.parameterTypes.size()) {\n+                    for (int parameter = 0; parameter < fd.parameterNames.size(); ++parameter) {\n+                        variables.put(fd.parameterNames.get(parameter), fd.parameterTypes.get(parameter));\n+                    }\n+                }\n+            }\n+\n+            suggestions = collect(functions, variables, as.segment);\n+        }\n+\n+        return suggestions;\n+    }\n+\n+    protected List<Suggestion> collect(Map<String, String> functions, Map<String, String> variables, AccessMachine.AccessData segment) {\n+\n+        Class<?> resolved = null;\n+\n+        // resolve the types for each segment\n+        while (segment.child != null && (segment.modifiers & AccessMachine.AccessData.RESOLVE) == AccessMachine.AccessData.RESOLVE) {\n+\n+            if ((segment.modifiers & AccessMachine.AccessData.ID) == AccessMachine.AccessData.ID) {\n+                // resolve a type for a variable\n+                String type = variables.get(segment.text);\n+                resolved = type == null ? null : lookup.canonicalTypeNameToType(type);\n+            } else if ((segment.modifiers & AccessMachine.AccessData.TYPE) == AccessMachine.AccessData.TYPE) {\n+                // resolve a type for a type\n+                resolved = segment.text == null ? null : lookup.canonicalTypeNameToType(segment.text);\n+            } else if ((segment.modifiers & AccessMachine.AccessData.CALL) == AccessMachine.AccessData.CALL) {\n+                // resolve a type for a call\n+                String type = functions.get(segment.text + \"/\" + segment.arity);\n+\n+                if (type != null) {\n+                    resolved = lookup.canonicalTypeNameToType(type);\n+                } else {\n+                    PainlessMethod pm = lookup.lookupImportedPainlessMethod(segment.text, segment.arity);\n+\n+                    if (pm != null) {\n+                        resolved = pm.returnType;\n+                    } else {\n+                        PainlessClassBinding pcb = lookup.lookupPainlessClassBinding(segment.text, segment.arity);\n+\n+                        if (pcb != null) {\n+                            resolved = pcb.returnType;\n+                        } else {\n+                            PainlessInstanceBinding pib = lookup.lookupPainlessInstanceBinding(segment.text, segment.arity);\n+                            resolved = pib == null ? null : pib.returnType;\n+                        }\n+                    }\n+                }\n+            } else if ((segment.modifiers & AccessMachine.AccessData.METHOD) == AccessMachine.AccessData.METHOD) {\n+                // resolve a type for a method\n+                PainlessMethod pm = lookup.lookupPainlessMethod(\n+                        resolved,\n+                        (segment.modifiers & AccessMachine.AccessData.STATIC) == AccessMachine.AccessData.STATIC,\n+                        segment.text,\n+                        segment.arity);\n+                resolved = pm == null ? null : pm.returnType;\n+            } else if ((segment.modifiers & AccessMachine.AccessData.FIELD) == AccessMachine.AccessData.FIELD) {\n+                // resolve a type for a field\n+                PainlessField pf = lookup.lookupPainlessField(\n+                        resolved, (segment.modifiers & AccessMachine.AccessData.STATIC) == AccessMachine.AccessData.STATIC, segment.text);\n+                resolved = pf == null ? null : pf.typeParameter;\n+            } else if ((segment.modifiers & AccessMachine.AccessData.CONSTRUCTOR) == AccessMachine.AccessData.CONSTRUCTOR) {\n+                // resolve the type for a constructor\n+                resolved = lookup.canonicalTypeNameToType(segment.text);\n+            } else if ((segment.modifiers & AccessMachine.AccessData.INDEX) == AccessMachine.AccessData.INDEX) {\n+                // resolve the type for an index\n+                if (resolved != null) {\n+                    if (resolved.isArray()) {\n+                        resolved = resolved.getComponentType();\n+                    } else if (List.class.isAssignableFrom(resolved) || Map.class.isAssignableFrom(resolved)) {\n+                        resolved = def.class;\n+                    }\n+                }\n+            } else if ((segment.modifiers & AccessMachine.AccessData.NUMBER) == AccessMachine.AccessData.NUMBER) {\n+                // resolve the type for a number\n+                resolved = def.class;\n+            }\n+\n+            if (resolved == null || resolved == def.class) {\n+                // the def type does not have suggestions\n+                return new ArrayList<>();\n+            } else if (resolved.isPrimitive()) {\n+                // suggest based on a boxed type for a primitive\n+                resolved = PainlessLookupUtility.typeToBoxedType(resolved);\n+            }\n+\n+            // resolve the next segment\n+            segment = segment.child;\n+        }\n+\n+        List<Suggestion> suggestions = new ArrayList<>();\n+\n+        // generate suggestions for the final segment\n+        if (segment.child == null && (segment.modifiers & AccessMachine.AccessData.SUGGEST) == AccessMachine.AccessData.SUGGEST) {\n+\n+            // generate suggestions for variables\n+            if ((segment.modifiers & AccessMachine.AccessData.ID) == AccessMachine.AccessData.ID) {\n+                for (String name : variables.keySet()) {\n+                    if (name.startsWith(segment.text)) {\n+                        suggestions.add(new Suggestion(Suggestion.VARIABLE, name));\n+                    }\n+                }\n+            }\n+\n+            // generate suggestions for types\n+            if ((segment.modifiers & AccessMachine.AccessData.TYPE) == AccessMachine.AccessData.TYPE) {\n+                for (String type : lookup.getCanonicalClassNames()) {\n+                    if (type.startsWith(segment.text)) {\n+                        suggestions.add(new Suggestion(Suggestion.TYPE, type));\n+                    }\n+                }\n+            }\n+\n+            // generate suggestions for calls\n+            if ((segment.modifiers & AccessMachine.AccessData.CALL) == AccessMachine.AccessData.CALL) {\n+                for (String call : functions.keySet()) {\n+                    if (call.startsWith(segment.text)) {\n+                        suggestions.add(new Suggestion(Suggestion.USER, call));\n+                    }\n+                }\n+\n+                for (String call : lookup.getImportedPainlessMethodsKeys()) {\n+                    if (call.startsWith(segment.text)) {\n+                        suggestions.add(new Suggestion(Suggestion.CALL, call));\n+                    }\n+                }\n+\n+                for (String call : lookup.getPainlessClassBindingsKeys()) {\n+                    if (call.startsWith(segment.text)) {\n+                        suggestions.add(new Suggestion(Suggestion.CALL, call));\n+                    }\n+                }\n+\n+                for (String call : lookup.getPainlessInstanceBindingsKeys()) {\n+                    if (call.startsWith(segment.text)) {\n+                        suggestions.add(new Suggestion(Suggestion.CALL, call));\n+                    }\n+                }\n+            }\n+\n+            // generate suggestions for methods\n+            if ((segment.modifiers & AccessMachine.AccessData.METHOD) == AccessMachine.AccessData.METHOD) {\n+                if (resolved != null) {\n+                    PainlessClass pc = lookup.lookupPainlessClass(resolved);\n+\n+                    if (pc != null) {\n+                        if ((segment.modifiers & AccessMachine.AccessData.STATIC) == AccessMachine.AccessData.STATIC) {\n+                            for (String method : pc.staticMethods.keySet()) {\n+                                if (segment.text == null || method.startsWith(segment.text)) {\n+                                    suggestions.add(new Suggestion(Suggestion.METHOD, method));\n+                                }\n+                            }\n+                        } else {\n+                            for (String method : pc.methods.keySet()) {\n+                                if (segment.text == null || method.startsWith(segment.text)) {\n+                                    suggestions.add(new Suggestion(Suggestion.METHOD, method));\n+                                }\n+                            }\n+                        }\n+                    }\n+                }\n+            }\n+\n+            // generate suggestions for fields\n+            if ((segment.modifiers & AccessMachine.AccessData.FIELD) == AccessMachine.AccessData.FIELD) {\n+                if (resolved != null) {\n+                    PainlessClass pc = lookup.lookupPainlessClass(resolved);\n+\n+                    if (pc != null) {\n+                        if ((segment.modifiers & AccessMachine.AccessData.STATIC) == AccessMachine.AccessData.STATIC) {\n+                            for (String field : pc.staticFields.keySet()) {\n+                                if (segment.text == null || field.startsWith(segment.text)) {\n+                                    suggestions.add(new Suggestion(Suggestion.FIELD, field));\n+                                }\n+                            }\n+                        } else {\n+                            for (String field : pc.fields.keySet()) {\n+                                if (segment.text == null || field.startsWith(segment.text)) {\n+                                    suggestions.add(new Suggestion(Suggestion.FIELD, field));\n+                                }\n+                            }\n+                        }\n+                    }\n+                }\n+            }\n+        // generate suggestions for the parameters of a specific constructor/call/method\n+        } else if ((segment.modifiers & AccessMachine.AccessData.PARAMETERS) == AccessMachine.AccessData.PARAMETERS) {\n+\n+            // generate parameters for a specific constructor\n+            if ((segment.modifiers & AccessMachine.AccessData.CONSTRUCTOR) == AccessMachine.AccessData.CONSTRUCTOR) {\n+                PainlessClass pc = lookup.lookupPainlessClass(lookup.canonicalTypeNameToType(segment.text));\n+\n+                if (pc != null) {\n+                    for (PainlessConstructor pcon : pc.constructors.values()) {\n+                        StringBuilder parameters = new StringBuilder(\" \");\n+                        for (Class<?> type : pcon.typeParameters) {\n+                            parameters.append(PainlessLookupUtility.typeToCanonicalTypeName(type));\n+                            parameters.append(\" \");\n+                        }\n+                        suggestions.add(new Suggestion(Suggestion.PARAMETERS, parameters.toString()));\n+                    }\n+                }\n+            }\n+\n+            // generate parameters for a specific method\n+            if ((segment.modifiers & AccessMachine.AccessData.METHOD) == AccessMachine.AccessData.METHOD) {\n+                if (resolved != null) {\n+                    PainlessClass pc = lookup.lookupPainlessClass(resolved);\n+\n+                    if (pc != null) {\n+                        if ((segment.modifiers & AccessMachine.AccessData.STATIC) == AccessMachine.AccessData.STATIC) {\n+                            for (PainlessMethod pm : pc.staticMethods.values()) {\n+                                if (pm.javaMethod.getName().equals(segment.text)) {\n+                                    StringBuilder parameters = new StringBuilder(\" \");\n+                                    for (Class<?> type : pm.typeParameters) {\n+                                        parameters.append(PainlessLookupUtility.typeToCanonicalTypeName(type));\n+                                        parameters.append(\" \");\n+                                    }\n+                                    suggestions.add(new Suggestion(\"parameters\", parameters.toString()));\n+                                }\n+                            }\n+                        } else {\n+                            for (PainlessMethod pm : pc.methods.values()) {\n+                                if (pm.javaMethod.getName().equals(segment.text)) {\n+                                    StringBuilder parameters = new StringBuilder(\" \");\n+                                    for (Class<?> type : pm.typeParameters) {\n+                                        parameters.append(PainlessLookupUtility.typeToCanonicalTypeName(type));\n+                                        parameters.append(\" \");\n+                                    }\n+                                    suggestions.add(new Suggestion(\"parameters\", parameters.toString()));\n+                                }\n+                            }\n+                        }\n+                    }\n+                }\n+            }\n+        }\n+\n+        return suggestions;\n+    }\n+\n+    /**\n+     * Suggestion contains the type of suggestion along\n+     * with the suggested text.\n+     */\n+    public static class Suggestion {\n+\n+        public static final String VARIABLE = \"variable\";\n+        public static final String TYPE = \"type\";\n+        public static final String USER = \"user\";\n+        public static final String CALL = \"call\";\n+        public static final String METHOD = \"method\";\n+        public static final String FIELD = \"field\";\n+        public static final String PARAMETERS = \"parameters\";\n+\n+        protected final String type;\n+        protected final String text;\n+\n+        public Suggestion(String type, String text) {\n+            this.type = type;\n+            this.text = text;\n+        }\n+\n+        public String getType() {\n+            return type;\n+        }\n+\n+        public String getText() {\n+            return text;\n+        }\n+\n+        @Override\n+        public boolean equals(Object o) {\n+            if (this == o) return true;\n+            if (o == null || getClass() != o.getClass()) return false;\n+            Suggestion that = (Suggestion)o;\n+            return Objects.equals(type, that.type) && Objects.equals(text, that.text);\n+        }\n+\n+        @Override\n+        public int hashCode() {\n+            return Objects.hash(type, text);\n+        }\n+\n+        @Override\n+        public String toString() {\n+            return \"Suggestion{\" +\n+                    \"type='\" + type + '\\'' +\n+                    \", text='\" + text + '\\'' +\n+                    '}';\n+        }\n+    }\n+\n+    /**\n+     * TokenState keeps track of the current token. The state machines\n+     * each increment a single token at a time and make decisions by\n+     * storing state appropriately.\n+     */\n+    protected static class TokenState {\n+\n+        protected final List<? extends Token> tokens;\n+\n+        protected int current = 0;\n+\n+        protected TokenState(List<? extends Token> tokens) {\n+            this.tokens = Collections.unmodifiableList(tokens);\n+        }\n+    }\n+\n+    /**\n+     * FunctionMachine collects information about user-defined functions.\n+     * This is required for suggestions relating to static-style calls,\n+     * and to determine what top-level variables are available.\n+     */\n+    protected static class FunctionMachine {\n+\n+        protected static class FunctionData {\n+\n+            protected String returnType = \"\";\n+            protected String functionName = \"\";\n+            protected final List<String> parameterTypes = new ArrayList<>();\n+            protected final List<String> parameterNames = new ArrayList<>();\n+\n+            protected int bodyStartToken = -1;\n+            protected int bodyEndToken = -1;\n+\n+            @Override\n+            public String toString() {\n+                return \"FunctionState{\" +\n+                        \"returnType='\" + returnType + '\\'' +\n+                        \", functionName='\" + functionName + '\\'' +\n+                        \", parameterTypes=\" + parameterTypes +\n+                        \", parameterNames=\" + parameterNames +\n+                        \", bodyStartToken=\" + bodyStartToken +\n+                        \", bodyEndToken=\" + bodyEndToken +\n+                        '}';\n+            }\n+        }\n+\n+        protected static class FunctionState extends TokenState {\n+\n+            protected int target = 0;\n+\n+            protected String returnType;\n+            protected String functionName;\n+            protected String parameterType;\n+            protected FunctionData functionData;\n+\n+            protected final List<FunctionData> functions = new ArrayList<>();\n+\n+            protected int brackets;\n+\n+            protected FunctionState(List<? extends Token> tokens) {\n+                super(tokens);\n+            }\n+        }\n+\n+        protected static final List<Function<FunctionState, Integer>> fstates;\n+\n+        static {\n+            fstates = new ArrayList<>();\n+            // 0 - possible start of function\n+            fstates.add(fs -> {\n+                Token token = fs.tokens.get(fs.current);\n+                if (token.getType() == SuggestLexer.ATYPE || token.getType() == SuggestLexer.TYPE) {\n+                    // VALID: possible return type for function\n+                    fs.returnType = token.getText();\n+                    return 1;\n+                }\n+                // VALID: not a function\n+                return 0;\n+            });\n+            // 1 - possible function name\n+            fstates.add(fs -> {\n+                Token token = fs.tokens.get(fs.current);\n+                if (token.getType() == SuggestLexer.ID) {\n+                    // VALID: possible function name\n+                    fs.functionName = token.getText();\n+                    return 2;\n+                }\n+                // VALID: not a function\n+                return 0;\n+            });\n+            // 2 - start of parameters\n+            fstates.add(fs -> {\n+                Token token = fs.tokens.get(fs.current);\n+                if (token.getType() == SuggestLexer.LP) {\n+                    // VALID: found a function, record return type and function name\n+                    fs.functionData = new FunctionData();\n+                    fs.functionData.returnType = fs.returnType;\n+                    fs.functionData.functionName = fs.functionName;\n+                    fs.functions.add(fs.functionData);\n+                    return 3;\n+                }\n+                // VALID: not a function\n+                return 0;\n+            });\n+            // 3 - start of a parameter or end of parameters\n+            fstates.add(fs -> {\n+                Token token = fs.tokens.get(fs.current);\n+                if (token.getType() == SuggestLexer.ATYPE || token.getType() == SuggestLexer.TYPE) {\n+                    // VALID: found a parameter type\n+                    fs.parameterType = token.getText();\n+                    return 6;\n+                } else if (token.getType() == SuggestLexer.RP) {\n+                    // VALID: end of function header\n+                    return 4;\n+                } else if (token.getType() == SuggestLexer.LBRACK) {\n+                    // ERROR (process): missing right parenthesis, but found start of function body\n+                    fs.brackets = 1;\n+                    fs.functionData.bodyStartToken = fs.current + 1;\n+                    return 5;\n+                }\n+                // ERROR (ignore): unexpected token, keep looking for a sentinel\n+                return 3;\n+            });\n+            // 4 - start of function body\n+            fstates.add(fs -> {\n+                Token token = fs.tokens.get(fs.current);\n+                if (token.getType() == SuggestLexer.LBRACK) {\n+                    // VALID: found start of function body\n+                    fs.brackets = 1;\n+                    fs.functionData.bodyStartToken = fs.current + 1;\n+                    return 5;\n+                }\n+                // ERROR (ignore): unexpected token, keep looking for a sentinel\n+                return 4;\n+            });\n+            // 5 - possible end of function body\n+            fstates.add(fs -> {\n+                Token token = fs.tokens.get(fs.current);\n+                if (token.getType() == SuggestLexer.LBRACK) {\n+                    // VALID: increase scope\n+                    ++fs.brackets;\n+                } else if (token.getType() == SuggestLexer.RBRACK) {\n+                    // VALID: decrease scope\n+                    --fs.brackets;\n+                    if (fs.brackets == 0) {\n+                        // VALID: end of function body\n+                        fs.functionData.bodyEndToken = fs.current - 1;\n+                        return 0;\n+                    }\n+                }\n+                // VALID: keep looking for end of function body\n+                return 5;\n+            });\n+            // 6 - parameter name\n+            fstates.add(fs -> {\n+                Token token = fs.tokens.get(fs.current);\n+                if (token.getType() == SuggestLexer.ID) {\n+                    // VALID: found a parameter name, record parameter type and name\n+                    fs.functionData.parameterTypes.add(fs.parameterType);\n+                    fs.functionData.parameterNames.add(token.getText());\n+                    return 7;\n+                } else if (token.getType() == SuggestLexer.RP) {\n+                    // ERROR (process): missing parameter name, but found end of function header\n+                    return 4;\n+                } else if (token.getType() == SuggestLexer.LBRACK) {\n+                    // ERROR (process): missing parameter name, but found start of function body\n+                    return 5;\n+                }\n+                // ERROR (ignore): unexpected token, keep looking for a sentinel\n+                return 6;\n+            });\n+            // 7 - start of another parameter or end of parameters\n+            fstates.add(fs -> {\n+                Token token = fs.tokens.get(fs.current);\n+                if (token.getType() == SuggestLexer.COMMA) {\n+                    // VALID: found comma, look for another parameter\n+                    return 8;\n+                } else if (token.getType() == SuggestLexer.RP) {\n+                    // VALID: end of function header\n+                    return 4;\n+                } else if (token.getType() == SuggestLexer.LBRACK) {\n+                    // ERROR (process): missing comma or right parenthesis, but found start of function body\n+                    return 5;\n+                }\n+                // ERROR (ignore): unexpected token, keep looking for a sentinel\n+                return 7;\n+            });\n+            // 8 - start of another parameter\n+            fstates.add(fs -> {\n+                Token token = fs.tokens.get(fs.current);\n+                if (token.getType() == SuggestLexer.ATYPE || token.getType() == SuggestLexer.TYPE) {\n+                    // VALID: found a parameter type\n+                    fs.parameterType = token.getText();\n+                    return 6;\n+                } else if (token.getType() == SuggestLexer.RP) {\n+                    // ERROR (process): missing parameter type, but found end of function header\n+                    return 4;\n+                } else if (token.getType() == SuggestLexer.LBRACK) {\n+                    // ERROR (process): missing parameter type, but found start of function body\n+                    return 5;\n+                }\n+                // ERROR (ignore): unexpected token, keep looking for a sentinel\n+                return 8;\n+            });\n+        }\n+\n+        protected static void walk(FunctionState fs) {\n+            while (fs.current < fs.tokens.size()) {\n+                Function<FunctionState, Integer> state = fstates.get(fs.target);\n+                fs.target = state.apply(fs);\n+                ++fs.current;\n+            }\n+        }\n+\n+        private FunctionMachine() {\n+            // do not instantiate\n+        }\n+    }\n+\n+    /**\n+     * LambdaMachine collects information about lambdas by doing a pass through\n+     * each token in reverse order. This allows for easier collection of\n+     * parameter types and parameter names by using the arrow '->' token as a\n+     * sentinel. Skipping the parameters is possible in BlockMachine using the\n+     * data collected here.\n+     */\n+    protected static class LambdaMachine {\n+\n+        protected static class LambdaData {\n+\n+            protected final List<String> parameterTypes = new ArrayList<>();\n+            protected final List<String> parameterNames = new ArrayList<>();\n+\n+            protected int headerStartToken = -1;\n+            protected int headerEndToken = -1;\n+\n+            @Override\n+            public String toString() {\n+                return \"LambdaData{\" +\n+                        \"parameterTypes=\" + parameterTypes +\n+                        \", parameterNames=\" + parameterNames +\n+                        \", headerStartToken=\" + headerStartToken +\n+                        \", headerEndToken=\" + headerEndToken +\n+                        '}';\n+            }\n+        }\n+\n+        protected static class LambdaState extends TokenState {\n+\n+            protected int target = 0;\n+\n+            protected LambdaData lambdaData;\n+\n+            protected final List<LambdaMachine.LambdaData> lambdas = new ArrayList<>();\n+\n+            protected LambdaState(List<? extends Token> tokens) {\n+                super(tokens);\n+            }\n+        }\n+\n+        protected static final List<Function<LambdaMachine.LambdaState, Integer>> lstates;\n+\n+        static {\n+            lstates = new ArrayList<>();\n+\n+            // 0 - possible start of a lambda header\n+            lstates.add(ls -> {\n+                Token token = ls.tokens.get(ls.current);\n+                if (token.getType() == SuggestLexer.ARROW) {\n+                    // VALID: found start of a lambda header\n+                    ls.lambdaData = new LambdaData();\n+                    ls.lambdas.add(ls.lambdaData);\n+                    ls.lambdaData.headerStartToken = ls.current;\n+                    ls.lambdaData.headerEndToken = ls.current;\n+                    return 1;\n+                }\n+                // VALID: not a start of a lambda header\n+                return 0;\n+            });\n+            // 1 - parameter name or start of parameters\n+            lstates.add(ls -> {\n+                Token token = ls.tokens.get(ls.current);\n+                if (token.getType() == SuggestLexer.ID) {\n+                    // VALID: found a singular parameter name\n+                    ls.lambdaData.headerStartToken = ls.current;\n+                    ls.lambdaData.parameterTypes.add(\"def\");\n+                    ls.lambdaData.parameterNames.add(token.getText());\n+                } else if (token.getType() == SuggestLexer.ARROW) {\n+                    // ERROR (process): unexpected token, found a possible new start of a lambda header\n+                    ls.lambdaData = new LambdaData();\n+                    ls.lambdas.add(ls.lambdaData);\n+                    ls.lambdaData.headerStartToken = ls.current;\n+                    ls.lambdaData.headerEndToken = ls.current;\n+                    return 1;\n+                } else if (token.getType() == SuggestLexer.RP) {\n+                    // VALID: found a right parenthesis\n+                    return 2;\n+                }\n+                // ERROR (ignore): unexpected token, start looking for a new lambda header\n+                return 0;\n+            });\n+            // 2 - parameter name or end of parameters\n+            lstates.add(ls -> {\n+                Token token = ls.tokens.get(ls.current);\n+                if (token.getType() == SuggestLexer.LP) {\n+                    // VALID: found a left parenthesis, end of lambda header\n+                    ls.lambdaData.headerStartToken = ls.current;\n+                    return 0;\n+                } else if (token.getType() == SuggestLexer.ID) {\n+                    // VALID: found a parameter name\n+                    ls.lambdaData.headerStartToken = ls.current;\n+                    ls.lambdaData.parameterTypes.add(\"def\");\n+                    ls.lambdaData.parameterNames.add(token.getText());\n+                    return 3;\n+                } else if (token.getType() == SuggestLexer.ARROW) {\n+                    // ERROR (process): unexpected token, found a possible new start of a lambda header\n+                    ls.lambdaData = new LambdaData();\n+                    ls.lambdas.add(ls.lambdaData);\n+                    ls.lambdaData.headerStartToken = ls.current;\n+                    ls.lambdaData.headerEndToken = ls.current;\n+                    return 1;\n+                }\n+                // ERROR (ignore): unexpected token, start looking for a new lambda header\n+                return 0;\n+            });\n+            // 3 - parameter type or end of parameters\n+            lstates.add(ls -> {\n+                Token token = ls.tokens.get(ls.current);\n+                if (token.getType() == SuggestLexer.LP) {\n+                    // VALID: found a left parenthesis, end of lambda header\n+                    ls.lambdaData.headerStartToken = ls.current;\n+                    return 0;\n+                } else if (token.getType() == SuggestLexer.ATYPE || token.getType() == SuggestLexer.TYPE) {\n+                    // VALID: found a type to complete a parameter declaration\n+                    ls.lambdaData.headerStartToken = ls.current;\n+                    ls.lambdaData.parameterTypes.set(ls.lambdaData.parameterTypes.size() - 1, token.getText());\n+                    return 4;\n+                } else if (token.getType() == SuggestLexer.COMMA) {\n+                    // VALID: found a comma to complete a parameter declaration and specify another\n+                    return 2;\n+                } else if (token.getType() == SuggestLexer.ARROW) {\n+                    // ERROR (process): unexpected token, found a possible new start of a lambda header\n+                    ls.lambdaData = new LambdaData();\n+                    ls.lambdas.add(ls.lambdaData);\n+                    ls.lambdaData.headerStartToken = ls.current;\n+                    ls.lambdaData.headerEndToken = ls.current;\n+                    return 1;\n+                }\n+                // ERROR (ignore): unexpected token, start looking for a new lambda header\n+                return 0;\n+            });\n+            // 4\n+            lstates.add(ls -> {\n+                Token token = ls.tokens.get(ls.current);\n+                if (token.getType() == SuggestLexer.LP) {\n+                    // VALID: found a left parenthesis, end of lambda header\n+                    ls.lambdaData.headerStartToken = ls.current;\n+                    return 0;\n+                } if (token.getType() == SuggestLexer.COMMA) {\n+                    // VALID: found a comma to complete a parameter declaration and specify another\n+                    return 2;\n+                } else if (token.getType() == SuggestLexer.ARROW) {\n+                    // ERROR (process): unexpected token, found a possible new start of a lambda header\n+                    ls.lambdaData = new LambdaData();\n+                    ls.lambdas.add(ls.lambdaData);\n+                    ls.lambdaData.headerStartToken = ls.current;\n+                    ls.lambdaData.headerEndToken = ls.current;\n+                    return 1;\n+                }\n+                // ERROR (ignore): unexpected token, start looking for a new lambda header\n+                return 0;\n+            });\n+        }\n+\n+        protected static void walk(LambdaMachine.LambdaState ls) {\n+            ls.current = ls.tokens.size() - 1;\n+\n+            while (ls.current >= 0) {\n+                Function<LambdaMachine.LambdaState, Integer> state = lstates.get(ls.target);\n+                ls.target = state.apply(ls);\n+                --ls.current;\n+            }\n+        }\n+\n+        private LambdaMachine() {\n+            // do not instantiate\n+        }\n+    }\n+\n+    /**\n+     * BlockMachine collects data about declarations within each\n+     * scope. This allows for suggestions based on variables that are\n+     * available within the appropriate scope. BlockMachine maintains\n+     * two separate pieces of state that combine to give an accurate\n+     * representation of current variables in a scope. BlockMachine must\n+     * maintain the appropriate scope through a stack with a potentially\n+     * different delimiter for a scope's closure. BlockMachine must\n+     * also use a state machine to track declarations and adds\n+     * new variables to the current scope. While these are both within\n+     * BlockMachine, the state transitions are handled separately.\n+     */\n+    protected static class BlockMachine {\n+\n+        protected static class BlockData {\n+\n+            protected final BlockData parent;\n+\n+            protected int type;\n+            protected int sentinel;\n+            protected boolean pop = false;\n+            protected int parens = 0;\n+            protected int braces = 0;\n+\n+            protected int decltarget = 0;\n+            protected String decltype = null;\n+            protected int declparens = 0;\n+            protected int declbraces = 0;\n+\n+            protected final Map<String, String> variables = new HashMap<>();\n+\n+            protected BlockData(BlockData parent, int type, int sentinel) {\n+                this.parent = parent;\n+                this.type = type;\n+                this.sentinel = sentinel;\n+            }\n+\n+            protected Map<String, String> getVariables() {\n+                Map<String, String> rtn = new HashMap<>(variables);\n+\n+                if (parent != null) {\n+                    rtn.putAll(parent.getVariables());\n+                }\n+\n+                return rtn;\n+            }\n+\n+            @Override\n+            public String toString() {\n+                StringBuilder builder = new StringBuilder();\n+                builder.append(\"[\");\n+                builder.append(type == -1 ? \"EOF\" : SuggestLexer.ruleNames[type - 1]);\n+                builder.append(\" : \");\n+                builder.append(sentinel == -1 ? \"EOF\" : SuggestLexer.ruleNames[sentinel - 1]);\n+                builder.append(\" : \");\n+                builder.append(variables);\n+                builder.append(\"]\");\n+\n+                if (parent != null) {\n+                    builder.append(\" \");\n+                    builder.append(parent.toString());\n+                }\n+\n+                return builder.toString();\n+            }\n+        }\n+\n+        protected static class BlockState extends TokenState {\n+\n+            protected final Map<Integer, LambdaMachine.LambdaData> mld;\n+\n+            protected BlockData scope = new BlockData(null, SuggestLexer.EOF, SuggestLexer.EOF);\n+\n+            protected BlockState(List<? extends Token> tokens, Map<Integer, LambdaMachine.LambdaData> mld) {\n+                super(tokens);\n+                this.mld = mld;\n+            }\n+        }\n+\n+        protected static final List<Function<BlockState, Integer>> declstates;\n+\n+        static {\n+            declstates = new ArrayList<>();\n+\n+            // 0 - possible start of a declaration\n+            declstates.add(bs -> {\n+                Token token = bs.tokens.get(bs.current);\n+                if (token.getType() == SuggestLexer.ATYPE || token.getType() == SuggestLexer.TYPE) {\n+                    // VALID: found a type, possible start of a declaration\n+                    bs.scope.decltype = token.getText();\n+                    return 1;\n+                } else if (token.getType() == SuggestLexer.IN) {\n+                    // VALID: found a for each loop, add the variable to the scope if previous is a name\n+                    Token prev = bs.current > 0 ? bs.tokens.get(bs.current - 1) : null;\n+\n+                    if (prev != null && prev.getType() == SuggestLexer.ID) {\n+                        bs.scope.variables.put(prev.getText(), \"def\");\n+                    }\n+                }\n+                // VALID: no declaration found, continue looking for sentinel\n+                return 0;\n+            });\n+            // 1 - possible declaration name\n+            declstates.add(bs -> {\n+                Token token = bs.tokens.get(bs.current);\n+                if (token.getType() == SuggestLexer.ATYPE || token.getType() == SuggestLexer.TYPE) {\n+                    // ERROR (process): found a type, possible start of a declaration\n+                    bs.scope.decltype = token.getText();\n+                    return 1;\n+                } else if (token.getType() == SuggestLexer.ID) {\n+                    // VALID: found a declaration name, add the variable to the scope\n+                    bs.scope.variables.put(token.getText(), bs.scope.decltype);\n+                    return 2;\n+                }\n+                // VALID: no declaration found, continue looking for sentinel\n+                return 0;\n+            });\n+            // 2 - possible multiple names in a declaration\n+            declstates.add(bs -> {\n+                Token token = bs.tokens.get(bs.current);\n+                if (token.getType() == SuggestLexer.COMMA) {\n+                    // VALID: found a comma, look for another declaration name\n+                    return 1;\n+                } else if (token.getType() == SuggestLexer.ASSIGN) {\n+                    // VALID: found an assignment\n+                    return 3;\n+                } else if (token.getType() == SuggestLexer.ATYPE || token.getType() == SuggestLexer.TYPE) {\n+                    // ERROR (process): found a type, possible start of a declaration\n+                    bs.scope.decltype = token.getText();\n+                    return 1;\n+                }\n+                // VALID: declaration completed, look for next possible declaration\n+                return 0;\n+            });\n+            // 3 - skip an assignment expression\n+            declstates.add(bs -> {\n+                Token token = bs.tokens.get(bs.current);\n+                if (token.getType() == SuggestLexer.COMMA && bs.scope.declparens == 0 && bs.scope.declbraces == 0) {\n+                    return 1;\n+                } else if (token.getType() == SuggestLexer.LP) {\n+                    ++bs.scope.declparens;\n+                    return 3;\n+                } else if (token.getType() == SuggestLexer.RP) {\n+                    --bs.scope.declparens;\n+                    return 3;\n+                } else if (token.getType() == SuggestLexer.LBRACE) {\n+                    ++bs.scope.declbraces;\n+                    return 3;\n+                } else if (token.getType() == SuggestLexer.RBRACE) {\n+                    --bs.scope.declbraces;\n+                } else if (token.getType() == SuggestLexer.SEMICOLON) {\n+                    return 0;\n+                }\n+                return 3;\n+            });\n+        }\n+\n+        protected static void scope(BlockState bs) {\n+            int token = bs.tokens.get(bs.current).getType();\n+            int prev = bs.current > 0 ? bs.tokens.get(bs.current - 1).getType() : SuggestLexer.EOF;\n+\n+            if (bs.scope.pop) {\n+                // NOTE: current scope is marked for closure\n+\n+                if (token == SuggestLexer.CATCH && (bs.scope.type == SuggestLexer.TRY || bs.scope.type == SuggestLexer.CATCH)) {\n+                    // CLOSE: found a catch, close the sibling try or catch scope\n+                    bs.scope = bs.scope.parent;\n+                } else if (token == SuggestLexer.ELSE) {\n+                    while (bs.scope.type != SuggestLexer.IF && bs.scope.sentinel == SuggestLexer.SEMICOLON) {\n+                        // CLOSE: close scopes until we reach the sibling if scope for this specific else\n+                        bs.scope = bs.scope.parent;\n+                    }\n+\n+                    if (bs.scope.type == SuggestLexer.IF) {\n+                        // CLOSE: close the sibling if scope\n+                        bs.scope = bs.scope.parent;\n+                    }\n+                } else {\n+                    // CLOSE: close the child scope\n+                    bs.scope = bs.scope.parent;\n+\n+                    while (bs.scope.sentinel == SuggestLexer.SEMICOLON) {\n+                        // CLOSE: a scope without brackets may require that multiple child scopes close based on a single delimiter\n+                        bs.scope = bs.scope.parent;\n+                    }\n+                }\n+            }\n+\n+            LambdaMachine.LambdaData ld = bs.mld.get(bs.current);\n+\n+            if (ld != null) {\n+                // OPEN: open a lambda scope and skip the previously processed header\n+                bs.scope = new BlockData(bs.scope, SuggestLexer.ARROW, SuggestLexer.EOF);\n+\n+                for (int param = 0; param < ld.parameterTypes.size(); ++param) {\n+                    // NOTE: add lambda parameters to the scope\n+                    bs.scope.variables.put(ld.parameterNames.get(param), ld.parameterTypes.get(param));\n+                }\n+\n+                // NOTE: skip to the end of the pre-processed lambda header\n+                bs.current = ld.headerEndToken;\n+                token = SuggestLexer.ARROW;\n+            } else if (token == SuggestLexer.WHILE || token == SuggestLexer.IF || token == SuggestLexer.ELSE) {\n+                if (prev == SuggestLexer.ELSE && token == SuggestLexer.IF) {\n+                    // SWITCH: found an else if statement, so just switch the scope type\n+                    bs.scope.type = SuggestLexer.IF;\n+                } else {\n+                    // OPEN: open a new scope for a while/if/else statement with a semicolon delimiter\n+                    bs.scope = new BlockData(bs.scope, token, SuggestLexer.SEMICOLON);\n+                }\n+            } else if (token == SuggestLexer.FOR) {\n+                // OPEN: open a new scope for a for loop with a right parenthesis delimiter\n+                bs.scope = new BlockData(bs.scope, token, SuggestLexer.RP);\n+            } else if (token == SuggestLexer.DO || token == SuggestLexer.TRY || token == SuggestLexer.CATCH) {\n+                // OPEN: open a new scope for a do/try/catch statement with a right bracket delimiter\n+                bs.scope = new BlockData(bs.scope, token, SuggestLexer.RBRACK);\n+            } else if (token == SuggestLexer.LBRACK) {\n+                if (bs.scope.sentinel == SuggestLexer.SEMICOLON || bs.scope.sentinel == SuggestLexer.RP) {\n+                    // NOTE: found a left bracket so switch semicolon or right parenthesis delimiters to\n+                    bs.scope.sentinel = SuggestLexer.RBRACK;\n+                }\n+            } else if (token == SuggestLexer.LP) {\n+                // NOTE: track our parenthesis depth\n+                ++bs.scope.parens;\n+            } else if (token == SuggestLexer.RP) {\n+                // NOTE: track our parenthesis depth\n+                bs.scope.parens = Math.max(0, bs.scope.parens - 1);\n+\n+                if (bs.scope.sentinel == SuggestLexer.RP && bs.scope.parens == 0) {\n+                    // SWITCH: switch a right parenthesis delimiter to a semicolon delimiter\n+                    bs.scope.sentinel = SuggestLexer.SEMICOLON;\n+                }\n+            } else if (token == SuggestLexer.LBRACE) {\n+                // NOTE: track our brace depth\n+                ++bs.scope.braces;\n+            } else if (token == SuggestLexer.RBRACE) {\n+                // NOTE: track our brace depth\n+                bs.scope.braces = Math.max(0, bs.scope.braces - 1);\n+            }\n+\n+            if (bs.scope.type == SuggestLexer.ARROW) {\n+                if (token == SuggestLexer.COMMA || token == SuggestLexer.RP && bs.scope.parens == 0 && bs.scope.braces == 0) {\n+                    // CLOSE: close the current lambda scope\n+                    bs.scope = bs.scope.parent;\n+                }\n+            } else if (token == bs.scope.sentinel) {\n+                if (bs.scope.type == SuggestLexer.DO) {\n+                    // SWITCH: update a closed do scope to a while scope\n+                    bs.scope.type = SuggestLexer.WHILE;\n+                    bs.scope.sentinel = SuggestLexer.SEMICOLON;\n+                } else {\n+                    // NOTE: mark the current scope for closure\n+                    bs.scope.pop = true;\n+                }\n+            }\n+        }\n+\n+        protected static void walk(BlockState bs) {\n+            while (bs.current < bs.tokens.size()) {\n+                scope(bs);\n+                Function<BlockState, Integer> declstate = declstates.get(bs.scope.decltarget);\n+                bs.scope.decltarget = declstate.apply(bs);\n+                ++bs.current;\n+            }\n+        }\n+\n+        private BlockMachine() {\n+            // do not instantiate\n+        }\n+    }\n+\n+    /**\n+     * AccessMachine builds a chain of type resolvable pieces processing\n+     * each token from the end in reverse order until it reaches a\n+     * piece that is not resolvable. Upon completion, the AccessData\n+     * chain is used to resolve types and offer suggestions based on\n+     * data collected from the other machines. Sometimes no suggestions\n+     * are available depending on whether the types exist or if\n+     * the result is a def type.\n+     */\n+    protected static class AccessMachine {\n+\n+        protected static class AccessData {\n+\n+            protected static final int RESOLVE = 1 << 0;     // piece to resolve type from\n+            protected static final int SUGGEST = 1 << 1;     // piece to generate suggestions from\n+            protected static final int ID = 1 << 2;          // piece that is a simple id\n+            protected static final int TYPE = 1 << 3;        // piece that is a known type\n+            protected static final int CALL = 1 << 4;        // piece that is a loose call\n+            protected static final int STATIC = 1 << 5;      // piece that is static\n+            protected static final int METHOD = 1 << 6;      // piece that a method call\n+            protected static final int FIELD = 1 << 7;       // piece that is a field access\n+            protected static final int CONSTRUCTOR = 1 << 8; // piece that is a constructor\n+            protected static final int INDEX = 1 << 9;       // piece that is an index\n+            protected static final int NUMBER = 1 << 10;     // piece that a number\n+            protected static final int PARAMETERS = 1 << 12; // piece that is an open parenthesis\n+\n+            protected AccessData child;\n+            protected int modifiers;\n+            protected String text;\n+            protected int arity;\n+\n+            protected AccessData(AccessData child, int modifiers, String text, int arity) {\n+                this.child = child;\n+                this.modifiers = modifiers;\n+                this.text = text;\n+                this.arity = arity;\n+            }\n+\n+            @Override\n+            public String toString() {\n+                String mods = \"[ \";\n+\n+                if ((modifiers & RESOLVE) == RESOLVE) {\n+                    mods += \"RESOLVE \";\n+                }\n+                if ((modifiers & SUGGEST) == SUGGEST) {\n+                    mods += \"SUGGEST \";\n+                }\n+                if ((modifiers & ID) == ID) {\n+                    mods += \"ID \";\n+                }\n+                if ((modifiers & TYPE) == TYPE) {\n+                    mods += \"TYPE \";\n+                }\n+                if ((modifiers & CALL) == CALL) {\n+                    mods += \"CALL \";\n+                }\n+                if ((modifiers & STATIC) == STATIC) {\n+                    mods += \"STATIC \";\n+                }\n+                if ((modifiers & METHOD) == METHOD) {\n+                    mods += \"METHOD \";\n+                }\n+                if ((modifiers & FIELD) == FIELD) {\n+                    mods += \"FIELD \";\n+                }\n+                if ((modifiers & CONSTRUCTOR) == CONSTRUCTOR) {\n+                    mods += \"CONSTRUCTOR \";\n+                }\n+                if ((modifiers & INDEX) == INDEX) {\n+                    mods += \"INDEX \";\n+                }\n+                if ((modifiers & NUMBER) == NUMBER) {\n+                    mods += \"NUMBER \";\n+                }\n+                if ((modifiers & PARAMETERS) == PARAMETERS) {\n+                    mods += \"PARAMETERS \";\n+                }\n+\n+                mods += \"]\";\n+\n+                return \"Segment{\" +\n+                        \"child=\" + child +\n+                        \", modifiers=\" + mods +\n+                        \", text='\" + text + '\\'' +\n+                        \", arity=\" + arity +\n+                        '}';\n+            }\n+        }\n+\n+        protected static class AccessState extends TokenState {\n+\n+            protected int target = 0;\n+            AccessData segment;\n+\n+            int brackets = 0;\n+            int parens = 0;\n+            int braces = 0;\n+\n+            protected AccessState(List<? extends Token> tokens) {\n+                super(tokens);\n+            }\n+        }\n+\n+        protected static final List<Function<AccessState, Integer>> astates;\n+\n+        static {\n+            astates = new ArrayList<>();\n+\n+            // 0 - possible piece to generate suggestions from\n+            astates.add(as -> {\n+                Token token = as.tokens.get(as.current);\n+                if (token.getType() == SuggestLexer.ID || token.getType() == SuggestLexer.TYPE) {\n+                    // VALID: found a name to generate suggestions from\n+                    as.segment = new AccessData(\n+                            null, AccessData.SUGGEST | AccessData.TYPE | AccessData.ID | AccessData.CALL, token.getText(), -1);\n+                    return as.current == 0 ? -2 : 1;\n+                } else if (token.getType() == SuggestLexer.LP) {\n+                    // VALID: found a possible call/method to generate suggestions for\n+                    as.segment = new AccessData(null, AccessData.PARAMETERS, null, -1);\n+                    return 2;\n+                } else if (token.getType() == SuggestLexer.DOT || token.getType() == SuggestLexer.NSDOT) {\n+                    // VALID: found a dot to generate suggestions for\n+                    as.segment = new AccessData(null, AccessData.SUGGEST | AccessData.FIELD | AccessData.METHOD, null, -1);\n+                    return 4;\n+                } else if (token.getType() == SuggestLexer.DOTID) {\n+                    // VALID: found a name to generate suggestions from\n+                    as.segment = new AccessData(null, AccessData.SUGGEST | AccessData.FIELD | AccessData.METHOD, token.getText(), -1);\n+                    return 3;\n+                }\n+                // VALID: cannot generate suggestions\n+                return -1;\n+            });\n+            // 1 - check for declaration or constructor\n+            astates.add(as -> {\n+                Token token = as.tokens.get(as.current);\n+                if (token.getType() == SuggestLexer.TYPE || token.getType() == SuggestLexer.ATYPE) {\n+                    // VALID: found a declaration, do not generate suggestions\n+                    return -1;\n+                } else if (token.getType() == SuggestLexer.NEW) {\n+                    // VALID: found an instantiation, generate suggestions\n+                    as.segment = new AccessData(null, AccessData.SUGGEST | AccessData.TYPE, token.getText(), -1);\n+                }\n+                // VALID: generate suggestions\n+                return -2;\n+            });\n+            // 2 - check for valid open parenthesis\n+            astates.add(as -> {\n+                Token token = as.tokens.get(as.current);\n+                if (token.getType() == SuggestLexer.TYPE) {\n+                    // VALID: found a constructor\n+                    as.segment.modifiers |= AccessData.CONSTRUCTOR;\n+                    as.segment.text = token.getText();\n+                    return 9;\n+                } else if (token.getType() == SuggestLexer.ID) {\n+                    // VALID: found a call, generate suggestions\n+                    as.segment.modifiers |= AccessData.CALL;\n+                    as.segment.text = token.getText();\n+                    return -2;\n+                } else if (token.getType() == SuggestLexer.DOTID) {\n+                    // VALID: found a method\n+                    as.segment.modifiers |= AccessData.METHOD;\n+                    as.segment.text = token.getText();\n+                    return 3;\n+                }\n+                // VALID: cannot generate suggestions\n+                return -1;\n+            });\n+            // 3 - check for valid method/field\n+            astates.add(as -> {\n+                Token token = as.tokens.get(as.current);\n+                if (token.getType() == SuggestLexer.DOT || token.getType() == SuggestLexer.NSDOT) {\n+                    // VALID: found a dot\n+                    return 4;\n+                }\n+\n+                // ERROR (ignore): cannot generate suggestions\n+                return -1;\n+            });\n+            // 4 - look for a resolvable piece from a dot\n+            astates.add(as -> {\n+                Token token = as.tokens.get(as.current);\n+                if (token.getType() == SuggestLexer.ID) {\n+                    // VALID: found a variable, generate suggestions\n+                    as.segment = new AccessData(as.segment, AccessData.RESOLVE | AccessData.ID, token.getText(), -1);\n+                    return -2;\n+                } else if (token.getType() == SuggestLexer.TYPE || token.getType() == SuggestLexer.ATYPE) {\n+                    // VALID: found a type, generate suggestions\n+                    as.segment.modifiers |= AccessData.STATIC;\n+                    as.segment = new AccessData(as.segment, AccessData.RESOLVE | AccessData.TYPE, token.getText(), -1);\n+                    return -2;\n+                } else if (token.getType() == SuggestLexer.DOTID) {\n+                    // VALID: found a method/field\n+                    as.segment = new AccessData(as.segment, AccessData.RESOLVE | AccessData.FIELD, token.getText(), -1);\n+                    return 3;\n+                } else if (token.getType() == SuggestLexer.DOTINTEGER) {\n+                    // VALID: found a list access\n+                    as.segment = new AccessData(as.segment, AccessData.RESOLVE | AccessData.NUMBER, token.getText(), -1);\n+                    return 3;\n+                } else if (token.getType() == SuggestLexer.RBRACE) {\n+                    // VALID: found an index access\n+                    as.segment = new AccessData(as.segment, AccessData.RESOLVE | AccessData.INDEX, null, -1);\n+                    return 5;\n+                } else if (token.getType() == SuggestLexer.RP) {\n+                    // VALID: found a possible call/method\n+                    as.segment = new AccessData(as.segment, AccessData.RESOLVE, null, 0);\n+                    return 7;\n+                }\n+                // VALID: cannot generate suggestions\n+                return -1;\n+            });\n+            // 5 - look for a brace access completion\n+            astates.add(as -> {\n+                Token token = as.tokens.get(as.current);\n+                if (token.getType() == SuggestLexer.LBRACE) {\n+                    if (as.brackets == 0 && as.parens == 0 && as.braces == 0) {\n+                        // VALID: found a left brace\n+                        return 6;\n+                    } else {\n+                        --as.braces;\n+                    }\n+                } else if (token.getType() == SuggestLexer.RBRACE) {\n+                    ++as.braces;\n+                } else if (token.getType() == SuggestLexer.LP) {\n+                    --as.parens;\n+                } else if (token.getType() == SuggestLexer.RP) {\n+                    ++as.parens;\n+                } else if (token.getType() == SuggestLexer.LBRACK) {\n+                    --as.brackets;\n+                } else if (token.getType() == SuggestLexer.RBRACK) {\n+                    ++as.brackets;\n+                }\n+\n+                if (as.brackets < 0 || as.parens < 0 || as.braces < 0) {\n+                    // ERROR (ignore): cannot track brackets/parens/braces, cannot generate suggestions\n+                    return -1;\n+                }\n+\n+                // VALID: continue looking for a sentinel to complete the brace access\n+                return 5;\n+            });\n+            // 6 - look for a resolvable piece from a brace\n+            astates.add(as -> {\n+                Token token = as.tokens.get(as.current);\n+                if (token.getType() == SuggestLexer.ID) {\n+                    // VALID: found a variable, generate suggestions\n+                    as.segment = new AccessData(as.segment, AccessData.RESOLVE | AccessData.ID, token.getText(), -1);\n+                    return -2;\n+                } else if (token.getType() == SuggestLexer.DOTID) {\n+                    // VALID: found a method/field\n+                    as.segment = new AccessData(as.segment, AccessData.RESOLVE | AccessData.FIELD, token.getText(), -1);\n+                    return 3;\n+                } else if (token.getType() == SuggestLexer.RBRACE) {\n+                    // VALID: found an index access\n+                    as.segment = new AccessData(as.segment, AccessData.RESOLVE | AccessData.INDEX, null, -1);\n+                    return 5;\n+                } else if (token.getType() == SuggestLexer.RP) {\n+                    // VALID: found a possible call/method\n+                    as.segment = new AccessData(as.segment, AccessData.RESOLVE, null, 0);\n+                    return 7;\n+                }\n+                // VALID: cannot generate suggestions\n+                return -1;\n+            });\n+            // 7 - look for a call/method parenthesis completion\n+            astates.add(as -> {\n+                Token token = as.tokens.get(as.current);\n+                if (token.getType() == SuggestLexer.LP) {\n+                    if (as.brackets == 0 && as.parens == 0 && as.braces == 0) {\n+                        // VALID: found a left parenthesis\n+                        return 8;\n+                    } else {\n+                        --as.parens;\n+                    }\n+                } else if (token.getType() == SuggestLexer.COMMA) {\n+                    if (as.brackets == 0 && as.parens == 0 && as.braces == 0) {\n+                        // VALID: found a comma for an additional argument\n+                        ++as.segment.arity;\n+                    }\n+                } else if (token.getType() == SuggestLexer.RP) {\n+                    ++as.parens;\n+                } else if (token.getType() == SuggestLexer.LBRACE) {\n+                    --as.braces;\n+                } else if (token.getType() == SuggestLexer.RBRACE) {\n+                    ++as.braces;\n+                } else if (token.getType() == SuggestLexer.LBRACK) {\n+                    --as.brackets;\n+                } else if (token.getType() == SuggestLexer.RBRACK) {\n+                    ++as.brackets;\n+                }\n+\n+                if (as.brackets < 0 || as.parens < 0 || as.braces < 0) {\n+                    // ERROR (ignore): cannot track brackets/parens/braces, cannot generate suggestions\n+                    return -1;\n+                }\n+\n+                if (as.segment.arity == 0) {\n+                    // NOTE: assume arity is 1 if a left parenthesis isn't immediately found\n+                    as.segment.arity = 1;\n+                }\n+\n+                // VALID: continue looking for a sentinel to complete the call/method parenthesis\n+                return 7;\n+            });\n+            // 8 - look for call/method completion\n+            astates.add(as -> {\n+                Token token = as.tokens.get(as.current);\n+                if (token.getType() == SuggestLexer.ID) {\n+                    // VALID: found a call, generate suggestions\n+                    as.segment.modifiers |= AccessData.CALL;\n+                    as.segment.text = token.getText();\n+                    return -2;\n+                } else if (token.getType() == SuggestLexer.DOTID) {\n+                    // VALID: found a method\n+                    as.segment.modifiers |= AccessData.METHOD;\n+                    as.segment.text = token.getText();\n+                    return 3;\n+                } else if (token.getType() == SuggestLexer.TYPE) {\n+                    // VALID: found a constructor\n+                    as.segment.modifiers |= AccessData.CONSTRUCTOR;\n+                    as.segment.text = token.getText();\n+                    return 9;\n+                }\n+                // VALID: cannot generate suggestions\n+                return -1;\n+            });\n+            // 9 - validate constructor\n+            astates.add(as -> {\n+                Token token = as.tokens.get(as.current);\n+                if (token.getType() == SuggestLexer.NEW) {\n+                    // VALID: generate suggestions\n+                    return -2;\n+                }\n+                // ERROR (ignore): cannot generate suggestions\n+                return -1;\n+            });\n+        }\n+\n+        protected static void walk(AccessMachine.AccessState as) {\n+            as.current = as.tokens.size() - 1;\n+\n+            while (as.current >= 0) {\n+                Function<AccessMachine.AccessState, Integer> state = astates.get(as.target);\n+                as.target = state.apply(as);\n+\n+                if (as.target < 0) {\n+                    break;\n+                }\n+\n+                --as.current;\n+            }\n+        }\n+\n+        protected AccessMachine() {\n+            // do not instantiate\n+        }\n+    }\n+}"
  },
  {
    "sha": "16167f4cbaf689c662d7fdf4744ddde86bc376c4",
    "filename": "modules/lang-painless/src/main/java/org/elasticsearch/painless/action/PainlessSuggestAction.java",
    "status": "added",
    "additions": 328,
    "deletions": 0,
    "changes": 328,
    "blob_url": "https://github.com/elastic/elasticsearch/blob/d0893e5ae135f0ac881e86cf558fe67a9c65268d/modules/lang-painless/src/main/java/org/elasticsearch/painless/action/PainlessSuggestAction.java",
    "raw_url": "https://github.com/elastic/elasticsearch/raw/d0893e5ae135f0ac881e86cf558fe67a9c65268d/modules/lang-painless/src/main/java/org/elasticsearch/painless/action/PainlessSuggestAction.java",
    "contents_url": "https://api.github.com/repos/elastic/elasticsearch/contents/modules/lang-painless/src/main/java/org/elasticsearch/painless/action/PainlessSuggestAction.java?ref=d0893e5ae135f0ac881e86cf558fe67a9c65268d",
    "patch": "@@ -0,0 +1,328 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License\n+ * 2.0 and the Server Side Public License, v 1; you may not use this file except\n+ * in compliance with, at your election, the Elastic License 2.0 or the Server\n+ * Side Public License, v 1.\n+ */\n+\n+package org.elasticsearch.painless.action;\n+\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.ActionRequest;\n+import org.elasticsearch.action.ActionRequestValidationException;\n+import org.elasticsearch.action.ActionResponse;\n+import org.elasticsearch.action.ActionType;\n+import org.elasticsearch.action.support.ActionFilters;\n+import org.elasticsearch.action.support.HandledTransportAction;\n+import org.elasticsearch.client.node.NodeClient;\n+import org.elasticsearch.common.ParseField;\n+import org.elasticsearch.common.inject.Inject;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.io.stream.Writeable;\n+import org.elasticsearch.common.xcontent.ConstructingObjectParser;\n+import org.elasticsearch.common.xcontent.ToXContentObject;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.painless.PainlessScriptEngine;\n+import org.elasticsearch.painless.ScriptClassInfo;\n+import org.elasticsearch.painless.action.PainlessExecuteAction.PainlessTestScript;\n+import org.elasticsearch.painless.lookup.PainlessLookup;\n+import org.elasticsearch.rest.BaseRestHandler;\n+import org.elasticsearch.rest.RestRequest;\n+import org.elasticsearch.rest.action.RestToXContentListener;\n+import org.elasticsearch.script.Script;\n+import org.elasticsearch.script.ScriptContext;\n+import org.elasticsearch.tasks.Task;\n+import org.elasticsearch.transport.TransportService;\n+\n+import java.io.IOException;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.stream.Collectors;\n+\n+import static org.elasticsearch.rest.RestRequest.Method.POST;\n+\n+/**\n+ * Internal REST API for providing auto-complete suggestions for a\n+ * partially completed Painless script.\n+ * {@code\n+ * Request:\n+ *\n+ * POST _scripts/painless/suggestions\n+ * {\n+ *     \"context\": \"score\", // optional\n+ *     \"script\": {\n+ *         \"source\": \"partially completed script\", // required\n+ *     }\n+ * }\n+ *\n+ * Response:\n+ * {\n+ *     \"suggestions\": [\n+ *         {\n+ *             \"type\": \"variable/method/field/type\",\n+ *             \"text\": \"suggested text\"\n+ *         },\n+ *         ...\n+ *     ]\n+ * }\n+ * }\n+ */\n+public class PainlessSuggestAction extends ActionType<PainlessSuggestAction.Response> {\n+\n+    public static final PainlessSuggestAction INSTANCE = new PainlessSuggestAction();\n+    private static final String NAME = \"cluster:admin/scripts/painless/suggestions\";\n+\n+    private PainlessSuggestAction() {\n+        super(NAME, PainlessSuggestAction.Response::new);\n+    }\n+\n+    public static class Request extends ActionRequest {\n+\n+        private static final ParseField SCRIPT_FIELD = new ParseField(\"script\");\n+        private static final ParseField CONTEXT_FIELD = new ParseField(\"context\");\n+        private static final ConstructingObjectParser<PainlessSuggestAction.Request, Void> PARSER = new ConstructingObjectParser<>(\n+                \"painless_suggestions_request\", args -> new PainlessSuggestAction.Request((String)args[0], (Script)args[1]));\n+\n+        static {\n+            PARSER.declareString(ConstructingObjectParser.optionalConstructorArg(), CONTEXT_FIELD);\n+            PARSER.declareObject(ConstructingObjectParser.constructorArg(), (p, c) -> Script.parse(p), SCRIPT_FIELD);\n+        }\n+\n+        static Request parse(XContentParser parser) throws IOException {\n+            return PARSER.parse(parser, null);\n+        }\n+\n+        private final String context;\n+        private final Script script;\n+\n+        public Request(String context, Script script) {\n+            this.context = context;\n+            this.script = Objects.requireNonNull(script);\n+        }\n+\n+        public Request(StreamInput in) throws IOException {\n+            super(in);\n+            this.context = in.readOptionalString();\n+            this.script = new Script(in);\n+        }\n+\n+        @Override\n+        public void writeTo(StreamOutput out) throws IOException {\n+            super.writeTo(out);\n+            out.writeOptionalString(this.context);\n+            this.script.writeTo(out);\n+        }\n+\n+        @Override\n+        public ActionRequestValidationException validate() {\n+            return null;\n+        }\n+\n+        public Script getScript() {\n+            return script;\n+        }\n+\n+        public String getContext() {\n+            return context;\n+        }\n+\n+        @Override\n+        public boolean equals(Object o) {\n+            if (this == o) return true;\n+            if (o == null || getClass() != o.getClass()) return false;\n+            Request request = (Request)o;\n+            return Objects.equals(context, request.context) && Objects.equals(script, request.script);\n+        }\n+\n+        @Override\n+        public int hashCode() {\n+            return Objects.hash(context, script);\n+        }\n+\n+        @Override\n+        public String toString() {\n+            return \"Request{\" +\n+                    \"context='\" + context + '\\'' +\n+                    \", script=\" + script +\n+                    '}';\n+        }\n+    }\n+\n+    public static class Response extends ActionResponse implements ToXContentObject {\n+\n+        public static final ParseField SUGGESTIONS = new ParseField(\"suggestions\");\n+\n+        private final List<Suggestion> suggestions;\n+\n+        public Response(List<Suggestion> suggestions) {\n+            this.suggestions = Collections.unmodifiableList(Objects.requireNonNull(suggestions));\n+        }\n+\n+        public Response(StreamInput in) throws IOException {\n+            super(in);\n+            suggestions = Collections.unmodifiableList(in.readList(Suggestion::new));\n+        }\n+\n+        @Override\n+        public void writeTo(StreamOutput out) throws IOException {\n+            out.writeList(suggestions);\n+        }\n+\n+        @Override\n+        public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {\n+            builder.startObject();\n+            builder.field(SUGGESTIONS.getPreferredName(), suggestions);\n+            builder.endObject();\n+            return builder;\n+        }\n+\n+        @Override\n+        public boolean equals(Object o) {\n+            if (this == o) return true;\n+            if (o == null || getClass() != o.getClass()) return false;\n+            Response response = (Response)o;\n+            return Objects.equals(suggestions, response.suggestions);\n+        }\n+\n+        @Override\n+        public int hashCode() {\n+            return Objects.hash(suggestions);\n+        }\n+\n+        @Override\n+        public String toString() {\n+            return \"Response{\" +\n+                    \"suggestions=\" + suggestions +\n+                    '}';\n+        }\n+    }\n+\n+    public static class TransportAction extends HandledTransportAction<Request, Response> {\n+\n+        private final PainlessScriptEngine painlessScriptEngine;\n+\n+        @Inject\n+        public TransportAction(TransportService transportService, ActionFilters actionFilters, PainlessScriptEngine painlessScriptEngine) {\n+            super(NAME, transportService, actionFilters, Request::new);\n+            this.painlessScriptEngine = painlessScriptEngine;\n+        }\n+\n+        @Override\n+        protected void doExecute(Task task, Request request, ActionListener<Response> listener) {\n+            String source = request.getScript().getIdOrCode();\n+            String context = request.getContext();\n+\n+            if (request.getContext() == null) {\n+                context = PainlessTestScript.CONTEXT.name;\n+            }\n+\n+            Class<?> script = null;\n+            PainlessLookup lookup = null;\n+\n+            for (Map.Entry<ScriptContext<?>, PainlessLookup> contextLookupEntry : painlessScriptEngine.getContextsToLookups().entrySet()) {\n+                if (contextLookupEntry.getKey().name.equals(context)) {\n+                    script = contextLookupEntry.getKey().instanceClazz;\n+                    lookup = contextLookupEntry.getValue();\n+                    break;\n+                }\n+            }\n+\n+            if (script == null || lookup == null) {\n+                throw new IllegalArgumentException(\"script context [\" + request.getContext() + \"] not found\");\n+            }\n+\n+            ScriptClassInfo info = new ScriptClassInfo(lookup, script);\n+            List<Suggestion> suggestions = PainlessSuggest.suggest(lookup, info, source).stream()\n+                    .map(suggestion -> new Suggestion(suggestion.type, suggestion.text)).collect(Collectors.toList());\n+\n+            listener.onResponse(new Response(suggestions));\n+        }\n+    }\n+\n+    public static class RestAction extends BaseRestHandler {\n+\n+        @Override\n+        public List<Route> routes() {\n+            return List.of(new Route(POST, \"/_scripts/painless/_suggestions\"));\n+        }\n+\n+        @Override\n+        public String getName() {\n+            return \"_scripts_painless_suggestions\";\n+        }\n+\n+        @Override\n+        protected RestChannelConsumer prepareRequest(RestRequest restRequest, NodeClient client) throws IOException {\n+            Request request = Request.parse(restRequest.contentOrSourceParamParser());\n+            return channel -> client.executeLocally(INSTANCE, request, new RestToXContentListener<>(channel));\n+        }\n+    }\n+\n+    public static class Suggestion implements Writeable, ToXContentObject {\n+\n+        private static final ParseField TYPE_FIELD = new ParseField(\"type\");\n+        private static final ParseField TEXT_FIELD = new ParseField(\"text\");\n+\n+        private final String type;\n+        private final String text;\n+\n+        public Suggestion(String type, String text) {\n+            this.type = type;\n+            this.text = text;\n+        }\n+\n+        public Suggestion(StreamInput in) throws IOException {\n+            this.type = in.readString();\n+            this.text = in.readString();\n+        }\n+\n+        public String getType() {\n+            return type;\n+        }\n+\n+        public String getText() {\n+            return text;\n+        }\n+\n+        @Override\n+        public void writeTo(StreamOutput out) throws IOException {\n+            out.writeString(this.type);\n+            out.writeString(this.text);\n+        }\n+\n+        @Override\n+        public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {\n+            builder.startObject();\n+            builder.field(TYPE_FIELD.getPreferredName(), type);\n+            builder.field(TEXT_FIELD.getPreferredName(), text);\n+            builder.endObject();\n+            return builder;\n+        }\n+\n+        @Override\n+        public boolean equals(Object o) {\n+            if (this == o) return true;\n+            if (o == null || getClass() != o.getClass()) return false;\n+            Suggestion that = (Suggestion)o;\n+            return Objects.equals(type, that.type) && Objects.equals(text, that.text);\n+        }\n+\n+        @Override\n+        public int hashCode() {\n+            return Objects.hash(type, text);\n+        }\n+\n+        @Override\n+        public String toString() {\n+            return \"Suggestion{\" +\n+                    \"type='\" + type + '\\'' +\n+                    \", text='\" + text + '\\'' +\n+                    '}';\n+        }\n+    }\n+}"
  },
  {
    "sha": "253cd2f08da0c47492b193f7dc3fc99a79b6a028",
    "filename": "modules/lang-painless/src/main/java/org/elasticsearch/painless/antlr/EnhancedSuggestLexer.java",
    "status": "added",
    "additions": 78,
    "deletions": 0,
    "changes": 78,
    "blob_url": "https://github.com/elastic/elasticsearch/blob/d0893e5ae135f0ac881e86cf558fe67a9c65268d/modules/lang-painless/src/main/java/org/elasticsearch/painless/antlr/EnhancedSuggestLexer.java",
    "raw_url": "https://github.com/elastic/elasticsearch/raw/d0893e5ae135f0ac881e86cf558fe67a9c65268d/modules/lang-painless/src/main/java/org/elasticsearch/painless/antlr/EnhancedSuggestLexer.java",
    "contents_url": "https://api.github.com/repos/elastic/elasticsearch/contents/modules/lang-painless/src/main/java/org/elasticsearch/painless/antlr/EnhancedSuggestLexer.java?ref=d0893e5ae135f0ac881e86cf558fe67a9c65268d",
    "patch": "@@ -0,0 +1,78 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License\n+ * 2.0 and the Server Side Public License, v 1; you may not use this file except\n+ * in compliance with, at your election, the Elastic License 2.0 or the Server\n+ * Side Public License, v 1.\n+ */\n+\n+package org.elasticsearch.painless.antlr;\n+\n+import org.antlr.v4.runtime.CharStream;\n+import org.antlr.v4.runtime.LexerNoViableAltException;\n+import org.antlr.v4.runtime.Token;\n+import org.elasticsearch.painless.lookup.PainlessLookup;\n+\n+/**\n+ * A lexer that is customized for painless. It:\n+ * <ul>\n+ * <li>Overrides the default error behavior to fail on the first error.\n+ * <li>Stores the last token in case we need to do lookbehind for semicolon insertion and regex vs division detection.\n+ * <li>Implements the regex vs division detection.\n+ * <li>Insert semicolons where they'd improve the language's readability. Rather than hack this into the parser and create a ton of\n+ * ambiguity we hack them here where we can use heuristics to do it quickly.\n+ * <li>Enhances the error message when a string contains invalid escape sequences to include a list of valid escape sequences.\n+ * </ul>\n+ */\n+public final class EnhancedSuggestLexer extends SuggestLexer {\n+\n+    private Token current = null;\n+    private final PainlessLookup painlessLookup;\n+\n+    public EnhancedSuggestLexer(CharStream charStream, PainlessLookup painlessLookup) {\n+        super(charStream);\n+        this.painlessLookup = painlessLookup;\n+    }\n+\n+    @Override\n+    public Token nextToken() {\n+        current = super.nextToken();\n+        return current;\n+    }\n+\n+    @Override\n+    public void recover(final LexerNoViableAltException lnvae) {\n+        if (this._mode != PainlessLexer.DEFAULT_MODE) {\n+            this._mode = DEFAULT_MODE;\n+        } else {\n+            throw new IllegalStateException(\"unexpected token [\" + lnvae.getOffendingToken().getText() + \"]\", lnvae);\n+        }\n+    }\n+\n+    @Override\n+    protected boolean isSlashRegex() {\n+        Token lastToken = current;\n+        if (lastToken == null) {\n+            return true;\n+        }\n+        switch (lastToken.getType()) {\n+            case PainlessLexer.RBRACE:\n+            case PainlessLexer.RP:\n+            case PainlessLexer.OCTAL:\n+            case PainlessLexer.HEX:\n+            case PainlessLexer.INTEGER:\n+            case PainlessLexer.DECIMAL:\n+            case PainlessLexer.ID:\n+            case PainlessLexer.DOTINTEGER:\n+            case PainlessLexer.DOTID:\n+                return false;\n+            default:\n+                return true;\n+        }\n+    }\n+\n+    @Override\n+    protected boolean isType(String text) {\n+        return painlessLookup.isValidCanonicalClassName(text);\n+    }\n+}"
  },
  {
    "sha": "90c410c46c8a075462f6e558d935d57f73f5ff30",
    "filename": "modules/lang-painless/src/main/java/org/elasticsearch/painless/antlr/SuggestLexer.java",
    "status": "added",
    "additions": 389,
    "deletions": 0,
    "changes": 389,
    "blob_url": "https://github.com/elastic/elasticsearch/blob/d0893e5ae135f0ac881e86cf558fe67a9c65268d/modules/lang-painless/src/main/java/org/elasticsearch/painless/antlr/SuggestLexer.java",
    "raw_url": "https://github.com/elastic/elasticsearch/raw/d0893e5ae135f0ac881e86cf558fe67a9c65268d/modules/lang-painless/src/main/java/org/elasticsearch/painless/antlr/SuggestLexer.java",
    "contents_url": "https://api.github.com/repos/elastic/elasticsearch/contents/modules/lang-painless/src/main/java/org/elasticsearch/painless/antlr/SuggestLexer.java?ref=d0893e5ae135f0ac881e86cf558fe67a9c65268d",
    "patch": "@@ -0,0 +1,389 @@\n+// ANTLR GENERATED CODE: DO NOT EDIT\n+package org.elasticsearch.painless.antlr;\n+import org.antlr.v4.runtime.Lexer;\n+import org.antlr.v4.runtime.CharStream;\n+import org.antlr.v4.runtime.Token;\n+import org.antlr.v4.runtime.TokenStream;\n+import org.antlr.v4.runtime.*;\n+import org.antlr.v4.runtime.atn.*;\n+import org.antlr.v4.runtime.dfa.DFA;\n+import org.antlr.v4.runtime.misc.*;\n+\n+@SuppressWarnings({\"all\", \"warnings\", \"unchecked\", \"unused\", \"cast\"})\n+public abstract class SuggestLexer extends Lexer {\n+  static { RuntimeMetaData.checkVersion(\"4.5.3\", RuntimeMetaData.VERSION); }\n+\n+  protected static final DFA[] _decisionToDFA;\n+  protected static final PredictionContextCache _sharedContextCache =\n+    new PredictionContextCache();\n+  public static final int\n+    WS=1, COMMENT=2, LBRACK=3, RBRACK=4, LBRACE=5, RBRACE=6, LP=7, RP=8, DOT=9, \n+    NSDOT=10, COMMA=11, SEMICOLON=12, IF=13, IN=14, ELSE=15, WHILE=16, DO=17, \n+    FOR=18, CONTINUE=19, BREAK=20, RETURN=21, NEW=22, TRY=23, CATCH=24, THROW=25, \n+    THIS=26, INSTANCEOF=27, BOOLNOT=28, BWNOT=29, MUL=30, DIV=31, REM=32, \n+    ADD=33, SUB=34, LSH=35, RSH=36, USH=37, LT=38, LTE=39, GT=40, GTE=41, \n+    EQ=42, EQR=43, NE=44, NER=45, BWAND=46, XOR=47, BWOR=48, BOOLAND=49, BOOLOR=50, \n+    COND=51, COLON=52, ELVIS=53, REF=54, ARROW=55, FIND=56, MATCH=57, INCR=58, \n+    DECR=59, ASSIGN=60, AADD=61, ASUB=62, AMUL=63, ADIV=64, AREM=65, AAND=66, \n+    AXOR=67, AOR=68, ALSH=69, ARSH=70, AUSH=71, OCTAL=72, HEX=73, INTEGER=74, \n+    DECIMAL=75, STRING=76, REGEX=77, TRUE=78, FALSE=79, NULL=80, ATYPE=81, \n+    TYPE=82, ID=83, UNKNOWN=84, DOTINTEGER=85, DOTID=86;\n+  public static final int AFTER_DOT = 1;\n+  public static String[] modeNames = {\n+    \"DEFAULT_MODE\", \"AFTER_DOT\"\n+  };\n+\n+  public static final String[] ruleNames = {\n+    \"WS\", \"COMMENT\", \"LBRACK\", \"RBRACK\", \"LBRACE\", \"RBRACE\", \"LP\", \"RP\", \"DOT\", \n+    \"NSDOT\", \"COMMA\", \"SEMICOLON\", \"IF\", \"IN\", \"ELSE\", \"WHILE\", \"DO\", \"FOR\", \n+    \"CONTINUE\", \"BREAK\", \"RETURN\", \"NEW\", \"TRY\", \"CATCH\", \"THROW\", \"THIS\", \n+    \"INSTANCEOF\", \"BOOLNOT\", \"BWNOT\", \"MUL\", \"DIV\", \"REM\", \"ADD\", \"SUB\", \"LSH\", \n+    \"RSH\", \"USH\", \"LT\", \"LTE\", \"GT\", \"GTE\", \"EQ\", \"EQR\", \"NE\", \"NER\", \"BWAND\", \n+    \"XOR\", \"BWOR\", \"BOOLAND\", \"BOOLOR\", \"COND\", \"COLON\", \"ELVIS\", \"REF\", \"ARROW\", \n+    \"FIND\", \"MATCH\", \"INCR\", \"DECR\", \"ASSIGN\", \"AADD\", \"ASUB\", \"AMUL\", \"ADIV\", \n+    \"AREM\", \"AAND\", \"AXOR\", \"AOR\", \"ALSH\", \"ARSH\", \"AUSH\", \"OCTAL\", \"HEX\", \n+    \"INTEGER\", \"DECIMAL\", \"STRING\", \"REGEX\", \"TRUE\", \"FALSE\", \"NULL\", \"ATYPE\", \n+    \"TYPE\", \"ID\", \"UNKNOWN\", \"DOTINTEGER\", \"DOTID\"\n+  };\n+\n+  private static final String[] _LITERAL_NAMES = {\n+    null, null, null, \"'{'\", \"'}'\", \"'['\", \"']'\", \"'('\", \"')'\", \"'.'\", \"'?.'\", \n+    \"','\", \"';'\", \"'if'\", \"'in'\", \"'else'\", \"'while'\", \"'do'\", \"'for'\", \"'continue'\", \n+    \"'break'\", \"'return'\", \"'new'\", \"'try'\", \"'catch'\", \"'throw'\", \"'this'\", \n+    \"'instanceof'\", \"'!'\", \"'~'\", \"'*'\", \"'/'\", \"'%'\", \"'+'\", \"'-'\", \"'<<'\", \n+    \"'>>'\", \"'>>>'\", \"'<'\", \"'<='\", \"'>'\", \"'>='\", \"'=='\", \"'==='\", \"'!='\", \n+    \"'!=='\", \"'&'\", \"'^'\", \"'|'\", \"'&&'\", \"'||'\", \"'?'\", \"':'\", \"'?:'\", \"'::'\", \n+    \"'->'\", \"'=~'\", \"'==~'\", \"'++'\", \"'--'\", \"'='\", \"'+='\", \"'-='\", \"'*='\", \n+    \"'/='\", \"'%='\", \"'&='\", \"'^='\", \"'|='\", \"'<<='\", \"'>>='\", \"'>>>='\", null, \n+    null, null, null, null, null, \"'true'\", \"'false'\", \"'null'\"\n+  };\n+  private static final String[] _SYMBOLIC_NAMES = {\n+    null, \"WS\", \"COMMENT\", \"LBRACK\", \"RBRACK\", \"LBRACE\", \"RBRACE\", \"LP\", \"RP\", \n+    \"DOT\", \"NSDOT\", \"COMMA\", \"SEMICOLON\", \"IF\", \"IN\", \"ELSE\", \"WHILE\", \"DO\", \n+    \"FOR\", \"CONTINUE\", \"BREAK\", \"RETURN\", \"NEW\", \"TRY\", \"CATCH\", \"THROW\", \n+    \"THIS\", \"INSTANCEOF\", \"BOOLNOT\", \"BWNOT\", \"MUL\", \"DIV\", \"REM\", \"ADD\", \n+    \"SUB\", \"LSH\", \"RSH\", \"USH\", \"LT\", \"LTE\", \"GT\", \"GTE\", \"EQ\", \"EQR\", \"NE\", \n+    \"NER\", \"BWAND\", \"XOR\", \"BWOR\", \"BOOLAND\", \"BOOLOR\", \"COND\", \"COLON\", \"ELVIS\", \n+    \"REF\", \"ARROW\", \"FIND\", \"MATCH\", \"INCR\", \"DECR\", \"ASSIGN\", \"AADD\", \"ASUB\", \n+    \"AMUL\", \"ADIV\", \"AREM\", \"AAND\", \"AXOR\", \"AOR\", \"ALSH\", \"ARSH\", \"AUSH\", \n+    \"OCTAL\", \"HEX\", \"INTEGER\", \"DECIMAL\", \"STRING\", \"REGEX\", \"TRUE\", \"FALSE\", \n+    \"NULL\", \"ATYPE\", \"TYPE\", \"ID\", \"UNKNOWN\", \"DOTINTEGER\", \"DOTID\"\n+  };\n+  public static final Vocabulary VOCABULARY = new VocabularyImpl(_LITERAL_NAMES, _SYMBOLIC_NAMES);\n+\n+  /**\n+   * @deprecated Use {@link #VOCABULARY} instead.\n+   */\n+  @Deprecated\n+  public static final String[] tokenNames;\n+  static {\n+    tokenNames = new String[_SYMBOLIC_NAMES.length];\n+    for (int i = 0; i < tokenNames.length; i++) {\n+      tokenNames[i] = VOCABULARY.getLiteralName(i);\n+      if (tokenNames[i] == null) {\n+        tokenNames[i] = VOCABULARY.getSymbolicName(i);\n+      }\n+\n+      if (tokenNames[i] == null) {\n+        tokenNames[i] = \"<INVALID>\";\n+      }\n+    }\n+  }\n+\n+  @Override\n+  @Deprecated\n+  public String[] getTokenNames() {\n+    return tokenNames;\n+  }\n+\n+  @Override\n+\n+  public Vocabulary getVocabulary() {\n+    return VOCABULARY;\n+  }\n+\n+\n+  /** Is the preceding {@code /} a the beginning of a regex (true) or a division (false). */\n+  protected abstract boolean isSlashRegex();\n+  protected abstract boolean isType(String text);\n+\n+\n+  public SuggestLexer(CharStream input) {\n+    super(input);\n+    _interp = new LexerATNSimulator(this,_ATN,_decisionToDFA,_sharedContextCache);\n+  }\n+\n+  @Override\n+  public String getGrammarFileName() { return \"SuggestLexer.g4\"; }\n+\n+  @Override\n+  public String[] getRuleNames() { return ruleNames; }\n+\n+  @Override\n+  public String getSerializedATN() { return _serializedATN; }\n+\n+  @Override\n+  public String[] getModeNames() { return modeNames; }\n+\n+  @Override\n+  public ATN getATN() { return _ATN; }\n+\n+  @Override\n+  public boolean sempred(RuleContext _localctx, int ruleIndex, int predIndex) {\n+    switch (ruleIndex) {\n+    case 30:\n+      return DIV_sempred((RuleContext)_localctx, predIndex);\n+    case 76:\n+      return REGEX_sempred((RuleContext)_localctx, predIndex);\n+    case 81:\n+      return TYPE_sempred((RuleContext)_localctx, predIndex);\n+    }\n+    return true;\n+  }\n+  private boolean DIV_sempred(RuleContext _localctx, int predIndex) {\n+    switch (predIndex) {\n+    case 0:\n+      return  isSlashRegex() == false ;\n+    }\n+    return true;\n+  }\n+  private boolean REGEX_sempred(RuleContext _localctx, int predIndex) {\n+    switch (predIndex) {\n+    case 1:\n+      return  isSlashRegex() ;\n+    }\n+    return true;\n+  }\n+  private boolean TYPE_sempred(RuleContext _localctx, int predIndex) {\n+    switch (predIndex) {\n+    case 2:\n+      return  isType(getText()) ;\n+    }\n+    return true;\n+  }\n+\n+  public static final String _serializedATN =\n+    \"\\3\\u0430\\ud6d1\\u8206\\uad2d\\u4417\\uaef1\\u8d80\\uaadd\\2X\\u0267\\b\\1\\b\\1\\4\"+\n+    \"\\2\\t\\2\\4\\3\\t\\3\\4\\4\\t\\4\\4\\5\\t\\5\\4\\6\\t\\6\\4\\7\\t\\7\\4\\b\\t\\b\\4\\t\\t\\t\\4\\n\\t\\n\"+\n+    \"\\4\\13\\t\\13\\4\\f\\t\\f\\4\\r\\t\\r\\4\\16\\t\\16\\4\\17\\t\\17\\4\\20\\t\\20\\4\\21\\t\\21\\4\\22\"+\n+    \"\\t\\22\\4\\23\\t\\23\\4\\24\\t\\24\\4\\25\\t\\25\\4\\26\\t\\26\\4\\27\\t\\27\\4\\30\\t\\30\\4\\31\"+\n+    \"\\t\\31\\4\\32\\t\\32\\4\\33\\t\\33\\4\\34\\t\\34\\4\\35\\t\\35\\4\\36\\t\\36\\4\\37\\t\\37\\4 \\t\"+\n+    \" \\4!\\t!\\4\\\"\\t\\\"\\4#\\t#\\4$\\t$\\4%\\t%\\4&\\t&\\4\\'\\t\\'\\4(\\t(\\4)\\t)\\4*\\t*\\4+\\t\"+\n+    \"+\\4,\\t,\\4-\\t-\\4.\\t.\\4/\\t/\\4\\60\\t\\60\\4\\61\\t\\61\\4\\62\\t\\62\\4\\63\\t\\63\\4\\64\"+\n+    \"\\t\\64\\4\\65\\t\\65\\4\\66\\t\\66\\4\\67\\t\\67\\48\\t8\\49\\t9\\4:\\t:\\4;\\t;\\4<\\t<\\4=\\t\"+\n+    \"=\\4>\\t>\\4?\\t?\\4@\\t@\\4A\\tA\\4B\\tB\\4C\\tC\\4D\\tD\\4E\\tE\\4F\\tF\\4G\\tG\\4H\\tH\\4\"+\n+    \"I\\tI\\4J\\tJ\\4K\\tK\\4L\\tL\\4M\\tM\\4N\\tN\\4O\\tO\\4P\\tP\\4Q\\tQ\\4R\\tR\\4S\\tS\\4T\\t\"+\n+    \"T\\4U\\tU\\4V\\tV\\4W\\tW\\3\\2\\6\\2\\u00b2\\n\\2\\r\\2\\16\\2\\u00b3\\3\\2\\3\\2\\3\\3\\3\\3\\3\"+\n+    \"\\3\\3\\3\\7\\3\\u00bc\\n\\3\\f\\3\\16\\3\\u00bf\\13\\3\\3\\3\\3\\3\\3\\3\\3\\3\\3\\3\\7\\3\\u00c6\"+\n+    \"\\n\\3\\f\\3\\16\\3\\u00c9\\13\\3\\3\\3\\3\\3\\5\\3\\u00cd\\n\\3\\3\\3\\3\\3\\3\\4\\3\\4\\3\\5\\3\\5\"+\n+    \"\\3\\6\\3\\6\\3\\7\\3\\7\\3\\b\\3\\b\\3\\t\\3\\t\\3\\n\\3\\n\\3\\n\\3\\n\\3\\13\\3\\13\\3\\13\\3\\13\\3\"+\n+    \"\\13\\3\\f\\3\\f\\3\\r\\3\\r\\3\\16\\3\\16\\3\\16\\3\\17\\3\\17\\3\\17\\3\\20\\3\\20\\3\\20\\3\\20\"+\n+    \"\\3\\20\\3\\21\\3\\21\\3\\21\\3\\21\\3\\21\\3\\21\\3\\22\\3\\22\\3\\22\\3\\23\\3\\23\\3\\23\\3\\23\"+\n+    \"\\3\\24\\3\\24\\3\\24\\3\\24\\3\\24\\3\\24\\3\\24\\3\\24\\3\\24\\3\\25\\3\\25\\3\\25\\3\\25\\3\\25\"+\n+    \"\\3\\25\\3\\26\\3\\26\\3\\26\\3\\26\\3\\26\\3\\26\\3\\26\\3\\27\\3\\27\\3\\27\\3\\27\\3\\30\\3\\30\"+\n+    \"\\3\\30\\3\\30\\3\\31\\3\\31\\3\\31\\3\\31\\3\\31\\3\\31\\3\\32\\3\\32\\3\\32\\3\\32\\3\\32\\3\\32\"+\n+    \"\\3\\33\\3\\33\\3\\33\\3\\33\\3\\33\\3\\34\\3\\34\\3\\34\\3\\34\\3\\34\\3\\34\\3\\34\\3\\34\\3\\34\"+\n+    \"\\3\\34\\3\\34\\3\\35\\3\\35\\3\\36\\3\\36\\3\\37\\3\\37\\3 \\3 \\3 \\3!\\3!\\3\\\"\\3\\\"\\3#\\3#\"+\n+    \"\\3$\\3$\\3$\\3%\\3%\\3%\\3&\\3&\\3&\\3&\\3\\'\\3\\'\\3(\\3(\\3(\\3)\\3)\\3*\\3*\\3*\\3+\\3+\\3\"+\n+    \"+\\3,\\3,\\3,\\3,\\3-\\3-\\3-\\3.\\3.\\3.\\3.\\3/\\3/\\3\\60\\3\\60\\3\\61\\3\\61\\3\\62\\3\\62\"+\n+    \"\\3\\62\\3\\63\\3\\63\\3\\63\\3\\64\\3\\64\\3\\65\\3\\65\\3\\66\\3\\66\\3\\66\\3\\67\\3\\67\\3\\67\"+\n+    \"\\38\\38\\38\\39\\39\\39\\3:\\3:\\3:\\3:\\3;\\3;\\3;\\3<\\3<\\3<\\3=\\3=\\3>\\3>\\3>\\3?\\3?\"+\n+    \"\\3?\\3@\\3@\\3@\\3A\\3A\\3A\\3B\\3B\\3B\\3C\\3C\\3C\\3D\\3D\\3D\\3E\\3E\\3E\\3F\\3F\\3F\\3F\"+\n+    \"\\3G\\3G\\3G\\3G\\3H\\3H\\3H\\3H\\3H\\3I\\3I\\6I\\u01bc\\nI\\rI\\16I\\u01bd\\3I\\5I\\u01c1\"+\n+    \"\\nI\\3J\\3J\\3J\\6J\\u01c6\\nJ\\rJ\\16J\\u01c7\\3J\\5J\\u01cb\\nJ\\3K\\3K\\3K\\7K\\u01d0\"+\n+    \"\\nK\\fK\\16K\\u01d3\\13K\\5K\\u01d5\\nK\\3K\\5K\\u01d8\\nK\\3L\\3L\\3L\\7L\\u01dd\\nL\\f\"+\n+    \"L\\16L\\u01e0\\13L\\5L\\u01e2\\nL\\3L\\3L\\6L\\u01e6\\nL\\rL\\16L\\u01e7\\5L\\u01ea\\n\"+\n+    \"L\\3L\\3L\\5L\\u01ee\\nL\\3L\\6L\\u01f1\\nL\\rL\\16L\\u01f2\\5L\\u01f5\\nL\\3L\\5L\\u01f8\"+\n+    \"\\nL\\3M\\3M\\3M\\3M\\3M\\3M\\7M\\u0200\\nM\\fM\\16M\\u0203\\13M\\3M\\3M\\3M\\3M\\3M\\3M\\3\"+\n+    \"M\\7M\\u020c\\nM\\fM\\16M\\u020f\\13M\\3M\\5M\\u0212\\nM\\3N\\3N\\3N\\3N\\6N\\u0218\\nN\"+\n+    \"\\rN\\16N\\u0219\\3N\\3N\\7N\\u021e\\nN\\fN\\16N\\u0221\\13N\\3N\\3N\\3O\\3O\\3O\\3O\\3O\"+\n+    \"\\3P\\3P\\3P\\3P\\3P\\3P\\3Q\\3Q\\3Q\\3Q\\3Q\\3R\\3R\\3R\\3R\\6R\\u0239\\nR\\rR\\16R\\u023a\"+\n+    \"\\3S\\3S\\3S\\3S\\7S\\u0241\\nS\\fS\\16S\\u0244\\13S\\3S\\3S\\3T\\3T\\7T\\u024a\\nT\\fT\\16\"+\n+    \"T\\u024d\\13T\\3U\\3U\\3U\\3U\\3V\\3V\\3V\\7V\\u0256\\nV\\fV\\16V\\u0259\\13V\\5V\\u025b\"+\n+    \"\\nV\\3V\\3V\\3W\\3W\\7W\\u0261\\nW\\fW\\16W\\u0264\\13W\\3W\\3W\\7\\u00bd\\u00c7\\u0201\"+\n+    \"\\u020d\\u0219\\2X\\4\\3\\6\\4\\b\\5\\n\\6\\f\\7\\16\\b\\20\\t\\22\\n\\24\\13\\26\\f\\30\\r\\32\"+\n+    \"\\16\\34\\17\\36\\20 \\21\\\"\\22$\\23&\\24(\\25*\\26,\\27.\\30\\60\\31\\62\\32\\64\\33\\66\"+\n+    \"\\348\\35:\\36<\\37> @!B\\\"D#F$H%J&L\\'N(P)R*T+V,X-Z.\\\\/^\\60`\\61b\\62d\\63f\\64\"+\n+    \"h\\65j\\66l\\67n8p9r:t;v<x=z>|?~@\\u0080A\\u0082B\\u0084C\\u0086D\\u0088E\\u008a\"+\n+    \"F\\u008cG\\u008eH\\u0090I\\u0092J\\u0094K\\u0096L\\u0098M\\u009aN\\u009cO\\u009e\"+\n+    \"P\\u00a0Q\\u00a2R\\u00a4S\\u00a6T\\u00a8U\\u00aaV\\u00acW\\u00aeX\\4\\2\\3\\25\\5\\2\"+\n+    \"\\13\\f\\17\\17\\\"\\\"\\4\\2\\f\\f\\17\\17\\3\\2\\629\\4\\2NNnn\\4\\2ZZzz\\5\\2\\62;CHch\\3\\2\"+\n+    \"\\63;\\3\\2\\62;\\b\\2FFHHNNffhhnn\\4\\2GGgg\\4\\2--//\\6\\2FFHHffhh\\4\\2$$^^\\4\\2)\"+\n+    \")^^\\3\\2\\f\\f\\4\\2\\f\\f\\61\\61\\t\\2WWeekknouuwwzz\\5\\2C\\\\aac|\\6\\2\\62;C\\\\aac|\"+\n+    \"\\u0288\\2\\4\\3\\2\\2\\2\\2\\6\\3\\2\\2\\2\\2\\b\\3\\2\\2\\2\\2\\n\\3\\2\\2\\2\\2\\f\\3\\2\\2\\2\\2\\16\"+\n+    \"\\3\\2\\2\\2\\2\\20\\3\\2\\2\\2\\2\\22\\3\\2\\2\\2\\2\\24\\3\\2\\2\\2\\2\\26\\3\\2\\2\\2\\2\\30\\3\\2\"+\n+    \"\\2\\2\\2\\32\\3\\2\\2\\2\\2\\34\\3\\2\\2\\2\\2\\36\\3\\2\\2\\2\\2 \\3\\2\\2\\2\\2\\\"\\3\\2\\2\\2\\2$\"+\n+    \"\\3\\2\\2\\2\\2&\\3\\2\\2\\2\\2(\\3\\2\\2\\2\\2*\\3\\2\\2\\2\\2,\\3\\2\\2\\2\\2.\\3\\2\\2\\2\\2\\60\\3\"+\n+    \"\\2\\2\\2\\2\\62\\3\\2\\2\\2\\2\\64\\3\\2\\2\\2\\2\\66\\3\\2\\2\\2\\28\\3\\2\\2\\2\\2:\\3\\2\\2\\2\\2\"+\n+    \"<\\3\\2\\2\\2\\2>\\3\\2\\2\\2\\2@\\3\\2\\2\\2\\2B\\3\\2\\2\\2\\2D\\3\\2\\2\\2\\2F\\3\\2\\2\\2\\2H\\3\"+\n+    \"\\2\\2\\2\\2J\\3\\2\\2\\2\\2L\\3\\2\\2\\2\\2N\\3\\2\\2\\2\\2P\\3\\2\\2\\2\\2R\\3\\2\\2\\2\\2T\\3\\2\\2\"+\n+    \"\\2\\2V\\3\\2\\2\\2\\2X\\3\\2\\2\\2\\2Z\\3\\2\\2\\2\\2\\\\\\3\\2\\2\\2\\2^\\3\\2\\2\\2\\2`\\3\\2\\2\\2\"+\n+    \"\\2b\\3\\2\\2\\2\\2d\\3\\2\\2\\2\\2f\\3\\2\\2\\2\\2h\\3\\2\\2\\2\\2j\\3\\2\\2\\2\\2l\\3\\2\\2\\2\\2n\"+\n+    \"\\3\\2\\2\\2\\2p\\3\\2\\2\\2\\2r\\3\\2\\2\\2\\2t\\3\\2\\2\\2\\2v\\3\\2\\2\\2\\2x\\3\\2\\2\\2\\2z\\3\\2\"+\n+    \"\\2\\2\\2|\\3\\2\\2\\2\\2~\\3\\2\\2\\2\\2\\u0080\\3\\2\\2\\2\\2\\u0082\\3\\2\\2\\2\\2\\u0084\\3\\2\"+\n+    \"\\2\\2\\2\\u0086\\3\\2\\2\\2\\2\\u0088\\3\\2\\2\\2\\2\\u008a\\3\\2\\2\\2\\2\\u008c\\3\\2\\2\\2\\2\"+\n+    \"\\u008e\\3\\2\\2\\2\\2\\u0090\\3\\2\\2\\2\\2\\u0092\\3\\2\\2\\2\\2\\u0094\\3\\2\\2\\2\\2\\u0096\"+\n+    \"\\3\\2\\2\\2\\2\\u0098\\3\\2\\2\\2\\2\\u009a\\3\\2\\2\\2\\2\\u009c\\3\\2\\2\\2\\2\\u009e\\3\\2\\2\"+\n+    \"\\2\\2\\u00a0\\3\\2\\2\\2\\2\\u00a2\\3\\2\\2\\2\\2\\u00a4\\3\\2\\2\\2\\2\\u00a6\\3\\2\\2\\2\\2\\u00a8\"+\n+    \"\\3\\2\\2\\2\\2\\u00aa\\3\\2\\2\\2\\3\\u00ac\\3\\2\\2\\2\\3\\u00ae\\3\\2\\2\\2\\4\\u00b1\\3\\2\\2\"+\n+    \"\\2\\6\\u00cc\\3\\2\\2\\2\\b\\u00d0\\3\\2\\2\\2\\n\\u00d2\\3\\2\\2\\2\\f\\u00d4\\3\\2\\2\\2\\16\"+\n+    \"\\u00d6\\3\\2\\2\\2\\20\\u00d8\\3\\2\\2\\2\\22\\u00da\\3\\2\\2\\2\\24\\u00dc\\3\\2\\2\\2\\26\\u00e0\"+\n+    \"\\3\\2\\2\\2\\30\\u00e5\\3\\2\\2\\2\\32\\u00e7\\3\\2\\2\\2\\34\\u00e9\\3\\2\\2\\2\\36\\u00ec\\3\"+\n+    \"\\2\\2\\2 \\u00ef\\3\\2\\2\\2\\\"\\u00f4\\3\\2\\2\\2$\\u00fa\\3\\2\\2\\2&\\u00fd\\3\\2\\2\\2(\\u0101\"+\n+    \"\\3\\2\\2\\2*\\u010a\\3\\2\\2\\2,\\u0110\\3\\2\\2\\2.\\u0117\\3\\2\\2\\2\\60\\u011b\\3\\2\\2\\2\"+\n+    \"\\62\\u011f\\3\\2\\2\\2\\64\\u0125\\3\\2\\2\\2\\66\\u012b\\3\\2\\2\\28\\u0130\\3\\2\\2\\2:\\u013b\"+\n+    \"\\3\\2\\2\\2<\\u013d\\3\\2\\2\\2>\\u013f\\3\\2\\2\\2@\\u0141\\3\\2\\2\\2B\\u0144\\3\\2\\2\\2D\"+\n+    \"\\u0146\\3\\2\\2\\2F\\u0148\\3\\2\\2\\2H\\u014a\\3\\2\\2\\2J\\u014d\\3\\2\\2\\2L\\u0150\\3\\2\"+\n+    \"\\2\\2N\\u0154\\3\\2\\2\\2P\\u0156\\3\\2\\2\\2R\\u0159\\3\\2\\2\\2T\\u015b\\3\\2\\2\\2V\\u015e\"+\n+    \"\\3\\2\\2\\2X\\u0161\\3\\2\\2\\2Z\\u0165\\3\\2\\2\\2\\\\\\u0168\\3\\2\\2\\2^\\u016c\\3\\2\\2\\2\"+\n+    \"`\\u016e\\3\\2\\2\\2b\\u0170\\3\\2\\2\\2d\\u0172\\3\\2\\2\\2f\\u0175\\3\\2\\2\\2h\\u0178\\3\"+\n+    \"\\2\\2\\2j\\u017a\\3\\2\\2\\2l\\u017c\\3\\2\\2\\2n\\u017f\\3\\2\\2\\2p\\u0182\\3\\2\\2\\2r\\u0185\"+\n+    \"\\3\\2\\2\\2t\\u0188\\3\\2\\2\\2v\\u018c\\3\\2\\2\\2x\\u018f\\3\\2\\2\\2z\\u0192\\3\\2\\2\\2|\"+\n+    \"\\u0194\\3\\2\\2\\2~\\u0197\\3\\2\\2\\2\\u0080\\u019a\\3\\2\\2\\2\\u0082\\u019d\\3\\2\\2\\2\"+\n+    \"\\u0084\\u01a0\\3\\2\\2\\2\\u0086\\u01a3\\3\\2\\2\\2\\u0088\\u01a6\\3\\2\\2\\2\\u008a\\u01a9\"+\n+    \"\\3\\2\\2\\2\\u008c\\u01ac\\3\\2\\2\\2\\u008e\\u01b0\\3\\2\\2\\2\\u0090\\u01b4\\3\\2\\2\\2\\u0092\"+\n+    \"\\u01b9\\3\\2\\2\\2\\u0094\\u01c2\\3\\2\\2\\2\\u0096\\u01d4\\3\\2\\2\\2\\u0098\\u01e1\\3\\2\"+\n+    \"\\2\\2\\u009a\\u0211\\3\\2\\2\\2\\u009c\\u0213\\3\\2\\2\\2\\u009e\\u0224\\3\\2\\2\\2\\u00a0\"+\n+    \"\\u0229\\3\\2\\2\\2\\u00a2\\u022f\\3\\2\\2\\2\\u00a4\\u0234\\3\\2\\2\\2\\u00a6\\u023c\\3\\2\"+\n+    \"\\2\\2\\u00a8\\u0247\\3\\2\\2\\2\\u00aa\\u024e\\3\\2\\2\\2\\u00ac\\u025a\\3\\2\\2\\2\\u00ae\"+\n+    \"\\u025e\\3\\2\\2\\2\\u00b0\\u00b2\\t\\2\\2\\2\\u00b1\\u00b0\\3\\2\\2\\2\\u00b2\\u00b3\\3\\2\"+\n+    \"\\2\\2\\u00b3\\u00b1\\3\\2\\2\\2\\u00b3\\u00b4\\3\\2\\2\\2\\u00b4\\u00b5\\3\\2\\2\\2\\u00b5\"+\n+    \"\\u00b6\\b\\2\\2\\2\\u00b6\\5\\3\\2\\2\\2\\u00b7\\u00b8\\7\\61\\2\\2\\u00b8\\u00b9\\7\\61\\2\"+\n+    \"\\2\\u00b9\\u00bd\\3\\2\\2\\2\\u00ba\\u00bc\\13\\2\\2\\2\\u00bb\\u00ba\\3\\2\\2\\2\\u00bc\"+\n+    \"\\u00bf\\3\\2\\2\\2\\u00bd\\u00be\\3\\2\\2\\2\\u00bd\\u00bb\\3\\2\\2\\2\\u00be\\u00c0\\3\\2\"+\n+    \"\\2\\2\\u00bf\\u00bd\\3\\2\\2\\2\\u00c0\\u00cd\\t\\3\\2\\2\\u00c1\\u00c2\\7\\61\\2\\2\\u00c2\"+\n+    \"\\u00c3\\7,\\2\\2\\u00c3\\u00c7\\3\\2\\2\\2\\u00c4\\u00c6\\13\\2\\2\\2\\u00c5\\u00c4\\3\\2\"+\n+    \"\\2\\2\\u00c6\\u00c9\\3\\2\\2\\2\\u00c7\\u00c8\\3\\2\\2\\2\\u00c7\\u00c5\\3\\2\\2\\2\\u00c8\"+\n+    \"\\u00ca\\3\\2\\2\\2\\u00c9\\u00c7\\3\\2\\2\\2\\u00ca\\u00cb\\7,\\2\\2\\u00cb\\u00cd\\7\\61\"+\n+    \"\\2\\2\\u00cc\\u00b7\\3\\2\\2\\2\\u00cc\\u00c1\\3\\2\\2\\2\\u00cd\\u00ce\\3\\2\\2\\2\\u00ce\"+\n+    \"\\u00cf\\b\\3\\2\\2\\u00cf\\7\\3\\2\\2\\2\\u00d0\\u00d1\\7}\\2\\2\\u00d1\\t\\3\\2\\2\\2\\u00d2\"+\n+    \"\\u00d3\\7\\177\\2\\2\\u00d3\\13\\3\\2\\2\\2\\u00d4\\u00d5\\7]\\2\\2\\u00d5\\r\\3\\2\\2\\2\\u00d6\"+\n+    \"\\u00d7\\7_\\2\\2\\u00d7\\17\\3\\2\\2\\2\\u00d8\\u00d9\\7*\\2\\2\\u00d9\\21\\3\\2\\2\\2\\u00da\"+\n+    \"\\u00db\\7+\\2\\2\\u00db\\23\\3\\2\\2\\2\\u00dc\\u00dd\\7\\60\\2\\2\\u00dd\\u00de\\3\\2\\2\"+\n+    \"\\2\\u00de\\u00df\\b\\n\\3\\2\\u00df\\25\\3\\2\\2\\2\\u00e0\\u00e1\\7A\\2\\2\\u00e1\\u00e2\"+\n+    \"\\7\\60\\2\\2\\u00e2\\u00e3\\3\\2\\2\\2\\u00e3\\u00e4\\b\\13\\3\\2\\u00e4\\27\\3\\2\\2\\2\\u00e5\"+\n+    \"\\u00e6\\7.\\2\\2\\u00e6\\31\\3\\2\\2\\2\\u00e7\\u00e8\\7=\\2\\2\\u00e8\\33\\3\\2\\2\\2\\u00e9\"+\n+    \"\\u00ea\\7k\\2\\2\\u00ea\\u00eb\\7h\\2\\2\\u00eb\\35\\3\\2\\2\\2\\u00ec\\u00ed\\7k\\2\\2\\u00ed\"+\n+    \"\\u00ee\\7p\\2\\2\\u00ee\\37\\3\\2\\2\\2\\u00ef\\u00f0\\7g\\2\\2\\u00f0\\u00f1\\7n\\2\\2\\u00f1\"+\n+    \"\\u00f2\\7u\\2\\2\\u00f2\\u00f3\\7g\\2\\2\\u00f3!\\3\\2\\2\\2\\u00f4\\u00f5\\7y\\2\\2\\u00f5\"+\n+    \"\\u00f6\\7j\\2\\2\\u00f6\\u00f7\\7k\\2\\2\\u00f7\\u00f8\\7n\\2\\2\\u00f8\\u00f9\\7g\\2\\2\"+\n+    \"\\u00f9#\\3\\2\\2\\2\\u00fa\\u00fb\\7f\\2\\2\\u00fb\\u00fc\\7q\\2\\2\\u00fc%\\3\\2\\2\\2\\u00fd\"+\n+    \"\\u00fe\\7h\\2\\2\\u00fe\\u00ff\\7q\\2\\2\\u00ff\\u0100\\7t\\2\\2\\u0100\\'\\3\\2\\2\\2\\u0101\"+\n+    \"\\u0102\\7e\\2\\2\\u0102\\u0103\\7q\\2\\2\\u0103\\u0104\\7p\\2\\2\\u0104\\u0105\\7v\\2\\2\"+\n+    \"\\u0105\\u0106\\7k\\2\\2\\u0106\\u0107\\7p\\2\\2\\u0107\\u0108\\7w\\2\\2\\u0108\\u0109\"+\n+    \"\\7g\\2\\2\\u0109)\\3\\2\\2\\2\\u010a\\u010b\\7d\\2\\2\\u010b\\u010c\\7t\\2\\2\\u010c\\u010d\"+\n+    \"\\7g\\2\\2\\u010d\\u010e\\7c\\2\\2\\u010e\\u010f\\7m\\2\\2\\u010f+\\3\\2\\2\\2\\u0110\\u0111\"+\n+    \"\\7t\\2\\2\\u0111\\u0112\\7g\\2\\2\\u0112\\u0113\\7v\\2\\2\\u0113\\u0114\\7w\\2\\2\\u0114\"+\n+    \"\\u0115\\7t\\2\\2\\u0115\\u0116\\7p\\2\\2\\u0116-\\3\\2\\2\\2\\u0117\\u0118\\7p\\2\\2\\u0118\"+\n+    \"\\u0119\\7g\\2\\2\\u0119\\u011a\\7y\\2\\2\\u011a/\\3\\2\\2\\2\\u011b\\u011c\\7v\\2\\2\\u011c\"+\n+    \"\\u011d\\7t\\2\\2\\u011d\\u011e\\7{\\2\\2\\u011e\\61\\3\\2\\2\\2\\u011f\\u0120\\7e\\2\\2\\u0120\"+\n+    \"\\u0121\\7c\\2\\2\\u0121\\u0122\\7v\\2\\2\\u0122\\u0123\\7e\\2\\2\\u0123\\u0124\\7j\\2\\2\"+\n+    \"\\u0124\\63\\3\\2\\2\\2\\u0125\\u0126\\7v\\2\\2\\u0126\\u0127\\7j\\2\\2\\u0127\\u0128\\7\"+\n+    \"t\\2\\2\\u0128\\u0129\\7q\\2\\2\\u0129\\u012a\\7y\\2\\2\\u012a\\65\\3\\2\\2\\2\\u012b\\u012c\"+\n+    \"\\7v\\2\\2\\u012c\\u012d\\7j\\2\\2\\u012d\\u012e\\7k\\2\\2\\u012e\\u012f\\7u\\2\\2\\u012f\"+\n+    \"\\67\\3\\2\\2\\2\\u0130\\u0131\\7k\\2\\2\\u0131\\u0132\\7p\\2\\2\\u0132\\u0133\\7u\\2\\2\\u0133\"+\n+    \"\\u0134\\7v\\2\\2\\u0134\\u0135\\7c\\2\\2\\u0135\\u0136\\7p\\2\\2\\u0136\\u0137\\7e\\2\\2\"+\n+    \"\\u0137\\u0138\\7g\\2\\2\\u0138\\u0139\\7q\\2\\2\\u0139\\u013a\\7h\\2\\2\\u013a9\\3\\2\\2\"+\n+    \"\\2\\u013b\\u013c\\7#\\2\\2\\u013c;\\3\\2\\2\\2\\u013d\\u013e\\7\\u0080\\2\\2\\u013e=\\3\"+\n+    \"\\2\\2\\2\\u013f\\u0140\\7,\\2\\2\\u0140?\\3\\2\\2\\2\\u0141\\u0142\\7\\61\\2\\2\\u0142\\u0143\"+\n+    \"\\6 \\2\\2\\u0143A\\3\\2\\2\\2\\u0144\\u0145\\7\\'\\2\\2\\u0145C\\3\\2\\2\\2\\u0146\\u0147\"+\n+    \"\\7-\\2\\2\\u0147E\\3\\2\\2\\2\\u0148\\u0149\\7/\\2\\2\\u0149G\\3\\2\\2\\2\\u014a\\u014b\\7\"+\n+    \">\\2\\2\\u014b\\u014c\\7>\\2\\2\\u014cI\\3\\2\\2\\2\\u014d\\u014e\\7@\\2\\2\\u014e\\u014f\"+\n+    \"\\7@\\2\\2\\u014fK\\3\\2\\2\\2\\u0150\\u0151\\7@\\2\\2\\u0151\\u0152\\7@\\2\\2\\u0152\\u0153\"+\n+    \"\\7@\\2\\2\\u0153M\\3\\2\\2\\2\\u0154\\u0155\\7>\\2\\2\\u0155O\\3\\2\\2\\2\\u0156\\u0157\\7\"+\n+    \">\\2\\2\\u0157\\u0158\\7?\\2\\2\\u0158Q\\3\\2\\2\\2\\u0159\\u015a\\7@\\2\\2\\u015aS\\3\\2\"+\n+    \"\\2\\2\\u015b\\u015c\\7@\\2\\2\\u015c\\u015d\\7?\\2\\2\\u015dU\\3\\2\\2\\2\\u015e\\u015f\"+\n+    \"\\7?\\2\\2\\u015f\\u0160\\7?\\2\\2\\u0160W\\3\\2\\2\\2\\u0161\\u0162\\7?\\2\\2\\u0162\\u0163\"+\n+    \"\\7?\\2\\2\\u0163\\u0164\\7?\\2\\2\\u0164Y\\3\\2\\2\\2\\u0165\\u0166\\7#\\2\\2\\u0166\\u0167\"+\n+    \"\\7?\\2\\2\\u0167[\\3\\2\\2\\2\\u0168\\u0169\\7#\\2\\2\\u0169\\u016a\\7?\\2\\2\\u016a\\u016b\"+\n+    \"\\7?\\2\\2\\u016b]\\3\\2\\2\\2\\u016c\\u016d\\7(\\2\\2\\u016d_\\3\\2\\2\\2\\u016e\\u016f\\7\"+\n+    \"`\\2\\2\\u016fa\\3\\2\\2\\2\\u0170\\u0171\\7~\\2\\2\\u0171c\\3\\2\\2\\2\\u0172\\u0173\\7(\"+\n+    \"\\2\\2\\u0173\\u0174\\7(\\2\\2\\u0174e\\3\\2\\2\\2\\u0175\\u0176\\7~\\2\\2\\u0176\\u0177\"+\n+    \"\\7~\\2\\2\\u0177g\\3\\2\\2\\2\\u0178\\u0179\\7A\\2\\2\\u0179i\\3\\2\\2\\2\\u017a\\u017b\\7\"+\n+    \"<\\2\\2\\u017bk\\3\\2\\2\\2\\u017c\\u017d\\7A\\2\\2\\u017d\\u017e\\7<\\2\\2\\u017em\\3\\2\"+\n+    \"\\2\\2\\u017f\\u0180\\7<\\2\\2\\u0180\\u0181\\7<\\2\\2\\u0181o\\3\\2\\2\\2\\u0182\\u0183\"+\n+    \"\\7/\\2\\2\\u0183\\u0184\\7@\\2\\2\\u0184q\\3\\2\\2\\2\\u0185\\u0186\\7?\\2\\2\\u0186\\u0187\"+\n+    \"\\7\\u0080\\2\\2\\u0187s\\3\\2\\2\\2\\u0188\\u0189\\7?\\2\\2\\u0189\\u018a\\7?\\2\\2\\u018a\"+\n+    \"\\u018b\\7\\u0080\\2\\2\\u018bu\\3\\2\\2\\2\\u018c\\u018d\\7-\\2\\2\\u018d\\u018e\\7-\\2\"+\n+    \"\\2\\u018ew\\3\\2\\2\\2\\u018f\\u0190\\7/\\2\\2\\u0190\\u0191\\7/\\2\\2\\u0191y\\3\\2\\2\\2\"+\n+    \"\\u0192\\u0193\\7?\\2\\2\\u0193{\\3\\2\\2\\2\\u0194\\u0195\\7-\\2\\2\\u0195\\u0196\\7?\\2\"+\n+    \"\\2\\u0196}\\3\\2\\2\\2\\u0197\\u0198\\7/\\2\\2\\u0198\\u0199\\7?\\2\\2\\u0199\\177\\3\\2\"+\n+    \"\\2\\2\\u019a\\u019b\\7,\\2\\2\\u019b\\u019c\\7?\\2\\2\\u019c\\u0081\\3\\2\\2\\2\\u019d\\u019e\"+\n+    \"\\7\\61\\2\\2\\u019e\\u019f\\7?\\2\\2\\u019f\\u0083\\3\\2\\2\\2\\u01a0\\u01a1\\7\\'\\2\\2\\u01a1\"+\n+    \"\\u01a2\\7?\\2\\2\\u01a2\\u0085\\3\\2\\2\\2\\u01a3\\u01a4\\7(\\2\\2\\u01a4\\u01a5\\7?\\2\"+\n+    \"\\2\\u01a5\\u0087\\3\\2\\2\\2\\u01a6\\u01a7\\7`\\2\\2\\u01a7\\u01a8\\7?\\2\\2\\u01a8\\u0089\"+\n+    \"\\3\\2\\2\\2\\u01a9\\u01aa\\7~\\2\\2\\u01aa\\u01ab\\7?\\2\\2\\u01ab\\u008b\\3\\2\\2\\2\\u01ac\"+\n+    \"\\u01ad\\7>\\2\\2\\u01ad\\u01ae\\7>\\2\\2\\u01ae\\u01af\\7?\\2\\2\\u01af\\u008d\\3\\2\\2\"+\n+    \"\\2\\u01b0\\u01b1\\7@\\2\\2\\u01b1\\u01b2\\7@\\2\\2\\u01b2\\u01b3\\7?\\2\\2\\u01b3\\u008f\"+\n+    \"\\3\\2\\2\\2\\u01b4\\u01b5\\7@\\2\\2\\u01b5\\u01b6\\7@\\2\\2\\u01b6\\u01b7\\7@\\2\\2\\u01b7\"+\n+    \"\\u01b8\\7?\\2\\2\\u01b8\\u0091\\3\\2\\2\\2\\u01b9\\u01bb\\7\\62\\2\\2\\u01ba\\u01bc\\t\\4\"+\n+    \"\\2\\2\\u01bb\\u01ba\\3\\2\\2\\2\\u01bc\\u01bd\\3\\2\\2\\2\\u01bd\\u01bb\\3\\2\\2\\2\\u01bd\"+\n+    \"\\u01be\\3\\2\\2\\2\\u01be\\u01c0\\3\\2\\2\\2\\u01bf\\u01c1\\t\\5\\2\\2\\u01c0\\u01bf\\3\\2\"+\n+    \"\\2\\2\\u01c0\\u01c1\\3\\2\\2\\2\\u01c1\\u0093\\3\\2\\2\\2\\u01c2\\u01c3\\7\\62\\2\\2\\u01c3\"+\n+    \"\\u01c5\\t\\6\\2\\2\\u01c4\\u01c6\\t\\7\\2\\2\\u01c5\\u01c4\\3\\2\\2\\2\\u01c6\\u01c7\\3\\2\"+\n+    \"\\2\\2\\u01c7\\u01c5\\3\\2\\2\\2\\u01c7\\u01c8\\3\\2\\2\\2\\u01c8\\u01ca\\3\\2\\2\\2\\u01c9\"+\n+    \"\\u01cb\\t\\5\\2\\2\\u01ca\\u01c9\\3\\2\\2\\2\\u01ca\\u01cb\\3\\2\\2\\2\\u01cb\\u0095\\3\\2\"+\n+    \"\\2\\2\\u01cc\\u01d5\\7\\62\\2\\2\\u01cd\\u01d1\\t\\b\\2\\2\\u01ce\\u01d0\\t\\t\\2\\2\\u01cf\"+\n+    \"\\u01ce\\3\\2\\2\\2\\u01d0\\u01d3\\3\\2\\2\\2\\u01d1\\u01cf\\3\\2\\2\\2\\u01d1\\u01d2\\3\\2\"+\n+    \"\\2\\2\\u01d2\\u01d5\\3\\2\\2\\2\\u01d3\\u01d1\\3\\2\\2\\2\\u01d4\\u01cc\\3\\2\\2\\2\\u01d4\"+\n+    \"\\u01cd\\3\\2\\2\\2\\u01d5\\u01d7\\3\\2\\2\\2\\u01d6\\u01d8\\t\\n\\2\\2\\u01d7\\u01d6\\3\\2\"+\n+    \"\\2\\2\\u01d7\\u01d8\\3\\2\\2\\2\\u01d8\\u0097\\3\\2\\2\\2\\u01d9\\u01e2\\7\\62\\2\\2\\u01da\"+\n+    \"\\u01de\\t\\b\\2\\2\\u01db\\u01dd\\t\\t\\2\\2\\u01dc\\u01db\\3\\2\\2\\2\\u01dd\\u01e0\\3\\2\"+\n+    \"\\2\\2\\u01de\\u01dc\\3\\2\\2\\2\\u01de\\u01df\\3\\2\\2\\2\\u01df\\u01e2\\3\\2\\2\\2\\u01e0\"+\n+    \"\\u01de\\3\\2\\2\\2\\u01e1\\u01d9\\3\\2\\2\\2\\u01e1\\u01da\\3\\2\\2\\2\\u01e2\\u01e9\\3\\2\"+\n+    \"\\2\\2\\u01e3\\u01e5\\5\\24\\n\\2\\u01e4\\u01e6\\t\\t\\2\\2\\u01e5\\u01e4\\3\\2\\2\\2\\u01e6\"+\n+    \"\\u01e7\\3\\2\\2\\2\\u01e7\\u01e5\\3\\2\\2\\2\\u01e7\\u01e8\\3\\2\\2\\2\\u01e8\\u01ea\\3\\2\"+\n+    \"\\2\\2\\u01e9\\u01e3\\3\\2\\2\\2\\u01e9\\u01ea\\3\\2\\2\\2\\u01ea\\u01f4\\3\\2\\2\\2\\u01eb\"+\n+    \"\\u01ed\\t\\13\\2\\2\\u01ec\\u01ee\\t\\f\\2\\2\\u01ed\\u01ec\\3\\2\\2\\2\\u01ed\\u01ee\\3\"+\n+    \"\\2\\2\\2\\u01ee\\u01f0\\3\\2\\2\\2\\u01ef\\u01f1\\t\\t\\2\\2\\u01f0\\u01ef\\3\\2\\2\\2\\u01f1\"+\n+    \"\\u01f2\\3\\2\\2\\2\\u01f2\\u01f0\\3\\2\\2\\2\\u01f2\\u01f3\\3\\2\\2\\2\\u01f3\\u01f5\\3\\2\"+\n+    \"\\2\\2\\u01f4\\u01eb\\3\\2\\2\\2\\u01f4\\u01f5\\3\\2\\2\\2\\u01f5\\u01f7\\3\\2\\2\\2\\u01f6\"+\n+    \"\\u01f8\\t\\r\\2\\2\\u01f7\\u01f6\\3\\2\\2\\2\\u01f7\\u01f8\\3\\2\\2\\2\\u01f8\\u0099\\3\\2\"+\n+    \"\\2\\2\\u01f9\\u0201\\7$\\2\\2\\u01fa\\u01fb\\7^\\2\\2\\u01fb\\u0200\\7$\\2\\2\\u01fc\\u01fd\"+\n+    \"\\7^\\2\\2\\u01fd\\u0200\\7^\\2\\2\\u01fe\\u0200\\n\\16\\2\\2\\u01ff\\u01fa\\3\\2\\2\\2\\u01ff\"+\n+    \"\\u01fc\\3\\2\\2\\2\\u01ff\\u01fe\\3\\2\\2\\2\\u0200\\u0203\\3\\2\\2\\2\\u0201\\u0202\\3\\2\"+\n+    \"\\2\\2\\u0201\\u01ff\\3\\2\\2\\2\\u0202\\u0204\\3\\2\\2\\2\\u0203\\u0201\\3\\2\\2\\2\\u0204\"+\n+    \"\\u0212\\7$\\2\\2\\u0205\\u020d\\7)\\2\\2\\u0206\\u0207\\7^\\2\\2\\u0207\\u020c\\7)\\2\\2\"+\n+    \"\\u0208\\u0209\\7^\\2\\2\\u0209\\u020c\\7^\\2\\2\\u020a\\u020c\\n\\17\\2\\2\\u020b\\u0206\"+\n+    \"\\3\\2\\2\\2\\u020b\\u0208\\3\\2\\2\\2\\u020b\\u020a\\3\\2\\2\\2\\u020c\\u020f\\3\\2\\2\\2\\u020d\"+\n+    \"\\u020e\\3\\2\\2\\2\\u020d\\u020b\\3\\2\\2\\2\\u020e\\u0210\\3\\2\\2\\2\\u020f\\u020d\\3\\2\"+\n+    \"\\2\\2\\u0210\\u0212\\7)\\2\\2\\u0211\\u01f9\\3\\2\\2\\2\\u0211\\u0205\\3\\2\\2\\2\\u0212\"+\n+    \"\\u009b\\3\\2\\2\\2\\u0213\\u0217\\7\\61\\2\\2\\u0214\\u0215\\7^\\2\\2\\u0215\\u0218\\n\\20\"+\n+    \"\\2\\2\\u0216\\u0218\\n\\21\\2\\2\\u0217\\u0214\\3\\2\\2\\2\\u0217\\u0216\\3\\2\\2\\2\\u0218\"+\n+    \"\\u0219\\3\\2\\2\\2\\u0219\\u021a\\3\\2\\2\\2\\u0219\\u0217\\3\\2\\2\\2\\u021a\\u021b\\3\\2\"+\n+    \"\\2\\2\\u021b\\u021f\\7\\61\\2\\2\\u021c\\u021e\\t\\22\\2\\2\\u021d\\u021c\\3\\2\\2\\2\\u021e\"+\n+    \"\\u0221\\3\\2\\2\\2\\u021f\\u021d\\3\\2\\2\\2\\u021f\\u0220\\3\\2\\2\\2\\u0220\\u0222\\3\\2\"+\n+    \"\\2\\2\\u0221\\u021f\\3\\2\\2\\2\\u0222\\u0223\\6N\\3\\2\\u0223\\u009d\\3\\2\\2\\2\\u0224\"+\n+    \"\\u0225\\7v\\2\\2\\u0225\\u0226\\7t\\2\\2\\u0226\\u0227\\7w\\2\\2\\u0227\\u0228\\7g\\2\\2\"+\n+    \"\\u0228\\u009f\\3\\2\\2\\2\\u0229\\u022a\\7h\\2\\2\\u022a\\u022b\\7c\\2\\2\\u022b\\u022c\"+\n+    \"\\7n\\2\\2\\u022c\\u022d\\7u\\2\\2\\u022d\\u022e\\7g\\2\\2\\u022e\\u00a1\\3\\2\\2\\2\\u022f\"+\n+    \"\\u0230\\7p\\2\\2\\u0230\\u0231\\7w\\2\\2\\u0231\\u0232\\7n\\2\\2\\u0232\\u0233\\7n\\2\\2\"+\n+    \"\\u0233\\u00a3\\3\\2\\2\\2\\u0234\\u0238\\5\\u00a6S\\2\\u0235\\u0236\\5\\f\\6\\2\\u0236\"+\n+    \"\\u0237\\5\\16\\7\\2\\u0237\\u0239\\3\\2\\2\\2\\u0238\\u0235\\3\\2\\2\\2\\u0239\\u023a\\3\"+\n+    \"\\2\\2\\2\\u023a\\u0238\\3\\2\\2\\2\\u023a\\u023b\\3\\2\\2\\2\\u023b\\u00a5\\3\\2\\2\\2\\u023c\"+\n+    \"\\u0242\\5\\u00a8T\\2\\u023d\\u023e\\5\\24\\n\\2\\u023e\\u023f\\5\\u00a8T\\2\\u023f\\u0241\"+\n+    \"\\3\\2\\2\\2\\u0240\\u023d\\3\\2\\2\\2\\u0241\\u0244\\3\\2\\2\\2\\u0242\\u0240\\3\\2\\2\\2\\u0242\"+\n+    \"\\u0243\\3\\2\\2\\2\\u0243\\u0245\\3\\2\\2\\2\\u0244\\u0242\\3\\2\\2\\2\\u0245\\u0246\\6S\"+\n+    \"\\4\\2\\u0246\\u00a7\\3\\2\\2\\2\\u0247\\u024b\\t\\23\\2\\2\\u0248\\u024a\\t\\24\\2\\2\\u0249\"+\n+    \"\\u0248\\3\\2\\2\\2\\u024a\\u024d\\3\\2\\2\\2\\u024b\\u0249\\3\\2\\2\\2\\u024b\\u024c\\3\\2\"+\n+    \"\\2\\2\\u024c\\u00a9\\3\\2\\2\\2\\u024d\\u024b\\3\\2\\2\\2\\u024e\\u024f\\13\\2\\2\\2\\u024f\"+\n+    \"\\u0250\\3\\2\\2\\2\\u0250\\u0251\\bU\\2\\2\\u0251\\u00ab\\3\\2\\2\\2\\u0252\\u025b\\7\\62\"+\n+    \"\\2\\2\\u0253\\u0257\\t\\b\\2\\2\\u0254\\u0256\\t\\t\\2\\2\\u0255\\u0254\\3\\2\\2\\2\\u0256\"+\n+    \"\\u0259\\3\\2\\2\\2\\u0257\\u0255\\3\\2\\2\\2\\u0257\\u0258\\3\\2\\2\\2\\u0258\\u025b\\3\\2\"+\n+    \"\\2\\2\\u0259\\u0257\\3\\2\\2\\2\\u025a\\u0252\\3\\2\\2\\2\\u025a\\u0253\\3\\2\\2\\2\\u025b\"+\n+    \"\\u025c\\3\\2\\2\\2\\u025c\\u025d\\bV\\4\\2\\u025d\\u00ad\\3\\2\\2\\2\\u025e\\u0262\\t\\23\"+\n+    \"\\2\\2\\u025f\\u0261\\t\\24\\2\\2\\u0260\\u025f\\3\\2\\2\\2\\u0261\\u0264\\3\\2\\2\\2\\u0262\"+\n+    \"\\u0260\\3\\2\\2\\2\\u0262\\u0263\\3\\2\\2\\2\\u0263\\u0265\\3\\2\\2\\2\\u0264\\u0262\\3\\2\"+\n+    \"\\2\\2\\u0265\\u0266\\bW\\4\\2\\u0266\\u00af\\3\\2\\2\\2%\\2\\3\\u00b3\\u00bd\\u00c7\\u00cc\"+\n+    \"\\u01bd\\u01c0\\u01c7\\u01ca\\u01d1\\u01d4\\u01d7\\u01de\\u01e1\\u01e7\\u01e9\\u01ed\"+\n+    \"\\u01f2\\u01f4\\u01f7\\u01ff\\u0201\\u020b\\u020d\\u0211\\u0217\\u0219\\u021f\\u023a\"+\n+    \"\\u0242\\u024b\\u0257\\u025a\\u0262\\5\\b\\2\\2\\4\\3\\2\\4\\2\\2\";\n+  public static final ATN _ATN =\n+    new ATNDeserializer().deserialize(_serializedATN.toCharArray());\n+  static {\n+    _decisionToDFA = new DFA[_ATN.getNumberOfDecisions()];\n+    for (int i = 0; i < _ATN.getNumberOfDecisions(); i++) {\n+      _decisionToDFA[i] = new DFA(_ATN.getDecisionState(i), i);\n+    }\n+  }\n+}"
  },
  {
    "sha": "c58f2c7055c6827e551fd04dab92a2e474305b9b",
    "filename": "modules/lang-painless/src/main/java/org/elasticsearch/painless/lookup/PainlessLookup.java",
    "status": "modified",
    "additions": 4,
    "deletions": 0,
    "changes": 4,
    "blob_url": "https://github.com/elastic/elasticsearch/blob/d0893e5ae135f0ac881e86cf558fe67a9c65268d/modules/lang-painless/src/main/java/org/elasticsearch/painless/lookup/PainlessLookup.java",
    "raw_url": "https://github.com/elastic/elasticsearch/raw/d0893e5ae135f0ac881e86cf558fe67a9c65268d/modules/lang-painless/src/main/java/org/elasticsearch/painless/lookup/PainlessLookup.java",
    "contents_url": "https://api.github.com/repos/elastic/elasticsearch/contents/modules/lang-painless/src/main/java/org/elasticsearch/painless/lookup/PainlessLookup.java?ref=d0893e5ae135f0ac881e86cf558fe67a9c65268d",
    "patch": "@@ -71,6 +71,10 @@ public boolean isValidCanonicalClassName(String canonicalClassName) {\n         return PainlessLookupUtility.canonicalTypeNameToType(canonicalTypeName, canonicalClassNamesToClasses);\n     }\n \n+    public Set<String> getCanonicalClassNames() {\n+        return canonicalClassNamesToClasses.keySet();\n+    }\n+\n     public Set<Class<?>> getClasses() {\n         return classesToPainlessClasses.keySet();\n     }"
  },
  {
    "sha": "4635d9d75199496646eb14021b78606ddd8b86cf",
    "filename": "modules/lang-painless/src/test/java/org/elasticsearch/painless/ScriptTestCase.java",
    "status": "modified",
    "additions": 24,
    "deletions": 0,
    "changes": 24,
    "blob_url": "https://github.com/elastic/elasticsearch/blob/d0893e5ae135f0ac881e86cf558fe67a9c65268d/modules/lang-painless/src/test/java/org/elasticsearch/painless/ScriptTestCase.java",
    "raw_url": "https://github.com/elastic/elasticsearch/raw/d0893e5ae135f0ac881e86cf558fe67a9c65268d/modules/lang-painless/src/test/java/org/elasticsearch/painless/ScriptTestCase.java",
    "contents_url": "https://api.github.com/repos/elastic/elasticsearch/contents/modules/lang-painless/src/test/java/org/elasticsearch/painless/ScriptTestCase.java?ref=d0893e5ae135f0ac881e86cf558fe67a9c65268d",
    "patch": "@@ -10,7 +10,10 @@\n \n import junit.framework.AssertionFailedError;\n import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.painless.action.PainlessSuggest;\n+import org.elasticsearch.painless.action.PainlessSuggest.Suggestion;\n import org.elasticsearch.painless.antlr.Walker;\n+import org.elasticsearch.painless.lookup.PainlessLookup;\n import org.elasticsearch.painless.spi.Whitelist;\n import org.elasticsearch.painless.spi.WhitelistLoader;\n import org.elasticsearch.script.ScriptContext;\n@@ -90,6 +93,27 @@ public Object exec(String script, Map<String, Object> vars, Map<String,String> c\n         return testScript.execute();\n     }\n \n+    /** Generates suggestions for the given source using the PainlessTestScript context */\n+    public List<Suggestion> suggest(String source) {\n+        Class<?> clazz = null;\n+        PainlessLookup lookup = null;\n+\n+        for (Map.Entry<ScriptContext<?>, PainlessLookup> contextLookupEntry : scriptEngine.getContextsToLookups().entrySet()) {\n+            if (contextLookupEntry.getKey().name.equals(PainlessTestScript.CONTEXT.name)) {\n+                clazz = contextLookupEntry.getKey().instanceClazz;\n+                lookup = contextLookupEntry.getValue();\n+                break;\n+            }\n+        }\n+\n+        if (clazz == null || lookup == null) {\n+            throw new IllegalArgumentException(\"script context [\" + PainlessTestScript.CONTEXT.name + \"] not found\");\n+        }\n+\n+        ScriptClassInfo info = new ScriptClassInfo(lookup, clazz);\n+        return PainlessSuggest.suggest(lookup, info, source);\n+    }\n+\n     /**\n      * Uses the {@link Debugger} to get the bytecode output for a script and compare\n      * it against an expected bytecode passed in as a String."
  },
  {
    "sha": "ef5fb7b07abf2000e1fe3cfe9bc8d53643ffa4aa",
    "filename": "modules/lang-painless/src/test/java/org/elasticsearch/painless/action/SuggestTests.java",
    "status": "added",
    "additions": 145,
    "deletions": 0,
    "changes": 145,
    "blob_url": "https://github.com/elastic/elasticsearch/blob/d0893e5ae135f0ac881e86cf558fe67a9c65268d/modules/lang-painless/src/test/java/org/elasticsearch/painless/action/SuggestTests.java",
    "raw_url": "https://github.com/elastic/elasticsearch/raw/d0893e5ae135f0ac881e86cf558fe67a9c65268d/modules/lang-painless/src/test/java/org/elasticsearch/painless/action/SuggestTests.java",
    "contents_url": "https://api.github.com/repos/elastic/elasticsearch/contents/modules/lang-painless/src/test/java/org/elasticsearch/painless/action/SuggestTests.java?ref=d0893e5ae135f0ac881e86cf558fe67a9c65268d",
    "patch": "@@ -0,0 +1,145 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License\n+ * 2.0 and the Server Side Public License, v 1; you may not use this file except\n+ * in compliance with, at your election, the Elastic License 2.0 or the Server\n+ * Side Public License, v 1.\n+ */\n+\n+package org.elasticsearch.painless.action;\n+\n+import org.elasticsearch.painless.ScriptTestCase;\n+import org.elasticsearch.painless.action.PainlessSuggest.Suggestion;\n+\n+import java.util.List;\n+\n+public class SuggestTests extends ScriptTestCase {\n+\n+    private static void compareSuggestions(List<Suggestion> actual, String... values) {\n+        assertEquals(values.length % 2, 0);\n+        assertEquals(actual.size(), values.length / 2);\n+\n+        for (int i = 0; i < values.length; ++i) {\n+            assertTrue(actual.contains(new Suggestion(values[i], values[++i])));\n+        }\n+    }\n+\n+    public void testVariables() {\n+        compareSuggestions(\n+                suggest(\"List test; tes\"),\n+                Suggestion.VARIABLE, \"test\"\n+        );\n+\n+        compareSuggestions(suggest(\"List test0, test1; int teaser; te\"),\n+                Suggestion.VARIABLE, \"test0\",\n+                Suggestion.VARIABLE, \"test1\",\n+                Suggestion.VARIABLE, \"teaser\"\n+        );\n+\n+        compareSuggestions(\n+                suggest(\"List test0, test1; if (condition) { int teaser; } return te\"),\n+                Suggestion.VARIABLE, \"test0\",\n+                Suggestion.VARIABLE, \"test1\"\n+        );\n+\n+        compareSuggestions(\n+                suggest(\"List test0, test1; if (condition) { int teaser; return te\"),\n+                Suggestion.VARIABLE, \"test0\",\n+                Suggestion.VARIABLE, \"test1\",\n+                Suggestion.VARIABLE, \"teaser\"\n+        );\n+\n+        compareSuggestions(\n+                suggest(\"List test0, test1; if (condition) { int teaser; } else return te\"),\n+                Suggestion.VARIABLE, \"test0\",\n+                Suggestion.VARIABLE, \"test1\"\n+        );\n+\n+        compareSuggestions(\n+                suggest(\"List test0, test1; if (condition) if (condition) { int teaser; } else return te\"),\n+                Suggestion.VARIABLE, \"test0\",\n+                Suggestion.VARIABLE, \"test1\"\n+        );\n+    }\n+\n+    public void testMethods() {\n+        compareSuggestions(\n+                suggest(\"GeoPoint test; test.\"),\n+                Suggestion.METHOD, \"getLat/0\",\n+                Suggestion.METHOD, \"getLon/0\",\n+                Suggestion.METHOD, \"hashCode/0\",\n+                Suggestion.METHOD, \"equals/1\",\n+                Suggestion.METHOD, \"toString/0\"\n+        );\n+\n+        compareSuggestions(\n+                suggest(\"List list; list.add\"),\n+                Suggestion.METHOD, \"add/1\",\n+                Suggestion.METHOD, \"add/2\",\n+                Suggestion.METHOD, \"addAll/1\",\n+                Suggestion.METHOD, \"addAll/2\"\n+        );\n+\n+        compareSuggestions(\n+                suggest(\"Math.ma\"),\n+                Suggestion.METHOD, \"max/2\"\n+        );\n+\n+        compareSuggestions(\n+                suggest(\"int value = Math.max(2.0, 2.0), Math.min(va\"),\n+                Suggestion.VARIABLE, \"value\"\n+        );\n+    }\n+\n+    public void testFields() {\n+        compareSuggestions(\n+                suggest(\"Math.P\"),\n+                Suggestion.FIELD, \"PI\"\n+        );\n+    }\n+\n+    public void testFunctions() {\n+        compareSuggestions(\n+                suggest(\"para\"),\n+                Suggestion.VARIABLE, \"params\"\n+        );\n+\n+        compareSuggestions(\n+                suggest(\"int testF() {} int testY(blah) {} test\"),\n+                Suggestion.USER, \"testF/0\",\n+                Suggestion.USER, \"testY/0\"\n+        );\n+\n+        compareSuggestions(\n+                suggest(\"int testF() {} int testY(blah) {} test\"),\n+                Suggestion.USER, \"testF/0\",\n+                Suggestion.USER, \"testY/0\"\n+        );\n+\n+        compareSuggestions(\n+                suggest(\"int testF() {} int testY(blah) {} testY().toS\"),\n+                Suggestion.METHOD, \"toString/0\"\n+        );\n+\n+        compareSuggestions(\n+                suggest(\"int testF() {} int testY(List x) {return blah blah} test\"),\n+                Suggestion.USER, \"testF/0\",\n+                Suggestion.USER, \"testY/1\"\n+        );\n+\n+        compareSuggestions(\n+                suggest(\"int testF() {} int testY(blah) {trash trash} testY().toS\"),\n+                Suggestion.METHOD, \"toString/0\"\n+        );\n+\n+        compareSuggestions(\n+                suggest(\"int testF(int para) {par\"),\n+                Suggestion.VARIABLE, \"para\"\n+        );\n+\n+        compareSuggestions(\n+                suggest(\"int testF(int para) {int par = para; return par} par\"),\n+                Suggestion.VARIABLE, \"params\"\n+        );\n+    }\n+}"
  },
  {
    "sha": "67108bb28549913173239ed21bdc43895ab77b64",
    "filename": "modules/lang-painless/src/yamlRestTest/resources/rest-api-spec/api/scripts_painless_suggestions.json",
    "status": "added",
    "additions": 23,
    "deletions": 0,
    "changes": 23,
    "blob_url": "https://github.com/elastic/elasticsearch/blob/d0893e5ae135f0ac881e86cf558fe67a9c65268d/modules/lang-painless/src/yamlRestTest/resources/rest-api-spec/api/scripts_painless_suggestions.json",
    "raw_url": "https://github.com/elastic/elasticsearch/raw/d0893e5ae135f0ac881e86cf558fe67a9c65268d/modules/lang-painless/src/yamlRestTest/resources/rest-api-spec/api/scripts_painless_suggestions.json",
    "contents_url": "https://api.github.com/repos/elastic/elasticsearch/contents/modules/lang-painless/src/yamlRestTest/resources/rest-api-spec/api/scripts_painless_suggestions.json?ref=d0893e5ae135f0ac881e86cf558fe67a9c65268d",
    "patch": "@@ -0,0 +1,23 @@\n+{\n+  \"scripts_painless_suggestions\": {\n+    \"stability\": \"experimental\",\n+    \"visibility\": \"public\",\n+    \"headers\":{\n+      \"accept\": [ \"application/json\"],\n+      \"content_type\": [\"application/json\"]\n+    },\n+    \"url\": {\n+      \"paths\": [\n+        {\n+          \"path\": \"/_scripts/painless/_suggestions\",\n+          \"methods\": [\n+            \"POST\"\n+          ]\n+        }\n+      ]\n+    },\n+    \"body\":{\n+      \"description\":\"the script, and optionally context to collect suggestions for\"\n+    }\n+  }\n+}"
  },
  {
    "sha": "e9d3e42b946b48a357fc5c1354c1dafa16edf0c4",
    "filename": "modules/lang-painless/src/yamlRestTest/resources/rest-api-spec/test/painless/120_script_suggestions.yml",
    "status": "added",
    "additions": 20,
    "deletions": 0,
    "changes": 20,
    "blob_url": "https://github.com/elastic/elasticsearch/blob/d0893e5ae135f0ac881e86cf558fe67a9c65268d/modules/lang-painless/src/yamlRestTest/resources/rest-api-spec/test/painless/120_script_suggestions.yml",
    "raw_url": "https://github.com/elastic/elasticsearch/raw/d0893e5ae135f0ac881e86cf558fe67a9c65268d/modules/lang-painless/src/yamlRestTest/resources/rest-api-spec/test/painless/120_script_suggestions.yml",
    "contents_url": "https://api.github.com/repos/elastic/elasticsearch/contents/modules/lang-painless/src/yamlRestTest/resources/rest-api-spec/test/painless/120_script_suggestions.yml?ref=d0893e5ae135f0ac881e86cf558fe67a9c65268d",
    "patch": "@@ -0,0 +1,20 @@\n+---\n+\"Action to get suggestions with a default context\":\n+  - do:\n+      scripts_painless_suggestions:\n+        body:\n+          script:\n+            source: \"int test; te\"\n+  - match: { suggestions.0.type: variable }\n+  - match: { suggestions.0.text: test }\n+\n+---\n+\"Action to get suggestions with a specific context\":\n+  - do:\n+      scripts_painless_suggestions:\n+        body:\n+          context: score\n+          script:\n+            source: \"satura\"\n+  - match: { suggestions.0.type: call }\n+  - match: { suggestions.0.text: \"saturation/2\" }"
  },
  {
    "sha": "2f44eec06bab0f847a371eb332a18938ae45388e",
    "filename": "x-pack/plugin/security/qa/operator-privileges-tests/src/javaRestTest/java/org/elasticsearch/xpack/security/operator/Constants.java",
    "status": "modified",
    "additions": 1,
    "deletions": 0,
    "changes": 1,
    "blob_url": "https://github.com/elastic/elasticsearch/blob/d0893e5ae135f0ac881e86cf558fe67a9c65268d/x-pack/plugin/security/qa/operator-privileges-tests/src/javaRestTest/java/org/elasticsearch/xpack/security/operator/Constants.java",
    "raw_url": "https://github.com/elastic/elasticsearch/raw/d0893e5ae135f0ac881e86cf558fe67a9c65268d/x-pack/plugin/security/qa/operator-privileges-tests/src/javaRestTest/java/org/elasticsearch/xpack/security/operator/Constants.java",
    "contents_url": "https://api.github.com/repos/elastic/elasticsearch/contents/x-pack/plugin/security/qa/operator-privileges-tests/src/javaRestTest/java/org/elasticsearch/xpack/security/operator/Constants.java?ref=d0893e5ae135f0ac881e86cf558fe67a9c65268d",
    "patch": "@@ -63,6 +63,7 @@\n         \"cluster:admin/script_language/get\",\n         \"cluster:admin/scripts/painless/context\",\n         \"cluster:admin/scripts/painless/execute\",\n+        \"cluster:admin/scripts/painless/suggestions\",\n         \"cluster:admin/settings/update\",\n         \"cluster:admin/slm/delete\",\n         \"cluster:admin/slm/execute\","
  }
]
