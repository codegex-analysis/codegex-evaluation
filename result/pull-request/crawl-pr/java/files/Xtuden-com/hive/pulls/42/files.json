[
  {
    "sha": "baf1addc7e5a7d03b575af5cb474e09fdbec438a",
    "filename": "pom.xml",
    "status": "modified",
    "additions": 15,
    "deletions": 16,
    "changes": 31,
    "blob_url": "https://github.com/Xtuden-com/hive/blob/53d7325849611fb4dde518f900694a882ae3a453/pom.xml",
    "raw_url": "https://github.com/Xtuden-com/hive/raw/53d7325849611fb4dde518f900694a882ae3a453/pom.xml",
    "contents_url": "https://api.github.com/repos/Xtuden-com/hive/contents/pom.xml?ref=53d7325849611fb4dde518f900694a882ae3a453",
    "patch": "@@ -79,7 +79,7 @@\n     <checkstyle.conf.dir>${basedir}/${hive.path.to.root}/checkstyle</checkstyle.conf.dir>\n \n     <!-- Test Properties -->\n-    <test.extra.path></test.extra.path>\n+    <test.extra.path/>\n     <itest.jdbc.jars>set-this-to-colon-separated-full-path-list-of-jars-to-run-integration-tests\n     </itest.jdbc.jars>\n     <!--suppress UnresolvedMavenProperty -->\n@@ -95,7 +95,7 @@\n     <test.warehouse.scheme>pfile://</test.warehouse.scheme>\n \n     <!-- To add additional exclude patterns set this property -->\n-    <test.excludes.additional></test.excludes.additional>\n+    <test.excludes.additional/>\n     <skip.spark.files>**/TestSparkStatistics*,**/TestSparkSessionTimeout*,**/TestJdbcWithMiniHS2ErasureCoding*,**/TestLocalHiveSparkClient*</skip.spark.files>\n \n     <!-- Plugin and Plugin Dependency Versions -->\n@@ -137,7 +137,7 @@\n     <guava.version>19.0</guava.version>\n     <groovy.version>2.4.11</groovy.version>\n     <h2database.version>1.3.166</h2database.version>\n-    <hadoop.version>3.1.0</hadoop.version>\n+    <hadoop.version>3.3.0</hadoop.version>\n     <hadoop.bin.path>${basedir}/${hive.path.to.root}/testutils/hadoop</hadoop.bin.path>\n     <hamcrest.version>1.3</hamcrest.version>\n     <hbase.version>2.0.0-alpha4</hbase.version>\n@@ -196,7 +196,7 @@\n     <storage-api.version>2.7.0-SNAPSHOT</storage-api.version>\n     <tez.version>0.10.0</tez.version>\n     <super-csv.version>2.2.0</super-csv.version>\n-    <spark.version>2.4.5</spark.version>\n+    <spark.version>3.1.0</spark.version>\n     <scala.binary.version>2.12</scala.binary.version>\n     <scala.version>2.12.10</scala.version>\n     <tempus-fugit.version>1.1</tempus-fugit.version>\n@@ -1191,12 +1191,12 @@\n             </goals>\n             <configuration>\n               <target>\n-                <delete dir=\"${test.tmp.dir}\" />\n-                <delete dir=\"${test.conf.dir}\" />\n-                <delete dir=\"${test.warehouse.dir}\" />\n-                <mkdir dir=\"${test.tmp.dir}\" />\n-                <mkdir dir=\"${test.warehouse.dir}\" />\n-                <mkdir dir=\"${test.conf.dir}\" />\n+                <delete dir=\"${test.tmp.dir}\"/>\n+                <delete dir=\"${test.conf.dir}\"/>\n+                <delete dir=\"${test.warehouse.dir}\"/>\n+                <mkdir dir=\"${test.tmp.dir}\"/>\n+                <mkdir dir=\"${test.warehouse.dir}\"/>\n+                <mkdir dir=\"${test.conf.dir}\"/>\n                 <!-- copies hive-site.xml so it can be modified -->\n                 <copy todir=\"${test.conf.dir}\">\n                   <fileset dir=\"${basedir}/${hive.path.to.root}/data/conf/\"/>\n@@ -1398,7 +1398,7 @@\n             <test.local.warehouse.dir>${test.warehouse.scheme}${test.local.warehouse.dir}</test.local.warehouse.dir>\n             <java.net.preferIPv4Stack>true</java.net.preferIPv4Stack>\n             <!-- EnforceReadOnlyTables hook and QTestUtil -->\n-            <test.src.tables></test.src.tables>\n+            <test.src.tables/>\n             <java.security.krb5.conf>${test.conf.dir}/krb5.conf</java.security.krb5.conf>\n             <!-- Required by spark to work around SPARK-14958 -->\n             <antlr.version>${antlr.version}</antlr.version>\n@@ -1495,20 +1495,19 @@\n                 <phase>generate-sources</phase>\n                 <configuration>\n                   <target>\n-                    <taskdef name=\"for\" classname=\"net.sf.antcontrib.logic.ForTask\"\n-                      classpathref=\"maven.plugin.classpath\" />\n+                    <taskdef name=\"for\" classname=\"net.sf.antcontrib.logic.ForTask\" classpathref=\"maven.plugin.classpath\"/>\n                     <property name=\"thrift.args\" value=\"-I ${thrift.home} --gen java:beans,generated_annotations=undated --gen cpp --gen php --gen py --gen rb\"/>\n                     <property name=\"thrift.gen.dir\" value=\"${basedir}/src/gen/thrift\"/>\n                     <delete dir=\"${thrift.gen.dir}\"/>\n                     <mkdir dir=\"${thrift.gen.dir}\"/>\n                     <for param=\"thrift.file\">\n                       <path>\n-                        <fileset dir=\".\" includes=\"if/*.thrift,if/test/*.thrift,src/main/thrift/*.thrift\" />\n+                        <fileset dir=\".\" includes=\"if/*.thrift,if/test/*.thrift,src/main/thrift/*.thrift\"/>\n                       </path>\n                       <sequential>\n                         <echo message=\"Generating Thrift code for @{thrift.file}\"/>\n-                        <exec executable=\"${thrift.home}/bin/thrift\"  failonerror=\"true\" dir=\".\">\n-                          <arg line=\"${thrift.args} -I ${basedir}/include -I ${basedir}/.. -o ${thrift.gen.dir} @{thrift.file} \" />\n+                        <exec executable=\"${thrift.home}/bin/thrift\" failonerror=\"true\" dir=\".\">\n+                          <arg line=\"${thrift.args} -I ${basedir}/include -I ${basedir}/.. -o ${thrift.gen.dir} @{thrift.file} \"/>\n                         </exec>\n                       </sequential>\n                     </for>"
  }
]
