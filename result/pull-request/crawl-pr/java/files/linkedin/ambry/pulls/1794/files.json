[
  {
    "sha": "5099c1ca036a2150a10f75430fe9c1c4d86e8898",
    "filename": "ambry-cloud/src/main/java/com/github/ambry/cloud/VcrReplicationManager.java",
    "status": "modified",
    "additions": 1,
    "deletions": 1,
    "changes": 2,
    "blob_url": "https://github.com/linkedin/ambry/blob/4775b969c853e2e441e026228b6e282fb35c317d/ambry-cloud/src/main/java/com/github/ambry/cloud/VcrReplicationManager.java",
    "raw_url": "https://github.com/linkedin/ambry/raw/4775b969c853e2e441e026228b6e282fb35c317d/ambry-cloud/src/main/java/com/github/ambry/cloud/VcrReplicationManager.java",
    "contents_url": "https://api.github.com/repos/linkedin/ambry/contents/ambry-cloud/src/main/java/com/github/ambry/cloud/VcrReplicationManager.java?ref=4775b969c853e2e441e026228b6e282fb35c317d",
    "patch": "@@ -188,7 +188,7 @@ void addReplica(PartitionId partitionId) throws ReplicationException {\n             tokenHelper.getFindTokenFactoryFromReplicaType(peerReplica.getReplicaType());\n         RemoteReplicaInfo remoteReplicaInfo =\n             new RemoteReplicaInfo(peerReplica, cloudReplica, store, findTokenFactory.getNewFindToken(),\n-                storeConfig.storeDataFlushIntervalSeconds * SystemTime.MsPerSec * Replication_Delay_Multiplier,\n+                storeConfig.storeDataFlushIntervalSeconds * TimeUnit.SECONDS.toMicros(1) * Replication_Delay_Multiplier,\n                 SystemTime.getInstance(), peerReplica.getDataNodeId().getPortToConnectTo());\n         replicationMetrics.addMetricsForRemoteReplicaInfo(remoteReplicaInfo, trackPerDatacenterLagInMetric);\n         remoteReplicaInfos.add(remoteReplicaInfo);"
  },
  {
    "sha": "9982beabbe88fac02efc1b2097ab0b2144d01bd5",
    "filename": "ambry-frontend/src/main/java/com/github/ambry/frontend/AmbrySecurityService.java",
    "status": "modified",
    "additions": 2,
    "deletions": 1,
    "changes": 3,
    "blob_url": "https://github.com/linkedin/ambry/blob/4775b969c853e2e441e026228b6e282fb35c317d/ambry-frontend/src/main/java/com/github/ambry/frontend/AmbrySecurityService.java",
    "raw_url": "https://github.com/linkedin/ambry/raw/4775b969c853e2e441e026228b6e282fb35c317d/ambry-frontend/src/main/java/com/github/ambry/frontend/AmbrySecurityService.java",
    "contents_url": "https://api.github.com/repos/linkedin/ambry/contents/ambry-frontend/src/main/java/com/github/ambry/frontend/AmbrySecurityService.java?ref=4775b969c853e2e441e026228b6e282fb35c317d",
    "patch": "@@ -44,6 +44,7 @@\n import java.util.Map;\n import java.util.Set;\n import java.util.TreeSet;\n+import java.util.concurrent.TimeUnit;\n import java.util.stream.Collectors;\n \n import static com.github.ambry.rest.RestUtils.*;\n@@ -365,7 +366,7 @@ private void setCacheHeaders(RestRequest restRequest, RestResponseChannel restRe\n     Container container = RestUtils.getContainerFromArgs(restRequest.getArgs());\n     if (container.isCacheable()) {\n       restResponseChannel.setHeader(RestUtils.Headers.EXPIRES,\n-          new Date(System.currentTimeMillis() + frontendConfig.cacheValiditySeconds * Time.MsPerSec));\n+          new Date(System.currentTimeMillis() + frontendConfig.cacheValiditySeconds * TimeUnit.SECONDS.toMicros(1)));\n       restResponseChannel.setHeader(RestUtils.Headers.CACHE_CONTROL, \"max-age=\" + frontendConfig.cacheValiditySeconds);\n     } else {\n       restResponseChannel.setHeader(RestUtils.Headers.EXPIRES, restResponseChannel.getHeader(RestUtils.Headers.DATE));"
  },
  {
    "sha": "96b0a68fa38e7adcb158ead8f09ce47b00175cd3",
    "filename": "ambry-network/src/main/java/com/github/ambry/network/SocketNetworkClient.java",
    "status": "modified",
    "additions": 3,
    "deletions": 2,
    "changes": 5,
    "blob_url": "https://github.com/linkedin/ambry/blob/4775b969c853e2e441e026228b6e282fb35c317d/ambry-network/src/main/java/com/github/ambry/network/SocketNetworkClient.java",
    "raw_url": "https://github.com/linkedin/ambry/raw/4775b969c853e2e441e026228b6e282fb35c317d/ambry-network/src/main/java/com/github/ambry/network/SocketNetworkClient.java",
    "contents_url": "https://api.github.com/repos/linkedin/ambry/contents/ambry-network/src/main/java/com/github/ambry/network/SocketNetworkClient.java?ref=4775b969c853e2e441e026228b6e282fb35c317d",
    "patch": "@@ -84,7 +84,8 @@ public SocketNetworkClient(Selector selector, NetworkConfig networkConfig, Netwo\n     connectionIdToRequestInFlight = new HashMap<>();\n     correlationIdInFlightToConnectionId = new HashMap<>();\n     pendingConnectionsToAssociatedRequests = new HashMap<>();\n-    nextReplenishMs = time.milliseconds() + ThreadLocalRandom.current().nextInt(Time.MsPerSec);\n+    nextReplenishMs = time.milliseconds() + ThreadLocalRandom.current().nextInt(\n+            Math.toIntExact(TimeUnit.SECONDS.toMicros(1)));\n     networkMetrics.registerNetworkClientPendingConnections(numPendingRequests);\n   }\n \n@@ -245,7 +246,7 @@ private void replenishConnections() {\n       if (connectionsInitiated > 0) {\n         networkMetrics.connectionReplenished.inc(connectionsInitiated);\n         logger.debug(\"replenishConnections initiated {} connections\", connectionsInitiated);\n-        nextReplenishMs = currentTimeMs + Time.MsPerSec;\n+        nextReplenishMs = currentTimeMs + TimeUnit.SECONDS.toMicros(1);\n       }\n     }\n   }"
  },
  {
    "sha": "dca274e90b4b55de2e4fdf59b02fd2afa8465fb5",
    "filename": "ambry-network/src/main/java/com/github/ambry/network/Transmission.java",
    "status": "modified",
    "additions": 3,
    "deletions": 2,
    "changes": 5,
    "blob_url": "https://github.com/linkedin/ambry/blob/4775b969c853e2e441e026228b6e282fb35c317d/ambry-network/src/main/java/com/github/ambry/network/Transmission.java",
    "raw_url": "https://github.com/linkedin/ambry/raw/4775b969c853e2e441e026228b6e282fb35c317d/ambry-network/src/main/java/com/github/ambry/network/Transmission.java",
    "contents_url": "https://api.github.com/repos/linkedin/ambry/contents/ambry-network/src/main/java/com/github/ambry/network/Transmission.java?ref=4775b969c853e2e441e026228b6e282fb35c317d",
    "patch": "@@ -20,6 +20,7 @@\n import java.net.SocketAddress;\n import java.nio.channels.SelectionKey;\n import java.nio.channels.SocketChannel;\n+import java.util.concurrent.TimeUnit;\n \n \n /**\n@@ -114,7 +115,7 @@ public void onSendComplete() {\n     sendCompleteTime = time.milliseconds();\n     long sendTimeMs = sendCompleteTime - networkSend.getSendStartTimeInMs();\n     metrics.transmissionSendAllTime.update(sendTimeMs);\n-    double sendBytesRate = networkSend.getPayload().sizeInBytes() / ((double) sendTimeMs / SystemTime.MsPerSec);\n+    double sendBytesRate = networkSend.getPayload().sizeInBytes() / ((double) sendTimeMs / TimeUnit.SECONDS.toMicros(1));\n     metrics.transmissionSendBytesRate.mark((long) sendBytesRate);\n   }\n \n@@ -125,7 +126,7 @@ public void onReceiveComplete() {\n     long receiveTimeMs = time.milliseconds() - networkReceive.getReceiveStartTimeInMs();\n     metrics.transmissionReceiveAllTime.update(receiveTimeMs);\n     double receiveBytesRate =\n-        networkReceive.getReceivedBytes().sizeRead() / ((double) receiveTimeMs / SystemTime.MsPerSec);\n+        networkReceive.getReceivedBytes().sizeRead() / ((double) receiveTimeMs / TimeUnit.SECONDS.toMicros(1));\n     metrics.transmissionReceiveBytesRate.mark((long) receiveBytesRate);\n   }\n "
  },
  {
    "sha": "dfde3514fab77c5eb86c9b7f52ff155a3d8539eb",
    "filename": "ambry-network/src/test/java/com/github/ambry/network/SocketNetworkClientTest.java",
    "status": "modified",
    "additions": 1,
    "deletions": 1,
    "changes": 2,
    "blob_url": "https://github.com/linkedin/ambry/blob/4775b969c853e2e441e026228b6e282fb35c317d/ambry-network/src/test/java/com/github/ambry/network/SocketNetworkClientTest.java",
    "raw_url": "https://github.com/linkedin/ambry/raw/4775b969c853e2e441e026228b6e282fb35c317d/ambry-network/src/test/java/com/github/ambry/network/SocketNetworkClientTest.java",
    "contents_url": "https://api.github.com/repos/linkedin/ambry/contents/ambry-network/src/test/java/com/github/ambry/network/SocketNetworkClientTest.java?ref=4775b969c853e2e441e026228b6e282fb35c317d",
    "patch": "@@ -399,7 +399,7 @@ public void testConnectionReplenishment() {\n     responseInfoList.forEach(ResponseInfo::release);\n \n     // 4. one of the connection lost in sendAndPoll 3 should be replenished\n-    time.setCurrentMilliseconds(time.milliseconds() + Time.MsPerSec);\n+    time.setCurrentMilliseconds(time.milliseconds() + TimeUnit.SECONDS.toMicros(1));\n     selector.setState(MockSelectorState.Good);\n     responseInfoList = networkClient.sendAndPoll(requestGen.apply(0), Collections.emptySet(), POLL_TIMEOUT_MS);\n     expectedConnectCalls.addAndGet(1);"
  },
  {
    "sha": "9c26036a97bcf70fd322ceda91fa53c4a4a9a70b",
    "filename": "ambry-replication/src/main/java/com/github/ambry/replication/CloudToStoreReplicationManager.java",
    "status": "modified",
    "additions": 1,
    "deletions": 1,
    "changes": 2,
    "blob_url": "https://github.com/linkedin/ambry/blob/4775b969c853e2e441e026228b6e282fb35c317d/ambry-replication/src/main/java/com/github/ambry/replication/CloudToStoreReplicationManager.java",
    "raw_url": "https://github.com/linkedin/ambry/raw/4775b969c853e2e441e026228b6e282fb35c317d/ambry-replication/src/main/java/com/github/ambry/replication/CloudToStoreReplicationManager.java",
    "contents_url": "https://api.github.com/repos/linkedin/ambry/contents/ambry-replication/src/main/java/com/github/ambry/replication/CloudToStoreReplicationManager.java?ref=4775b969c853e2e441e026228b6e282fb35c317d",
    "patch": "@@ -177,7 +177,7 @@ private void addCloudReplica(String partitionName) throws ReplicationException {\n         tokenHelper.getFindTokenFactoryFromReplicaType(peerCloudReplica.getReplicaType());\n     RemoteReplicaInfo remoteReplicaInfo =\n         new RemoteReplicaInfo(peerCloudReplica, localReplica, store, findTokenFactory.getNewFindToken(),\n-            storeConfig.storeDataFlushIntervalSeconds * SystemTime.MsPerSec * Replication_Delay_Multiplier,\n+            storeConfig.storeDataFlushIntervalSeconds * TimeUnit.SECONDS.toMicros(1) * Replication_Delay_Multiplier,\n             SystemTime.getInstance(), peerCloudReplica.getDataNodeId().getPortToConnectTo());\n     replicationMetrics.addMetricsForRemoteReplicaInfo(remoteReplicaInfo, trackPerDatacenterLagInMetric);\n "
  },
  {
    "sha": "e7a5d37a4a8c2b7361226c63b7c13bb41989cb05",
    "filename": "ambry-router/src/main/java/com/github/ambry/router/NonBlockingRouter.java",
    "status": "modified",
    "additions": 1,
    "deletions": 1,
    "changes": 2,
    "blob_url": "https://github.com/linkedin/ambry/blob/4775b969c853e2e441e026228b6e282fb35c317d/ambry-router/src/main/java/com/github/ambry/router/NonBlockingRouter.java",
    "raw_url": "https://github.com/linkedin/ambry/raw/4775b969c853e2e441e026228b6e282fb35c317d/ambry-router/src/main/java/com/github/ambry/router/NonBlockingRouter.java",
    "contents_url": "https://api.github.com/repos/linkedin/ambry/contents/ambry-router/src/main/java/com/github/ambry/router/NonBlockingRouter.java?ref=4775b969c853e2e441e026228b6e282fb35c317d",
    "patch": "@@ -81,7 +81,7 @@\n   private static final Logger logger = LoggerFactory.getLogger(NonBlockingRouter.class);\n   static final AtomicInteger currentOperationsCount = new AtomicInteger(0);\n   private final AtomicInteger currentBackgroundOperationsCount = new AtomicInteger(0);\n-  static final int SHUTDOWN_WAIT_MS = 10 * Time.MsPerSec;\n+  static final long SHUTDOWN_WAIT_MS = 10 * TimeUnit.SECONDS.toMicros(1);\n   static final AtomicInteger correlationIdGenerator = new AtomicInteger(0);\n \n   /**"
  },
  {
    "sha": "730aaf98bc8dbb60999f869b18103093d993e933",
    "filename": "ambry-store/src/main/java/com/github/ambry/store/BlobStoreCompactor.java",
    "status": "modified",
    "additions": 2,
    "deletions": 2,
    "changes": 4,
    "blob_url": "https://github.com/linkedin/ambry/blob/4775b969c853e2e441e026228b6e282fb35c317d/ambry-store/src/main/java/com/github/ambry/store/BlobStoreCompactor.java",
    "raw_url": "https://github.com/linkedin/ambry/raw/4775b969c853e2e441e026228b6e282fb35c317d/ambry-store/src/main/java/com/github/ambry/store/BlobStoreCompactor.java",
    "contents_url": "https://api.github.com/repos/linkedin/ambry/contents/ambry-store/src/main/java/com/github/ambry/store/BlobStoreCompactor.java?ref=4775b969c853e2e441e026228b6e282fb35c317d",
    "patch": "@@ -70,7 +70,7 @@ public boolean accept(File dir, String name) {\n     }\n   };\n \n-  private static final long WAIT_TIME_FOR_CLEANUP_MS = 5 * Time.MsPerSec;\n+  private static final long WAIT_TIME_FOR_CLEANUP_MS = 5 * TimeUnit.SECONDS.toMicros(1);\n   private static final Logger logger = LoggerFactory.getLogger(BlobStoreCompactor.class);\n   private final File dataDir;\n   private final String storeId;\n@@ -842,7 +842,7 @@ private boolean copyRecords(LogSegment logSegmentToCopy, List<IndexEntry> srcInd\n               tgtIndex.addToIndex(new IndexEntry(srcIndexEntry.getKey(), tgtValue), fileSpan);\n             }\n             long lastModifiedTimeSecsToSet =\n-                srcValue.getOperationTimeInMs() != Utils.Infinite_Time ? srcValue.getOperationTimeInMs() / Time.MsPerSec\n+                srcValue.getOperationTimeInMs() != Utils.Infinite_Time ? srcValue.getOperationTimeInMs() / TimeUnit.SECONDS.toMicros(1)\n                     : lastModifiedTimeSecs;\n             tgtIndex.getIndexSegments().lastEntry().getValue().setLastModifiedTimeSecs(lastModifiedTimeSecsToSet);\n             writtenLastTime = srcValue.getSize();"
  },
  {
    "sha": "d4dd0701090fb2c92d3a726c843636cbac8d1237",
    "filename": "ambry-store/src/main/java/com/github/ambry/store/HardDeleter.java",
    "status": "modified",
    "additions": 1,
    "deletions": 1,
    "changes": 2,
    "blob_url": "https://github.com/linkedin/ambry/blob/4775b969c853e2e441e026228b6e282fb35c317d/ambry-store/src/main/java/com/github/ambry/store/HardDeleter.java",
    "raw_url": "https://github.com/linkedin/ambry/raw/4775b969c853e2e441e026228b6e282fb35c317d/ambry-store/src/main/java/com/github/ambry/store/HardDeleter.java",
    "contents_url": "https://api.github.com/repos/linkedin/ambry/contents/ambry-store/src/main/java/com/github/ambry/store/HardDeleter.java?ref=4775b969c853e2e441e026228b6e282fb35c317d",
    "patch": "@@ -52,7 +52,7 @@\n   public static final short Cleanup_Token_Version_V1 = 1;\n   private static final String Cleanup_Token_Filename = \"cleanuptoken\";\n   //how long to sleep if token does not advance.\n-  static final long HARD_DELETE_SLEEP_TIME_ON_CAUGHT_UP_MS = 60 * Time.MsPerSec;\n+  static final long HARD_DELETE_SLEEP_TIME_ON_CAUGHT_UP_MS = 60 * TimeUnit.SECONDS.toMicros(1);\n \n   final AtomicBoolean enabled = new AtomicBoolean(true);\n   private volatile boolean awaitingAfterCaughtUp = false;"
  },
  {
    "sha": "9fadccdfa23931d1f006713f5be55468a92e5e44",
    "filename": "ambry-store/src/main/java/com/github/ambry/store/IndexSegment.java",
    "status": "modified",
    "additions": 2,
    "deletions": 2,
    "changes": 4,
    "blob_url": "https://github.com/linkedin/ambry/blob/4775b969c853e2e441e026228b6e282fb35c317d/ambry-store/src/main/java/com/github/ambry/store/IndexSegment.java",
    "raw_url": "https://github.com/linkedin/ambry/raw/4775b969c853e2e441e026228b6e282fb35c317d/ambry-store/src/main/java/com/github/ambry/store/IndexSegment.java",
    "contents_url": "https://api.github.com/repos/linkedin/ambry/contents/ambry-store/src/main/java/com/github/ambry/store/IndexSegment.java?ref=4775b969c853e2e441e026228b6e282fb35c317d",
    "patch": "@@ -571,8 +571,8 @@ void addEntry(IndexEntry entry, Offset fileEndOffset) throws StoreException {\n       long operationTimeInMs = entry.getValue().getOperationTimeInMs();\n       if (operationTimeInMs == Utils.Infinite_Time) {\n         lastModifiedTimeSec.set(time.seconds());\n-      } else if ((operationTimeInMs / Time.MsPerSec) > lastModifiedTimeSec.get()) {\n-        lastModifiedTimeSec.set(operationTimeInMs / Time.MsPerSec);\n+      } else if ((operationTimeInMs / TimeUnit.SECONDS.toMicros(1)) > lastModifiedTimeSec.get()) {\n+        lastModifiedTimeSec.set(operationTimeInMs / TimeUnit.SECONDS.toMicros(1));\n       }\n       if (valueSize == VALUE_SIZE_INVALID_VALUE) {\n         valueSize = entry.getValue().getBytes().capacity();"
  },
  {
    "sha": "db47e6a65cdd849e0fffc5013feb468288207304",
    "filename": "ambry-store/src/main/java/com/github/ambry/store/IndexValue.java",
    "status": "modified",
    "additions": 4,
    "deletions": 4,
    "changes": 8,
    "blob_url": "https://github.com/linkedin/ambry/blob/4775b969c853e2e441e026228b6e282fb35c317d/ambry-store/src/main/java/com/github/ambry/store/IndexValue.java",
    "raw_url": "https://github.com/linkedin/ambry/raw/4775b969c853e2e441e026228b6e282fb35c317d/ambry-store/src/main/java/com/github/ambry/store/IndexValue.java",
    "contents_url": "https://api.github.com/repos/linkedin/ambry/contents/ambry-store/src/main/java/com/github/ambry/store/IndexValue.java?ref=4775b969c853e2e441e026228b6e282fb35c317d",
    "patch": "@@ -414,9 +414,9 @@ ByteBuffer getBytes() {\n         value.putLong(size);\n         value.putLong(offset.getOffset());\n         value.put(flags);\n-        value.putInt(expiresAtMs != Utils.Infinite_Time ? (int) (expiresAtMs / Time.MsPerSec) : (int) expiresAtMs);\n+        value.putInt(expiresAtMs != Utils.Infinite_Time ? (int) (expiresAtMs / TimeUnit.SECONDS.toMicros(1)) : (int) expiresAtMs);\n         value.putLong(originalMessageOffset);\n-        value.putInt(operationTimeInMs != Utils.Infinite_Time ? (int) (operationTimeInMs / Time.MsPerSec)\n+        value.putInt(operationTimeInMs != Utils.Infinite_Time ? (int) (operationTimeInMs / TimeUnit.SECONDS.toMicros(1))\n             : (int) operationTimeInMs);\n         value.putShort(accountId);\n         value.putShort(containerId);\n@@ -427,9 +427,9 @@ ByteBuffer getBytes() {\n         value.putLong(size);\n         value.putLong(offset.getOffset());\n         value.put(flags);\n-        value.putInt(expiresAtMs != Utils.Infinite_Time ? (int) (expiresAtMs / Time.MsPerSec) : (int) expiresAtMs);\n+        value.putInt(expiresAtMs != Utils.Infinite_Time ? (int) (expiresAtMs / TimeUnit.SECONDS.toMicros(1)) : (int) expiresAtMs);\n         value.putLong(originalMessageOffset);\n-        value.putInt(operationTimeInMs != Utils.Infinite_Time ? (int) (operationTimeInMs / Time.MsPerSec)\n+        value.putInt(operationTimeInMs != Utils.Infinite_Time ? (int) (operationTimeInMs / TimeUnit.SECONDS.toMicros(1))\n             : (int) operationTimeInMs);\n         value.putShort(accountId);\n         value.putShort(containerId);"
  },
  {
    "sha": "19d11bbc60f09c852900fad8bd3e761535dd303d",
    "filename": "ambry-store/src/main/java/com/github/ambry/store/PersistentIndex.java",
    "status": "modified",
    "additions": 4,
    "deletions": 2,
    "changes": 6,
    "blob_url": "https://github.com/linkedin/ambry/blob/4775b969c853e2e441e026228b6e282fb35c317d/ambry-store/src/main/java/com/github/ambry/store/PersistentIndex.java",
    "raw_url": "https://github.com/linkedin/ambry/raw/4775b969c853e2e441e026228b6e282fb35c317d/ambry-store/src/main/java/com/github/ambry/store/PersistentIndex.java",
    "contents_url": "https://api.github.com/repos/linkedin/ambry/contents/ambry-store/src/main/java/com/github/ambry/store/PersistentIndex.java?ref=4775b969c853e2e441e026228b6e282fb35c317d",
    "patch": "@@ -238,8 +238,10 @@ public int compare(IndexEntry e1, IndexEntry e2) {\n       if (scheduler != null) {\n         // start scheduler thread to persist index in the background\n         persistorTask = scheduler.scheduleAtFixedRate(persistor,\n-            config.storeDataFlushDelaySeconds + new Random().nextInt(Time.SecsPerMin),\n-            config.storeDataFlushIntervalSeconds, TimeUnit.SECONDS);\n+                config.storeDataFlushDelaySeconds +\n+                        new Random().nextInt(Math.toIntExact(TimeUnit.MINUTES.toSeconds(1))),\n+                config.storeDataFlushIntervalSeconds,\n+                TimeUnit.SECONDS);\n       } else {\n         persistorTask = null;\n       }"
  },
  {
    "sha": "ac4b56194209ad8099b9ca70e0a33c3a275136b7",
    "filename": "ambry-store/src/test/java/com/github/ambry/store/BlobStoreCompactorTest.java",
    "status": "modified",
    "additions": 20,
    "deletions": 20,
    "changes": 40,
    "blob_url": "https://github.com/linkedin/ambry/blob/4775b969c853e2e441e026228b6e282fb35c317d/ambry-store/src/test/java/com/github/ambry/store/BlobStoreCompactorTest.java",
    "raw_url": "https://github.com/linkedin/ambry/raw/4775b969c853e2e441e026228b6e282fb35c317d/ambry-store/src/test/java/com/github/ambry/store/BlobStoreCompactorTest.java",
    "contents_url": "https://api.github.com/repos/linkedin/ambry/contents/ambry-store/src/test/java/com/github/ambry/store/BlobStoreCompactorTest.java?ref=4775b969c853e2e441e026228b6e282fb35c317d",
    "patch": "@@ -192,12 +192,12 @@ public void badInputTest() throws Exception {\n     LogSegmentName firstLogSegmentName = state.referenceIndex.firstKey().getName();\n     LogSegmentName secondLogSegmentName = state.log.getNextSegment(state.log.getSegment(firstLogSegmentName)).getName();\n     LogSegmentName lastLogSegmentName = state.referenceIndex.lastKey().getName();\n-    CompactionDetails details = new CompactionDetails(state.time.milliseconds() + Time.MsPerSec,\n+    CompactionDetails details = new CompactionDetails(state.time.milliseconds() + TimeUnit.SECONDS.toMicros(1),\n         Arrays.asList(firstLogSegmentName, lastLogSegmentName));\n     ensureArgumentFailure(details, \"Should have failed because compaction range contains offsets still in the journal\");\n \n     // compaction range contains segments in the wrong order\n-    details = new CompactionDetails(state.time.milliseconds() + Time.MsPerSec,\n+    details = new CompactionDetails(state.time.milliseconds() + TimeUnit.SECONDS.toMicros(1),\n         Arrays.asList(secondLogSegmentName, firstLogSegmentName));\n     ensureArgumentFailure(details, \"Should have failed because segments are in the wrong order\");\n \n@@ -287,7 +287,7 @@ public void basicTestNoBundleReadBuffer() throws Exception {\n    */\n   @Test\n   public void compactWholeLogWithNoChangeExpectedTest() throws Exception {\n-    long delayBeforeLastLogSegmentWrite = 20 * Time.MsPerSec;\n+    long delayBeforeLastLogSegmentWrite = 20 * TimeUnit.SECONDS.toMicros(1);\n     refreshState(false, false);\n     // write data until the very last segment is reached\n     long requiredCount = state.log.getCapacityInBytes() / state.log.getSegmentCapacity();\n@@ -345,8 +345,8 @@ public void compactWholeLogMultipleTimesTest() throws Exception {\n     Set<MockId> idsInCompactedLogSegments = getIdsWithPutInSegments(segmentsUnderCompaction);\n \n     for (long setTimeMs : expiryTimesMs) {\n-      if (state.time.milliseconds() < setTimeMs + Time.MsPerSec) {\n-        state.advanceTime(setTimeMs + Time.MsPerSec - state.time.milliseconds());\n+      if (state.time.milliseconds() < setTimeMs + TimeUnit.SECONDS.toMicros(1)) {\n+        state.advanceTime(setTimeMs + TimeUnit.SECONDS.toMicros(1) - state.time.milliseconds());\n       }\n       long deleteReferenceTimeMs = state.time.milliseconds();\n       getCurrentBlobIdsFromWholeIndex(state.index, compactedDeletes, purgeExpiredDelete);\n@@ -423,7 +423,7 @@ public void dropAllSegmentsUnderCompactionTest() throws Exception {\n         state.addDeleteEntry(id);\n       }\n     }\n-    long deleteReferenceTimeMs = state.time.milliseconds() + Time.MsPerSec;\n+    long deleteReferenceTimeMs = state.time.milliseconds() + TimeUnit.SECONDS.toMicros(1);\n     state.advanceTime(deleteReferenceTimeMs - state.time.milliseconds());\n     assertEquals(\"Valid size in the segments under compaction should be 0\", 0,\n         getValidDataSize(segmentsUnderCompaction, deleteReferenceTimeMs, purgeExpiredDelete));\n@@ -452,7 +452,7 @@ public void expirationTimeEnforcementTest() throws Exception {\n \n     // there will be changes past expiration time\n     expiryTimeAndSegmentsUnderCompaction = setupStateWithExpiredBlobsAtSpecificTime();\n-    state.advanceTime(expiryTimeAndSegmentsUnderCompaction.getFirst() + Time.MsPerSec - state.time.milliseconds());\n+    state.advanceTime(expiryTimeAndSegmentsUnderCompaction.getFirst() + TimeUnit.SECONDS.toMicros(1) - state.time.milliseconds());\n     compactAndVerify(expiryTimeAndSegmentsUnderCompaction.getSecond(), state.time.milliseconds(), true);\n   }\n \n@@ -465,7 +465,7 @@ public void expirationTimeEnforcementTest() throws Exception {\n   public void deletionTimeEnforcementTest() throws Exception {\n     // no change before delete time\n     Pair<Long, List<LogSegmentName>> deleteTimeAndSegmentsUnderCompaction = setupStateWithDeletedBlobsAtSpecificTime();\n-    long deleteReferenceTimeMs = deleteTimeAndSegmentsUnderCompaction.getFirst() - Time.MsPerSec;\n+    long deleteReferenceTimeMs = deleteTimeAndSegmentsUnderCompaction.getFirst() - TimeUnit.SECONDS.toMicros(1);\n     Map<LogSegmentName, Long> oldSegmentNamesAndEndOffsets = getEndOffsets(deleteTimeAndSegmentsUnderCompaction.getSecond());\n     compactAndVerify(deleteTimeAndSegmentsUnderCompaction.getSecond(), deleteReferenceTimeMs, false);\n     verifyNoChangeInEndOffsets(oldSegmentNamesAndEndOffsets);\n@@ -479,7 +479,7 @@ public void deletionTimeEnforcementTest() throws Exception {\n \n     // there will be changes past delete time\n     deleteTimeAndSegmentsUnderCompaction = setupStateWithDeletedBlobsAtSpecificTime();\n-    state.advanceTime(Time.MsPerSec);\n+    state.advanceTime(TimeUnit.SECONDS.toMicros(1));\n     compactAndVerify(deleteTimeAndSegmentsUnderCompaction.getSecond(), state.time.milliseconds(), true);\n   }\n \n@@ -491,9 +491,9 @@ public void deletionTimeEnforcementTest() throws Exception {\n   @Test\n   public void differentDeleteAndExpiryTimesTest() throws Exception {\n     Pair<Long, List<LogSegmentName>> expiryTimeAndSegmentsUnderCompaction = setupStateWithExpiredBlobsAtSpecificTime();\n-    state.advanceTime(expiryTimeAndSegmentsUnderCompaction.getFirst() + Time.MsPerSec - state.time.milliseconds());\n+    state.advanceTime(expiryTimeAndSegmentsUnderCompaction.getFirst() + TimeUnit.SECONDS.toMicros(1) - state.time.milliseconds());\n     long deleteReferenceTimeMs = state.time.milliseconds();\n-    state.advanceTime(Time.MsPerSec);\n+    state.advanceTime(TimeUnit.SECONDS.toMicros(1));\n     int deleteCount = 10;\n     Set<MockId> idsInSegments = getIdsWithPutInSegments(expiryTimeAndSegmentsUnderCompaction.getSecond());\n     List<MockId> idsToExamine = new ArrayList<>();\n@@ -1188,7 +1188,7 @@ public void undeleteSameIndexSegmentTest_NoTtlUpdate() throws Exception {\n     state.initIndex(null);\n \n     // Log Segment 0\n-    long expirationTime = state.time.milliseconds() + 200 * Time.MsPerSec;\n+    long expirationTime = state.time.milliseconds() + 200 * TimeUnit.SECONDS.toMicros(1);\n     // Index Segment 0.1 P D U -> P U\n     IndexEntry p1 = state.addPutEntries(1, PUT_RECORD_SIZE, Utils.Infinite_Time).get(0);\n     state.addDeleteEntry((MockId) p1.getKey());\n@@ -1438,7 +1438,7 @@ public void undeleteSameIndexSegmentTest_WithTtlUpdate() throws Exception {\n     state.initIndex(null);\n \n     // Log Segment 0\n-    long expirationTime = state.time.milliseconds() + 500 * Time.MsPerSec;\n+    long expirationTime = state.time.milliseconds() + 500 * TimeUnit.SECONDS.toMicros(1);\n     // Index Segment 0.1 P T D U -> P T U\n     IndexEntry p1 = state.addPutEntries(1, PUT_RECORD_SIZE, Utils.Infinite_Time).get(0);\n     state.makePermanent((MockId) p1.getKey(), false);\n@@ -2291,7 +2291,7 @@ public void undeleteTargetIndexOnlyHasTtlUpdateTest() throws Exception {\n     state.initIndex(null);\n \n     // Insert P, D, U in the first log segment\n-    long p1Expiration = state.time.milliseconds() + 1000 * Time.MsPerSec;\n+    long p1Expiration = state.time.milliseconds() + 1000 * TimeUnit.SECONDS.toMicros(1);\n     IndexEntry p1 = state.addPutEntries(1, PUT_RECORD_SIZE, p1Expiration).get(0);\n     state.addDeleteEntry((MockId) p1.getKey());\n     state.addUndeleteEntry((MockId) p1.getKey());\n@@ -2563,7 +2563,7 @@ private long reduceValidDataSizeInLogSegments(List<LogSegmentName> logSegmentsTo\n         validDataSize = getValidDataSize(logSegmentsToReduceFrom, state.time.milliseconds() + 1, purgeExpiredDelete);\n       }\n     }\n-    state.advanceTime(Time.MsPerSec);\n+    state.advanceTime(TimeUnit.SECONDS.toMicros(1));\n     return state.time.milliseconds();\n   }\n \n@@ -3237,7 +3237,7 @@ private long getInvalidationTime(long numSegmentsToWritePutRecordsTo) {\n     long possibleIndexSegments = numSegmentsToWritePutRecordsTo + possiblePutRecords / state.getMaxInMemElements() + 1;\n     long invalidationTimeMs = state.time.milliseconds() + possibleIndexSegments * DELAY_BETWEEN_LAST_MODIFIED_TIMES_MS;\n     // round up to the next second\n-    return (invalidationTimeMs / Time.MsPerSec + 1) * Time.MsPerSec;\n+    return (invalidationTimeMs / TimeUnit.SECONDS.toMicros(1) + 1) * TimeUnit.SECONDS.toMicros(1);\n   }\n \n   /**\n@@ -3332,7 +3332,7 @@ private void doTestWithInterruptionInducingLog(int addSegmentCallCountToInterrup\n     // there will be changes past expiration time\n     expiryTimeAndSegmentsUnderCompaction = setupStateWithExpiredBlobsAtSpecificTime();\n     segmentsUnderCompaction = expiryTimeAndSegmentsUnderCompaction.getSecond();\n-    state.advanceTime(expiryTimeAndSegmentsUnderCompaction.getFirst() + Time.MsPerSec - state.time.milliseconds());\n+    state.advanceTime(expiryTimeAndSegmentsUnderCompaction.getFirst() + TimeUnit.SECONDS.toMicros(1) - state.time.milliseconds());\n     // create another log that wraps over the same files but induces close as required.\n     log = new InterruptionInducingLog(addSegmentCallCountToInterruptAt, dropSegmentCallCountToInterruptAt);\n     compactWithRecoveryAndVerify(log, DISK_IO_SCHEDULER, state.index, segmentsUnderCompaction,\n@@ -3359,7 +3359,7 @@ private void doInterruptionDuringIndexCommitTest() throws Exception {\n     // there will be changes past expiration time\n     expiryTimeAndSegmentsUnderCompaction = setupStateWithExpiredBlobsAtSpecificTime();\n     segmentsUnderCompaction = expiryTimeAndSegmentsUnderCompaction.getSecond();\n-    state.advanceTime(expiryTimeAndSegmentsUnderCompaction.getFirst() + Time.MsPerSec - state.time.milliseconds());\n+    state.advanceTime(expiryTimeAndSegmentsUnderCompaction.getFirst() + TimeUnit.SECONDS.toMicros(1) - state.time.milliseconds());\n     // create another index that wraps over the same files but induces close as required.\n     index = new InterruptionInducingIndex();\n     compactWithRecoveryAndVerify(state.log, DISK_IO_SCHEDULER, index, segmentsUnderCompaction,\n@@ -3391,7 +3391,7 @@ private void doInterruptionDuringOrAfterIndexSegmentProcessingTest() throws Exce\n       // there will be changes past expiration time\n       expiryTimeAndSegmentsUnderCompaction = setupStateWithExpiredBlobsAtSpecificTime();\n       segmentsUnderCompaction = expiryTimeAndSegmentsUnderCompaction.getSecond();\n-      state.advanceTime(expiryTimeAndSegmentsUnderCompaction.getFirst() + Time.MsPerSec - state.time.milliseconds());\n+      state.advanceTime(expiryTimeAndSegmentsUnderCompaction.getFirst() + TimeUnit.SECONDS.toMicros(1) - state.time.milliseconds());\n       // if negative, set crash count starting from the end\n       countToInterruptAt = interruptAt >= 0 ? interruptAt\n           : getIndexSegmentStartOffsetsForLogSegments(segmentsUnderCompaction).size() + interruptAt;\n@@ -3448,7 +3448,7 @@ private void doInterruptionDuringRecordCopyTest() throws Exception {\n       // there will be changes past expiration time\n       expiryTimeAndSegmentsUnderCompaction = setupStateWithExpiredBlobsAtSpecificTime();\n       segmentsUnderCompaction = expiryTimeAndSegmentsUnderCompaction.getSecond();\n-      state.advanceTime(expiryTimeAndSegmentsUnderCompaction.getFirst() + Time.MsPerSec - state.time.milliseconds());\n+      state.advanceTime(expiryTimeAndSegmentsUnderCompaction.getFirst() + TimeUnit.SECONDS.toMicros(1) - state.time.milliseconds());\n       countToInterruptAt = interruptAt;\n       if (countToInterruptAt < 0) {\n         // while copying each index segment, the bytes copied for the last record is not reported to the diskIOScheduler"
  },
  {
    "sha": "29d8112b10373ab5605032fdb92f161e5d9bc657",
    "filename": "ambry-store/src/test/java/com/github/ambry/store/BlobStoreStatsTest.java",
    "status": "modified",
    "additions": 15,
    "deletions": 15,
    "changes": 30,
    "blob_url": "https://github.com/linkedin/ambry/blob/4775b969c853e2e441e026228b6e282fb35c317d/ambry-store/src/test/java/com/github/ambry/store/BlobStoreStatsTest.java",
    "raw_url": "https://github.com/linkedin/ambry/raw/4775b969c853e2e441e026228b6e282fb35c317d/ambry-store/src/test/java/com/github/ambry/store/BlobStoreStatsTest.java",
    "contents_url": "https://api.github.com/repos/linkedin/ambry/contents/ambry-store/src/test/java/com/github/ambry/store/BlobStoreStatsTest.java?ref=4775b969c853e2e441e026228b6e282fb35c317d",
    "patch": "@@ -65,10 +65,10 @@\n @RunWith(Parameterized.class)\n public class BlobStoreStatsTest {\n   private static final long TEST_TIME_INTERVAL_IN_MS = DELAY_BETWEEN_LAST_MODIFIED_TIMES_MS / 2;\n-  private static final long BUCKET_SPAN_IN_MS = Time.MsPerSec;\n+  private static final long BUCKET_SPAN_IN_MS = TimeUnit.SECONDS.toMicros(1);\n   private static final long QUEUE_PROCESSOR_PERIOD_IN_Ms = 100;\n   private static final StoreMetrics METRICS = new StoreMetrics(new MetricRegistry());\n-  private static final long DEFAULT_WAIT_TIMEOUT_SECS = Time.SecsPerMin;\n+  private static final long DEFAULT_WAIT_TIMEOUT_SECS = TimeUnit.MINUTES.toSeconds(1);\n   private final Map<String, Throttler> throttlers = new HashMap<>();\n   private final DiskIOScheduler diskIOScheduler = new DiskIOScheduler(throttlers);\n   private final ScheduledExecutorService indexScannerScheduler = Utils.newScheduler(1, true);\n@@ -427,15 +427,15 @@ public void testBucketingBasic() throws StoreException, InterruptedException {\n     }\n     // advance time to let the added puts to expire\n     long timeToLiveInMs = expiresAtInMs - state.time.milliseconds() < 0 ? 0 : expiresAtInMs - state.time.milliseconds();\n-    state.advanceTime(timeToLiveInMs + Time.MsPerSec);\n+    state.advanceTime(timeToLiveInMs + TimeUnit.SECONDS.toMicros(1));\n     for (long i = state.beginningTime; i <= state.time.milliseconds() + TEST_TIME_INTERVAL_IN_MS;\n         i += TEST_TIME_INTERVAL_IN_MS) {\n       verifyAndGetLogSegmentValidSize(blobStoreStats, new TimeRange(i, 0L));\n     }\n     verifyAndGetContainerValidSize(blobStoreStats, state.time.milliseconds());\n     // advance time near the end of log segment forecast time\n     state.advanceTime(logSegmentForecastEndTimeInMs - state.time.milliseconds() - 1);\n-    verifyAndGetLogSegmentValidSize(blobStoreStats, new TimeRange(state.time.milliseconds(), Time.MsPerSec));\n+    verifyAndGetLogSegmentValidSize(blobStoreStats, new TimeRange(state.time.milliseconds(), TimeUnit.SECONDS.toMicros(1)));\n     // advance time near the end of container forecast time\n     state.advanceTime(containerForecastEndTimeInMs - state.time.milliseconds() - 1);\n     verifyAndGetContainerValidSize(blobStoreStats, state.time.milliseconds());\n@@ -585,7 +585,7 @@ public void testBucketingWithNewEntriesAfterScan() throws StoreException, Interr\n     verifyAndGetContainerValidSize(blobStoreStats, state.time.milliseconds());\n     // advance time beyond expiration of the blobs and verify no double counting for expiration and delete\n     long timeToLiveInMs = expiresAtInMs - state.time.milliseconds() < 0 ? 0 : expiresAtInMs - state.time.milliseconds();\n-    state.advanceTime(timeToLiveInMs + Time.MsPerSec);\n+    state.advanceTime(timeToLiveInMs + TimeUnit.SECONDS.toMicros(1));\n     verifyAndGetLogSegmentValidSize(blobStoreStats, new TimeRange(state.time.milliseconds(), 0L));\n     verifyAndGetContainerValidSize(blobStoreStats, state.time.milliseconds());\n     assertEquals(\"Throttle count mismatch from expected value\", throttleCountBeforeRequests,\n@@ -671,7 +671,7 @@ public void testBucketingWithNewEntriesDuringScan() throws StoreException, Inter\n     }\n     verifyAndGetContainerValidSize(blobStoreStats, state.time.milliseconds());\n     long timeToLiveInMs = expiresAtInMs - state.time.milliseconds() < 0 ? 0 : expiresAtInMs - state.time.milliseconds();\n-    state.advanceTime(timeToLiveInMs + Time.MsPerSec);\n+    state.advanceTime(timeToLiveInMs + TimeUnit.SECONDS.toMicros(1));\n     advanceTimeToNextSecond();\n     verifyAndGetContainerValidSize(blobStoreStats, state.time.milliseconds());\n     blobStoreStats.close();\n@@ -787,7 +787,7 @@ public void testBucketingWithEmptyIndexToBegin()\n     verifyAndGetContainerValidSize(blobStoreStats, state.time.milliseconds());\n     verifyAndGetLogSegmentValidSize(blobStoreStats, new TimeRange(state.time.milliseconds(), 0));\n     long timeToLiveInMs = expiresAtInMs - state.time.milliseconds() < 0 ? 0 : expiresAtInMs - state.time.milliseconds();\n-    state.advanceTime(timeToLiveInMs + Time.MsPerSec);\n+    state.advanceTime(timeToLiveInMs + TimeUnit.SECONDS.toMicros(1));\n     verifyAndGetContainerValidSize(blobStoreStats, state.time.milliseconds());\n     verifyAndGetLogSegmentValidSize(blobStoreStats, new TimeRange(state.time.milliseconds(), 0));\n     blobStoreStats.close();\n@@ -866,30 +866,30 @@ public void testTimeRangeResolutionWithStats() throws InterruptedException, Stor\n     // ensure the scan is complete before proceeding\n     verifyAndGetContainerValidSize(blobStoreStats, state.time.milliseconds());\n     int throttleCountBeforeRequests = mockThrottler.throttleCount.get();\n-    TimeRange timeRange = new TimeRange(logSegmentForecastStartTimeMs, Time.MsPerSec);\n+    TimeRange timeRange = new TimeRange(logSegmentForecastStartTimeMs, TimeUnit.SECONDS.toMicros(1));\n     assertEquals(\"Unexpected collection time\", timeRange.getEndTimeInMs(),\n         blobStoreStats.getValidDataSizeByLogSegment(timeRange).getFirst().longValue());\n-    timeRange = new TimeRange(logSegmentForecastEndTimeMs, Time.MsPerSec);\n+    timeRange = new TimeRange(logSegmentForecastEndTimeMs, TimeUnit.SECONDS.toMicros(1));\n     assertEquals(\"Unexpected collection time\", logSegmentForecastEndTimeMs - BUCKET_SPAN_IN_MS,\n         blobStoreStats.getValidDataSizeByLogSegment(timeRange).getFirst().longValue());\n-    timeRange = new TimeRange((logSegmentForecastStartTimeMs + logSegmentForecastEndTimeMs) / 2, Time.MsPerSec);\n+    timeRange = new TimeRange((logSegmentForecastStartTimeMs + logSegmentForecastEndTimeMs) / 2, TimeUnit.SECONDS.toMicros(1));\n     assertEquals(\"Unexpected collection time\", timeRange.getEndTimeInMs(),\n         blobStoreStats.getValidDataSizeByLogSegment(timeRange).getFirst().longValue());\n     // time range end time is equal to the start of forecast range\n-    timeRange = new TimeRange(logSegmentForecastStartTimeMs - Time.MsPerSec, Time.MsPerSec);\n+    timeRange = new TimeRange(logSegmentForecastStartTimeMs - TimeUnit.SECONDS.toMicros(1), TimeUnit.SECONDS.toMicros(1));\n     assertEquals(\"Unexpected collection time\", timeRange.getEndTimeInMs(),\n         blobStoreStats.getValidDataSizeByLogSegment(timeRange).getFirst().longValue());\n     // all previous time range are inside the forecast range\n     assertEquals(\"Throttle count mismatch from expected value\", throttleCountBeforeRequests,\n         mockThrottler.throttleCount.get());\n     // time range start time is equal the end of forecast range (considered to be outside of forecast range)\n-    timeRange = new TimeRange(logSegmentForecastEndTimeMs + Time.MsPerSec, Time.MsPerSec);\n+    timeRange = new TimeRange(logSegmentForecastEndTimeMs + TimeUnit.SECONDS.toMicros(1), TimeUnit.SECONDS.toMicros(1));\n     assertEquals(\"Unexpected collection time\", timeRange.getEndTimeInMs(),\n         blobStoreStats.getValidDataSizeByLogSegment(timeRange).getFirst().longValue());\n-    timeRange = new TimeRange(logSegmentForecastEndTimeMs + TimeUnit.SECONDS.toMillis(5), Time.MsPerSec);\n+    timeRange = new TimeRange(logSegmentForecastEndTimeMs + TimeUnit.SECONDS.toMillis(5), TimeUnit.SECONDS.toMicros(1));\n     assertEquals(\"Unexpected collection time\", timeRange.getEndTimeInMs(),\n         blobStoreStats.getValidDataSizeByLogSegment(timeRange).getFirst().longValue());\n-    timeRange = new TimeRange(logSegmentForecastStartTimeMs - TimeUnit.SECONDS.toMillis(5), Time.MsPerSec);\n+    timeRange = new TimeRange(logSegmentForecastStartTimeMs - TimeUnit.SECONDS.toMillis(5), TimeUnit.SECONDS.toMicros(1));\n     assertEquals(\"Unexpected collection time\", timeRange.getEndTimeInMs(),\n         blobStoreStats.getValidDataSizeByLogSegment(timeRange).getFirst().longValue());\n     blobStoreStats.close();\n@@ -1150,7 +1150,7 @@ private void newTtlUpdate(BlobStoreStats blobStoreStats, MockId idToUpdate) thro\n    */\n   private void advanceTimeToNextSecond() {\n     long currentTimeInMs = state.time.milliseconds();\n-    state.advanceTime(Time.MsPerSec - currentTimeInMs % Time.MsPerSec);\n+    state.advanceTime(TimeUnit.SECONDS.toMicros(1) - currentTimeInMs % TimeUnit.SECONDS.toMicros(1));\n   }\n \n   /**"
  },
  {
    "sha": "3796e470e2759733ae1565d65be4f0b0ace82c02",
    "filename": "ambry-store/src/test/java/com/github/ambry/store/BlobStoreTest.java",
    "status": "modified",
    "additions": 3,
    "deletions": 3,
    "changes": 6,
    "blob_url": "https://github.com/linkedin/ambry/blob/4775b969c853e2e441e026228b6e282fb35c317d/ambry-store/src/test/java/com/github/ambry/store/BlobStoreTest.java",
    "raw_url": "https://github.com/linkedin/ambry/raw/4775b969c853e2e441e026228b6e282fb35c317d/ambry-store/src/test/java/com/github/ambry/store/BlobStoreTest.java",
    "contents_url": "https://api.github.com/repos/linkedin/ambry/contents/ambry-store/src/test/java/com/github/ambry/store/BlobStoreTest.java?ref=4775b969c853e2e441e026228b6e282fb35c317d",
    "patch": "@@ -572,7 +572,7 @@ public void storeStartupTests() throws IOException, StoreException {\n   public void basicTest() throws InterruptedException, IOException, StoreException {\n     // PUT a key that is slated to expire when time advances by 1s\n     MockId addedId = put(1, PUT_RECORD_SIZE, time.seconds() + 1).get(0);\n-    time.sleep(2 * Time.MsPerSec);\n+    time.sleep(2 * TimeUnit.SECONDS.toMicros(1));\n     liveKeys.remove(addedId);\n     expiredKeys.add(addedId);\n \n@@ -1439,7 +1439,7 @@ public void undeleteErrorCasesTest() throws Exception {\n     id = put(1, PUT_RECORD_SIZE, time.seconds()).get(0);\n     verifyUndeleteFailure(id, StoreErrorCodes.ID_Not_Deleted);\n     delete(id);\n-    time.sleep(2 * Time.MsPerSec);\n+    time.sleep(2 * TimeUnit.SECONDS.toMicros(1));\n     verifyUndeleteFailure(id, StoreErrorCodes.TTL_Expired);\n   }\n \n@@ -2535,7 +2535,7 @@ private void setupTestState(boolean addTtlUpdates, boolean addUndelete) throws I\n     store.start();\n     // advance time by a second in order to be able to add expired keys and to avoid keys that are expired from\n     // being picked for delete.\n-    time.sleep(Time.MsPerSec);\n+    time.sleep(TimeUnit.SECONDS.toMicros(1));\n     long expectedStoreSize;\n     assertTrue(\"Expected empty store\", store.isEmpty());\n     if (!isLogSegmented) {"
  },
  {
    "sha": "c061c5eb9d3069ce13f57d4840411be32f3cb035",
    "filename": "ambry-store/src/test/java/com/github/ambry/store/CuratedLogIndexState.java",
    "status": "modified",
    "additions": 7,
    "deletions": 7,
    "changes": 14,
    "blob_url": "https://github.com/linkedin/ambry/blob/4775b969c853e2e441e026228b6e282fb35c317d/ambry-store/src/test/java/com/github/ambry/store/CuratedLogIndexState.java",
    "raw_url": "https://github.com/linkedin/ambry/raw/4775b969c853e2e441e026228b6e282fb35c317d/ambry-store/src/test/java/com/github/ambry/store/CuratedLogIndexState.java",
    "contents_url": "https://api.github.com/repos/linkedin/ambry/contents/ambry-store/src/test/java/com/github/ambry/store/CuratedLogIndexState.java?ref=4775b969c853e2e441e026228b6e282fb35c317d",
    "patch": "@@ -72,7 +72,7 @@\n \n   static final int DEFAULT_MAX_IN_MEM_ELEMENTS = 5;\n   static final DiskIOScheduler DISK_IO_SCHEDULER = new DiskIOScheduler(null);\n-  static final long DELAY_BETWEEN_LAST_MODIFIED_TIMES_MS = 10 * Time.MsPerSec;\n+  static final long DELAY_BETWEEN_LAST_MODIFIED_TIMES_MS = 10 * TimeUnit.SECONDS.toMicros(1);\n   static final StoreKeyFactory STORE_KEY_FACTORY;\n   // deliberately do not divide the capacities perfectly.\n   static final long PUT_RECORD_SIZE = 53;\n@@ -275,7 +275,7 @@ void destroy() throws IOException, StoreException {\n         liveKeys.add(id);\n       }\n       index.addToIndex(Collections.singletonList(entry), fileSpan);\n-      lastModifiedTimesInSecs.put(indexSegmentStartOffset, value.getOperationTimeInMs() / Time.MsPerSec);\n+      lastModifiedTimesInSecs.put(indexSegmentStartOffset, value.getOperationTimeInMs() / TimeUnit.SECONDS.toMicros(1));\n       expectedJournalLastOffset = fileSpan.getStartOffset();\n       endOffsetOfPrevMsg = fileSpan.getEndOffset();\n     }\n@@ -321,7 +321,7 @@ void forceAddPutEntry(MockId id, IndexValue value, byte[] bytes) throws StoreExc\n       liveKeys.add(id);\n     }\n     index.addToIndex(Collections.singletonList(entry), fileSpan);\n-    lastModifiedTimesInSecs.put(indexSegmentStartOffset, value.getOperationTimeInMs() / Time.MsPerSec);\n+    lastModifiedTimesInSecs.put(indexSegmentStartOffset, value.getOperationTimeInMs() / TimeUnit.SECONDS.toMicros(1));\n   }\n \n   /**\n@@ -493,7 +493,7 @@ FileSpan addDeleteEntry(MockId idToDelete, MessageInfo info, short lifeVersion)\n     logOrder.put(startOffset, new Pair<>(idToDelete, new LogEntry(dataWritten, newValue)));\n     allKeys.computeIfAbsent(idToDelete, k -> new TreeSet<>()).add(newValue);\n     referenceIndex.get(indexSegmentStartOffset).computeIfAbsent(idToDelete, k -> new TreeSet<>()).add(newValue);\n-    lastModifiedTimesInSecs.put(indexSegmentStartOffset, newValue.getOperationTimeInMs() / Time.MsPerSec);\n+    lastModifiedTimesInSecs.put(indexSegmentStartOffset, newValue.getOperationTimeInMs() / TimeUnit.SECONDS.toMicros(1));\n     endOffsetOfPrevMsg = fileSpan.getEndOffset();\n     assertEquals(\"End Offset of index not as expected\", endOffsetOfPrevMsg, index.getCurrentEndOffset());\n     assertEquals(\"Journal's last offset not as expected\", startOffset, index.journal.getLastOffset());\n@@ -578,7 +578,7 @@ FileSpan addUndeleteEntry(MockId idToUndelete, MessageInfo info, short lifeVersi\n     logOrder.put(startOffset, new Pair<>(idToUndelete, new LogEntry(dataWritten, newValue)));\n     allKeys.computeIfAbsent(idToUndelete, k -> new TreeSet<>()).add(newValue);\n     referenceIndex.get(indexSegmentStartOffset).computeIfAbsent(idToUndelete, k -> new TreeSet<>()).add(newValue);\n-    lastModifiedTimesInSecs.put(indexSegmentStartOffset, newValue.getOperationTimeInMs() / Time.MsPerSec);\n+    lastModifiedTimesInSecs.put(indexSegmentStartOffset, newValue.getOperationTimeInMs() / TimeUnit.SECONDS.toMicros(1));\n     endOffsetOfPrevMsg = fileSpan.getEndOffset();\n     assertEquals(\"End Offset of index not as expected\", endOffsetOfPrevMsg, index.getCurrentEndOffset());\n     assertEquals(\"Journal's last offset not as expected\", startOffset, index.journal.getLastOffset());\n@@ -926,7 +926,7 @@ boolean isDeletedAt(MockId id, long referenceTimeMs) {\n     IndexValue value = getExpectedValue(id, false);\n     Offset deleteIndexSegmentStartOffset = value.isDelete() ? referenceIndex.floorKey(value.getOffset()) : null;\n     return deleteIndexSegmentStartOffset != null\n-        && lastModifiedTimesInSecs.get(deleteIndexSegmentStartOffset) * Time.MsPerSec < referenceTimeMs;\n+        && lastModifiedTimesInSecs.get(deleteIndexSegmentStartOffset) * TimeUnit.SECONDS.toMicros(1) < referenceTimeMs;\n   }\n \n   /**\n@@ -1133,7 +1133,7 @@ private void setupTestState(boolean isLogSegmented, long segmentCapacity, boolea\n     assertEquals(\"End Offset of index not as expected\", log.getEndOffset(), index.getCurrentEndOffset());\n     // advance time by a second in order to be able to add expired keys and to avoid keys that are expired from\n     // being picked for delete.\n-    advanceTime(Time.MsPerSec);\n+    advanceTime(TimeUnit.SECONDS.toMicros(1));\n     assertEquals(\"Incorrect log segment count\", 0, index.getLogSegmentCount());\n     long expectedUsedCapacity;\n     if (!isLogSegmented) {"
  },
  {
    "sha": "c886d8e6753473be8816fbd016a9e28628dcbb00",
    "filename": "ambry-store/src/test/java/com/github/ambry/store/IndexSegmentTest.java",
    "status": "modified",
    "additions": 1,
    "deletions": 1,
    "changes": 2,
    "blob_url": "https://github.com/linkedin/ambry/blob/4775b969c853e2e441e026228b6e282fb35c317d/ambry-store/src/test/java/com/github/ambry/store/IndexSegmentTest.java",
    "raw_url": "https://github.com/linkedin/ambry/raw/4775b969c853e2e441e026228b6e282fb35c317d/ambry-store/src/test/java/com/github/ambry/store/IndexSegmentTest.java",
    "contents_url": "https://api.github.com/repos/linkedin/ambry/contents/ambry-store/src/test/java/com/github/ambry/store/IndexSegmentTest.java?ref=4775b969c853e2e441e026228b6e282fb35c317d",
    "patch": "@@ -795,7 +795,7 @@ private void doComprehensiveTest(short version, boolean includeSmallKeys, boolea\n       NavigableMap<MockId, NavigableSet<IndexValue>> referenceIndex = new TreeMap<>();\n       // advance time so that last modified time for VERSION_1 has different last modified times for different index\n       // segments\n-      time.sleep(10 * Time.MsPerSec);\n+      time.sleep(10 * TimeUnit.SECONDS.toMicros(1));\n       PersistentIndex.cleanupIndexSegmentFilesForLogSegment(tempDir.getAbsolutePath(), logSegmentName);\n       IndexSegment indexSegment = generateIndexSegment(startOffset, STORE_KEY_FACTORY);\n       Pair<StoreKey, PersistentIndex.IndexEntryType> resetKey = null;"
  },
  {
    "sha": "1edbd76dc6514297ec95589c5b52cae690e470a5",
    "filename": "ambry-store/src/test/java/com/github/ambry/store/IndexTest.java",
    "status": "modified",
    "additions": 1,
    "deletions": 1,
    "changes": 2,
    "blob_url": "https://github.com/linkedin/ambry/blob/4775b969c853e2e441e026228b6e282fb35c317d/ambry-store/src/test/java/com/github/ambry/store/IndexTest.java",
    "raw_url": "https://github.com/linkedin/ambry/raw/4775b969c853e2e441e026228b6e282fb35c317d/ambry-store/src/test/java/com/github/ambry/store/IndexTest.java",
    "contents_url": "https://api.github.com/repos/linkedin/ambry/contents/ambry-store/src/test/java/com/github/ambry/store/IndexTest.java?ref=4775b969c853e2e441e026228b6e282fb35c317d",
    "patch": "@@ -607,7 +607,7 @@ public void hardDeletePauseResumeRestartTest() throws InterruptedException, IOEx\n   public void expirationTest() throws StoreException {\n     // add a PUT entry that will expire if time advances\n     // advance time so that time moves to whole second with no residual milliseconds\n-    state.time.sleep(Time.MsPerSec - state.time.milliseconds());\n+    state.time.sleep(TimeUnit.SECONDS.toMicros(1) - state.time.milliseconds());\n     long expiresAtMs = state.time.milliseconds() + CuratedLogIndexState.DELAY_BETWEEN_LAST_MODIFIED_TIMES_MS + 1000;\n     state.addPutEntries(1, 1, expiresAtMs);\n     MockId id = state.logOrder.lastEntry().getValue().getFirst();"
  },
  {
    "sha": "32883dea798f6c3da948d0aeeb55fbb70e43579c",
    "filename": "ambry-store/src/test/java/com/github/ambry/store/IndexValueTest.java",
    "status": "modified",
    "additions": 4,
    "deletions": 4,
    "changes": 8,
    "blob_url": "https://github.com/linkedin/ambry/blob/4775b969c853e2e441e026228b6e282fb35c317d/ambry-store/src/test/java/com/github/ambry/store/IndexValueTest.java",
    "raw_url": "https://github.com/linkedin/ambry/raw/4775b969c853e2e441e026228b6e282fb35c317d/ambry-store/src/test/java/com/github/ambry/store/IndexValueTest.java",
    "contents_url": "https://api.github.com/repos/linkedin/ambry/contents/ambry-store/src/test/java/com/github/ambry/store/IndexValueTest.java?ref=4775b969c853e2e441e026228b6e282fb35c317d",
    "patch": "@@ -352,10 +352,10 @@ static IndexValue getIndexValue(long size, Offset offset, byte flags, long expir\n         value.putLong(size);\n         value.putLong(offset.getOffset());\n         value.put(flags);\n-        value.putInt(expiresAtMs != Utils.Infinite_Time ? (int) (expiresAtMs / Time.MsPerSec) : (int) expiresAtMs);\n+        value.putInt(expiresAtMs != Utils.Infinite_Time ? (int) (expiresAtMs / TimeUnit.SECONDS.toMicros(1)) : (int) expiresAtMs);\n         value.putLong(originalMessageOffset);\n         value.putInt(\n-            operationTimeMs != Utils.Infinite_Time ? (int) (operationTimeMs / Time.MsPerSec) : (int) operationTimeMs);\n+            operationTimeMs != Utils.Infinite_Time ? (int) (operationTimeMs / TimeUnit.SECONDS.toMicros(1)) : (int) operationTimeMs);\n         value.putShort(accountId);\n         value.putShort(containerId);\n         value.position(0);\n@@ -366,10 +366,10 @@ static IndexValue getIndexValue(long size, Offset offset, byte flags, long expir\n         value.putLong(size);\n         value.putLong(offset.getOffset());\n         value.put(flags);\n-        value.putInt(expiresAtMs != Utils.Infinite_Time ? (int) (expiresAtMs / Time.MsPerSec) : (int) expiresAtMs);\n+        value.putInt(expiresAtMs != Utils.Infinite_Time ? (int) (expiresAtMs / TimeUnit.SECONDS.toMicros(1)) : (int) expiresAtMs);\n         value.putLong(originalMessageOffset);\n         value.putInt(\n-            operationTimeMs != Utils.Infinite_Time ? (int) (operationTimeMs / Time.MsPerSec) : (int) operationTimeMs);\n+            operationTimeMs != Utils.Infinite_Time ? (int) (operationTimeMs / TimeUnit.SECONDS.toMicros(1)) : (int) operationTimeMs);\n         value.putShort(accountId);\n         value.putShort(containerId);\n         value.putShort(lifeVersion);"
  },
  {
    "sha": "61d03f5790150ba600d34639b7f17f84c402f892",
    "filename": "ambry-tools/src/main/java/com/github/ambry/store/IndexReadPerformance.java",
    "status": "modified",
    "additions": 1,
    "deletions": 1,
    "changes": 2,
    "blob_url": "https://github.com/linkedin/ambry/blob/4775b969c853e2e441e026228b6e282fb35c317d/ambry-tools/src/main/java/com/github/ambry/store/IndexReadPerformance.java",
    "raw_url": "https://github.com/linkedin/ambry/raw/4775b969c853e2e441e026228b6e282fb35c317d/ambry-tools/src/main/java/com/github/ambry/store/IndexReadPerformance.java",
    "contents_url": "https://api.github.com/repos/linkedin/ambry/contents/ambry-tools/src/main/java/com/github/ambry/store/IndexReadPerformance.java?ref=4775b969c853e2e441e026228b6e282fb35c317d",
    "patch": "@@ -164,7 +164,7 @@ public void run() {\n             latch.await();\n             System.out.println(\"Total reads : \" + totalReads.get() + \"  Total time taken : \" + totalTimeTaken.get()\n                 + \" Nano Seconds  Average time taken per read \"\n-                + ((double) totalReads.get() / totalTimeTaken.get()) / SystemTime.NsPerSec + \" Seconds\");\n+                + ((double) totalReads.get() / totalTimeTaken.get()) / TimeUnit.SECONDS.toNanos(1) + \" Seconds\");\n           } catch (Exception e) {\n             System.out.println(\"Error while shutting down \" + e);\n           }"
  },
  {
    "sha": "2f1f5e1eba6675ace0b32db5c4b9820ce9a167a7",
    "filename": "ambry-tools/src/main/java/com/github/ambry/store/IndexWritePerformance.java",
    "status": "modified",
    "additions": 2,
    "deletions": 1,
    "changes": 3,
    "blob_url": "https://github.com/linkedin/ambry/blob/4775b969c853e2e441e026228b6e282fb35c317d/ambry-tools/src/main/java/com/github/ambry/store/IndexWritePerformance.java",
    "raw_url": "https://github.com/linkedin/ambry/raw/4775b969c853e2e441e026228b6e282fb35c317d/ambry-tools/src/main/java/com/github/ambry/store/IndexWritePerformance.java",
    "contents_url": "https://api.github.com/repos/linkedin/ambry/contents/ambry-tools/src/main/java/com/github/ambry/store/IndexWritePerformance.java?ref=4775b969c853e2e441e026228b6e282fb35c317d",
    "patch": "@@ -36,6 +36,7 @@\n import java.util.Random;\n import java.util.concurrent.CountDownLatch;\n import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n import java.util.concurrent.atomic.AtomicBoolean;\n import java.util.concurrent.atomic.AtomicLong;\n import joptsimple.ArgumentAcceptingOptionSpec;\n@@ -164,7 +165,7 @@ public void run() {\n             System.out.println(\n                 \"Total writes : \" + totalWrites.get() + \"  Total time taken : \" + totalTimeTakenInNs.get()\n                     + \" Nano Seconds  Average time taken per write \"\n-                    + ((double) totalWrites.get() / totalTimeTakenInNs.get()) / SystemTime.NsPerSec + \" Seconds\");\n+                    + ((double) totalWrites.get() / totalTimeTakenInNs.get()) / TimeUnit.SECONDS.toNanos(1) + \" Seconds\");\n           } catch (Exception e) {\n             System.out.println(\"Error while shutting down \" + e);\n           }"
  },
  {
    "sha": "96afa69a611b8f5d4a08c3b09c2b197071306287",
    "filename": "ambry-tools/src/main/java/com/github/ambry/tools/admin/ConcurrencyTestTool.java",
    "status": "modified",
    "additions": 1,
    "deletions": 1,
    "changes": 2,
    "blob_url": "https://github.com/linkedin/ambry/blob/4775b969c853e2e441e026228b6e282fb35c317d/ambry-tools/src/main/java/com/github/ambry/tools/admin/ConcurrencyTestTool.java",
    "raw_url": "https://github.com/linkedin/ambry/raw/4775b969c853e2e441e026228b6e282fb35c317d/ambry-tools/src/main/java/com/github/ambry/tools/admin/ConcurrencyTestTool.java",
    "contents_url": "https://api.github.com/repos/linkedin/ambry/contents/ambry-tools/src/main/java/com/github/ambry/tools/admin/ConcurrencyTestTool.java?ref=4775b969c853e2e441e026228b6e282fb35c317d",
    "patch": "@@ -536,7 +536,7 @@ public void onCompletion(Void result, Exception exception) {\n      */\n     synchronized void updateTimePassedSoFar(long timePassedInMs) {\n       this.timePassedInMs.addAndGet(timePassedInMs);\n-      if (this.timePassedInMs.get() >= measurementIntervalInSecs * SystemTime.MsPerSec) {\n+      if (this.timePassedInMs.get() >= measurementIntervalInSecs * TimeUnit.SECONDS.toMicros(1)) {\n         reportMetrics();\n         numberOfOperations.set(0);\n         this.timePassedInMs.set(0);"
  },
  {
    "sha": "d1c0b16378ffafe8327cb6610490376ed16f7b07",
    "filename": "ambry-tools/src/main/java/com/github/ambry/tools/perf/ServerReadPerformance.java",
    "status": "modified",
    "additions": 7,
    "deletions": 6,
    "changes": 13,
    "blob_url": "https://github.com/linkedin/ambry/blob/4775b969c853e2e441e026228b6e282fb35c317d/ambry-tools/src/main/java/com/github/ambry/tools/perf/ServerReadPerformance.java",
    "raw_url": "https://github.com/linkedin/ambry/raw/4775b969c853e2e441e026228b6e282fb35c317d/ambry-tools/src/main/java/com/github/ambry/tools/perf/ServerReadPerformance.java",
    "contents_url": "https://api.github.com/repos/linkedin/ambry/contents/ambry-tools/src/main/java/com/github/ambry/tools/perf/ServerReadPerformance.java?ref=4775b969c853e2e441e026228b6e282fb35c317d",
    "patch": "@@ -54,6 +54,7 @@\n import java.util.ArrayList;\n import java.util.Collections;\n import java.util.Properties;\n+import java.util.concurrent.TimeUnit;\n import java.util.concurrent.atomic.AtomicBoolean;\n import java.util.concurrent.atomic.AtomicLong;\n import joptsimple.ArgumentAcceptingOptionSpec;\n@@ -172,7 +173,7 @@ public static void main(String args[]) {\n \n       ToolUtils.ensureOrExit(listOpt, options, parser);\n \n-      long measurementIntervalNs = options.valueOf(measurementIntervalOpt) * SystemTime.NsPerSec;\n+      long measurementIntervalNs = options.valueOf(measurementIntervalOpt) * TimeUnit.SECONDS.toNanos(1);\n       ToolUtils.validateSSLOptions(options, parser, sslEnabledDatacentersOpt, sslKeystorePathOpt, sslKeystoreTypeOpt,\n           sslTruststorePathOpt, sslKeystorePasswordOpt, sslKeyPasswordOpt, sslTruststorePasswordOpt);\n \n@@ -213,7 +214,7 @@ public void run() {\n             shutdown.set(true);\n             String message = \"Total reads : \" + totalReads.get() + \"  Total time taken : \" + totalTimeTaken.get()\n                 + \" Nano Seconds  Average time taken per read \"\n-                + ((double) totalTimeTaken.get()) / SystemTime.NsPerSec / totalReads.get() + \" Seconds\";\n+                + ((double) totalTimeTaken.get()) / TimeUnit.SECONDS.toNanos(1) / totalReads.get() + \" Seconds\";\n             System.out.println(message);\n           } catch (Exception e) {\n             System.out.println(\"Error while shutting down \" + e);\n@@ -275,7 +276,7 @@ public void run() {\n             totalLatencyForGetBlobs += latencyPerBlob;\n             if (enableVerboseLogging) {\n               System.out.println(\n-                  \"Time taken to get blob id \" + blobId + \" in ms \" + latencyPerBlob / SystemTime.NsPerMs);\n+                  \"Time taken to get blob id \" + blobId + \" in ms \" + latencyPerBlob / TimeUnit.MICROSECONDS.toNanos(1));\n             }\n             if (latencyPerBlob > maxLatencyForGetBlobs) {\n               maxLatencyForGetBlobs = latencyPerBlob;\n@@ -288,9 +289,9 @@ public void run() {\n               int index99 = (int) (latenciesForGetBlobs.size() * 0.99) - 1;\n               int index95 = (int) (latenciesForGetBlobs.size() * 0.95) - 1;\n               String message =\n-                  totalNumberOfGetBlobs + \",\" + (double) latenciesForGetBlobs.get(index99) / SystemTime.NsPerSec + \",\"\n-                      + (double) latenciesForGetBlobs.get(index95) / SystemTime.NsPerSec + \",\" + (\n-                      (double) totalLatencyForGetBlobs / SystemTime.NsPerSec / totalNumberOfGetBlobs);\n+                  totalNumberOfGetBlobs + \",\" + (double) latenciesForGetBlobs.get(index99) / TimeUnit.SECONDS.toNanos(1) + \",\"\n+                      + (double) latenciesForGetBlobs.get(index95) / TimeUnit.SECONDS.toNanos(1) + \",\" + (\n+                      (double) totalLatencyForGetBlobs / TimeUnit.SECONDS.toNanos(1) / totalNumberOfGetBlobs);\n               System.out.println(message);\n               writer.write(message + \"\\n\");\n               totalLatencyForGetBlobs = 0;"
  },
  {
    "sha": "187f53ed6fd63bbd125f5b3d0ea6a6e4e9d229b4",
    "filename": "ambry-tools/src/main/java/com/github/ambry/tools/perf/ServerWritePerformance.java",
    "status": "modified",
    "additions": 7,
    "deletions": 6,
    "changes": 13,
    "blob_url": "https://github.com/linkedin/ambry/blob/4775b969c853e2e441e026228b6e282fb35c317d/ambry-tools/src/main/java/com/github/ambry/tools/perf/ServerWritePerformance.java",
    "raw_url": "https://github.com/linkedin/ambry/raw/4775b969c853e2e441e026228b6e282fb35c317d/ambry-tools/src/main/java/com/github/ambry/tools/perf/ServerWritePerformance.java",
    "contents_url": "https://api.github.com/repos/linkedin/ambry/contents/ambry-tools/src/main/java/com/github/ambry/tools/perf/ServerWritePerformance.java?ref=4775b969c853e2e441e026228b6e282fb35c317d",
    "patch": "@@ -51,6 +51,7 @@\n import java.util.Properties;\n import java.util.Random;\n import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n import java.util.concurrent.atomic.AtomicBoolean;\n import java.util.concurrent.atomic.AtomicLong;\n import joptsimple.ArgumentAcceptingOptionSpec;\n@@ -187,7 +188,7 @@ public static void main(String args[]) {\n \n       ToolUtils.ensureOrExit(listOpt, options, parser);\n \n-      long measurementIntervalNs = options.valueOf(measurementIntervalOpt) * SystemTime.NsPerSec;\n+      long measurementIntervalNs = options.valueOf(measurementIntervalOpt) * TimeUnit.SECONDS.toNanos(1);\n       ToolUtils.validateSSLOptions(options, parser, sslEnabledDatacentersOpt, sslKeystorePathOpt, sslKeystoreTypeOpt,\n           sslTruststorePathOpt, sslKeystorePasswordOpt, sslKeyPasswordOpt, sslTruststorePasswordOpt);\n \n@@ -236,7 +237,7 @@ public void run() {\n             latch.await();\n             System.out.println(\"Total writes : \" + totalWrites.get() + \"  Total time taken : \" + totalTimeTaken.get()\n                 + \" Nano Seconds  Average time taken per write \"\n-                + ((double) totalTimeTaken.get()) / SystemTime.NsPerSec / totalWrites.get() + \" Seconds\");\n+                + ((double) totalTimeTaken.get()) / TimeUnit.SECONDS.toNanos(1) / totalWrites.get() + \" Seconds\");\n           } catch (Exception e) {\n             System.out.println(\"Error while shutting down \" + e);\n           }\n@@ -370,7 +371,7 @@ public void run() {\n             blobIdWriter.write(\"Blob-\" + blobId + \"\\n\");\n             totalWrites.incrementAndGet();\n             if (enableVerboseLogging) {\n-              System.out.println(\"Time taken to put blob id \" + blobId + \" in ms \" + latencyPerBlob / SystemTime.NsPerMs\n+              System.out.println(\"Time taken to put blob id \" + blobId + \" in ms \" + latencyPerBlob / TimeUnit.MICROSECONDS.toNanos(1)\n                   + \" for blob of size \" + blob.length);\n             }\n             numberOfPuts++;\n@@ -386,9 +387,9 @@ public void run() {\n               int index99 = (int) (latenciesForPutBlobs.size() * 0.99) - 1;\n               int index95 = (int) (latenciesForPutBlobs.size() * 0.95) - 1;\n               String message = threadIndex + \",\" + numberOfPuts + \",\"\n-                  + (double) latenciesForPutBlobs.get(index99) / SystemTime.NsPerSec + \",\"\n-                  + (double) latenciesForPutBlobs.get(index95) / SystemTime.NsPerSec + \",\" + (\n-                  ((double) totalLatencyInNanoSeconds) / SystemTime.NsPerSec / numberOfPuts);\n+                  + (double) latenciesForPutBlobs.get(index99) / TimeUnit.SECONDS.toNanos(1) + \",\"\n+                  + (double) latenciesForPutBlobs.get(index95) / TimeUnit.SECONDS.toNanos(1) + \",\" + (\n+                  ((double) totalLatencyInNanoSeconds) / TimeUnit.SECONDS.toNanos(1) / numberOfPuts);\n               System.out.println(message);\n               performanceWriter.write(message + \"\\n\");\n               numberOfPuts = 0;"
  },
  {
    "sha": "b397d3396a60c8e0a371d74ed59c84ac73246fb3",
    "filename": "ambry-tools/src/main/java/com/github/ambry/tools/perf/rest/NettyPerfClient.java",
    "status": "modified",
    "additions": 2,
    "deletions": 2,
    "changes": 4,
    "blob_url": "https://github.com/linkedin/ambry/blob/4775b969c853e2e441e026228b6e282fb35c317d/ambry-tools/src/main/java/com/github/ambry/tools/perf/rest/NettyPerfClient.java",
    "raw_url": "https://github.com/linkedin/ambry/raw/4775b969c853e2e441e026228b6e282fb35c317d/ambry-tools/src/main/java/com/github/ambry/tools/perf/rest/NettyPerfClient.java",
    "contents_url": "https://api.github.com/repos/linkedin/ambry/contents/ambry-tools/src/main/java/com/github/ambry/tools/perf/rest/NettyPerfClient.java?ref=4775b969c853e2e441e026228b6e282fb35c317d",
    "patch": "@@ -433,8 +433,8 @@ protected void shutdown() {\n         logger.error(\"NettyPerfClient shutdown interrupted\", e);\n       } finally {\n         logger.info(\"Executed for approximately {} s and sent {} requests ({} requests/sec)\",\n-            (float) totalRunTimeInMs / (float) Time.MsPerSec, totalRequestCount.get(),\n-            (float) totalRequestCount.get() * (float) Time.MsPerSec / (float) totalRunTimeInMs);\n+            (float) totalRunTimeInMs / (float) TimeUnit.SECONDS.toMicros(1), totalRequestCount.get(),\n+            (float) totalRequestCount.get() * (float) TimeUnit.SECONDS.toMicros(1) / (float) totalRunTimeInMs);\n         Snapshot rttStatsSnapshot = perfClientMetrics.requestRoundTripTimeInMs.getSnapshot();\n         logger.info(\"RTT stats: Min - {} ms, Mean - {} ms, Max - {} ms\", rttStatsSnapshot.getMin(),\n             rttStatsSnapshot.getMean(), rttStatsSnapshot.getMax());"
  },
  {
    "sha": "793c962f5106a69b3c8b83ddce562b8de296a1f5",
    "filename": "ambry-tools/src/main/java/com/github/ambry/tools/perf/rest/PerfNioServer.java",
    "status": "modified",
    "additions": 2,
    "deletions": 2,
    "changes": 4,
    "blob_url": "https://github.com/linkedin/ambry/blob/4775b969c853e2e441e026228b6e282fb35c317d/ambry-tools/src/main/java/com/github/ambry/tools/perf/rest/PerfNioServer.java",
    "raw_url": "https://github.com/linkedin/ambry/raw/4775b969c853e2e441e026228b6e282fb35c317d/ambry-tools/src/main/java/com/github/ambry/tools/perf/rest/PerfNioServer.java",
    "contents_url": "https://api.github.com/repos/linkedin/ambry/contents/ambry-tools/src/main/java/com/github/ambry/tools/perf/rest/PerfNioServer.java?ref=4775b969c853e2e441e026228b6e282fb35c317d",
    "patch": "@@ -147,8 +147,8 @@ public void run() {\n       }\n       long totalRunTimeInMs = System.currentTimeMillis() - startTime;\n       logger.info(\"LoadCreator executed for approximately {} s and sent {} requests ({} requests/sec)\",\n-          (float) totalRunTimeInMs / (float) Time.MsPerSec, requestCount,\n-          (float) requestCount * (float) Time.MsPerSec / (float) totalRunTimeInMs);\n+          (float) totalRunTimeInMs / (float) TimeUnit.SECONDS.toMicros(1), requestCount,\n+          (float) requestCount * (float) TimeUnit.SECONDS.toMicros(1) / (float) totalRunTimeInMs);\n       Snapshot rttStatsSnapshot = perfNioServerMetrics.requestRoundTripTimeInMs.getSnapshot();\n       logger.info(\"RTT stats: Min - {} ms, Mean - {} ms, Max - {} ms\", rttStatsSnapshot.getMin(),\n           rttStatsSnapshot.getMean(), rttStatsSnapshot.getMax());"
  },
  {
    "sha": "32201e8a3f2edabe94bf3c9bb8f4e4194a056692",
    "filename": "ambry-utils/src/main/java/com/github/ambry/utils/Throttler.java",
    "status": "modified",
    "additions": 6,
    "deletions": 4,
    "changes": 10,
    "blob_url": "https://github.com/linkedin/ambry/blob/4775b969c853e2e441e026228b6e282fb35c317d/ambry-utils/src/main/java/com/github/ambry/utils/Throttler.java",
    "raw_url": "https://github.com/linkedin/ambry/raw/4775b969c853e2e441e026228b6e282fb35c317d/ambry-utils/src/main/java/com/github/ambry/utils/Throttler.java",
    "contents_url": "https://api.github.com/repos/linkedin/ambry/contents/ambry-utils/src/main/java/com/github/ambry/utils/Throttler.java?ref=4775b969c853e2e441e026228b6e282fb35c317d",
    "patch": "@@ -16,6 +16,8 @@\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n+import java.util.concurrent.TimeUnit;\n+\n \n /**\n  * A class to measure and throttle the rate of some process. The throttler takes a desired rate-per-second\n@@ -62,12 +64,12 @@ public void maybeThrottle(double observed) throws InterruptedException {\n \n       // if we have completed an interval AND we have observed something, maybe\n       // we should take a little nap\n-      if ((checkIntervalMs < 0 || elapsedNs > checkIntervalMs * Time.NsPerMs) && observedSoFar > 0) {\n-        double rateInSecs = elapsedNs > 0 ? (observedSoFar * Time.NsPerSec) / elapsedNs : Double.MAX_VALUE;\n+      if ((checkIntervalMs < 0 || elapsedNs > checkIntervalMs * TimeUnit.MICROSECONDS.toNanos(1)) && observedSoFar > 0) {\n+        double rateInSecs = elapsedNs > 0 ? (observedSoFar * TimeUnit.SECONDS.toNanos(1)) / elapsedNs : Double.MAX_VALUE;\n         if (throttleDown == rateInSecs > desiredRatePerSec) {\n           // solve for the amount of time to sleep to make us hit the desired rate\n-          double desiredRateMs = desiredRatePerSec / Time.MsPerSec;\n-          double elapsedMs = elapsedNs / Time.NsPerMs;\n+          double desiredRateMs = desiredRatePerSec / TimeUnit.SECONDS.toMicros(1);\n+          double elapsedMs = elapsedNs / TimeUnit.MICROSECONDS.toNanos(1);\n           long sleepTime = Math.round(observedSoFar / desiredRateMs - elapsedMs);\n           if (sleepTime > 0) {\n             logger.trace(\"Natural rate is {} per second but desired rate is {}, sleeping for {} ms to compensate.\","
  },
  {
    "sha": "7a26d44d637b7f632b67158ba2b046e9de1cf418",
    "filename": "ambry-utils/src/main/java/com/github/ambry/utils/Time.java",
    "status": "modified",
    "additions": 5,
    "deletions": 6,
    "changes": 11,
    "blob_url": "https://github.com/linkedin/ambry/blob/4775b969c853e2e441e026228b6e282fb35c317d/ambry-utils/src/main/java/com/github/ambry/utils/Time.java",
    "raw_url": "https://github.com/linkedin/ambry/raw/4775b969c853e2e441e026228b6e282fb35c317d/ambry-utils/src/main/java/com/github/ambry/utils/Time.java",
    "contents_url": "https://api.github.com/repos/linkedin/ambry/contents/ambry-utils/src/main/java/com/github/ambry/utils/Time.java?ref=4775b969c853e2e441e026228b6e282fb35c317d",
    "patch": "@@ -13,6 +13,7 @@\n  */\n package com.github.ambry.utils;\n \n+import java.util.concurrent.TimeUnit;\n import java.util.concurrent.locks.Condition;\n \n \n@@ -24,12 +25,10 @@\n   /**\n    * Some common constants\n    */\n-  public static final int NsPerUs = 1000;\n-  public static final int UsPerMs = 1000;\n-  public static final int MsPerSec = 1000;\n-  public static final int NsPerMs = NsPerUs * UsPerMs;\n-  public static final int NsPerSec = NsPerMs * MsPerSec;\n-  public static final int SecsPerMin = 60;\n+  public static final int MsPerSec = Math.toIntExact(TimeUnit.SECONDS.toMicros(1));\n+  public static final int NsPerMs = Math.toIntExact(TimeUnit.MICROSECONDS.toNanos(1));\n+  public static final int NsPerSec = Math.toIntExact(TimeUnit.SECONDS.toNanos(1));\n+  public static final int SecsPerMin = Math.toIntExact(TimeUnit.MINUTES.toSeconds(1));\n \n   public abstract long milliseconds();\n "
  },
  {
    "sha": "0486c7d22c54bd79445eaedd30a3466a224307d4",
    "filename": "ambry-utils/src/main/java/com/github/ambry/utils/Utils.java",
    "status": "modified",
    "additions": 2,
    "deletions": 2,
    "changes": 4,
    "blob_url": "https://github.com/linkedin/ambry/blob/4775b969c853e2e441e026228b6e282fb35c317d/ambry-utils/src/main/java/com/github/ambry/utils/Utils.java",
    "raw_url": "https://github.com/linkedin/ambry/raw/4775b969c853e2e441e026228b6e282fb35c317d/ambry-utils/src/main/java/com/github/ambry/utils/Utils.java",
    "contents_url": "https://api.github.com/repos/linkedin/ambry/contents/ambry-utils/src/main/java/com/github/ambry/utils/Utils.java?ref=4775b969c853e2e441e026228b6e282fb35c317d",
    "patch": "@@ -1167,8 +1167,8 @@ public static Throwable getRootCause(Throwable t) {\n    * @return the time in ms to the nearest second(floored) for the given time in ms\n    */\n   public static long getTimeInMsToTheNearestSec(long timeInMs) {\n-    long timeInSecs = timeInMs / Time.MsPerSec;\n-    return timeInMs != Utils.Infinite_Time ? (timeInSecs * Time.MsPerSec) : Utils.Infinite_Time;\n+    long timeInSecs = timeInMs / TimeUnit.SECONDS.toMicros(1);\n+    return timeInMs != Utils.Infinite_Time ? (timeInSecs * TimeUnit.SECONDS.toMicros(1)) : Utils.Infinite_Time;\n   }\n \n   /**"
  },
  {
    "sha": "8fd5613b57cfe8675a484a9efb5c0c066ab3b189",
    "filename": "ambry-utils/src/test/java/com/github/ambry/utils/UtilsTest.java",
    "status": "modified",
    "additions": 2,
    "deletions": 2,
    "changes": 4,
    "blob_url": "https://github.com/linkedin/ambry/blob/4775b969c853e2e441e026228b6e282fb35c317d/ambry-utils/src/test/java/com/github/ambry/utils/UtilsTest.java",
    "raw_url": "https://github.com/linkedin/ambry/raw/4775b969c853e2e441e026228b6e282fb35c317d/ambry-utils/src/test/java/com/github/ambry/utils/UtilsTest.java",
    "contents_url": "https://api.github.com/repos/linkedin/ambry/contents/ambry-utils/src/test/java/com/github/ambry/utils/UtilsTest.java?ref=4775b969c853e2e441e026228b6e282fb35c317d",
    "patch": "@@ -557,7 +557,7 @@ public String call() {\n   @Test\n   public void getTimeInMsToTheNearestSecTest() {\n     long msValue = Utils.getRandomLong(TestUtils.RANDOM, 1000000);\n-    long expectedMsValue = (msValue / Time.MsPerSec) * Time.MsPerSec;\n+    long expectedMsValue = (msValue / TimeUnit.SECONDS.toMicros(1)) * TimeUnit.SECONDS.toMicros(1);\n     assertEquals(\"Time in Ms to the nearest Sec mismatch \", expectedMsValue, Utils.getTimeInMsToTheNearestSec(msValue));\n     msValue = Utils.Infinite_Time;\n     assertEquals(\"Time in Ms to the nearest Sec mismatch \", msValue, Utils.getTimeInMsToTheNearestSec(msValue));\n@@ -571,7 +571,7 @@ public void addSecondsToEpochTimeTest() {\n     for (int i = 0; i < 5; i++) {\n       long epochTimeInMs = SystemTime.getInstance().milliseconds() + TestUtils.RANDOM.nextInt(10000);\n       long deltaInSecs = TestUtils.RANDOM.nextInt(10000);\n-      assertEquals(\"epoch epochTimeInMs mismatch \", epochTimeInMs + (deltaInSecs * Time.MsPerSec),\n+      assertEquals(\"epoch epochTimeInMs mismatch \", epochTimeInMs + (deltaInSecs * TimeUnit.SECONDS.toMicros(1)),\n           Utils.addSecondsToEpochTime(epochTimeInMs, deltaInSecs));\n       assertEquals(\"epoch epochTimeInMs mismatch \", Utils.Infinite_Time,\n           Utils.addSecondsToEpochTime(Utils.Infinite_Time, deltaInSecs));"
  }
]
