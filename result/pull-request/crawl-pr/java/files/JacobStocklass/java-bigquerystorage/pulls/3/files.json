[
  {
    "sha": "a7edbb19a439caf98c4f78b3930b6e747f88970c",
    "filename": "google-cloud-bigquerystorage/src/test/java/com/google/cloud/bigquery/storage/v1beta2/st/ITBigQueryStorageLongRunningWriteTest.java",
    "status": "modified",
    "additions": 189,
    "deletions": 64,
    "changes": 253,
    "blob_url": "https://github.com/JacobStocklass/java-bigquerystorage/blob/443304b2af634de35f3ddf9ea12722cc5f7cf604/google-cloud-bigquerystorage/src/test/java/com/google/cloud/bigquery/storage/v1beta2/st/ITBigQueryStorageLongRunningWriteTest.java",
    "raw_url": "https://github.com/JacobStocklass/java-bigquerystorage/raw/443304b2af634de35f3ddf9ea12722cc5f7cf604/google-cloud-bigquerystorage/src/test/java/com/google/cloud/bigquery/storage/v1beta2/st/ITBigQueryStorageLongRunningWriteTest.java",
    "contents_url": "https://api.github.com/repos/JacobStocklass/java-bigquerystorage/contents/google-cloud-bigquerystorage/src/test/java/com/google/cloud/bigquery/storage/v1beta2/st/ITBigQueryStorageLongRunningWriteTest.java?ref=443304b2af634de35f3ddf9ea12722cc5f7cf604",
    "patch": "@@ -19,6 +19,8 @@\n import static org.junit.Assert.assertTrue;\n \n import com.google.api.core.ApiFuture;\n+import com.google.api.core.ApiFutureCallback;\n+import com.google.api.core.ApiFutures;\n import com.google.cloud.ServiceOptions;\n import com.google.cloud.bigquery.BigQuery;\n import com.google.cloud.bigquery.DatasetInfo;\n@@ -39,13 +41,16 @@\n import com.google.cloud.bigquery.testing.RemoteBigQueryHelper;\n import com.google.protobuf.Descriptors;\n import java.io.IOException;\n+import java.util.ArrayList;\n import java.util.Iterator;\n+import java.util.List;\n import java.util.concurrent.ExecutionException;\n import java.util.logging.Logger;\n import org.json.JSONArray;\n import org.json.JSONObject;\n import org.junit.AfterClass;\n import org.junit.Assert;\n+import org.junit.Assume;\n import org.junit.BeforeClass;\n import org.junit.Test;\n import org.threeten.bp.LocalDateTime;\n@@ -60,17 +65,21 @@\n       Logger.getLogger(ITBigQueryStorageLongRunningTest.class.getName());\n   private static final String LONG_TESTS_ENABLED_PROPERTY =\n       \"bigquery.storage.enable_long_running_tests\";\n+  private static final String LONG_TESTS_DISABLED_MESSAGE =\n+      String.format(\n+          \"BigQuery Storage long running tests are not enabled and will be skipped. \"\n+              + \"To enable them, set system property '%s' to true.\",\n+          LONG_TESTS_ENABLED_PROPERTY);\n   private static final String DESCRIPTION = \"BigQuery Write Java long test dataset\";\n \n   private static String dataset;\n   private static BigQueryWriteClient client;\n   private static String parentProjectId;\n   private static BigQuery bigquery;\n-  private static int requestLimit = 10;\n+  private static int requestLimit = 1000;\n \n   private static JSONObject MakeJsonObject(RowComplexity complexity) throws IOException {\n     JSONObject object = new JSONObject();\n-    // size: (1, simple)(2,complex)()\n     // TODO(jstocklass): Add option for testing protobuf format using StreamWriter2\n     switch (complexity) {\n       case SIMPLE:\n@@ -148,8 +157,63 @@ private static JSONObject MakeJsonObject(RowComplexity complexity) throws IOExce\n     return object;\n   }\n \n+  private static TableInfo MakeSimpleSchemaTable(String name) {\n+    TableInfo tableInfo =\n+        TableInfo.newBuilder(\n+                TableId.of(dataset, name),\n+                StandardTableDefinition.of(\n+                    Schema.of(\n+                        com.google.cloud.bigquery.Field.newBuilder(\n+                                \"test_str\", StandardSQLTypeName.STRING)\n+                            .build(),\n+                        com.google.cloud.bigquery.Field.newBuilder(\n+                                \"test_numerics\", StandardSQLTypeName.NUMERIC)\n+                            .setMode(Field.Mode.REPEATED)\n+                            .build(),\n+                        com.google.cloud.bigquery.Field.newBuilder(\n+                                \"test_datetime\", StandardSQLTypeName.DATETIME)\n+                            .build())))\n+            .build();\n+    bigquery.create(tableInfo);\n+    return tableInfo;\n+  }\n+\n+  private static TableInfo MakeComplexSchemaTable(String name) {\n+    TableInfo tableInfo =\n+        TableInfo.newBuilder(\n+                TableId.of(dataset, name),\n+                StandardTableDefinition.of(\n+                    Schema.of(\n+                        Field.newBuilder(\"test_str\", StandardSQLTypeName.STRING).build(),\n+                        Field.newBuilder(\"test_numerics1\", StandardSQLTypeName.NUMERIC)\n+                            .setMode(Mode.REPEATED)\n+                            .build(),\n+                        Field.newBuilder(\"test_numerics2\", StandardSQLTypeName.NUMERIC)\n+                            .setMode(Mode.REPEATED)\n+                            .build(),\n+                        Field.newBuilder(\"test_numerics3\", StandardSQLTypeName.NUMERIC)\n+                            .setMode(Mode.REPEATED)\n+                            .build(),\n+                        Field.newBuilder(\"test_datetime\", StandardSQLTypeName.DATETIME).build(),\n+                        Field.newBuilder(\"test_bools\", StandardSQLTypeName.BOOL)\n+                            .setMode(Mode.REPEATED)\n+                            .build(),\n+                        Field.newBuilder(\n+                                \"test_subs\",\n+                                StandardSQLTypeName.STRUCT,\n+                                Field.of(\"sub_bool\", StandardSQLTypeName.BOOL),\n+                                Field.of(\"sub_int\", StandardSQLTypeName.INT64),\n+                                Field.of(\"sub_string\", StandardSQLTypeName.STRING))\n+                            .setMode(Mode.REPEATED)\n+                            .build())))\n+            .build();\n+    bigquery.create(tableInfo);\n+    return tableInfo;\n+  }\n+\n   @BeforeClass\n   public static void beforeClass() throws IOException {\n+    Assume.assumeTrue(LONG_TESTS_DISABLED_MESSAGE, Boolean.getBoolean(LONG_TESTS_ENABLED_PROPERTY));\n     parentProjectId = String.format(\"projects/%s\", ServiceOptions.getDefaultProjectId());\n \n     client = BigQueryWriteClient.create();\n@@ -177,31 +241,13 @@ public static void afterClass() {\n   public void testDefaultStreamSimpleSchema()\n       throws IOException, InterruptedException, ExecutionException,\n           Descriptors.DescriptorValidationException {\n-    // TODO(jstocklass): Set up a default stream. Write to it for a long time,\n-    // (a few minutes for now) and make sure that everything goes well, report stats.\n     LOG.info(\n         String.format(\n             \"%s tests running with parent project: %s\",\n             ITBigQueryStorageLongRunningWriteTest.class.getSimpleName(), parentProjectId));\n \n     String tableName = \"JsonSimpleTableDefaultStream\";\n-    TableInfo tableInfo =\n-        TableInfo.newBuilder(\n-                TableId.of(dataset, tableName),\n-                StandardTableDefinition.of(\n-                    Schema.of(\n-                        com.google.cloud.bigquery.Field.newBuilder(\n-                                \"test_str\", StandardSQLTypeName.STRING)\n-                            .build(),\n-                        com.google.cloud.bigquery.Field.newBuilder(\n-                                \"test_numerics\", StandardSQLTypeName.NUMERIC)\n-                            .setMode(Field.Mode.REPEATED)\n-                            .build(),\n-                        com.google.cloud.bigquery.Field.newBuilder(\n-                                \"test_datetime\", StandardSQLTypeName.DATETIME)\n-                            .build())))\n-            .build();\n-    bigquery.create(tableInfo);\n+    TableInfo tableInfo = MakeSimpleSchemaTable(tableName);\n \n     long averageLatency = 0;\n     long totalLatency = 0;\n@@ -214,16 +260,12 @@ public void testDefaultStreamSimpleSchema()\n         JSONObject row = MakeJsonObject(RowComplexity.SIMPLE);\n         JSONArray jsonArr = new JSONArray(new JSONObject[] {row});\n         long startTime = System.nanoTime();\n-        // TODO(jstocklass): Make asynchronized calls instead of synchronized calls\n         ApiFuture<AppendRowsResponse> response = jsonStreamWriter.append(jsonArr, -1);\n         long finishTime = System.nanoTime();\n         Assert.assertFalse(response.get().getAppendResult().hasOffset());\n-        // Ignore first entry, it is way slower than the others and ruins expected behavior\n-        if (i != 0) {\n-          totalLatency += (finishTime - startTime);\n-        }\n+        totalLatency += (finishTime - startTime);\n       }\n-      averageLatency = totalLatency / requestLimit;\n+      averageLatency = totalLatency / (requestLimit - 1);\n       // TODO(jstocklass): Is there a better way to get this than to log it?\n       LOG.info(\"Simple average Latency: \" + String.valueOf(averageLatency) + \" ns\");\n       averageLatency = totalLatency = 0;\n@@ -248,67 +290,150 @@ public void testDefaultStreamComplexSchema()\n           Descriptors.DescriptorValidationException {\n     StandardSQLTypeName[] array = new StandardSQLTypeName[] {StandardSQLTypeName.INT64};\n     String complexTableName = \"JsonComplexTableDefaultStream\";\n-    TableInfo tableInfo2 =\n-        TableInfo.newBuilder(\n-                TableId.of(dataset, complexTableName),\n-                StandardTableDefinition.of(\n-                    Schema.of(\n-                        Field.newBuilder(\"test_str\", StandardSQLTypeName.STRING).build(),\n-                        Field.newBuilder(\"test_numerics1\", StandardSQLTypeName.NUMERIC)\n-                            .setMode(Mode.REPEATED)\n-                            .build(),\n-                        Field.newBuilder(\"test_numerics2\", StandardSQLTypeName.NUMERIC)\n-                            .setMode(Mode.REPEATED)\n-                            .build(),\n-                        Field.newBuilder(\"test_numerics3\", StandardSQLTypeName.NUMERIC)\n-                            .setMode(Mode.REPEATED)\n-                            .build(),\n-                        Field.newBuilder(\"test_datetime\", StandardSQLTypeName.DATETIME).build(),\n-                        Field.newBuilder(\"test_bools\", StandardSQLTypeName.BOOL)\n-                            .setMode(Mode.REPEATED)\n-                            .build(),\n-                        Field.newBuilder(\n-                                \"test_subs\",\n-                                StandardSQLTypeName.STRUCT,\n-                                Field.of(\"sub_bool\", StandardSQLTypeName.BOOL),\n-                                Field.of(\"sub_int\", StandardSQLTypeName.INT64),\n-                                Field.of(\"sub_string\", StandardSQLTypeName.STRING))\n-                            .setMode(Mode.REPEATED)\n-                            .build())))\n-            .build();\n-    bigquery.create(tableInfo2);\n-\n+    TableInfo tableInfo = MakeComplexSchemaTable(complexTableName);\n     long totalLatency = 0;\n     long averageLatency = 0;\n     TableName parent =\n         TableName.of(ServiceOptions.getDefaultProjectId(), dataset, complexTableName);\n     try (JsonStreamWriter jsonStreamWriter =\n-        JsonStreamWriter.newBuilder(parent.toString(), tableInfo2.getDefinition().getSchema())\n+        JsonStreamWriter.newBuilder(parent.toString(), tableInfo.getDefinition().getSchema())\n             .createDefaultStream()\n             .build()) {\n       for (int i = 0; i < requestLimit; i++) {\n         JSONObject row = MakeJsonObject(RowComplexity.COMPLEX);\n         JSONArray jsonArr = new JSONArray(new JSONObject[] {row});\n         long startTime = System.nanoTime();\n-        // TODO(jstocklass): Make asynchronized calls instead of synchronized calls\n         ApiFuture<AppendRowsResponse> response = jsonStreamWriter.append(jsonArr, -1);\n         long finishTime = System.nanoTime();\n         Assert.assertFalse(response.get().getAppendResult().hasOffset());\n         if (i != 0) {\n           totalLatency += (finishTime - startTime);\n         }\n       }\n-      averageLatency = totalLatency / requestLimit;\n+      averageLatency = totalLatency / (requestLimit - 1);\n       LOG.info(\"Complex average Latency: \" + String.valueOf(averageLatency) + \" ns\");\n       TableResult result2 =\n           bigquery.listTableData(\n-              tableInfo2.getTableId(), BigQuery.TableDataListOption.startIndex(0L));\n+              tableInfo.getTableId(), BigQuery.TableDataListOption.startIndex(0L));\n       Iterator<FieldValueList> iter = result2.getValues().iterator();\n-      FieldValueList currentRow2;\n+      FieldValueList currentRow;\n       for (int i = 0; i < requestLimit; i++) {\n         assertTrue(iter.hasNext());\n-        currentRow2 = iter.next();\n-        assertEquals(\"aaa\", currentRow2.get(0).getStringValue());\n+        currentRow = iter.next();\n+        assertEquals(\"aaa\", currentRow.get(0).getStringValue());\n+      }\n+      assertEquals(false, iter.hasNext());\n+    }\n+  }\n+\n+  @Test\n+  public void testDefaultStreamAsyncSimpleSchema()\n+      throws IOException, InterruptedException, ExecutionException,\n+          Descriptors.DescriptorValidationException {\n+    String tableName = \"JsonSimpleAsyncTableDefaultStream\";\n+    TableInfo tableInfo = MakeSimpleSchemaTable(tableName);\n+    final List<Long> startTimes = new ArrayList<Long>(requestLimit);\n+    final List<Long> finishTimes = new ArrayList<Long>(requestLimit);\n+    long averageLatency = 0;\n+    long totalLatency = 0;\n+    TableName parent = TableName.of(ServiceOptions.getDefaultProjectId(), dataset, tableName);\n+    try (JsonStreamWriter jsonStreamWriter =\n+        JsonStreamWriter.newBuilder(parent.toString(), tableInfo.getDefinition().getSchema())\n+            .createDefaultStream()\n+            .build()) {\n+      for (int i = 0; i < requestLimit; i++) {\n+        JSONObject row = MakeJsonObject(RowComplexity.SIMPLE);\n+        JSONArray jsonArr = new JSONArray(new JSONObject[] {row});\n+        startTimes.add(System.nanoTime());\n+        ApiFuture<AppendRowsResponse> response = jsonStreamWriter.append(jsonArr, -1);\n+        ApiFutures.addCallback(\n+            response,\n+            new ApiFutureCallback<AppendRowsResponse>() {\n+              @Override\n+              public void onFailure(Throwable t) {\n+                LOG.info(\"Error: api future callback on failure.\");\n+              }\n+\n+              @Override\n+              public void onSuccess(AppendRowsResponse result) {\n+                finishTimes.add(System.nanoTime());\n+              }\n+            });\n+        Assert.assertFalse(response.get().getAppendResult().hasOffset());\n+      }\n+      for (int i = 0; i < requestLimit; i++) {\n+        totalLatency += (finishTimes.get(i) - startTimes.get(i));\n+      }\n+      averageLatency = totalLatency / requestLimit;\n+      LOG.info(\"Simple Async average Latency: \" + String.valueOf(averageLatency) + \" ns\");\n+      TableResult result2 =\n+          bigquery.listTableData(\n+              tableInfo.getTableId(), BigQuery.TableDataListOption.startIndex(0L));\n+      Iterator<FieldValueList> iter = result2.getValues().iterator();\n+      FieldValueList currentRow;\n+      for (int i = 0; i < requestLimit; i++) {\n+        assertTrue(iter.hasNext());\n+        currentRow = iter.next();\n+        assertEquals(\"aaa\", currentRow.get(0).getStringValue());\n+      }\n+      assertEquals(false, iter.hasNext());\n+    }\n+  }\n+\n+  @Test\n+  public void testDefaultStreamAsyncComplexSchema()\n+      throws IOException, InterruptedException, ExecutionException,\n+          Descriptors.DescriptorValidationException {\n+    StandardSQLTypeName[] array = new StandardSQLTypeName[] {StandardSQLTypeName.INT64};\n+    String complexTableName = \"JsonAsyncTableDefaultStream\";\n+    TableInfo tableInfo = MakeComplexSchemaTable(complexTableName);\n+    final List<Long> startTimes = new ArrayList<Long>(requestLimit);\n+    final List<Long> finishTimes = new ArrayList<Long>(requestLimit);\n+    long averageLatency = 0;\n+    long totalLatency = 0;\n+    TableName parent =\n+        TableName.of(ServiceOptions.getDefaultProjectId(), dataset, complexTableName);\n+    try (JsonStreamWriter jsonStreamWriter =\n+        JsonStreamWriter.newBuilder(parent.toString(), tableInfo.getDefinition().getSchema())\n+            .createDefaultStream()\n+            .build()) {\n+      for (int i = 0; i < requestLimit; i++) {\n+        JSONObject row = MakeJsonObject(RowComplexity.COMPLEX);\n+        JSONArray jsonArr = new JSONArray(new JSONObject[] {row});\n+        startTimes.add(System.nanoTime());\n+        ApiFuture<AppendRowsResponse> response = jsonStreamWriter.append(jsonArr, -1);\n+        ApiFutures.addCallback(\n+            response,\n+            new ApiFutureCallback<AppendRowsResponse>() {\n+              @Override\n+              public void onFailure(Throwable t) {\n+                LOG.info(\"Error: api future callback on failure.\");\n+              }\n+\n+              @Override\n+              public void onSuccess(AppendRowsResponse result) {\n+                finishTimes.add(System.nanoTime());\n+              }\n+            });\n+        Assert.assertFalse(response.get().getAppendResult().hasOffset());\n+      }\n+      for (int i = 0; i < requestLimit; i++) {\n+        totalLatency += (finishTimes.get(i) - startTimes.get(i));\n+        if (finishTimes.get(i) == 0) {\n+          LOG.info(\"We have a problem\");\n+        }\n+      }\n+      averageLatency = totalLatency / requestLimit;\n+      LOG.info(\"Complex Async average Latency: \" + String.valueOf(averageLatency) + \" ns\");\n+      TableResult result =\n+          bigquery.listTableData(\n+              tableInfo.getTableId(), BigQuery.TableDataListOption.startIndex(0L));\n+      Iterator<FieldValueList> iter = result.getValues().iterator();\n+      FieldValueList currentRow;\n+      for (int i = 0; i < requestLimit; i++) {\n+        assertTrue(\"failed at \" + i, iter.hasNext());\n+        currentRow = iter.next();\n+        assertEquals(\"aaa\", currentRow.get(0).getStringValue());\n       }\n       assertEquals(false, iter.hasNext());\n     }"
  }
]
