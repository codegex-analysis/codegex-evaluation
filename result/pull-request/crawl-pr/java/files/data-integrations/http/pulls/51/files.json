[
  {
    "sha": "8f9093479b92dc4c29c0302136016f4f2559e73f",
    "filename": "src/main/java/io/cdap/plugin/http/sink/batch/HTTPSinkConfig.java",
    "status": "modified",
    "additions": 7,
    "deletions": 5,
    "changes": 12,
    "blob_url": "https://github.com/data-integrations/http/blob/ae280c07da18fe8396cb3be05250d4fa43d40d7d/src/main/java/io/cdap/plugin/http/sink/batch/HTTPSinkConfig.java",
    "raw_url": "https://github.com/data-integrations/http/raw/ae280c07da18fe8396cb3be05250d4fa43d40d7d/src/main/java/io/cdap/plugin/http/sink/batch/HTTPSinkConfig.java",
    "contents_url": "https://api.github.com/repos/data-integrations/http/contents/src/main/java/io/cdap/plugin/http/sink/batch/HTTPSinkConfig.java?ref=ae280c07da18fe8396cb3be05250d4fa43d40d7d",
    "patch": "@@ -272,11 +272,13 @@ public Boolean getFailOnNon200Response() {\n   }\n \n   public void validate(FailureCollector collector) {\n-    try {\n-      new URL(url);\n-    } catch (MalformedURLException e) {\n-      collector.addFailure(String.format(\"URL '%s' is malformed: %s\", url, e.getMessage()), null)\n-        .withConfigProperty(URL);\n+    if (!containsMacro(URL)) {\n+      try {\n+        new URL(url);\n+      } catch (MalformedURLException e) {\n+        collector.addFailure(String.format(\"URL '%s' is malformed: %s\", url, e.getMessage()), null)\n+          .withConfigProperty(URL);\n+      }\n     }\n \n     if (!containsMacro(CONNECTION_TIMEOUT) && Objects.nonNull(connectTimeout) && connectTimeout < 0) {"
  },
  {
    "sha": "215a7453fa560efb2c4bea7d0336239f4c7c621f",
    "filename": "src/test/java/io/cdap/plugin/http/sink/batch/HTTPSinkTest.java",
    "status": "modified",
    "additions": 68,
    "deletions": 0,
    "changes": 68,
    "blob_url": "https://github.com/data-integrations/http/blob/ae280c07da18fe8396cb3be05250d4fa43d40d7d/src/test/java/io/cdap/plugin/http/sink/batch/HTTPSinkTest.java",
    "raw_url": "https://github.com/data-integrations/http/raw/ae280c07da18fe8396cb3be05250d4fa43d40d7d/src/test/java/io/cdap/plugin/http/sink/batch/HTTPSinkTest.java",
    "contents_url": "https://api.github.com/repos/data-integrations/http/contents/src/test/java/io/cdap/plugin/http/sink/batch/HTTPSinkTest.java?ref=ae280c07da18fe8396cb3be05250d4fa43d40d7d",
    "patch": "@@ -23,6 +23,7 @@\n import io.cdap.cdap.api.data.format.StructuredRecord;\n import io.cdap.cdap.api.data.schema.Schema;\n import io.cdap.cdap.api.dataset.table.Table;\n+import io.cdap.cdap.common.utils.Tasks;\n import io.cdap.cdap.datapipeline.DataPipelineApp;\n import io.cdap.cdap.datapipeline.SmartWorkflow;\n import io.cdap.cdap.etl.api.batch.BatchSink;\n@@ -58,7 +59,9 @@\n import java.util.ArrayList;\n import java.util.List;\n import java.util.Map;\n+import java.util.concurrent.ExecutionException;\n import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n import javax.ws.rs.HttpMethod;\n \n /**\n@@ -174,4 +177,69 @@ private int getFeeds() throws IOException {\n     urlConn.disconnect();\n     return responseCode;\n   }\n+\n+  @Test\n+  public void testHTTPSinkMacroUrl() throws Exception {\n+    String inputDatasetName = \"input-http-sink-with-macro\";\n+    ETLStage source = new ETLStage(\"source\", MockSource.getPlugin(inputDatasetName));\n+    Map<String, String> properties = new ImmutableMap.Builder<String, String>()\n+      .put(\"url\", \"${url}\")\n+      .put(\"method\", \"PUT\")\n+      .put(\"messageFormat\", \"Custom\")\n+      .put(\"charset\", \"UTF-8\")\n+      .put(\"body\", \"cask cdap, hydrator tracker, ui cli\")\n+      .put(\"batchSize\", \"1\")\n+      .put(\"referenceName\", \"HTTPSinkReference\")\n+      .put(\"delimiterForMessages\", \"\\n\")\n+      .put(\"numRetries\", \"3\")\n+      .put(\"followRedirects\", \"true\")\n+      .put(\"disableSSLValidation\", \"true\")\n+      .put(\"connectTimeout\", \"60000\")\n+      .put(\"readTimeout\", \"60000\")\n+      .put(\"failOnNon200Response\", \"true\")\n+      .build();\n+\n+    ImmutableMap<String, String> runtimeProperties =\n+      ImmutableMap.of(\"url\", baseURL + \"/feeds/users\");\n+\n+    ETLStage sink = new ETLStage(\"HTTP\", new ETLPlugin(\"HTTP\", BatchSink.PLUGIN_TYPE, properties, null));\n+    ETLBatchConfig etlConfig = ETLBatchConfig.builder(\"* * * * *\")\n+      .addStage(source)\n+      .addStage(sink)\n+      .addConnection(source.getName(), sink.getName())\n+      .build();\n+\n+    ApplicationManager appManager = deployETL(etlConfig, inputDatasetName);\n+\n+    DataSetManager<Table> inputManager = getDataset(inputDatasetName);\n+    List<StructuredRecord> input = ImmutableList.of(\n+      StructuredRecord.builder(inputSchema).set(\"id\", \"1\").build()\n+    );\n+    MockSource.writeInput(inputManager, input);\n+    // run the pipeline\n+    runETLOnce(appManager, runtimeProperties);\n+  }\n+\n+  /**\n+   * Run the SmartWorkflow in the given ETL application for once and wait for the workflow's COMPLETED status\n+   * with 5 minutes timeout.\n+   *\n+   * @param appManager the ETL application to run\n+   * @param arguments  the arguments to be passed when running SmartWorkflow\n+   */\n+  protected WorkflowManager runETLOnce(ApplicationManager appManager, Map<String, String> arguments)\n+    throws TimeoutException, InterruptedException, ExecutionException {\n+    final WorkflowManager workflowManager = appManager.getWorkflowManager(SmartWorkflow.NAME);\n+    int numRuns = workflowManager.getHistory().size();\n+    workflowManager.start(arguments);\n+    Tasks.waitFor(numRuns + 1, () -> workflowManager.getHistory().size(), 20, TimeUnit.SECONDS);\n+    workflowManager.waitForStopped(5, TimeUnit.MINUTES);\n+    return workflowManager;\n+  }\n+\n+  protected ApplicationManager deployETL(ETLBatchConfig etlConfig, String appName) throws Exception {\n+    AppRequest<ETLBatchConfig> appRequest = new AppRequest<>(BATCH_ARTIFACT, etlConfig);\n+    ApplicationId appId = NamespaceId.DEFAULT.app(appName);\n+    return deployApplication(appId, appRequest);\n+  }\n }"
  }
]
