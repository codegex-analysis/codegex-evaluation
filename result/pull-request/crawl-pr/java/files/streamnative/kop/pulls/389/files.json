[
  {
    "sha": "2013be99a99507353026582a39d9323e823f0576",
    "filename": "kafka-impl/conf/kop.conf",
    "status": "modified",
    "additions": 14,
    "deletions": 0,
    "changes": 14,
    "blob_url": "https://github.com/streamnative/kop/blob/84e0f20463cc04f823c4ef48d002f73313afb26e/kafka-impl/conf/kop.conf",
    "raw_url": "https://github.com/streamnative/kop/raw/84e0f20463cc04f823c4ef48d002f73313afb26e/kafka-impl/conf/kop.conf",
    "contents_url": "https://api.github.com/repos/streamnative/kop/contents/kafka-impl/conf/kop.conf?ref=84e0f20463cc04f823c4ef48d002f73313afb26e",
    "patch": "@@ -890,3 +890,17 @@ globalZookeeperServers=\n # Deprecated - Enable TLS when talking with other clusters to replicate messages\n replicationTlsEnabled=false\n \n+### --- Prometheus metric provider configuration --- ###\n+# Prometheus provider class, default: io.streamnative.pulsar.handlers.kop.stats.PrometheusMetricsProvider\n+kopStatsProviderClass=io.streamnative.pulsar.handlers.kop.stats.PrometheusMetricsProvider\n+\n+# Prometheus provider http port, default: 8112\n+kopPrometheusPort=8112\n+\n+# Whether enable prometheus provider, default: true\n+kopPrometheusStatsHttpEnable=true\n+\n+# Prometheus stats rollover latency, default: 60s\n+kopPrometheusStatsLatencyRolloverSeconds=60\n+\n+"
  },
  {
    "sha": "7e5293f26d0a3cbf46cc196bb61cc386928fbc31",
    "filename": "kafka-impl/src/main/java/io/streamnative/pulsar/handlers/kop/KafkaChannelInitializer.java",
    "status": "modified",
    "additions": 7,
    "deletions": 2,
    "changes": 9,
    "blob_url": "https://github.com/streamnative/kop/blob/84e0f20463cc04f823c4ef48d002f73313afb26e/kafka-impl/src/main/java/io/streamnative/pulsar/handlers/kop/KafkaChannelInitializer.java",
    "raw_url": "https://github.com/streamnative/kop/raw/84e0f20463cc04f823c4ef48d002f73313afb26e/kafka-impl/src/main/java/io/streamnative/pulsar/handlers/kop/KafkaChannelInitializer.java",
    "contents_url": "https://api.github.com/repos/streamnative/kop/contents/kafka-impl/src/main/java/io/streamnative/pulsar/handlers/kop/KafkaChannelInitializer.java?ref=84e0f20463cc04f823c4ef48d002f73313afb26e",
    "patch": "@@ -24,6 +24,7 @@\n import io.streamnative.pulsar.handlers.kop.coordinator.transaction.TransactionCoordinator;\n import io.streamnative.pulsar.handlers.kop.utils.ssl.SSLUtils;\n import lombok.Getter;\n+import org.apache.bookkeeper.stats.StatsLogger;\n import org.apache.pulsar.broker.PulsarService;\n import org.eclipse.jetty.util.ssl.SslContextFactory;\n \n@@ -48,20 +49,24 @@\n     private final EndPoint advertisedEndPoint;\n     @Getter\n     private final SslContextFactory sslContextFactory;\n+    @Getter\n+    private final StatsLogger statsLogger;\n \n     public KafkaChannelInitializer(PulsarService pulsarService,\n                                    KafkaServiceConfiguration kafkaConfig,\n                                    GroupCoordinator groupCoordinator,\n                                    TransactionCoordinator transactionCoordinator,\n                                    boolean enableTLS,\n-                                   EndPoint advertisedEndPoint) {\n+                                   EndPoint advertisedEndPoint,\n+                                   StatsLogger statsLogger) {\n         super();\n         this.pulsarService = pulsarService;\n         this.kafkaConfig = kafkaConfig;\n         this.groupCoordinator = groupCoordinator;\n         this.transactionCoordinator = transactionCoordinator;\n         this.enableTls = enableTLS;\n         this.advertisedEndPoint = advertisedEndPoint;\n+        this.statsLogger = statsLogger;\n \n         if (enableTls) {\n             sslContextFactory = SSLUtils.createSslContextFactory(kafkaConfig);\n@@ -80,7 +85,7 @@ protected void initChannel(SocketChannel ch) throws Exception {\n             new LengthFieldBasedFrameDecoder(MAX_FRAME_LENGTH, 0, 4, 0, 4));\n         ch.pipeline().addLast(\"handler\",\n             new KafkaRequestHandler(pulsarService, kafkaConfig,\n-                    groupCoordinator, transactionCoordinator, enableTls, advertisedEndPoint));\n+                    groupCoordinator, transactionCoordinator, enableTls, advertisedEndPoint, statsLogger));\n     }\n \n }"
  },
  {
    "sha": "cf83841e5e6b9b921d72ab5c88e3cd6a1c4cc252",
    "filename": "kafka-impl/src/main/java/io/streamnative/pulsar/handlers/kop/KafkaProtocolHandler.java",
    "status": "modified",
    "additions": 14,
    "deletions": 2,
    "changes": 16,
    "blob_url": "https://github.com/streamnative/kop/blob/84e0f20463cc04f823c4ef48d002f73313afb26e/kafka-impl/src/main/java/io/streamnative/pulsar/handlers/kop/KafkaProtocolHandler.java",
    "raw_url": "https://github.com/streamnative/kop/raw/84e0f20463cc04f823c4ef48d002f73313afb26e/kafka-impl/src/main/java/io/streamnative/pulsar/handlers/kop/KafkaProtocolHandler.java",
    "contents_url": "https://api.github.com/repos/streamnative/kop/contents/kafka-impl/src/main/java/io/streamnative/pulsar/handlers/kop/KafkaProtocolHandler.java?ref=84e0f20463cc04f823c4ef48d002f73313afb26e",
    "patch": "@@ -14,6 +14,7 @@\n package io.streamnative.pulsar.handlers.kop;\n \n import static com.google.common.base.Preconditions.checkState;\n+import static io.streamnative.pulsar.handlers.kop.KopServerStats.SERVER_SCOPE;\n import static io.streamnative.pulsar.handlers.kop.utils.TopicNameUtils.getKafkaTopicNameFromPulsarTopicname;\n import static org.apache.pulsar.common.naming.TopicName.PARTITIONED_TOPIC_SUFFIX;\n \n@@ -39,6 +40,7 @@\n import java.util.stream.Collectors;\n import lombok.Getter;\n import lombok.extern.slf4j.Slf4j;\n+import org.apache.bookkeeper.stats.StatsLogger;\n import org.apache.kafka.common.internals.Topic;\n import org.apache.kafka.common.record.CompressionType;\n import org.apache.kafka.common.security.auth.SecurityProtocol;\n@@ -66,6 +68,8 @@\n     public static final String PROTOCOL_NAME = \"kafka\";\n     public static final String TLS_HANDLER = \"tls\";\n \n+    private StatsLogger rootStatsLogger;\n+    private StatsProviderService statsProviderService;\n     /**\n      * Listener for the changing of topic that stores offsets of consumer group.\n      */\n@@ -223,6 +227,9 @@ public void initialize(ServiceConfiguration conf) throws Exception {\n         }\n         this.bindAddress = ServiceConfigurationUtils.getDefaultOrConfiguredAddress(kafkaConfig.getBindAddress());\n         KopTopic.initialize(kafkaConfig.getKafkaTenant() + \"/\" + kafkaConfig.getKafkaNamespace());\n+\n+        statsProviderService = new StatsProviderService(kafkaConfig);\n+        rootStatsLogger = statsProviderService.getStatsProvider().getStatsLogger(\"\");\n     }\n \n     // This method is called after initialize\n@@ -264,6 +271,9 @@ public void start(BrokerService service) {\n                 log.error(\"Initialized transaction coordinator failed.\", e);\n             }\n         }\n+\n+        statsProviderService.start();\n+\n     }\n \n     // this is called after initialize, and with kafkaConfig, brokerService all set.\n@@ -291,12 +301,14 @@ public void start(BrokerService service) {\n                     case PLAINTEXT:\n                     case SASL_PLAINTEXT:\n                         builder.put(endPoint.getInetAddress(), new KafkaChannelInitializer(brokerService.getPulsar(),\n-                                kafkaConfig, groupCoordinator, transactionCoordinator, false, advertisedEndPoint));\n+                                kafkaConfig, groupCoordinator, transactionCoordinator, false,\n+                            advertisedEndPoint, rootStatsLogger.scope(SERVER_SCOPE)));\n                         break;\n                     case SSL:\n                     case SASL_SSL:\n                         builder.put(endPoint.getInetAddress(), new KafkaChannelInitializer(brokerService.getPulsar(),\n-                                kafkaConfig, groupCoordinator, transactionCoordinator, true, advertisedEndPoint));\n+                                kafkaConfig, groupCoordinator, transactionCoordinator, true,\n+                            advertisedEndPoint, rootStatsLogger.scope(SERVER_SCOPE)));\n                         break;\n                 }\n             });"
  },
  {
    "sha": "647f83cc113c28c12c925d906583707aecb1fb21",
    "filename": "kafka-impl/src/main/java/io/streamnative/pulsar/handlers/kop/KafkaRequestHandler.java",
    "status": "modified",
    "additions": 22,
    "deletions": 2,
    "changes": 24,
    "blob_url": "https://github.com/streamnative/kop/blob/84e0f20463cc04f823c4ef48d002f73313afb26e/kafka-impl/src/main/java/io/streamnative/pulsar/handlers/kop/KafkaRequestHandler.java",
    "raw_url": "https://github.com/streamnative/kop/raw/84e0f20463cc04f823c4ef48d002f73313afb26e/kafka-impl/src/main/java/io/streamnative/pulsar/handlers/kop/KafkaRequestHandler.java",
    "contents_url": "https://api.github.com/repos/streamnative/kop/contents/kafka-impl/src/main/java/io/streamnative/pulsar/handlers/kop/KafkaRequestHandler.java?ref=84e0f20463cc04f823c4ef48d002f73313afb26e",
    "patch": "@@ -56,18 +56,21 @@\n import java.util.concurrent.CompletableFuture;\n import java.util.concurrent.ConcurrentHashMap;\n import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n import java.util.concurrent.atomic.AtomicInteger;\n import java.util.stream.Collectors;\n import java.util.stream.IntStream;\n import javax.naming.AuthenticationException;\n \n import lombok.Getter;\n import lombok.extern.slf4j.Slf4j;\n+import org.apache.bookkeeper.common.util.MathUtils;\n import org.apache.bookkeeper.mledger.AsyncCallbacks;\n import org.apache.bookkeeper.mledger.ManagedLedgerException;\n import org.apache.bookkeeper.mledger.Position;\n import org.apache.bookkeeper.mledger.impl.ManagedLedgerImpl;\n import org.apache.bookkeeper.mledger.impl.PositionImpl;\n+import org.apache.bookkeeper.stats.StatsLogger;\n import org.apache.commons.lang3.NotImplementedException;\n import org.apache.kafka.common.Node;\n import org.apache.kafka.common.TopicPartition;\n@@ -152,6 +155,7 @@\n import org.apache.pulsar.policies.data.loadbalancer.ServiceLookupData;\n import org.apache.pulsar.zookeeper.ZooKeeperCache;\n import org.apache.pulsar.zookeeper.ZooKeeperCache.Deserializer;\n+import org.inferred.freebuilder.shaded.org.openjdk.tools.javac.util.MatchingUtils;\n \n /**\n  * This class contains all the request handling methods.\n@@ -185,13 +189,16 @@\n     private final EntryFormatter entryFormatter;\n \n     private final Map<TopicPartition, PendingProduceQueue> pendingProduceQueueMap = new ConcurrentHashMap<>();\n+    private final StatsLogger statsLogger;\n+    private final RequestStats requestStats;\n \n     public KafkaRequestHandler(PulsarService pulsarService,\n                                KafkaServiceConfiguration kafkaConfig,\n                                GroupCoordinator groupCoordinator,\n                                TransactionCoordinator transactionCoordinator,\n                                Boolean tlsEnabled,\n-                               EndPoint advertisedEndPoint) throws Exception {\n+                               EndPoint advertisedEndPoint,\n+                               StatsLogger statsLogger) throws Exception {\n         super();\n         this.pulsarService = pulsarService;\n         this.kafkaConfig = kafkaConfig;\n@@ -215,6 +222,8 @@ public KafkaRequestHandler(PulsarService pulsarService,\n         this.entryFormatter = EntryFormatterFactory.create(kafkaConfig.getEntryFormat());\n         this.currentConnectedGroup = new ConcurrentHashMap<>();\n         this.groupIdStoredPath = kafkaConfig.getGroupIdZooKeeperPath();\n+        this.statsLogger = statsLogger;\n+        this.requestStats = new RequestStats(statsLogger);\n     }\n \n     @Override\n@@ -603,6 +612,8 @@ protected void handleTopicMetadataRequest(KafkaHeaderAndRequest metadataHar,\n \n     protected void handleProduceRequest(KafkaHeaderAndRequest produceHar,\n                                         CompletableFuture<AbstractResponse> resultFuture) {\n+        final long startProduceNanos = MathUtils.nowInNano();\n+\n         checkArgument(produceHar.getRequest() instanceof ProduceRequest);\n         ProduceRequest produceRequest = (ProduceRequest) produceHar.getRequest();\n         if (produceRequest.transactionalId() != null) {\n@@ -633,7 +644,7 @@ protected void handleProduceRequest(KafkaHeaderAndRequest produceHar,\n             MemoryRecords records = (MemoryRecords) entry.getValue();\n             String fullPartitionName = KopTopic.toString(topicPartition);\n             PendingProduce pendingProduce = new PendingProduce(partitionResponse, topicManager, fullPartitionName,\n-                    entryFormatter, records, executor, transactionCoordinator);\n+                    entryFormatter, records, executor, transactionCoordinator, requestStats);\n             PendingProduceQueue queue =\n                     pendingProduceQueueMap.computeIfAbsent(topicPartition, ignored -> new PendingProduceQueue());\n             queue.add(pendingProduce);\n@@ -654,6 +665,15 @@ protected void handleProduceRequest(KafkaHeaderAndRequest produceHar,\n                         log.debug(\"[{}] Request {}: Complete handle produce.\",\n                                 ctx.channel(), produceHar.toString());\n                     }\n+\n+                    if (ex != null) {\n+                        requestStats.getHandleProduceRequestStats()\n+                            .registerFailedEvent(MathUtils.elapsedNanos(startProduceNanos), TimeUnit.NANOSECONDS);\n+                    } else {\n+                        requestStats.getHandleProduceRequestStats()\n+                            .registerSuccessfulEvent(MathUtils.elapsedNanos(startProduceNanos), TimeUnit.NANOSECONDS);\n+                    }\n+\n                     resultFuture.complete(new ProduceResponse(responses));\n                 });\n     }"
  },
  {
    "sha": "ed254da247f39378893e4f752aefde104e414152",
    "filename": "kafka-impl/src/main/java/io/streamnative/pulsar/handlers/kop/KafkaServiceConfiguration.java",
    "status": "modified",
    "additions": 25,
    "deletions": 0,
    "changes": 25,
    "blob_url": "https://github.com/streamnative/kop/blob/84e0f20463cc04f823c4ef48d002f73313afb26e/kafka-impl/src/main/java/io/streamnative/pulsar/handlers/kop/KafkaServiceConfiguration.java",
    "raw_url": "https://github.com/streamnative/kop/raw/84e0f20463cc04f823c4ef48d002f73313afb26e/kafka-impl/src/main/java/io/streamnative/pulsar/handlers/kop/KafkaServiceConfiguration.java",
    "contents_url": "https://api.github.com/repos/streamnative/kop/contents/kafka-impl/src/main/java/io/streamnative/pulsar/handlers/kop/KafkaServiceConfiguration.java?ref=84e0f20463cc04f823c4ef48d002f73313afb26e",
    "patch": "@@ -292,6 +292,31 @@\n     )\n     private boolean enableTransactionCoordinator = false;\n \n+    @FieldContext(\n+        category = CATEGORY_KOP,\n+        doc = \"KOP Stats provider to expose statistic metric, \" +\n+            \"default: io.streamnative.pulsar.handlers.kop.stats.PrometheusMetricsProvider\"\n+    )\n+    private String kopStatsProviderClass = \"io.streamnative.pulsar.handlers.kop.stats.PrometheusMetricsProvider\";\n+\n+    @FieldContext(\n+        category = CATEGORY_KOP,\n+        doc = \"KOP Stats provider port to expose statistic metric, default: 8112\"\n+    )\n+    private int kopPrometheusPort = 8112;\n+\n+    @FieldContext(\n+        category = CATEGORY_KOP,\n+        doc = \"Whether enable KOP prometheus stats provider\"\n+    )\n+    private boolean kopPrometheusStatsHttpEnable = true;\n+\n+    @FieldContext(\n+        category = CATEGORY_KOP,\n+        doc = \"KOP Prometheus stats rollover latency\"\n+    )\n+    private int kopPrometheusStatsLatencyRolloverSeconds = 60;\n+\n     public @NonNull String getKafkaAdvertisedListeners() {\n         if (kafkaAdvertisedListeners != null) {\n             return kafkaAdvertisedListeners;"
  },
  {
    "sha": "852ae336d6cfa01f332707d01bdf2a15f1061dc3",
    "filename": "kafka-impl/src/main/java/io/streamnative/pulsar/handlers/kop/KopServerStats.java",
    "status": "added",
    "additions": 32,
    "deletions": 0,
    "changes": 32,
    "blob_url": "https://github.com/streamnative/kop/blob/84e0f20463cc04f823c4ef48d002f73313afb26e/kafka-impl/src/main/java/io/streamnative/pulsar/handlers/kop/KopServerStats.java",
    "raw_url": "https://github.com/streamnative/kop/raw/84e0f20463cc04f823c4ef48d002f73313afb26e/kafka-impl/src/main/java/io/streamnative/pulsar/handlers/kop/KopServerStats.java",
    "contents_url": "https://api.github.com/repos/streamnative/kop/contents/kafka-impl/src/main/java/io/streamnative/pulsar/handlers/kop/KopServerStats.java?ref=84e0f20463cc04f823c4ef48d002f73313afb26e",
    "patch": "@@ -0,0 +1,32 @@\n+/**\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.streamnative.pulsar.handlers.kop;\n+\n+public interface KopServerStats {\n+    String CATEGORY_SERVER = \"server\";\n+\n+    String SERVER_SCOPE = \"kop_server\";\n+\n+    String SERVER_STATUS = \"SERVER_STATUS\";\n+\n+\n+    /**\n+     * PRODUCE STATS\n+     */\n+    String HANDLE_PRODUCE_REQUEST = \"HANDLE_PRODUCE_REQUEST\";\n+    String PRODUCE_ENCODE = \"PRODUCE_ENCODE\";\n+    String MESSAGE_PUBLISH = \"MESSAGE_PUBLISH\";\n+    String MESSAGE_QUEUED_LATENCY = \"MESSAGE_QUEUED_LATENCY\";\n+\n+}"
  },
  {
    "sha": "980995205b0afbea147f45af5180fb30bff5aae6",
    "filename": "kafka-impl/src/main/java/io/streamnative/pulsar/handlers/kop/PendingProduce.java",
    "status": "modified",
    "additions": 20,
    "deletions": 1,
    "changes": 21,
    "blob_url": "https://github.com/streamnative/kop/blob/84e0f20463cc04f823c4ef48d002f73313afb26e/kafka-impl/src/main/java/io/streamnative/pulsar/handlers/kop/PendingProduce.java",
    "raw_url": "https://github.com/streamnative/kop/raw/84e0f20463cc04f823c4ef48d002f73313afb26e/kafka-impl/src/main/java/io/streamnative/pulsar/handlers/kop/PendingProduce.java",
    "contents_url": "https://api.github.com/repos/streamnative/kop/contents/kafka-impl/src/main/java/io/streamnative/pulsar/handlers/kop/PendingProduce.java?ref=84e0f20463cc04f823c4ef48d002f73313afb26e",
    "patch": "@@ -19,7 +19,9 @@\n import java.util.concurrent.CompletableFuture;\n import java.util.concurrent.ExecutionException;\n import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.TimeUnit;\n import lombok.extern.slf4j.Slf4j;\n+import org.apache.bookkeeper.common.util.MathUtils;\n import org.apache.kafka.common.protocol.Errors;\n import org.apache.kafka.common.record.MemoryRecords;\n import org.apache.kafka.common.record.RecordBatch;\n@@ -44,14 +46,18 @@\n     private final TransactionCoordinator transactionCoordinator;\n     private long pid;\n     private boolean isTransactional;\n+    private RequestStats requestStats;\n+    private final long enqueueTimestamp;\n \n     public PendingProduce(CompletableFuture<PartitionResponse> responseFuture,\n                           KafkaTopicManager topicManager,\n                           String partitionName,\n                           EntryFormatter entryFormatter,\n                           MemoryRecords memoryRecords,\n                           ExecutorService executor,\n-                          TransactionCoordinator transactionCoordinator) {\n+                          TransactionCoordinator transactionCoordinator,\n+                          RequestStats requestStats) {\n+        this.enqueueTimestamp = MathUtils.nowInNano();\n         this.responseFuture = responseFuture;\n         this.topicManager = topicManager;\n         this.partitionName = partitionName;\n@@ -67,12 +73,15 @@ public PendingProduce(CompletableFuture<PartitionResponse> responseFuture,\n             return null;\n         });\n         executor.execute(() -> byteBufFuture.complete(entryFormatter.encode(memoryRecords, numMessages)));\n+        requestStats.getProduceEncodeStats()\n+            .registerSuccessfulEvent(MathUtils.elapsedNanos(enqueueTimestamp), TimeUnit.NANOSECONDS);\n         this.offsetFuture = new CompletableFuture<>();\n \n         RecordBatch batch = memoryRecords.batchIterator().next();\n         this.transactionCoordinator = transactionCoordinator;\n         this.pid = batch.producerId();\n         this.isTransactional = batch.isTransactional();\n+        this.requestStats = requestStats;\n     }\n \n     public boolean ready() {\n@@ -103,6 +112,10 @@ public void publishMessages() {\n         if (!ready()) {\n             throw new RuntimeException(\"Try to send while PendingProduce is not ready\");\n         }\n+\n+        requestStats.getMessageQueuedLatencyStats()\n+            .registerSuccessfulEvent(MathUtils.elapsedNanos(enqueueTimestamp), TimeUnit.NANOSECONDS);\n+\n         PersistentTopic persistentTopic;\n         ByteBuf byteBuf;\n         try {\n@@ -129,9 +142,15 @@ public void publishMessages() {\n                 if (this.isTransactional) {\n                     transactionCoordinator.addActivePidOffset(TopicName.get(partitionName), pid, offset);\n                 }\n+                requestStats.getMessagePublishStats().registerSuccessfulEvent(\n+                    MathUtils.elapsedNanos(enqueueTimestamp), TimeUnit.NANOSECONDS);\n+\n                 responseFuture.complete(new PartitionResponse(Errors.NONE, offset, -1L, -1L));\n             } else {\n                 log.error(\"publishMessages for topic partition: {} failed when write.\", partitionName, e);\n+                requestStats.getMessagePublishStats()\n+                    .registerFailedEvent(MathUtils.elapsedNanos(enqueueTimestamp), TimeUnit.NANOSECONDS);\n+\n                 responseFuture.complete(new PartitionResponse(Errors.KAFKA_STORAGE_ERROR));\n             }\n             byteBuf.release();"
  },
  {
    "sha": "b12c9029be556e0d25645928919c92cd8c7b2e60",
    "filename": "kafka-impl/src/main/java/io/streamnative/pulsar/handlers/kop/RequestStats.java",
    "status": "added",
    "additions": 66,
    "deletions": 0,
    "changes": 66,
    "blob_url": "https://github.com/streamnative/kop/blob/84e0f20463cc04f823c4ef48d002f73313afb26e/kafka-impl/src/main/java/io/streamnative/pulsar/handlers/kop/RequestStats.java",
    "raw_url": "https://github.com/streamnative/kop/raw/84e0f20463cc04f823c4ef48d002f73313afb26e/kafka-impl/src/main/java/io/streamnative/pulsar/handlers/kop/RequestStats.java",
    "contents_url": "https://api.github.com/repos/streamnative/kop/contents/kafka-impl/src/main/java/io/streamnative/pulsar/handlers/kop/RequestStats.java?ref=84e0f20463cc04f823c4ef48d002f73313afb26e",
    "patch": "@@ -0,0 +1,66 @@\n+/**\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.streamnative.pulsar.handlers.kop;\n+\n+import lombok.Getter;\n+import org.apache.bookkeeper.stats.OpStatsLogger;\n+import org.apache.bookkeeper.stats.StatsLogger;\n+import org.apache.bookkeeper.stats.annotations.StatsDoc;\n+\n+import static io.streamnative.pulsar.handlers.kop.KopServerStats.CATEGORY_SERVER;\n+import static io.streamnative.pulsar.handlers.kop.KopServerStats.HANDLE_PRODUCE_REQUEST;\n+import static io.streamnative.pulsar.handlers.kop.KopServerStats.MESSAGE_PUBLISH;\n+import static io.streamnative.pulsar.handlers.kop.KopServerStats.MESSAGE_QUEUED_LATENCY;\n+import static io.streamnative.pulsar.handlers.kop.KopServerStats.PRODUCE_ENCODE;\n+import static io.streamnative.pulsar.handlers.kop.KopServerStats.SERVER_SCOPE;\n+\n+@StatsDoc(\n+    name = SERVER_SCOPE,\n+    category = CATEGORY_SERVER,\n+    help = \"KOP request stats\"\n+)\n+\n+@Getter\n+public class RequestStats {\n+    @StatsDoc(\n+        name = HANDLE_PRODUCE_REQUEST,\n+        help = \"handle produce request stats of Kop\"\n+    )\n+    private final OpStatsLogger handleProduceRequestStats;\n+\n+    @StatsDoc(\n+        name = PRODUCE_ENCODE,\n+        help = \"produce encode stats of Kop\"\n+    )\n+    private final OpStatsLogger produceEncodeStats;\n+\n+    @StatsDoc(\n+        name = MESSAGE_PUBLISH,\n+        help = \"message publish stats from kop to pulsar broker\"\n+    )\n+    private final OpStatsLogger messagePublishStats;\n+\n+    @StatsDoc(\n+        name = MESSAGE_QUEUED_LATENCY,\n+        help = \"message queued stats from kop to pulsar broker\"\n+    )\n+    private final OpStatsLogger messageQueuedLatencyStats;\n+\n+    public RequestStats(StatsLogger statsLogger) {\n+        this.handleProduceRequestStats = statsLogger.getOpStatsLogger(HANDLE_PRODUCE_REQUEST);\n+        this.produceEncodeStats = statsLogger.getOpStatsLogger(PRODUCE_ENCODE);\n+        this.messagePublishStats = statsLogger.getOpStatsLogger(MESSAGE_PUBLISH);\n+        this.messageQueuedLatencyStats = statsLogger.getOpStatsLogger(MESSAGE_QUEUED_LATENCY);\n+    }\n+}"
  },
  {
    "sha": "3fedf5a287552494e02c4b57a873ad7aba85a2c8",
    "filename": "kafka-impl/src/main/java/io/streamnative/pulsar/handlers/kop/StatsProviderService.java",
    "status": "added",
    "additions": 50,
    "deletions": 0,
    "changes": 50,
    "blob_url": "https://github.com/streamnative/kop/blob/84e0f20463cc04f823c4ef48d002f73313afb26e/kafka-impl/src/main/java/io/streamnative/pulsar/handlers/kop/StatsProviderService.java",
    "raw_url": "https://github.com/streamnative/kop/raw/84e0f20463cc04f823c4ef48d002f73313afb26e/kafka-impl/src/main/java/io/streamnative/pulsar/handlers/kop/StatsProviderService.java",
    "contents_url": "https://api.github.com/repos/streamnative/kop/contents/kafka-impl/src/main/java/io/streamnative/pulsar/handlers/kop/StatsProviderService.java?ref=84e0f20463cc04f823c4ef48d002f73313afb26e",
    "patch": "@@ -0,0 +1,50 @@\n+/**\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.streamnative.pulsar.handlers.kop;\n+\n+import lombok.extern.slf4j.Slf4j;\n+import org.apache.bookkeeper.stats.StatsProvider;\n+import org.apache.commons.configuration.Configuration;\n+import org.apache.commons.configuration.PropertiesConfiguration;\n+\n+@Slf4j\n+public class StatsProviderService {\n+    private final StatsProvider statsProvider;\n+    private final Configuration conf;\n+\n+    public StatsProviderService(KafkaServiceConfiguration kafkaServiceConfiguration) throws Exception {\n+        Class statsProviderClass = Class.forName(kafkaServiceConfiguration.getKopStatsProviderClass());\n+        this.statsProvider = (StatsProvider) statsProviderClass.newInstance();\n+\n+        conf = new PropertiesConfiguration();\n+        conf.addProperty(\"prometheusStatsHttpEnable\", kafkaServiceConfiguration.isKopPrometheusStatsHttpEnable());\n+        conf.addProperty(\"prometheusStatsHttpPort\", kafkaServiceConfiguration.getKopPrometheusPort());\n+        conf.addProperty(\"prometheusStatsLatencyRolloverSeconds\",\n+            kafkaServiceConfiguration.getKopPrometheusStatsLatencyRolloverSeconds());\n+        conf.addProperty(\"prometheusBasicStatsEnable\", false);\n+    }\n+\n+    public StatsProvider getStatsProvider() {\n+        return this.statsProvider;\n+    }\n+\n+    protected void start() {\n+        statsProvider.start(conf);\n+    }\n+\n+    protected void stop() {\n+        statsProvider.stop();\n+    }\n+\n+}"
  },
  {
    "sha": "e78c916f8d8b4ba38bbd1b89565f7bf1d2620d86",
    "filename": "kafka-impl/src/main/java/io/streamnative/pulsar/handlers/kop/stats/DataSketchesOpStatsLogger.java",
    "status": "added",
    "additions": 193,
    "deletions": 0,
    "changes": 193,
    "blob_url": "https://github.com/streamnative/kop/blob/84e0f20463cc04f823c4ef48d002f73313afb26e/kafka-impl/src/main/java/io/streamnative/pulsar/handlers/kop/stats/DataSketchesOpStatsLogger.java",
    "raw_url": "https://github.com/streamnative/kop/raw/84e0f20463cc04f823c4ef48d002f73313afb26e/kafka-impl/src/main/java/io/streamnative/pulsar/handlers/kop/stats/DataSketchesOpStatsLogger.java",
    "contents_url": "https://api.github.com/repos/streamnative/kop/contents/kafka-impl/src/main/java/io/streamnative/pulsar/handlers/kop/stats/DataSketchesOpStatsLogger.java?ref=84e0f20463cc04f823c4ef48d002f73313afb26e",
    "patch": "@@ -0,0 +1,193 @@\n+/**\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.streamnative.pulsar.handlers.kop.stats;\n+\n+import com.yahoo.sketches.quantiles.DoublesSketch;\n+import com.yahoo.sketches.quantiles.DoublesSketchBuilder;\n+import com.yahoo.sketches.quantiles.DoublesUnion;\n+import com.yahoo.sketches.quantiles.DoublesUnionBuilder;\n+import io.netty.util.concurrent.FastThreadLocal;\n+import java.util.Map;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.LongAdder;\n+import java.util.concurrent.locks.StampedLock;\n+import org.apache.bookkeeper.stats.OpStatsData;\n+import org.apache.bookkeeper.stats.OpStatsLogger;\n+\n+/**\n+ * OpStatsLogger implementation that uses DataSketches library to calculate the approximated latency quantiles.\n+ */\n+public class DataSketchesOpStatsLogger implements OpStatsLogger {\n+\n+    /*\n+     * Use 2 rotating thread local accessor so that we can safely swap them.\n+     */\n+    private volatile ThreadLocalAccessor current;\n+    private volatile ThreadLocalAccessor replacement;\n+\n+    /*\n+     * These are the sketches where all the aggregated results are published.\n+     */\n+    private volatile DoublesSketch successResult;\n+    private volatile DoublesSketch failResult;\n+\n+    private final LongAdder successCountAdder = new LongAdder();\n+    private final LongAdder failCountAdder = new LongAdder();\n+\n+    private final LongAdder successSumAdder = new LongAdder();\n+    private final LongAdder failSumAdder = new LongAdder();\n+\n+    DataSketchesOpStatsLogger() {\n+        this.current = new ThreadLocalAccessor();\n+        this.replacement = new ThreadLocalAccessor();\n+    }\n+\n+    @Override\n+    public void registerFailedEvent(long eventLatency, TimeUnit unit) {\n+        double valueMillis = unit.toMicros(eventLatency) / 1000.0;\n+\n+        failCountAdder.increment();\n+        failSumAdder.add((long) valueMillis);\n+\n+        LocalData localData = current.localData.get();\n+\n+        long stamp = localData.lock.readLock();\n+        try {\n+            localData.failSketch.update(valueMillis);\n+        } finally {\n+            localData.lock.unlockRead(stamp);\n+        }\n+    }\n+\n+    @Override\n+    public void registerSuccessfulEvent(long eventLatency, TimeUnit unit) {\n+        double valueMillis = unit.toMicros(eventLatency) / 1000.0;\n+\n+        successCountAdder.increment();\n+        successSumAdder.add((long) valueMillis);\n+\n+        LocalData localData = current.localData.get();\n+\n+        long stamp = localData.lock.readLock();\n+        try {\n+            localData.successSketch.update(valueMillis);\n+        } finally {\n+            localData.lock.unlockRead(stamp);\n+        }\n+    }\n+\n+    @Override\n+    public void registerSuccessfulValue(long value) {\n+        successCountAdder.increment();\n+        successSumAdder.add(value);\n+\n+        LocalData localData = current.localData.get();\n+\n+        long stamp = localData.lock.readLock();\n+        try {\n+            localData.successSketch.update(value);\n+        } finally {\n+            localData.lock.unlockRead(stamp);\n+        }\n+    }\n+\n+    @Override\n+    public void registerFailedValue(long value) {\n+        failCountAdder.increment();\n+        failSumAdder.add(value);\n+\n+        LocalData localData = current.localData.get();\n+\n+        long stamp = localData.lock.readLock();\n+        try {\n+            localData.failSketch.update(value);\n+        } finally {\n+            localData.lock.unlockRead(stamp);\n+        }\n+    }\n+\n+    @Override\n+    public OpStatsData toOpStatsData() {\n+        // Not relevant as we don't use JMX here\n+        throw new UnsupportedOperationException();\n+    }\n+\n+    @Override\n+    public void clear() {\n+        // Not relevant as we don't use JMX here\n+        throw new UnsupportedOperationException();\n+    }\n+\n+    public void rotateLatencyCollection() {\n+        // Swap current with replacement\n+        ThreadLocalAccessor local = current;\n+        current = replacement;\n+        replacement = local;\n+\n+        final DoublesUnion aggregateSuccesss = new DoublesUnionBuilder().build();\n+        final DoublesUnion aggregateFail = new DoublesUnionBuilder().build();\n+        local.map.forEach((localData, b) -> {\n+            long stamp = localData.lock.writeLock();\n+            try {\n+                aggregateSuccesss.update(localData.successSketch);\n+                localData.successSketch.reset();\n+                aggregateFail.update(localData.failSketch);\n+                localData.failSketch.reset();\n+            } finally {\n+                localData.lock.unlockWrite(stamp);\n+            }\n+        });\n+\n+        successResult = aggregateSuccesss.getResultAndReset();\n+        failResult = aggregateFail.getResultAndReset();\n+    }\n+\n+    public long getCount(boolean success) {\n+        return success ? successCountAdder.sum() : failCountAdder.sum();\n+    }\n+\n+    public long getSum(boolean success) {\n+        return success ? successSumAdder.sum() : failSumAdder.sum();\n+    }\n+\n+    public double getQuantileValue(boolean success, double quantile) {\n+        DoublesSketch s = success ? successResult : failResult;\n+        return s != null ? s.getQuantile(quantile) : Double.NaN;\n+    }\n+\n+    private static class LocalData {\n+        private final DoublesSketch successSketch = new DoublesSketchBuilder().build();\n+        private final DoublesSketch failSketch = new DoublesSketchBuilder().build();\n+        private final StampedLock lock = new StampedLock();\n+    }\n+\n+    private static class ThreadLocalAccessor {\n+        private final Map<LocalData, Boolean> map = new ConcurrentHashMap<>();\n+        private final FastThreadLocal<LocalData> localData = new FastThreadLocal<LocalData>() {\n+\n+            @Override\n+            protected LocalData initialValue() throws Exception {\n+                LocalData localData = new LocalData();\n+                map.put(localData, Boolean.TRUE);\n+                return localData;\n+            }\n+\n+            @Override\n+            protected void onRemoval(LocalData value) throws Exception {\n+                map.remove(value);\n+            }\n+        };\n+    }\n+}"
  },
  {
    "sha": "7d678fd0bb9187e0fd1b02df2740546965d45d5c",
    "filename": "kafka-impl/src/main/java/io/streamnative/pulsar/handlers/kop/stats/LongAdderCounter.java",
    "status": "added",
    "additions": 52,
    "deletions": 0,
    "changes": 52,
    "blob_url": "https://github.com/streamnative/kop/blob/84e0f20463cc04f823c4ef48d002f73313afb26e/kafka-impl/src/main/java/io/streamnative/pulsar/handlers/kop/stats/LongAdderCounter.java",
    "raw_url": "https://github.com/streamnative/kop/raw/84e0f20463cc04f823c4ef48d002f73313afb26e/kafka-impl/src/main/java/io/streamnative/pulsar/handlers/kop/stats/LongAdderCounter.java",
    "contents_url": "https://api.github.com/repos/streamnative/kop/contents/kafka-impl/src/main/java/io/streamnative/pulsar/handlers/kop/stats/LongAdderCounter.java?ref=84e0f20463cc04f823c4ef48d002f73313afb26e",
    "patch": "@@ -0,0 +1,52 @@\n+/**\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.streamnative.pulsar.handlers.kop.stats;\n+\n+import java.util.concurrent.atomic.LongAdder;\n+import org.apache.bookkeeper.stats.Counter;\n+\n+/**\n+ * {@link Counter} implementation based on {@link LongAdder}.\n+ *\n+ * <p>LongAdder keeps a counter per-thread and then aggregates to get the result, in order to avoid contention between\n+ * multiple threads.\n+ */\n+public class LongAdderCounter implements Counter {\n+    private final LongAdder counter = new LongAdder();\n+\n+    @Override\n+    public void clear() {\n+        counter.reset();\n+    }\n+\n+    @Override\n+    public void inc() {\n+        counter.increment();\n+    }\n+\n+    @Override\n+    public void dec() {\n+        counter.decrement();\n+    }\n+\n+    @Override\n+    public void add(long delta) {\n+        counter.add(delta);\n+    }\n+\n+    @Override\n+    public Long get() {\n+        return counter.sum();\n+    }\n+}"
  },
  {
    "sha": "65bbbea75d1076214d1377b703bb0b6904202256",
    "filename": "kafka-impl/src/main/java/io/streamnative/pulsar/handlers/kop/stats/PrometheusMetricsProvider.java",
    "status": "added",
    "additions": 250,
    "deletions": 0,
    "changes": 250,
    "blob_url": "https://github.com/streamnative/kop/blob/84e0f20463cc04f823c4ef48d002f73313afb26e/kafka-impl/src/main/java/io/streamnative/pulsar/handlers/kop/stats/PrometheusMetricsProvider.java",
    "raw_url": "https://github.com/streamnative/kop/raw/84e0f20463cc04f823c4ef48d002f73313afb26e/kafka-impl/src/main/java/io/streamnative/pulsar/handlers/kop/stats/PrometheusMetricsProvider.java",
    "contents_url": "https://api.github.com/repos/streamnative/kop/contents/kafka-impl/src/main/java/io/streamnative/pulsar/handlers/kop/stats/PrometheusMetricsProvider.java?ref=84e0f20463cc04f823c4ef48d002f73313afb26e",
    "patch": "@@ -0,0 +1,250 @@\n+/**\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.streamnative.pulsar.handlers.kop.stats;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import io.netty.util.concurrent.DefaultThreadFactory;\n+import io.netty.util.internal.PlatformDependent;\n+import io.prometheus.client.Collector;\n+import io.prometheus.client.CollectorRegistry;\n+import io.prometheus.client.Gauge;\n+import io.prometheus.client.Gauge.Child;\n+import io.prometheus.client.hotspot.GarbageCollectorExports;\n+import io.prometheus.client.hotspot.MemoryPoolsExports;\n+import io.prometheus.client.hotspot.StandardExports;\n+import io.prometheus.client.hotspot.ThreadExports;\n+import java.io.IOException;\n+import java.io.Writer;\n+import java.lang.reflect.Field;\n+import java.net.InetSocketAddress;\n+import java.util.concurrent.ConcurrentMap;\n+import java.util.concurrent.ConcurrentSkipListMap;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicLong;\n+import org.apache.bookkeeper.stats.CachingStatsProvider;\n+import org.apache.bookkeeper.stats.StatsLogger;\n+import org.apache.bookkeeper.stats.StatsProvider;\n+import org.apache.commons.configuration.Configuration;\n+import org.apache.commons.lang.StringUtils;\n+import org.eclipse.jetty.server.Server;\n+import org.eclipse.jetty.servlet.ServletContextHandler;\n+import org.eclipse.jetty.servlet.ServletHolder;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+//CHECKSTYLE.OFF: IllegalImport\n+//CHECKSTYLE.ON: IllegalImport\n+\n+/**\n+ * A <i>Prometheus</i> based {@link StatsProvider} implementation.\n+ */\n+public class PrometheusMetricsProvider implements StatsProvider {\n+\n+    private ScheduledExecutorService executor;\n+\n+    public static final String PROMETHEUS_STATS_HTTP_ENABLE = \"prometheusStatsHttpEnable\";\n+    public static final boolean DEFAULT_PROMETHEUS_STATS_HTTP_ENABLE = true;\n+\n+    public static final String PROMETHEUS_STATS_HTTP_ADDRESS = \"prometheusStatsHttpAddress\";\n+    public static final String DEFAULT_PROMETHEUS_STATS_HTTP_ADDR = \"0.0.0.0\";\n+\n+    public static final String PROMETHEUS_STATS_HTTP_PORT = \"prometheusStatsHttpPort\";\n+    public static final int DEFAULT_PROMETHEUS_STATS_HTTP_PORT = 8000;\n+\n+    public static final String PROMETHEUS_STATS_LATENCY_ROLLOVER_SECONDS = \"prometheusStatsLatencyRolloverSeconds\";\n+    public static final int DEFAULT_PROMETHEUS_STATS_LATENCY_ROLLOVER_SECONDS = 60;\n+\n+    public static final String PROMETHEUS_BASIC_STATS_ENABLE = \"prometheusBasicStatsEnable\";\n+    public static final boolean DEFAULT_PROMETHEUS_BASIC_STATS_ENABLE = true;\n+\n+    final CollectorRegistry registry;\n+\n+    Server server;\n+    private final CachingStatsProvider cachingStatsProvider;\n+\n+    /*\n+     * These acts a registry of the metrics defined in this provider\n+     */\n+    final ConcurrentMap<String, LongAdderCounter> counters = new ConcurrentSkipListMap<>();\n+    final ConcurrentMap<String, SimpleGauge<? extends Number>> gauges = new ConcurrentSkipListMap<>();\n+    final ConcurrentMap<String, DataSketchesOpStatsLogger> opStats = new ConcurrentSkipListMap<>();\n+\n+    public PrometheusMetricsProvider() {\n+        this(CollectorRegistry.defaultRegistry);\n+    }\n+\n+    public PrometheusMetricsProvider(CollectorRegistry registry) {\n+        this.registry = registry;\n+        this.cachingStatsProvider = new CachingStatsProvider(new StatsProvider() {\n+            @Override\n+            public void start(Configuration conf) {\n+                // nop\n+            }\n+\n+            @Override\n+            public void stop() {\n+                // nop\n+            }\n+\n+            @Override\n+            public StatsLogger getStatsLogger(String scope) {\n+                return new PrometheusStatsLogger(PrometheusMetricsProvider.this, scope);\n+            }\n+\n+            @Override\n+            public String getStatsName(String... statsComponents) {\n+                String completeName;\n+                if (statsComponents.length == 0) {\n+                    return \"\";\n+                } else if (statsComponents[0].isEmpty()) {\n+                    completeName = StringUtils.join(statsComponents, '_', 1, statsComponents.length);\n+                } else {\n+                    completeName = StringUtils.join(statsComponents, '_');\n+                }\n+                return Collector.sanitizeMetricName(completeName);\n+            }\n+        });\n+    }\n+\n+    @Override\n+    public void start(Configuration conf) {\n+        boolean httpEnabled = conf.getBoolean(PROMETHEUS_STATS_HTTP_ENABLE, DEFAULT_PROMETHEUS_STATS_HTTP_ENABLE);\n+        boolean bkHttpServerEnabled = conf.getBoolean(\"httpServerEnabled\", false);\n+        // only start its own http server when prometheus http is enabled and bk http server is not enabled.\n+        if (httpEnabled && !bkHttpServerEnabled) {\n+            String httpAddr = conf.getString(PROMETHEUS_STATS_HTTP_ADDRESS, DEFAULT_PROMETHEUS_STATS_HTTP_ADDR);\n+            int httpPort = conf.getInt(PROMETHEUS_STATS_HTTP_PORT, DEFAULT_PROMETHEUS_STATS_HTTP_PORT);\n+            InetSocketAddress httpEndpoint = InetSocketAddress.createUnresolved(httpAddr, httpPort);\n+            this.server = new Server(httpEndpoint);\n+            ServletContextHandler context = new ServletContextHandler();\n+            context.setContextPath(\"/\");\n+            server.setHandler(context);\n+\n+            context.addServlet(new ServletHolder(new PrometheusServlet(this)), \"/metrics\");\n+\n+            try {\n+                server.start();\n+                log.info(\"Started Prometheus stats endpoint at {}\", httpEndpoint);\n+            } catch (Exception e) {\n+                throw new RuntimeException(e);\n+            }\n+        }\n+\n+        boolean basicStatsEnabled = conf.getBoolean(PROMETHEUS_BASIC_STATS_ENABLE,\n+            DEFAULT_PROMETHEUS_BASIC_STATS_ENABLE);\n+        if (basicStatsEnabled) {\n+            // Include standard JVM stats\n+            registerMetrics(new StandardExports());\n+            registerMetrics(new MemoryPoolsExports());\n+            registerMetrics(new GarbageCollectorExports());\n+            registerMetrics(new ThreadExports());\n+\n+            // Add direct memory allocated through unsafe\n+            registerMetrics(Gauge.build(\"jvm_memory_direct_bytes_used\", \"-\").create().setChild(new Child() {\n+                @Override\n+                public double get() {\n+                    return directMemoryUsage != null ? directMemoryUsage.longValue() : Double.NaN;\n+                }\n+            }));\n+\n+            registerMetrics(Gauge.build(\"jvm_memory_direct_bytes_max\", \"-\").create().setChild(new Child() {\n+                @Override\n+                public double get() {\n+                    return PlatformDependent.maxDirectMemory();\n+                }\n+            }));\n+        }\n+\n+        executor = Executors.newSingleThreadScheduledExecutor(new DefaultThreadFactory(\"metrics\"));\n+\n+        int latencyRolloverSeconds = conf.getInt(PROMETHEUS_STATS_LATENCY_ROLLOVER_SECONDS,\n+                DEFAULT_PROMETHEUS_STATS_LATENCY_ROLLOVER_SECONDS);\n+\n+        executor.scheduleAtFixedRate(() -> {\n+            rotateLatencyCollection();\n+        }, 1, latencyRolloverSeconds, TimeUnit.SECONDS);\n+\n+    }\n+\n+    @Override\n+    public void stop() {\n+        if (server != null) {\n+            try {\n+                server.stop();\n+            } catch (Exception e) {\n+                log.warn(\"Failed to shutdown Jetty server\", e);\n+            }\n+        }\n+    }\n+\n+    @Override\n+    public StatsLogger getStatsLogger(String scope) {\n+        return this.cachingStatsProvider.getStatsLogger(scope);\n+    }\n+\n+    @Override\n+    public void writeAllMetrics(Writer writer) throws IOException {\n+        PrometheusTextFormatUtil.writeMetricsCollectedByPrometheusClient(writer, registry);\n+\n+        gauges.forEach((name, gauge) -> PrometheusTextFormatUtil.writeGauge(writer, name, gauge));\n+        counters.forEach((name, counter) -> PrometheusTextFormatUtil.writeCounter(writer, name, counter));\n+        opStats.forEach((name, opStatLogger) -> PrometheusTextFormatUtil.writeOpStat(writer, name, opStatLogger));\n+    }\n+\n+    @Override\n+    public String getStatsName(String... statsComponents) {\n+        return cachingStatsProvider.getStatsName(statsComponents);\n+    }\n+\n+    @VisibleForTesting\n+    void rotateLatencyCollection() {\n+        opStats.forEach((name, metric) -> {\n+            metric.rotateLatencyCollection();\n+        });\n+    }\n+\n+    private void registerMetrics(Collector collector) {\n+        try {\n+            collector.register(registry);\n+        } catch (Exception e) {\n+            // Ignore if these were already registered\n+            if (log.isDebugEnabled()) {\n+                log.debug(\"Failed to register Prometheus collector exports\", e);\n+            }\n+        }\n+    }\n+\n+\n+    private static final Logger log = LoggerFactory.getLogger(org.apache.bookkeeper.stats.prometheus.PrometheusMetricsProvider.class);\n+\n+    /*\n+     * Try to get Netty counter of used direct memory. This will be correct, unlike the JVM values.\n+     */\n+    private static final AtomicLong directMemoryUsage;\n+    static {\n+        AtomicLong tmpDirectMemoryUsage = null;\n+\n+        try {\n+            Field field = PlatformDependent.class.getDeclaredField(\"DIRECT_MEMORY_COUNTER\");\n+            field.setAccessible(true);\n+            tmpDirectMemoryUsage = (AtomicLong) field.get(null);\n+        } catch (Throwable t) {\n+            log.warn(\"Failed to access netty DIRECT_MEMORY_COUNTER field {}\", t.getMessage());\n+        }\n+\n+        directMemoryUsage = tmpDirectMemoryUsage;\n+    }\n+}"
  },
  {
    "sha": "21624ffe39bb7fd8e4a77b4abf95ce9c497d89ce",
    "filename": "kafka-impl/src/main/java/io/streamnative/pulsar/handlers/kop/stats/PrometheusServlet.java",
    "status": "added",
    "additions": 55,
    "deletions": 0,
    "changes": 55,
    "blob_url": "https://github.com/streamnative/kop/blob/84e0f20463cc04f823c4ef48d002f73313afb26e/kafka-impl/src/main/java/io/streamnative/pulsar/handlers/kop/stats/PrometheusServlet.java",
    "raw_url": "https://github.com/streamnative/kop/raw/84e0f20463cc04f823c4ef48d002f73313afb26e/kafka-impl/src/main/java/io/streamnative/pulsar/handlers/kop/stats/PrometheusServlet.java",
    "contents_url": "https://api.github.com/repos/streamnative/kop/contents/kafka-impl/src/main/java/io/streamnative/pulsar/handlers/kop/stats/PrometheusServlet.java?ref=84e0f20463cc04f823c4ef48d002f73313afb26e",
    "patch": "@@ -0,0 +1,55 @@\n+/**\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.streamnative.pulsar.handlers.kop.stats;\n+\n+import io.prometheus.client.exporter.common.TextFormat;\n+import java.io.IOException;\n+import java.io.Writer;\n+import javax.servlet.ServletException;\n+import javax.servlet.http.HttpServlet;\n+import javax.servlet.http.HttpServletRequest;\n+import javax.servlet.http.HttpServletResponse;\n+\n+/**\n+ * Servlet used to export metrics in prometheus text format.\n+ */\n+public class PrometheusServlet extends HttpServlet {\n+    private static final long serialVersionUID = 1L;\n+\n+    private final transient PrometheusMetricsProvider provider;\n+\n+    public PrometheusServlet(PrometheusMetricsProvider provider) {\n+        this.provider = provider;\n+    }\n+\n+    @Override\n+    protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException {\n+        resp.setStatus(HttpServletResponse.SC_OK);\n+        resp.setContentType(TextFormat.CONTENT_TYPE_004);\n+\n+        Writer writer = resp.getWriter();\n+        try {\n+            provider.writeAllMetrics(writer);\n+            writer.flush();\n+        } finally {\n+            writer.close();\n+        }\n+    }\n+\n+    @Override\n+    protected void doPost(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException {\n+        doGet(req, resp);\n+    }\n+\n+}"
  },
  {
    "sha": "5727fca2fdff58308ce8d461a2c6b5dbfaae2943",
    "filename": "kafka-impl/src/main/java/io/streamnative/pulsar/handlers/kop/stats/PrometheusStatsLogger.java",
    "status": "added",
    "additions": 70,
    "deletions": 0,
    "changes": 70,
    "blob_url": "https://github.com/streamnative/kop/blob/84e0f20463cc04f823c4ef48d002f73313afb26e/kafka-impl/src/main/java/io/streamnative/pulsar/handlers/kop/stats/PrometheusStatsLogger.java",
    "raw_url": "https://github.com/streamnative/kop/raw/84e0f20463cc04f823c4ef48d002f73313afb26e/kafka-impl/src/main/java/io/streamnative/pulsar/handlers/kop/stats/PrometheusStatsLogger.java",
    "contents_url": "https://api.github.com/repos/streamnative/kop/contents/kafka-impl/src/main/java/io/streamnative/pulsar/handlers/kop/stats/PrometheusStatsLogger.java?ref=84e0f20463cc04f823c4ef48d002f73313afb26e",
    "patch": "@@ -0,0 +1,70 @@\n+/**\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.streamnative.pulsar.handlers.kop.stats;\n+\n+import com.google.common.base.Joiner;\n+import io.prometheus.client.Collector;\n+import org.apache.bookkeeper.stats.Counter;\n+import org.apache.bookkeeper.stats.Gauge;\n+import org.apache.bookkeeper.stats.OpStatsLogger;\n+import org.apache.bookkeeper.stats.StatsLogger;\n+\n+/**\n+ * A {@code Prometheus} based {@link StatsLogger} implementation.\n+ */\n+public class PrometheusStatsLogger implements StatsLogger {\n+\n+    private final PrometheusMetricsProvider provider;\n+    private final String scope;\n+\n+    PrometheusStatsLogger(PrometheusMetricsProvider provider, String scope) {\n+        this.provider = provider;\n+        this.scope = scope;\n+    }\n+\n+    @Override\n+    public OpStatsLogger getOpStatsLogger(String name) {\n+        return provider.opStats.computeIfAbsent(completeName(name), x -> new DataSketchesOpStatsLogger());\n+    }\n+\n+    @Override\n+    public Counter getCounter(String name) {\n+        return provider.counters.computeIfAbsent(completeName(name), x -> new LongAdderCounter());\n+    }\n+\n+    @Override\n+    public <T extends Number> void registerGauge(String name, Gauge<T> gauge) {\n+        provider.gauges.computeIfAbsent(completeName(name), x -> new SimpleGauge<T>(gauge));\n+    }\n+\n+    @Override\n+    public <T extends Number> void unregisterGauge(String name, Gauge<T> gauge) {\n+        // no-op\n+    }\n+\n+    @Override\n+    public void removeScope(String name, StatsLogger statsLogger) {\n+        // no-op\n+    }\n+\n+    @Override\n+    public StatsLogger scope(String name) {\n+        return new PrometheusStatsLogger(provider, completeName(name));\n+    }\n+\n+    private String completeName(String name) {\n+        String completeName = scope.isEmpty() ? name : Joiner.on('_').join(scope, name);\n+        return Collector.sanitizeMetricName(completeName);\n+    }\n+}"
  },
  {
    "sha": "e6f3d895645f1caedf61725193859b8a7390b8ac",
    "filename": "kafka-impl/src/main/java/io/streamnative/pulsar/handlers/kop/stats/PrometheusTextFormatUtil.java",
    "status": "added",
    "additions": 145,
    "deletions": 0,
    "changes": 145,
    "blob_url": "https://github.com/streamnative/kop/blob/84e0f20463cc04f823c4ef48d002f73313afb26e/kafka-impl/src/main/java/io/streamnative/pulsar/handlers/kop/stats/PrometheusTextFormatUtil.java",
    "raw_url": "https://github.com/streamnative/kop/raw/84e0f20463cc04f823c4ef48d002f73313afb26e/kafka-impl/src/main/java/io/streamnative/pulsar/handlers/kop/stats/PrometheusTextFormatUtil.java",
    "contents_url": "https://api.github.com/repos/streamnative/kop/contents/kafka-impl/src/main/java/io/streamnative/pulsar/handlers/kop/stats/PrometheusTextFormatUtil.java?ref=84e0f20463cc04f823c4ef48d002f73313afb26e",
    "patch": "@@ -0,0 +1,145 @@\n+/**\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.streamnative.pulsar.handlers.kop.stats;\n+\n+import io.prometheus.client.Collector;\n+import io.prometheus.client.Collector.MetricFamilySamples;\n+import io.prometheus.client.Collector.MetricFamilySamples.Sample;\n+import io.prometheus.client.CollectorRegistry;\n+import java.io.IOException;\n+import java.io.Writer;\n+import java.util.Enumeration;\n+import org.apache.bookkeeper.stats.Counter;\n+\n+/**\n+ * Logic to write metrics in Prometheus text format.\n+ */\n+public class PrometheusTextFormatUtil {\n+    static void writeGauge(Writer w, String name, SimpleGauge<? extends Number> gauge) {\n+        // Example:\n+        // # TYPE bookie_storage_entries_count gauge\n+        // bookie_storage_entries_count 519\n+        try {\n+            w.append(\"# TYPE \").append(name).append(\" gauge\\n\");\n+            w.append(name).append(' ').append(gauge.getSample().toString()).append('\\n');\n+        } catch (IOException e) {\n+            throw new RuntimeException(e);\n+        }\n+    }\n+\n+    static void writeCounter(Writer w, String name, Counter counter) {\n+        // Example:\n+        // # TYPE jvm_threads_started_total counter\n+        // jvm_threads_started_total 59\n+        try {\n+            w.append(\"# TYPE \").append(name).append(\" counter\\n\");\n+            w.append(name).append(' ').append(counter.get().toString()).append('\\n');\n+        } catch (IOException e) {\n+            throw new RuntimeException(e);\n+        }\n+    }\n+\n+    static void writeOpStat(Writer w, String name, DataSketchesOpStatsLogger opStat) {\n+        // Example:\n+        // # TYPE bookie_journal_JOURNAL_ADD_ENTRY summary\n+        // bookie_journal_JOURNAL_ADD_ENTRY{success=\"false\",quantile=\"0.5\",} NaN\n+        // bookie_journal_JOURNAL_ADD_ENTRY{success=\"false\",quantile=\"0.75\",} NaN\n+        // bookie_journal_JOURNAL_ADD_ENTRY{success=\"false\",quantile=\"0.95\",} NaN\n+        // bookie_journal_JOURNAL_ADD_ENTRY{success=\"false\",quantile=\"0.99\",} NaN\n+        // bookie_journal_JOURNAL_ADD_ENTRY{success=\"false\",quantile=\"0.999\",} NaN\n+        // bookie_journal_JOURNAL_ADD_ENTRY{success=\"false\",quantile=\"0.9999\",} NaN\n+        // bookie_journal_JOURNAL_ADD_ENTRY{success=\"false\",quantile=\"1.0\",} NaN\n+        // bookie_journal_JOURNAL_ADD_ENTRY_count{success=\"false\",} 0.0\n+        // bookie_journal_JOURNAL_ADD_ENTRY_sum{success=\"false\",} 0.0\n+        // bookie_journal_JOURNAL_ADD_ENTRY{success=\"true\",quantile=\"0.5\",} 1.706\n+        // bookie_journal_JOURNAL_ADD_ENTRY{success=\"true\",quantile=\"0.75\",} 1.89\n+        // bookie_journal_JOURNAL_ADD_ENTRY{success=\"true\",quantile=\"0.95\",} 2.121\n+        // bookie_journal_JOURNAL_ADD_ENTRY{success=\"true\",quantile=\"0.99\",} 10.708\n+        // bookie_journal_JOURNAL_ADD_ENTRY{success=\"true\",quantile=\"0.999\",} 10.902\n+        // bookie_journal_JOURNAL_ADD_ENTRY{success=\"true\",quantile=\"0.9999\",} 10.902\n+        // bookie_journal_JOURNAL_ADD_ENTRY{success=\"true\",quantile=\"1.0\",} 10.902\n+        // bookie_journal_JOURNAL_ADD_ENTRY_count{success=\"true\",} 658.0\n+        // bookie_journal_JOURNAL_ADD_ENTRY_sum{success=\"true\",} 1265.0800000000002\n+        try {\n+            w.append(\"# TYPE \").append(name).append(\" summary\\n\");\n+            writeQuantile(w, opStat, name, false, 0.5);\n+            writeQuantile(w, opStat, name, false, 0.75);\n+            writeQuantile(w, opStat, name, false, 0.95);\n+            writeQuantile(w, opStat, name, false, 0.99);\n+            writeQuantile(w, opStat, name, false, 0.999);\n+            writeQuantile(w, opStat, name, false, 0.9999);\n+            writeQuantile(w, opStat, name, false, 1.0);\n+            writeCount(w, opStat, name, false);\n+            writeSum(w, opStat, name, false);\n+\n+            writeQuantile(w, opStat, name, true, 0.5);\n+            writeQuantile(w, opStat, name, true, 0.75);\n+            writeQuantile(w, opStat, name, true, 0.95);\n+            writeQuantile(w, opStat, name, true, 0.99);\n+            writeQuantile(w, opStat, name, true, 0.999);\n+            writeQuantile(w, opStat, name, true, 0.9999);\n+            writeQuantile(w, opStat, name, true, 1.0);\n+            writeCount(w, opStat, name, true);\n+            writeSum(w, opStat, name, true);\n+\n+        } catch (IOException e) {\n+            throw new RuntimeException(e);\n+        }\n+    }\n+\n+    private static void writeQuantile(Writer w, DataSketchesOpStatsLogger opStat, String name, Boolean success,\n+                                      double quantile) throws IOException {\n+        w.append(name).append(\"{success=\\\"\").append(success.toString()).append(\"\\\",quantile=\\\"\")\n+                .append(Double.toString(quantile)).append(\"\\\"} \")\n+                .append(Double.toString(opStat.getQuantileValue(success, quantile))).append('\\n');\n+    }\n+\n+    private static void writeCount(Writer w, DataSketchesOpStatsLogger opStat, String name, Boolean success)\n+            throws IOException {\n+        w.append(name).append(\"_count{success=\\\"\").append(success.toString()).append(\"\\\"} \")\n+                .append(Long.toString(opStat.getCount(success))).append('\\n');\n+    }\n+\n+    private static void writeSum(Writer w, DataSketchesOpStatsLogger opStat, String name, Boolean success)\n+            throws IOException {\n+        w.append(name).append(\"_sum{success=\\\"\").append(success.toString()).append(\"\\\"} \")\n+                .append(Double.toString(opStat.getSum(success))).append('\\n');\n+    }\n+\n+    static void writeMetricsCollectedByPrometheusClient(Writer w, CollectorRegistry registry) throws IOException {\n+        Enumeration<MetricFamilySamples> metricFamilySamples = registry.metricFamilySamples();\n+        while (metricFamilySamples.hasMoreElements()) {\n+            MetricFamilySamples metricFamily = metricFamilySamples.nextElement();\n+\n+            for (int i = 0; i < metricFamily.samples.size(); i++) {\n+                Sample sample = metricFamily.samples.get(i);\n+                w.write(sample.name);\n+                w.write('{');\n+                for (int j = 0; j < sample.labelNames.size(); j++) {\n+                    if (j != 0) {\n+                        w.write(\", \");\n+                    }\n+                    w.write(sample.labelNames.get(j));\n+                    w.write(\"=\\\"\");\n+                    w.write(sample.labelValues.get(j));\n+                    w.write('\"');\n+                }\n+\n+                w.write(\"} \");\n+                w.write(Collector.doubleToGoString(sample.value));\n+                w.write('\\n');\n+            }\n+        }\n+    }\n+}"
  },
  {
    "sha": "60b75702b8e9a81a6967aaf88249546c4571c800",
    "filename": "kafka-impl/src/main/java/io/streamnative/pulsar/handlers/kop/stats/SimpleGauge.java",
    "status": "added",
    "additions": 37,
    "deletions": 0,
    "changes": 37,
    "blob_url": "https://github.com/streamnative/kop/blob/84e0f20463cc04f823c4ef48d002f73313afb26e/kafka-impl/src/main/java/io/streamnative/pulsar/handlers/kop/stats/SimpleGauge.java",
    "raw_url": "https://github.com/streamnative/kop/raw/84e0f20463cc04f823c4ef48d002f73313afb26e/kafka-impl/src/main/java/io/streamnative/pulsar/handlers/kop/stats/SimpleGauge.java",
    "contents_url": "https://api.github.com/repos/streamnative/kop/contents/kafka-impl/src/main/java/io/streamnative/pulsar/handlers/kop/stats/SimpleGauge.java?ref=84e0f20463cc04f823c4ef48d002f73313afb26e",
    "patch": "@@ -0,0 +1,37 @@\n+/**\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.streamnative.pulsar.handlers.kop.stats;\n+\n+import org.apache.bookkeeper.stats.Gauge;\n+\n+/**\n+ * A {@link Gauge} implementation that forwards on the value supplier.\n+ */\n+public class SimpleGauge<T extends Number> {\n+\n+    // public SimpleGauge(CollectorRegistry registry, String name) {\n+    // this.gauge = PrometheusUtil.safeRegister(registry,\n+    // Gauge.build().name(Collector.sanitizeMetricName(name)).help(\"-\").create());\n+    // }\n+\n+    private final Gauge<T> gauge;\n+\n+    public SimpleGauge(final Gauge<T> gauge) {\n+        this.gauge = gauge;\n+    }\n+\n+    Number getSample() {\n+        return gauge.getSample();\n+    }\n+}"
  },
  {
    "sha": "054b5198fd6f5fce4e4ed789b49074290060bb36",
    "filename": "tests/src/test/java/io/streamnative/pulsar/handlers/kop/EntryPublishTimeTest.java",
    "status": "modified",
    "additions": 3,
    "deletions": 1,
    "changes": 4,
    "blob_url": "https://github.com/streamnative/kop/blob/84e0f20463cc04f823c4ef48d002f73313afb26e/tests/src/test/java/io/streamnative/pulsar/handlers/kop/EntryPublishTimeTest.java",
    "raw_url": "https://github.com/streamnative/kop/raw/84e0f20463cc04f823c4ef48d002f73313afb26e/tests/src/test/java/io/streamnative/pulsar/handlers/kop/EntryPublishTimeTest.java",
    "contents_url": "https://api.github.com/repos/streamnative/kop/contents/tests/src/test/java/io/streamnative/pulsar/handlers/kop/EntryPublishTimeTest.java?ref=84e0f20463cc04f823c4ef48d002f73313afb26e",
    "patch": "@@ -23,6 +23,7 @@\n import io.streamnative.pulsar.handlers.kop.coordinator.transaction.TransactionCoordinator;\n import java.net.InetSocketAddress;\n import java.net.SocketAddress;\n+import org.apache.bookkeeper.stats.NullStatsLogger;\n import org.apache.pulsar.broker.protocol.ProtocolHandler;\n import org.apache.pulsar.common.policies.data.ClusterData;\n import org.apache.pulsar.common.policies.data.RetentionPolicies;\n@@ -90,7 +91,8 @@ protected void setup() throws Exception {\n                 groupCoordinator,\n                 transactionCoordinator,\n                 false,\n-                getPlainEndPoint());\n+                getPlainEndPoint(),\n+                NullStatsLogger.INSTANCE);\n         ChannelHandlerContext mockCtx = mock(ChannelHandlerContext.class);\n         Channel mockChannel = mock(Channel.class);\n         doReturn(mockChannel).when(mockCtx).channel();"
  },
  {
    "sha": "233d797300f52cfc00faf274cad7d511559f3107",
    "filename": "tests/src/test/java/io/streamnative/pulsar/handlers/kop/KafkaApisTest.java",
    "status": "modified",
    "additions": 3,
    "deletions": 1,
    "changes": 4,
    "blob_url": "https://github.com/streamnative/kop/blob/84e0f20463cc04f823c4ef48d002f73313afb26e/tests/src/test/java/io/streamnative/pulsar/handlers/kop/KafkaApisTest.java",
    "raw_url": "https://github.com/streamnative/kop/raw/84e0f20463cc04f823c4ef48d002f73313afb26e/tests/src/test/java/io/streamnative/pulsar/handlers/kop/KafkaApisTest.java",
    "contents_url": "https://api.github.com/repos/streamnative/kop/contents/tests/src/test/java/io/streamnative/pulsar/handlers/kop/KafkaApisTest.java?ref=84e0f20463cc04f823c4ef48d002f73313afb26e",
    "patch": "@@ -44,6 +44,7 @@\n import java.util.stream.Collectors;\n import lombok.Cleanup;\n import lombok.extern.slf4j.Slf4j;\n+import org.apache.bookkeeper.stats.NullStatsLogger;\n import org.apache.commons.lang3.tuple.Pair;\n import org.apache.kafka.clients.producer.KafkaProducer;\n import org.apache.kafka.clients.producer.ProducerConfig;\n@@ -141,7 +142,8 @@ protected void setup() throws Exception {\n             groupCoordinator,\n             transactionCoordinator,\n             false,\n-            getPlainEndPoint());\n+            getPlainEndPoint(),\n+            NullStatsLogger.INSTANCE);\n         ChannelHandlerContext mockCtx = mock(ChannelHandlerContext.class);\n         Channel mockChannel = mock(Channel.class);\n         doReturn(mockChannel).when(mockCtx).channel();"
  },
  {
    "sha": "4264e591a3b276ab1e96081ce503b69397994ecc",
    "filename": "tests/src/test/java/io/streamnative/pulsar/handlers/kop/KafkaRequestHandlerTest.java",
    "status": "modified",
    "additions": 3,
    "deletions": 1,
    "changes": 4,
    "blob_url": "https://github.com/streamnative/kop/blob/84e0f20463cc04f823c4ef48d002f73313afb26e/tests/src/test/java/io/streamnative/pulsar/handlers/kop/KafkaRequestHandlerTest.java",
    "raw_url": "https://github.com/streamnative/kop/raw/84e0f20463cc04f823c4ef48d002f73313afb26e/tests/src/test/java/io/streamnative/pulsar/handlers/kop/KafkaRequestHandlerTest.java",
    "contents_url": "https://api.github.com/repos/streamnative/kop/contents/tests/src/test/java/io/streamnative/pulsar/handlers/kop/KafkaRequestHandlerTest.java?ref=84e0f20463cc04f823c4ef48d002f73313afb26e",
    "patch": "@@ -50,6 +50,7 @@\n \n import lombok.Cleanup;\n import lombok.extern.slf4j.Slf4j;\n+import org.apache.bookkeeper.stats.NullStatsLogger;\n import org.apache.kafka.clients.admin.AdminClient;\n import org.apache.kafka.clients.admin.AdminClientConfig;\n import org.apache.kafka.clients.admin.NewTopic;\n@@ -146,7 +147,8 @@ protected void setup() throws Exception {\n             groupCoordinator,\n             transactionCoordinator,\n             false,\n-            getPlainEndPoint());\n+            getPlainEndPoint(),\n+            NullStatsLogger.INSTANCE);\n     }\n \n     @AfterMethod"
  },
  {
    "sha": "0eca00c80e5f725055971314f1f8018a32213194",
    "filename": "tests/src/test/java/io/streamnative/pulsar/handlers/kop/KafkaTopicConsumerManagerTest.java",
    "status": "modified",
    "additions": 3,
    "deletions": 1,
    "changes": 4,
    "blob_url": "https://github.com/streamnative/kop/blob/84e0f20463cc04f823c4ef48d002f73313afb26e/tests/src/test/java/io/streamnative/pulsar/handlers/kop/KafkaTopicConsumerManagerTest.java",
    "raw_url": "https://github.com/streamnative/kop/raw/84e0f20463cc04f823c4ef48d002f73313afb26e/tests/src/test/java/io/streamnative/pulsar/handlers/kop/KafkaTopicConsumerManagerTest.java",
    "contents_url": "https://api.github.com/repos/streamnative/kop/contents/tests/src/test/java/io/streamnative/pulsar/handlers/kop/KafkaTopicConsumerManagerTest.java?ref=84e0f20463cc04f823c4ef48d002f73313afb26e",
    "patch": "@@ -31,6 +31,7 @@\n import java.util.concurrent.atomic.AtomicLong;\n import lombok.extern.slf4j.Slf4j;\n import org.apache.bookkeeper.mledger.ManagedCursor;\n+import org.apache.bookkeeper.stats.NullStatsLogger;\n import org.apache.commons.lang3.tuple.Pair;\n import org.apache.kafka.clients.producer.KafkaProducer;\n import org.apache.kafka.clients.producer.ProducerConfig;\n@@ -69,7 +70,8 @@ protected void setup() throws Exception {\n             groupCoordinator,\n             transactionCoordinator,\n             false,\n-            getPlainEndPoint());\n+            getPlainEndPoint(),\n+            NullStatsLogger.INSTANCE);\n \n         ChannelHandlerContext mockCtx = mock(ChannelHandlerContext.class);\n         Channel mockChannel = mock(Channel.class);"
  }
]
