[
  {
    "sha": "90723edb435860d9975937f2e7e7018206aaa546",
    "filename": "pom.xml",
    "status": "modified",
    "additions": 1,
    "deletions": 1,
    "changes": 2,
    "blob_url": "https://github.com/Mu-L/elasticsearch-sql/blob/c3fd4ad699986178351d7fb5a02df0c60ac7ef68/pom.xml",
    "raw_url": "https://github.com/Mu-L/elasticsearch-sql/raw/c3fd4ad699986178351d7fb5a02df0c60ac7ef68/pom.xml",
    "contents_url": "https://api.github.com/repos/Mu-L/elasticsearch-sql/contents/pom.xml?ref=c3fd4ad699986178351d7fb5a02df0c60ac7ef68",
    "patch": "@@ -3,7 +3,7 @@\n \t<modelVersion>4.0.0</modelVersion>\n \t<groupId>org.nlpcn</groupId>\n \t<artifactId>elasticsearch-sql</artifactId>\n-\t<version>7.9.3.3</version>\n+\t<version>7.9.3.4</version>\n \t<packaging>jar</packaging>\n \t<description>Query elasticsearch using SQL</description>\n \t<name>elasticsearch-sql</name>"
  },
  {
    "sha": "b24443a8c61b01e3f57daf2ceae36fb242c08785",
    "filename": "src/main/java/org/elasticsearch/plugin/nlpcn/executors/CSVResultsExtractor.java",
    "status": "modified",
    "additions": 24,
    "deletions": 15,
    "changes": 39,
    "blob_url": "https://github.com/Mu-L/elasticsearch-sql/blob/c3fd4ad699986178351d7fb5a02df0c60ac7ef68/src/main/java/org/elasticsearch/plugin/nlpcn/executors/CSVResultsExtractor.java",
    "raw_url": "https://github.com/Mu-L/elasticsearch-sql/raw/c3fd4ad699986178351d7fb5a02df0c60ac7ef68/src/main/java/org/elasticsearch/plugin/nlpcn/executors/CSVResultsExtractor.java",
    "contents_url": "https://api.github.com/repos/Mu-L/elasticsearch-sql/contents/src/main/java/org/elasticsearch/plugin/nlpcn/executors/CSVResultsExtractor.java?ref=c3fd4ad699986178351d7fb5a02df0c60ac7ef68",
    "patch": "@@ -28,11 +28,14 @@\n \n import java.util.ArrayList;\n import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashSet;\n import java.util.Iterator;\n import java.util.LinkedHashMap;\n import java.util.LinkedHashSet;\n import java.util.List;\n import java.util.Map;\n+import java.util.Optional;\n import java.util.Set;\n import java.util.stream.Collectors;\n \n@@ -72,8 +75,9 @@ public CSVResult extractResults(Object queryResult, boolean flat, String separat\n         if(queryResult instanceof SearchHits){\n             SearchHit[] hits = ((SearchHits) queryResult).getHits();\n             List<Map<String,Object>> docsAsMap = new ArrayList<>();\n-            List<String> headers = createHeadersAndFillDocsMap(flat, hits, null, docsAsMap);\n-            List<String> csvLines = createCSVLinesFromDocs(flat, separator, quote, docsAsMap, headers);\n+            Set<String> hitFieldNames = new HashSet<>();\n+            List<String> headers = createHeadersAndFillDocsMap(flat, hits, null, docsAsMap, hitFieldNames);\n+            List<String> csvLines = createCSVLinesFromDocs(flat, separator, quote, docsAsMap, headers, hitFieldNames);\n             return new CSVResult(headers,csvLines);\n         }\n         if(queryResult instanceof Aggregations){\n@@ -97,8 +101,9 @@ public CSVResult extractResults(Object queryResult, boolean flat, String separat\n         if (queryResult instanceof SearchResponse) {\n             SearchHit[] hits = ((SearchResponse) queryResult).getHits().getHits();\n             List<Map<String, Object>> docsAsMap = new ArrayList<>();\n-            List<String> headers = createHeadersAndFillDocsMap(flat, hits, ((SearchResponse) queryResult).getScrollId(), docsAsMap);\n-            List<String> csvLines = createCSVLinesFromDocs(flat, separator, quote, docsAsMap, headers);\n+            Set<String> hitFieldNames = new HashSet<>();\n+            List<String> headers = createHeadersAndFillDocsMap(flat, hits, ((SearchResponse) queryResult).getScrollId(), docsAsMap, hitFieldNames);\n+            List<String> csvLines = createCSVLinesFromDocs(flat, separator, quote, docsAsMap, headers, hitFieldNames);\n             //return new CSVResult(headers, csvLines);\n             return new CSVResult(headers, csvLines, ((SearchResponse) queryResult).getHits().getTotalHits().value);\n         }\n@@ -344,42 +349,46 @@ private Aggregation getFirstAggregation(Aggregations aggregations){\n         return aggregations.asList().get(0);\n     }\n \n-    private List<String> createCSVLinesFromDocs(boolean flat, String separator, boolean quote, List<Map<String, Object>> docsAsMap, List<String> headers) {\n+    private List<String> createCSVLinesFromDocs(boolean flat, String separator, boolean quote, List<Map<String, Object>> docsAsMap, List<String> headers, Set<String> hitFieldNames) {\n         List<String> csvLines = new ArrayList<>();\n         for(Map<String,Object> doc : docsAsMap){\n             String line = \"\";\n             for(String header : headers){\n-                line += findFieldValue(header, doc, flat, separator, quote);\n+                line += findFieldValue(header, doc, flat, separator, quote, hitFieldNames);\n             }\n             csvLines.add(line.substring(0, line.lastIndexOf(separator)));\n         }\n         return csvLines;\n     }\n \n-    private List<String> createHeadersAndFillDocsMap(boolean flat, SearchHit[] hits, String scrollId, List<Map<String, Object>> docsAsMap) {\n+    private List<String> createHeadersAndFillDocsMap(boolean flat, SearchHit[] hits, String scrollId, List<Map<String, Object>> docsAsMap, Set<String> hitFieldNames) {\n         Set<String> csvHeaders = new LinkedHashSet<>();\n         Map<String, String> highlightMap = Maps.newHashMap();\n         for (SearchHit hit : hits) {\n             //获取高亮内容\n-            hit.getHighlightFields().entrySet().stream().forEach(entry -> {\n-                String key = entry.getKey();\n-                String frag = entry.getValue().getFragments()[0].toString();\n+            hit.getHighlightFields().forEach((key, value) -> {\n+                String frag = value.getFragments()[0].toString();\n                 highlightMap.put(key, frag);\n             });\n \n-            Map<String, Object> doc = hit.getSourceAsMap();\n+            Map<String, Object> doc = Optional.ofNullable(hit.getSourceAsMap()).orElse(Maps.newHashMap());\n             //替换掉将原始结果中字段的值替换为高亮后的内容\n             for (Map.Entry<String, Object> entry : doc.entrySet()) {\n                 if(highlightMap.containsKey(entry.getKey())) {\n                     doc.put(entry.getKey(), highlightMap.get(entry.getKey()));\n                 }\n             }\n \n+            mergeHeaders(csvHeaders, doc, flat);\n+            // hit fields\n             Map<String, DocumentField> fields = hit.getFields();\n             for (DocumentField searchHitField : fields.values()) {\n-                doc.put(searchHitField.getName(), searchHitField.getValue());\n+                List<Object> values = Optional.ofNullable(searchHitField.getValues()).orElse(Collections.emptyList());\n+                int size = values.size();\n+                doc.put(searchHitField.getName(), size == 1 ? values.get(0) : size > 1 ? values : null);\n+                hitFieldNames.add(searchHitField.getName());\n+                csvHeaders.add(searchHitField.getName());\n             }\n-            mergeHeaders(csvHeaders, doc, flat);\n             if (this.includeIndex) {\n                 doc.put(\"_index\", hit.getIndex());\n             }\n@@ -424,8 +433,8 @@ private Aggregation getFirstAggregation(Aggregations aggregations){\n         return headers;\n     }\n \n-    private String findFieldValue(String header, Map<String, Object> doc, boolean flat, String separator, boolean quote) {\n-        if(flat && header.contains(\".\")){\n+    private String findFieldValue(String header, Map<String, Object> doc, boolean flat, String separator, boolean quote, Set<String> hitFieldNames) {\n+        if(flat && header.contains(\".\") && !hitFieldNames.contains(header)) {\n             String[] split = header.split(\"\\\\.\");\n             Object innerDoc = doc;\n             for(String innerField : split){"
  },
  {
    "sha": "f4adc85daf4fd7b4052910b03a7d835c85b88dac",
    "filename": "src/main/java/org/nlpcn/es4sql/jdbc/ObjectResultsExtractor.java",
    "status": "modified",
    "additions": 27,
    "deletions": 14,
    "changes": 41,
    "blob_url": "https://github.com/Mu-L/elasticsearch-sql/blob/c3fd4ad699986178351d7fb5a02df0c60ac7ef68/src/main/java/org/nlpcn/es4sql/jdbc/ObjectResultsExtractor.java",
    "raw_url": "https://github.com/Mu-L/elasticsearch-sql/raw/c3fd4ad699986178351d7fb5a02df0c60ac7ef68/src/main/java/org/nlpcn/es4sql/jdbc/ObjectResultsExtractor.java",
    "contents_url": "https://api.github.com/repos/Mu-L/elasticsearch-sql/contents/src/main/java/org/nlpcn/es4sql/jdbc/ObjectResultsExtractor.java?ref=c3fd4ad699986178351d7fb5a02df0c60ac7ef68",
    "patch": "@@ -1,5 +1,6 @@\n package org.nlpcn.es4sql.jdbc;\n \n+import com.google.common.collect.Maps;\n import org.elasticsearch.action.search.SearchResponse;\n import org.elasticsearch.common.document.DocumentField;\n import org.elasticsearch.search.SearchHit;\n@@ -20,9 +21,12 @@\n \n import java.util.ArrayList;\n import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashSet;\n import java.util.LinkedHashSet;\n import java.util.List;\n import java.util.Map;\n+import java.util.Optional;\n import java.util.Set;\n \n /**\n@@ -49,8 +53,9 @@ public ObjectResult extractResults(Object queryResult, boolean flat) throws Obje\n         if (queryResult instanceof SearchHits) {\n             SearchHit[] hits = ((SearchHits) queryResult).getHits();\n             List<Map<String, Object>> docsAsMap = new ArrayList<>();\n-            List<String> headers = createHeadersAndFillDocsMap(flat, hits, null, docsAsMap);\n-            List<List<Object>> lines = createLinesFromDocs(flat, docsAsMap, headers);\n+            Set<String> hitFieldNames = new HashSet<>();\n+            List<String> headers = createHeadersAndFillDocsMap(flat, hits, null, docsAsMap, hitFieldNames);\n+            List<List<Object>> lines = createLinesFromDocs(flat, docsAsMap, headers, hitFieldNames);\n             return new ObjectResult(headers, lines);\n         }\n         if (queryResult instanceof Aggregations) {\n@@ -73,8 +78,9 @@ public ObjectResult extractResults(Object queryResult, boolean flat) throws Obje\n         if (queryResult instanceof SearchResponse) {\n             SearchHit[] hits = ((SearchResponse) queryResult).getHits().getHits();\n             List<Map<String, Object>> docsAsMap = new ArrayList<>();\n-            List<String> headers = createHeadersAndFillDocsMap(flat, hits, ((SearchResponse) queryResult).getScrollId(), docsAsMap);\n-            List<List<Object>> lines = createLinesFromDocs(flat, docsAsMap, headers);\n+            Set<String> hitFieldNames = new HashSet<>();\n+            List<String> headers = createHeadersAndFillDocsMap(flat, hits, ((SearchResponse) queryResult).getScrollId(), docsAsMap, hitFieldNames);\n+            List<List<Object>> lines = createLinesFromDocs(flat, docsAsMap, headers, hitFieldNames);\n             return new ObjectResult(headers, lines);\n         }\n         return null;\n@@ -250,31 +256,27 @@ private Aggregation getFirstAggregation(Aggregations aggregations) {\n         return aggregations.asList().get(0);\n     }\n \n-    private List<List<Object>> createLinesFromDocs(boolean flat, List<Map<String, Object>> docsAsMap, List<String> headers) {\n+    private List<List<Object>> createLinesFromDocs(boolean flat, List<Map<String, Object>> docsAsMap, List<String> headers, Set<String> hitFieldNames) {\n         List<List<Object>> objectLines = new ArrayList<>();\n         for (Map<String, Object> doc : docsAsMap) {\n             List<Object> lines = new ArrayList<>();\n             for (String header : headers) {\n-                lines.add(findFieldValue(header, doc, flat));\n+                lines.add(findFieldValue(header, doc, flat, hitFieldNames));\n             }\n             objectLines.add(lines);\n         }\n         return objectLines;\n     }\n \n-    private List<String> createHeadersAndFillDocsMap(boolean flat, SearchHit[] hits, String scrollId, List<Map<String, Object>> docsAsMap) {\n+    private List<String> createHeadersAndFillDocsMap(boolean flat, SearchHit[] hits, String scrollId, List<Map<String, Object>> docsAsMap, Set<String> hitFieldNames) {\n         Set<String> headers = new LinkedHashSet<>();\n         List<String> fieldNames = new ArrayList<>();\n         if (this.queryAction instanceof DefaultQueryAction) {\n             fieldNames.addAll(((DefaultQueryAction) this.queryAction).getFieldNames());\n         }\n         boolean hasScrollId = this.includeScrollId || fieldNames.contains(\"_scroll_id\");\n         for (SearchHit hit : hits) {\n-            Map<String, Object> doc = hit.getSourceAsMap();\n-            Map<String, DocumentField> fields = hit.getFields();\n-            for (DocumentField searchHitField : fields.values()) {\n-                doc.put(searchHitField.getName(), searchHitField.getValue());\n-            }\n+            Map<String, Object> doc = Optional.ofNullable(hit.getSourceAsMap()).orElse(Maps.newHashMap());\n             if (this.includeScore) {\n                 doc.put(\"_score\", hit.getScore());\n             }\n@@ -288,6 +290,17 @@ private Aggregation getFirstAggregation(Aggregations aggregations) {\n                 doc.put(\"_scroll_id\", scrollId);\n             }\n             mergeHeaders(headers, doc, flat);\n+\n+            // hit fields\n+            Map<String, DocumentField> fields = hit.getFields();\n+            for (DocumentField searchHitField : fields.values()) {\n+                List<Object> values = Optional.ofNullable(searchHitField.getValues()).orElse(Collections.emptyList());\n+                int size = values.size();\n+                doc.put(searchHitField.getName(), size == 1 ? values.get(0) : size > 1 ? values : null);\n+                hitFieldNames.add(searchHitField.getName());\n+                headers.add(searchHitField.getName());\n+            }\n+\n             docsAsMap.add(doc);\n         }\n         List<String> list = new ArrayList<>(headers);\n@@ -301,8 +314,8 @@ private Aggregation getFirstAggregation(Aggregations aggregations) {\n         return list;\n     }\n \n-    private Object findFieldValue(String header, Map<String, Object> doc, boolean flat) {\n-        if (flat && header.contains(\".\")) {\n+    private Object findFieldValue(String header, Map<String, Object> doc, boolean flat, Set<String> hitFieldNames) {\n+        if (flat && header.contains(\".\") && !hitFieldNames.contains(header)) {\n             String[] split = header.split(\"\\\\.\");\n             Object innerDoc = doc;\n             for (String innerField : split) {"
  },
  {
    "sha": "7ada0bc11a6f8bbf6372c087fc6dd3176b14acb3",
    "filename": "src/test/java/org/nlpcn/es4sql/JDBCTests.java",
    "status": "modified",
    "additions": 6,
    "deletions": 5,
    "changes": 11,
    "blob_url": "https://github.com/Mu-L/elasticsearch-sql/blob/c3fd4ad699986178351d7fb5a02df0c60ac7ef68/src/test/java/org/nlpcn/es4sql/JDBCTests.java",
    "raw_url": "https://github.com/Mu-L/elasticsearch-sql/raw/c3fd4ad699986178351d7fb5a02df0c60ac7ef68/src/test/java/org/nlpcn/es4sql/JDBCTests.java",
    "contents_url": "https://api.github.com/repos/Mu-L/elasticsearch-sql/contents/src/test/java/org/nlpcn/es4sql/JDBCTests.java?ref=c3fd4ad699986178351d7fb5a02df0c60ac7ef68",
    "patch": "@@ -30,27 +30,28 @@ public void testJDBC() throws Exception {\n         properties.put(PROP_CONNECTIONPROPERTIES, \"client.transport.ignore_cluster_name=true\");\n         DruidDataSource dds = (DruidDataSource) ElasticSearchDruidDataSourceFactory.createDataSource(properties);\n         Connection connection = dds.getConnection();\n-        PreparedStatement ps = connection.prepareStatement(\"SELECT /*! USE_SCROLL*/ gender,lastname,age,_scroll_id from  \" + TestsConstants.TEST_INDEX_ACCOUNT + \" where lastname='Heath'\");\n+        PreparedStatement ps = connection.prepareStatement(\"SELECT /*! USE_SCROLL*/ gender,docvalue(gender.keyword),lastname,age,_scroll_id from  \" + TestsConstants.TEST_INDEX_ACCOUNT + \" where lastname='Heath'\");\n         ResultSet resultSet = ps.executeQuery();\n \n         ResultSetMetaData metaData = resultSet.getMetaData();\n         assertThat(metaData.getColumnName(1), equalTo(\"gender\"));\n-        assertThat(metaData.getColumnName(2), equalTo(\"lastname\"));\n-        assertThat(metaData.getColumnName(3), equalTo(\"age\"));\n+        assertThat(metaData.getColumnName(2), equalTo(\"gender.keyword\"));\n+        assertThat(metaData.getColumnName(3), equalTo(\"lastname\"));\n+        assertThat(metaData.getColumnName(4), equalTo(\"age\"));\n \n         List<String> result = new ArrayList<String>();\n         String scrollId = null;\n         while (resultSet.next()) {\n             scrollId = resultSet.getString(\"_scroll_id\");\n-            result.add(resultSet.getString(\"lastname\") + \",\" + resultSet.getInt(\"age\") + \",\" + resultSet.getString(\"gender\"));\n+            result.add(resultSet.getString(\"lastname\") + \",\" + resultSet.getInt(\"age\") + \",\" + resultSet.getString(\"gender\") + \",\" + resultSet.getString(\"gender.keyword\"));\n         }\n \n         ps.close();\n         connection.close();\n         dds.close();\n \n         Assert.assertEquals(1, result.size());\n-        Assert.assertEquals(\"Heath,39,F\", result.get(0));\n+        Assert.assertEquals(\"Heath,39,F,F\", result.get(0));\n         Assert.assertFalse(Matchers.isEmptyOrNullString().matches(scrollId));\n     }\n "
  },
  {
    "sha": "c8ee8c205d16981d904894f053a89aea5926f2d4",
    "filename": "src/test/java/org/nlpcn/es4sql/MainTestSuite.java",
    "status": "modified",
    "additions": 7,
    "deletions": 1,
    "changes": 8,
    "blob_url": "https://github.com/Mu-L/elasticsearch-sql/blob/c3fd4ad699986178351d7fb5a02df0c60ac7ef68/src/test/java/org/nlpcn/es4sql/MainTestSuite.java",
    "raw_url": "https://github.com/Mu-L/elasticsearch-sql/raw/c3fd4ad699986178351d7fb5a02df0c60ac7ef68/src/test/java/org/nlpcn/es4sql/MainTestSuite.java",
    "contents_url": "https://api.github.com/repos/Mu-L/elasticsearch-sql/contents/src/test/java/org/nlpcn/es4sql/MainTestSuite.java?ref=c3fd4ad699986178351d7fb5a02df0c60ac7ef68",
    "patch": "@@ -178,7 +178,13 @@ private static void prepareAccountsIndex() {\n                 \" \\\"properties\\\": {\\n\" +\n                 \"          \\\"gender\\\": {\\n\" +\n                 \"            \\\"type\\\": \\\"text\\\",\\n\" +\n-                \"            \\\"fielddata\\\": true\\n\" +\n+                \"            \\\"fielddata\\\": true,\\n\" +\n+                \"            \\\"fields\\\": {\\n\" +\n+                \"              \\\"keyword\\\": {\\n\" +\n+                \"                \\\"ignore_above\\\": 256,\\n\" +\n+                \"                \\\"type\\\": \\\"keyword\\\"\\n\" +\n+                \"              }\\n\" +\n+                \"            }\" +\n                 \"          },\" +\n                 \"          \\\"address\\\": {\\n\" +\n                 \"            \\\"type\\\": \\\"text\\\",\\n\" +"
  }
]
