[
  {
    "sha": "e8f298be158c70ac042f6da116a2311c9ecbf764",
    "filename": "plugin/trino-base-jdbc/src/main/java/io/trino/plugin/jdbc/RemoteTableNameCacheKey.java",
    "status": "modified",
    "additions": 2,
    "deletions": 2,
    "changes": 4,
    "blob_url": "https://github.com/trinodb/trino/blob/d2ec83e5b9aca38908480c319bf2b164c2c863a1/plugin/trino-base-jdbc/src/main/java/io/trino/plugin/jdbc/RemoteTableNameCacheKey.java",
    "raw_url": "https://github.com/trinodb/trino/raw/d2ec83e5b9aca38908480c319bf2b164c2c863a1/plugin/trino-base-jdbc/src/main/java/io/trino/plugin/jdbc/RemoteTableNameCacheKey.java",
    "contents_url": "https://api.github.com/repos/trinodb/trino/contents/plugin/trino-base-jdbc/src/main/java/io/trino/plugin/jdbc/RemoteTableNameCacheKey.java?ref=d2ec83e5b9aca38908480c319bf2b164c2c863a1",
    "patch": "@@ -18,12 +18,12 @@\n import static com.google.common.base.MoreObjects.toStringHelper;\n import static java.util.Objects.requireNonNull;\n \n-final class RemoteTableNameCacheKey\n+public final class RemoteTableNameCacheKey\n {\n     private final JdbcIdentity identity;\n     private final String schema;\n \n-    RemoteTableNameCacheKey(JdbcIdentity identity, String schema)\n+    public RemoteTableNameCacheKey(JdbcIdentity identity, String schema)\n     {\n         this.identity = requireNonNull(identity, \"identity is null\");\n         this.schema = requireNonNull(schema, \"schema is null\");"
  },
  {
    "sha": "b32585f26cd9f2f024fdf5dce9a561e36b2cdfb2",
    "filename": "plugin/trino-druid/src/main/java/io/trino/plugin/druid/DruidJdbcClient.java",
    "status": "modified",
    "additions": 75,
    "deletions": 5,
    "changes": 80,
    "blob_url": "https://github.com/trinodb/trino/blob/d2ec83e5b9aca38908480c319bf2b164c2c863a1/plugin/trino-druid/src/main/java/io/trino/plugin/druid/DruidJdbcClient.java",
    "raw_url": "https://github.com/trinodb/trino/raw/d2ec83e5b9aca38908480c319bf2b164c2c863a1/plugin/trino-druid/src/main/java/io/trino/plugin/druid/DruidJdbcClient.java",
    "contents_url": "https://api.github.com/repos/trinodb/trino/contents/plugin/trino-druid/src/main/java/io/trino/plugin/druid/DruidJdbcClient.java?ref=d2ec83e5b9aca38908480c319bf2b164c2c863a1",
    "patch": "@@ -13,19 +13,22 @@\n  */\n package io.trino.plugin.druid;\n \n+import com.google.common.base.CharMatcher;\n import com.google.common.collect.ImmutableList;\n import io.trino.plugin.jdbc.BaseJdbcClient;\n import io.trino.plugin.jdbc.BaseJdbcConfig;\n import io.trino.plugin.jdbc.ColumnMapping;\n import io.trino.plugin.jdbc.ConnectionFactory;\n import io.trino.plugin.jdbc.JdbcColumnHandle;\n+import io.trino.plugin.jdbc.JdbcIdentity;\n import io.trino.plugin.jdbc.JdbcNamedRelationHandle;\n import io.trino.plugin.jdbc.JdbcOutputTableHandle;\n import io.trino.plugin.jdbc.JdbcSplit;\n import io.trino.plugin.jdbc.JdbcTableHandle;\n import io.trino.plugin.jdbc.JdbcTypeHandle;\n import io.trino.plugin.jdbc.PreparedQuery;\n import io.trino.plugin.jdbc.RemoteTableName;\n+import io.trino.plugin.jdbc.RemoteTableNameCacheKey;\n import io.trino.plugin.jdbc.WriteFunction;\n import io.trino.plugin.jdbc.WriteMapping;\n import io.trino.spi.TrinoException;\n@@ -51,12 +54,15 @@\n import java.util.function.BiFunction;\n import java.util.stream.Collectors;\n \n+import static com.google.common.base.MoreObjects.firstNonNull;\n import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Verify.verify;\n import static com.google.common.collect.Iterables.getOnlyElement;\n import static io.trino.plugin.jdbc.JdbcErrorCode.JDBC_ERROR;\n import static io.trino.plugin.jdbc.StandardColumnMappings.defaultVarcharColumnMapping;\n import static io.trino.plugin.jdbc.StandardColumnMappings.varcharColumnMapping;\n import static io.trino.spi.type.VarcharType.createUnboundedVarcharType;\n+import static java.util.Objects.requireNonNull;\n \n public class DruidJdbcClient\n         extends BaseJdbcClient\n@@ -85,9 +91,10 @@ public DruidJdbcClient(BaseJdbcConfig config, ConnectionFactory connectionFactor\n     public Optional<JdbcTableHandle> getTableHandle(ConnectorSession session, SchemaTableName schemaTableName)\n     {\n         try (Connection connection = connectionFactory.openConnection(session)) {\n-            String jdbcSchemaName = schemaTableName.getSchemaName();\n-            String jdbcTableName = schemaTableName.getTableName();\n-            try (ResultSet resultSet = getTables(connection, Optional.of(jdbcSchemaName), Optional.of(jdbcTableName))) {\n+            JdbcIdentity identity = JdbcIdentity.from(session);\n+            String remoteSchema = toRemoteSchemaName(identity, connection, schemaTableName.getSchemaName());\n+            String remoteTable = toRemoteTableName(identity, connection, remoteSchema, schemaTableName.getTableName());\n+            try (ResultSet resultSet = getTables(connection, Optional.of(remoteSchema), Optional.of(remoteTable))) {\n                 List<JdbcTableHandle> tableHandles = new ArrayList<>();\n                 while (resultSet.next()) {\n                     tableHandles.add(new JdbcTableHandle(\n@@ -99,14 +106,15 @@ public DruidJdbcClient(BaseJdbcConfig config, ConnectionFactory connectionFactor\n                 if (tableHandles.isEmpty()) {\n                     return Optional.empty();\n                 }\n+\n                 return Optional.of(\n                         getOnlyElement(\n                                 tableHandles\n                                         .stream()\n                                         .filter(\n                                                 jdbcTableHandle ->\n-                                                        Objects.equals(jdbcTableHandle.getSchemaName(), schemaTableName.getSchemaName())\n-                                                                && Objects.equals(jdbcTableHandle.getTableName(), schemaTableName.getTableName()))\n+                                                        Objects.equals(jdbcTableHandle.getSchemaName(), remoteSchema)\n+                                                                && Objects.equals(jdbcTableHandle.getTableName(), remoteTable))\n                                         .collect(Collectors.toList())));\n             }\n         }\n@@ -136,6 +144,68 @@ protected ResultSet getTables(Connection connection, Optional<String> schemaName\n                 null);\n     }\n \n+    @Override\n+    protected String toRemoteSchemaName(JdbcIdentity identity, Connection connection, String schemaName)\n+    {\n+        requireNonNull(schemaName, \"schemaName is null\");\n+        verify(CharMatcher.forPredicate(Character::isUpperCase).matchesNoneOf(schemaName), \"Expected schema name from internal metadata to be lowercase: %s\", schemaName);\n+\n+        if (caseInsensitiveNameMatching) {\n+            try {\n+                Map<String, String> mapping = remoteSchemaNames.getIfPresent(identity);\n+                if (mapping != null && !mapping.containsKey(schemaName)) {\n+                    // This might be a schema that has just been created. Force reload.\n+                    mapping = null;\n+                }\n+                if (mapping == null) {\n+                    mapping = listSchemasByLowerCase(connection);\n+                    remoteSchemaNames.put(identity, mapping);\n+                }\n+                String remoteSchema = mapping.get(schemaName);\n+                if (remoteSchema != null) {\n+                    return remoteSchema;\n+                }\n+            }\n+            catch (RuntimeException e) {\n+                throw new TrinoException(JDBC_ERROR, \"Failed to find remote schema name: \" + firstNonNull(e.getMessage(), e), e);\n+            }\n+        }\n+\n+        return schemaName;\n+    }\n+\n+    @Override\n+    protected String toRemoteTableName(JdbcIdentity identity, Connection connection, String remoteSchema, String tableName)\n+    {\n+        requireNonNull(remoteSchema, \"remoteSchema is null\");\n+        requireNonNull(tableName, \"tableName is null\");\n+        verify(CharMatcher.forPredicate(Character::isUpperCase).matchesNoneOf(tableName), \"Expected table name from internal metadata to be lowercase: %s\", tableName);\n+\n+        if (caseInsensitiveNameMatching) {\n+            try {\n+                RemoteTableNameCacheKey cacheKey = new RemoteTableNameCacheKey(identity, remoteSchema);\n+                Map<String, String> mapping = remoteTableNames.getIfPresent(cacheKey);\n+                if (mapping != null && !mapping.containsKey(tableName)) {\n+                    // This might be a table that has just been created. Force reload.\n+                    mapping = null;\n+                }\n+                if (mapping == null) {\n+                    mapping = listTablesByLowerCase(connection, remoteSchema);\n+                    remoteTableNames.put(cacheKey, mapping);\n+                }\n+                String remoteTable = mapping.get(tableName);\n+                if (remoteTable != null) {\n+                    return remoteTable;\n+                }\n+            }\n+            catch (RuntimeException e) {\n+                throw new TrinoException(JDBC_ERROR, \"Failed to find remote table name: \" + firstNonNull(e.getMessage(), e), e);\n+            }\n+        }\n+\n+        return tableName;\n+    }\n+\n     @Override\n     public Optional<ColumnMapping> toColumnMapping(ConnectorSession session, Connection connection, JdbcTypeHandle typeHandle)\n     {"
  },
  {
    "sha": "58ce4722d996e891a189b5f0fbaa810774d92bda",
    "filename": "plugin/trino-druid/src/test/java/io/trino/plugin/druid/DruidQueryRunner.java",
    "status": "modified",
    "additions": 15,
    "deletions": 3,
    "changes": 18,
    "blob_url": "https://github.com/trinodb/trino/blob/d2ec83e5b9aca38908480c319bf2b164c2c863a1/plugin/trino-druid/src/test/java/io/trino/plugin/druid/DruidQueryRunner.java",
    "raw_url": "https://github.com/trinodb/trino/raw/d2ec83e5b9aca38908480c319bf2b164c2c863a1/plugin/trino-druid/src/test/java/io/trino/plugin/druid/DruidQueryRunner.java",
    "contents_url": "https://api.github.com/repos/trinodb/trino/contents/plugin/trino-druid/src/test/java/io/trino/plugin/druid/DruidQueryRunner.java?ref=d2ec83e5b9aca38908480c319bf2b164c2c863a1",
    "patch": "@@ -39,7 +39,10 @@\n {\n     private DruidQueryRunner() {}\n \n-    public static DistributedQueryRunner createDruidQueryRunnerTpch(TestingDruidServer testingDruidServer, Map<String, String> extraProperties)\n+    public static DistributedQueryRunner createDruidQueryRunnerTpch(\n+            TestingDruidServer testingDruidServer,\n+            Map<String, String> extraProperties,\n+            Map<String, String> connectorProperties)\n             throws Exception\n     {\n         DistributedQueryRunner queryRunner = null;\n@@ -50,7 +53,7 @@ public static DistributedQueryRunner createDruidQueryRunnerTpch(TestingDruidServ\n             queryRunner.installPlugin(new TpchPlugin());\n             queryRunner.createCatalog(\"tpch\", \"tpch\");\n \n-            Map<String, String> connectorProperties = new HashMap<>();\n+            connectorProperties = new HashMap<>(ImmutableMap.copyOf(connectorProperties));\n             connectorProperties.putIfAbsent(\"connection-url\", testingDruidServer.getJdbcUrl());\n             queryRunner.installPlugin(new DruidJdbcPlugin());\n             queryRunner.createCatalog(\"druid\", \"druid\", connectorProperties);\n@@ -62,6 +65,15 @@ public static DistributedQueryRunner createDruidQueryRunnerTpch(TestingDruidServ\n         }\n     }\n \n+    public static void copyAndIngestTpchData(MaterializedResult rows, TestingDruidServer testingDruidServer,\n+            String sourceDatasource, String targetDatasource)\n+            throws IOException, InterruptedException\n+    {\n+        String tsvFileLocation = format(\"%s/%s.tsv\", testingDruidServer.getHostWorkingDirectory(), targetDatasource);\n+        writeDataAsTsv(rows, tsvFileLocation);\n+        testingDruidServer.ingestData(targetDatasource, getIngestionSpecFileName(sourceDatasource), tsvFileLocation);\n+    }\n+\n     public static void copyAndIngestTpchData(MaterializedResult rows, TestingDruidServer testingDruidServer, String druidDatasource)\n             throws IOException, InterruptedException\n     {\n@@ -109,7 +121,7 @@ public static void main(String[] args)\n \n         DistributedQueryRunner queryRunner = createDruidQueryRunnerTpch(\n                 new TestingDruidServer(),\n-                ImmutableMap.of(\"http-server.http.port\", \"8080\"));\n+                ImmutableMap.of(\"http-server.http.port\", \"8080\"), ImmutableMap.of());\n \n         Logger log = Logger.get(DruidQueryRunner.class);\n         log.info(\"======== SERVER STARTED ========\");"
  },
  {
    "sha": "15cb43c3e15db065b96ee4cdd332a09176ec0ef3",
    "filename": "plugin/trino-druid/src/test/java/io/trino/plugin/druid/TestDruidCaseInsensitiveMatch.java",
    "status": "added",
    "additions": 90,
    "deletions": 0,
    "changes": 90,
    "blob_url": "https://github.com/trinodb/trino/blob/d2ec83e5b9aca38908480c319bf2b164c2c863a1/plugin/trino-druid/src/test/java/io/trino/plugin/druid/TestDruidCaseInsensitiveMatch.java",
    "raw_url": "https://github.com/trinodb/trino/raw/d2ec83e5b9aca38908480c319bf2b164c2c863a1/plugin/trino-druid/src/test/java/io/trino/plugin/druid/TestDruidCaseInsensitiveMatch.java",
    "contents_url": "https://api.github.com/repos/trinodb/trino/contents/plugin/trino-druid/src/test/java/io/trino/plugin/druid/TestDruidCaseInsensitiveMatch.java?ref=d2ec83e5b9aca38908480c319bf2b164c2c863a1",
    "patch": "@@ -0,0 +1,90 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.trino.plugin.druid;\n+\n+import com.google.common.collect.ImmutableMap;\n+import io.trino.testing.AbstractTestQueryFramework;\n+import io.trino.testing.DistributedQueryRunner;\n+import io.trino.testing.MaterializedResult;\n+import io.trino.testing.QueryRunner;\n+import io.trino.testing.assertions.Assert;\n+import org.testng.annotations.Test;\n+\n+import java.io.IOException;\n+\n+import static io.trino.plugin.druid.BaseDruidIntegrationSmokeTest.SELECT_FROM_ORDERS;\n+import static io.trino.plugin.druid.BaseDruidIntegrationSmokeTest.SELECT_FROM_REGION;\n+import static io.trino.plugin.druid.DruidQueryRunner.copyAndIngestTpchData;\n+import static io.trino.spi.type.VarcharType.VARCHAR;\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+@Test(singleThreaded = true)\n+public class TestDruidCaseInsensitiveMatch\n+        extends AbstractTestQueryFramework\n+{\n+    private TestingDruidServer druidServer;\n+\n+    @Override\n+    protected QueryRunner createQueryRunner()\n+            throws Exception\n+    {\n+        druidServer = new TestingDruidServer();\n+        closeAfterClass(() -> {\n+            druidServer.close();\n+            druidServer = null;\n+        });\n+        DistributedQueryRunner queryRunner = DruidQueryRunner.createDruidQueryRunnerTpch(\n+                druidServer, ImmutableMap.of(), ImmutableMap.of(\"case-insensitive-name-matching\", \"true\"));\n+        copyAndIngestTpchData(queryRunner.execute(SELECT_FROM_ORDERS + \" LIMIT 10\"), this.druidServer, \"orders\", \"CamelCase\");\n+        return queryRunner;\n+    }\n+\n+    @Test\n+    public void testNonLowerCaseTableName()\n+    {\n+        MaterializedResult expectedColumns = MaterializedResult.resultBuilder(getQueryRunner().getDefaultSession(), VARCHAR, VARCHAR, VARCHAR, VARCHAR)\n+                .row(\"__time\", \"timestamp(3)\", \"\", \"\")\n+                .row(\"clerk\", \"varchar\", \"\", \"\") // String columns are reported only as varchar\n+                .row(\"comment\", \"varchar\", \"\", \"\")\n+                .row(\"custkey\", \"bigint\", \"\", \"\") // Long columns are reported as bigint\n+                .row(\"orderdate\", \"varchar\", \"\", \"\")\n+                .row(\"orderkey\", \"bigint\", \"\", \"\")\n+                .row(\"orderpriority\", \"varchar\", \"\", \"\")\n+                .row(\"orderstatus\", \"varchar\", \"\", \"\")\n+                .row(\"shippriority\", \"bigint\", \"\", \"\") // Druid doesn't support int type\n+                .row(\"totalprice\", \"double\", \"\", \"\")\n+                .build();\n+        MaterializedResult actualColumns = computeActual(\"DESCRIBE \" + \"CamelCase\");\n+        Assert.assertEquals(actualColumns, expectedColumns);\n+        MaterializedResult materializedRows = computeActual(\"SELECT * FROM druid.druid.CAMELCASE\");\n+        Assert.assertEquals(materializedRows.getRowCount(), 10);\n+        MaterializedResult materializedRows1 = computeActual(\"SELECT * FROM druid.CamelCase\");\n+        MaterializedResult materializedRows2 = computeActual(\"SELECT * FROM druid.camelcase\");\n+        assertThat(materializedRows.equals(materializedRows1));\n+        assertThat(materializedRows.equals(materializedRows2));\n+    }\n+\n+    @Test\n+    public void testTableNameClash()\n+            throws IOException, InterruptedException\n+    {\n+        try {\n+            //ingesting data with already existing table name in lowercase which should fail\n+            copyAndIngestTpchData(getQueryRunner().execute(SELECT_FROM_REGION + \" LIMIT 10\"), this.druidServer, \"region\", \"camelcase\");\n+        }\n+        catch (AssertionError e) {\n+            Assert.assertEquals(e.getMessage(), \"Datasource camelcase not loaded expected [true] but found [false]\");\n+        }\n+    }\n+}"
  },
  {
    "sha": "5986ca70e4e2cadf06aeaa870d5cfadbdbf1c338",
    "filename": "plugin/trino-druid/src/test/java/io/trino/plugin/druid/TestDruidIntegrationSmokeTest.java",
    "status": "modified",
    "additions": 1,
    "deletions": 1,
    "changes": 2,
    "blob_url": "https://github.com/trinodb/trino/blob/d2ec83e5b9aca38908480c319bf2b164c2c863a1/plugin/trino-druid/src/test/java/io/trino/plugin/druid/TestDruidIntegrationSmokeTest.java",
    "raw_url": "https://github.com/trinodb/trino/raw/d2ec83e5b9aca38908480c319bf2b164c2c863a1/plugin/trino-druid/src/test/java/io/trino/plugin/druid/TestDruidIntegrationSmokeTest.java",
    "contents_url": "https://api.github.com/repos/trinodb/trino/contents/plugin/trino-druid/src/test/java/io/trino/plugin/druid/TestDruidIntegrationSmokeTest.java?ref=d2ec83e5b9aca38908480c319bf2b164c2c863a1",
    "patch": "@@ -32,7 +32,7 @@ protected QueryRunner createQueryRunner()\n             throws Exception\n     {\n         this.druidServer = new TestingDruidServer();\n-        QueryRunner runner = DruidQueryRunner.createDruidQueryRunnerTpch(druidServer, ImmutableMap.of());\n+        QueryRunner runner = DruidQueryRunner.createDruidQueryRunnerTpch(druidServer, ImmutableMap.of(), ImmutableMap.of());\n         copyAndIngestTpchData(runner.execute(SELECT_FROM_ORDERS), this.druidServer, ORDERS.getTableName());\n         copyAndIngestTpchData(runner.execute(SELECT_FROM_LINEITEM), this.druidServer, LINE_ITEM.getTableName());\n         copyAndIngestTpchData(runner.execute(SELECT_FROM_NATION), this.druidServer, NATION.getTableName());"
  },
  {
    "sha": "a721c02e352a32d81f26aeb9cbd9975e816c25c0",
    "filename": "plugin/trino-druid/src/test/java/io/trino/plugin/druid/TestDruidIntegrationSmokeTestLatest.java",
    "status": "modified",
    "additions": 1,
    "deletions": 1,
    "changes": 2,
    "blob_url": "https://github.com/trinodb/trino/blob/d2ec83e5b9aca38908480c319bf2b164c2c863a1/plugin/trino-druid/src/test/java/io/trino/plugin/druid/TestDruidIntegrationSmokeTestLatest.java",
    "raw_url": "https://github.com/trinodb/trino/raw/d2ec83e5b9aca38908480c319bf2b164c2c863a1/plugin/trino-druid/src/test/java/io/trino/plugin/druid/TestDruidIntegrationSmokeTestLatest.java",
    "contents_url": "https://api.github.com/repos/trinodb/trino/contents/plugin/trino-druid/src/test/java/io/trino/plugin/druid/TestDruidIntegrationSmokeTestLatest.java?ref=d2ec83e5b9aca38908480c319bf2b164c2c863a1",
    "patch": "@@ -34,7 +34,7 @@ protected QueryRunner createQueryRunner()\n             throws Exception\n     {\n         this.druidServer = new TestingDruidServer(LATEST_DRUID_DOCKER_IMAGE);\n-        QueryRunner runner = DruidQueryRunner.createDruidQueryRunnerTpch(druidServer, ImmutableMap.of());\n+        QueryRunner runner = DruidQueryRunner.createDruidQueryRunnerTpch(druidServer, ImmutableMap.of(), ImmutableMap.of());\n         copyAndIngestTpchData(runner.execute(SELECT_FROM_ORDERS), this.druidServer, ORDERS.getTableName());\n         copyAndIngestTpchData(runner.execute(SELECT_FROM_LINEITEM), this.druidServer, LINE_ITEM.getTableName());\n         copyAndIngestTpchData(runner.execute(SELECT_FROM_NATION), this.druidServer, NATION.getTableName());"
  },
  {
    "sha": "7e6431f8c452b612219bc8f3c6189b6b0794de4f",
    "filename": "plugin/trino-druid/src/test/java/io/trino/plugin/druid/TestingDruidServer.java",
    "status": "modified",
    "additions": 8,
    "deletions": 1,
    "changes": 9,
    "blob_url": "https://github.com/trinodb/trino/blob/d2ec83e5b9aca38908480c319bf2b164c2c863a1/plugin/trino-druid/src/test/java/io/trino/plugin/druid/TestingDruidServer.java",
    "raw_url": "https://github.com/trinodb/trino/raw/d2ec83e5b9aca38908480c319bf2b164c2c863a1/plugin/trino-druid/src/test/java/io/trino/plugin/druid/TestingDruidServer.java",
    "contents_url": "https://api.github.com/repos/trinodb/trino/contents/plugin/trino-druid/src/test/java/io/trino/plugin/druid/TestingDruidServer.java?ref=d2ec83e5b9aca38908480c319bf2b164c2c863a1",
    "patch": "@@ -223,7 +223,7 @@ void ingestData(String datasource, String indexTaskFile, String dataFilePath)\n         middleManager.withCopyFileToContainer(forHostPath(dataFilePath),\n                 getMiddleManagerContainerPathForDataFile(dataFilePath));\n         String indexTask = Resources.toString(getResource(indexTaskFile), Charset.defaultCharset());\n-\n+        indexTask = getReplacedIndexTask(datasource, indexTask);\n         Request.Builder requestBuilder = new Request.Builder();\n         requestBuilder.addHeader(\"content-type\", \"application/json;charset=utf-8\")\n                 .url(\"http://localhost:\" + getCoordinatorOverlordPort() + \"/druid/indexer/v1/task\")\n@@ -234,6 +234,13 @@ void ingestData(String datasource, String indexTaskFile, String dataFilePath)\n         }\n     }\n \n+    private String getReplacedIndexTask(String targetDataSource, String indexTask)\n+    {\n+        indexTask = indexTask.replaceAll(\"dataSource\\\":.*,\", \"dataSource\\\": \\\"\" + targetDataSource + \"\\\",\");\n+        indexTask = indexTask.replaceAll(\"filter\\\":.*\", \"filter\\\": \\\"\" + targetDataSource + \".tsv\\\"\");\n+        return indexTask;\n+    }\n+\n     private boolean checkDatasourceAvailable(String datasource)\n             throws IOException, InterruptedException\n     {"
  }
]
