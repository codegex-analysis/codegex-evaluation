[
  {
    "sha": "7e5868b6f1069cc4565f3118c5956d92cbe6b5fc",
    "filename": "libs/shared/build.gradle",
    "status": "modified",
    "additions": 1,
    "deletions": 0,
    "changes": 1,
    "blob_url": "https://github.com/crate/crate/blob/a45d4e4a7f5ebadd5f2f7a66fef58ddae8735aeb/libs/shared/build.gradle",
    "raw_url": "https://github.com/crate/crate/raw/a45d4e4a7f5ebadd5f2f7a66fef58ddae8735aeb/libs/shared/build.gradle",
    "contents_url": "https://api.github.com/repos/crate/crate/contents/libs/shared/build.gradle?ref=a45d4e4a7f5ebadd5f2f7a66fef58ddae8735aeb",
    "patch": "@@ -3,6 +3,7 @@ archivesBaseName = 'crate-shared'\n \n dependencies {\n     implementation \"com.google.code.findbugs:jsr305:${versions.jsr305}\"\n+    implementation \"org.apache.logging.log4j:log4j-api:${versions.log4j2}\"\n     testImplementation \"org.hamcrest:hamcrest:${versions.hamcrest}\"\n     testImplementation(\"org.junit.jupiter:junit-jupiter:${versions.junit5}\")\n     testImplementation(\"junit:junit:${versions.junit}\")"
  },
  {
    "sha": "de3c77b40af771602ddfeecc0cc045ab8c69c0ea",
    "filename": "libs/shared/src/main/java/io/crate/concurrent/limits/ConcurrencyLimit.java",
    "status": "added",
    "additions": 318,
    "deletions": 0,
    "changes": 318,
    "blob_url": "https://github.com/crate/crate/blob/a45d4e4a7f5ebadd5f2f7a66fef58ddae8735aeb/libs/shared/src/main/java/io/crate/concurrent/limits/ConcurrencyLimit.java",
    "raw_url": "https://github.com/crate/crate/raw/a45d4e4a7f5ebadd5f2f7a66fef58ddae8735aeb/libs/shared/src/main/java/io/crate/concurrent/limits/ConcurrencyLimit.java",
    "contents_url": "https://api.github.com/repos/crate/crate/contents/libs/shared/src/main/java/io/crate/concurrent/limits/ConcurrencyLimit.java?ref=a45d4e4a7f5ebadd5f2f7a66fef58ddae8735aeb",
    "patch": "@@ -0,0 +1,318 @@\n+/**\n+ * Copyright 2018 Netflix, Inc.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package io.crate.concurrent.limits;\n+\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Function;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+\n+\n+/**\n+ * This class is based on the `Gradient2Limit` from netflix/concurrency-limits\n+ *\n+ *\n+ * Concurrency limit algorithm that adjusts the limit based on the gradient of change of the current average RTT and\n+ * a long term exponentially smoothed average RTT.  Unlike traditional congestion control algorithms we use average\n+ * instead of minimum since RPC methods can be very bursty due to various factors such as non-homogenous request\n+ * processing complexity as well as a wide distribution of data size.  We have also found that using minimum can result\n+ * in an bias towards an impractically low base RTT resulting in excessive load shedding.  An exponential decay is\n+ * applied to the base RTT so that the value is kept stable yet is allowed to adapt to long term changes in latency\n+ * characteristics.\n+ *\n+ * The core algorithm re-calculates the limit every sampling window (ex. 1 second) using the formula\n+ *\n+ *      // Calculate the gradient limiting to the range [0.5, 1.0] to filter outliers\n+ *      gradient = max(0.5, min(1.0, longtermRtt / currentRtt));\n+ *\n+ *      // Calculate the new limit by applying the gradient and allowing for some queuing\n+ *      newLimit = gradient * currentLimit + queueSize;\n+ *\n+ *      // Update the limit using a smoothing factor (default 0.2)\n+ *      newLimit = currentLimit * (1-smoothing) + newLimit * smoothing\n+ *\n+ * The limit can be in one of three main states\n+ *\n+ * 1.  Steady state\n+ *\n+ * In this state the average RTT is very stable and the current measurement whipsaws around this value, sometimes reducing\n+ * the limit, sometimes increasing it.\n+ *\n+ * 2.  Transition from steady state to load\n+ *\n+ * In this state either the RPS to latency has spiked. The gradient is {@literal <} 1.0 due to a growing request queue that\n+ * cannot be handled by the system. Excessive requests and rejected due to the low limit. The baseline RTT grows using\n+ * exponential decay but lags the current measurement, which keeps the gradient {@literal <} 1.0 and limit low.\n+ *\n+ * 3.  Transition from load to steady state\n+ *\n+ * In this state the system goes back to steady state after a prolonged period of excessive load.  Requests aren't rejected\n+ * and the sample RTT remains low. During this state the long term RTT may take some time to go back to normal and could\n+ * potentially be several multiples higher than the current RTT.\n+ */\n+public final class ConcurrencyLimit {\n+\n+    private static final Logger LOG = LogManager.getLogger(ConcurrencyLimit.class);\n+\n+    public static class Builder {\n+        private int initialLimit = 20;\n+        private int minLimit = 20;\n+        private int maxConcurrency = 200;\n+\n+        private double smoothing = 0.2;\n+        private Function<Integer, Integer> queueSize = concurrency -> 4;\n+        private int longWindow = 600;\n+        private double rttTolerance = 1.5;\n+\n+        /**\n+         * Initial limit used by the limiter\n+         * @param initialLimit\n+         * @return Chainable builder\n+         */\n+        public Builder initialLimit(int initialLimit) {\n+            this.initialLimit = initialLimit;\n+            return this;\n+        }\n+\n+        /**\n+         * Minimum concurrency limit allowed.  The minimum helps prevent the algorithm from adjust the limit\n+         * too far down.  Note that this limit is not desirable when use as backpressure for batch apps.\n+         *\n+         * @param minLimit\n+         * @return Chainable builder\n+         */\n+        public Builder minLimit(int minLimit) {\n+            this.minLimit = minLimit;\n+            return this;\n+        }\n+\n+        /**\n+         * Maximum allowable concurrency.  Any estimated concurrency will be capped\n+         * at this value\n+         * @param maxConcurrency\n+         * @return Chainable builder\n+         */\n+        public Builder maxConcurrency(int maxConcurrency) {\n+            this.maxConcurrency = maxConcurrency;\n+            return this;\n+        }\n+\n+        /**\n+         * Fixed amount the estimated limit can grow while latencies remain low\n+         * @param queueSize\n+         * @return Chainable builder\n+         */\n+        public Builder queueSize(int queueSize) {\n+            this.queueSize = (ignore) -> queueSize;\n+            return this;\n+        }\n+\n+        /**\n+         * Function to dynamically determine the amount the estimated limit can grow while\n+         * latencies remain low as a function of the current limit.\n+         * @param queueSize\n+         * @return Chainable builder\n+         */\n+        public Builder queueSize(Function<Integer, Integer> queueSize) {\n+            this.queueSize = queueSize;\n+            return this;\n+        }\n+\n+        /**\n+         * Tolerance for changes in minimum latency.\n+         * @param rttTolerance Value {@literal >}= 1.0 indicating how much change in minimum latency is acceptable\n+         *  before reducing the limit.  For example, a value of 2.0 means that a 2x increase in latency is acceptable.\n+         * @return Chainable builder\n+         */\n+        public Builder rttTolerance(double rttTolerance) {\n+            assert rttTolerance >= 1.0 : \"Tolerance must be >= 1.0\";\n+            this.rttTolerance = rttTolerance;\n+            return this;\n+        }\n+\n+        /**\n+         * Maximum multiple of the fast window after which we need to reset the limiter\n+         * @param multiplier\n+         * @return\n+         */\n+        @Deprecated\n+        public Builder driftMultiplier(int multiplier) {\n+            return this;\n+        }\n+\n+        /**\n+         * Smoothing factor to limit how aggressively the estimated limit can shrink\n+         * when queuing has been detected.\n+         * @param smoothing Value of 0.0 to 1.0 where 1.0 means the limit is completely\n+         *  replicated by the new estimate.\n+         * @return Chainable builder\n+         */\n+        public Builder smoothing(double smoothing) {\n+            this.smoothing = smoothing;\n+            return this;\n+        }\n+\n+        public Builder longWindow(int n) {\n+            this.longWindow = n;\n+            return this;\n+        }\n+\n+        public ConcurrencyLimit build() {\n+            return new ConcurrencyLimit(this);\n+        }\n+    }\n+\n+    public static Builder newBuilder() {\n+        return new Builder();\n+    }\n+\n+    public static ConcurrencyLimit newDefault() {\n+        return newBuilder().build();\n+    }\n+\n+    /**\n+     * Estimated concurrency limit based on our algorithm\n+     */\n+    private volatile double estimatedLimit;\n+\n+    /**\n+     * Tracks a measurement of the short time, and more volatile, RTT meant to represent the current system latency\n+     */\n+    private long lastRtt;\n+\n+    /**\n+     * Tracks a measurement of the long term, less volatile, RTT meant to represent the baseline latency.  When the system\n+     * is under load this number is expect to trend higher.\n+     */\n+    private final Measurement longRtt;\n+\n+    /**\n+     * Maximum allowed limit providing an upper bound failsafe\n+     */\n+    private final int maxLimit;\n+\n+    private final int minLimit;\n+\n+    private final Function<Integer, Integer> queueSize;\n+\n+    private final double smoothing;\n+\n+    private final double tolerance;\n+\n+    private volatile int limit;\n+\n+    private final AtomicInteger numInflight = new AtomicInteger();\n+\n+    private ConcurrencyLimit(Builder builder) {\n+        this.limit = builder.initialLimit;\n+        this.estimatedLimit = builder.initialLimit;\n+        this.maxLimit = builder.maxConcurrency;\n+        this.minLimit = builder.minLimit;\n+        this.queueSize = builder.queueSize;\n+        this.smoothing = builder.smoothing;\n+        this.tolerance = builder.rttTolerance;\n+        this.lastRtt = 0;\n+        this.longRtt = new ExpAvgMeasurement(builder.longWindow, 10);\n+    }\n+\n+    /**\n+     * Start a sample, increasing the number of inflight operations and returning a\n+     * monotonic time value which should be used for `onSample`\n+     **/\n+    public long startSample() {\n+        numInflight.incrementAndGet();\n+        return System.nanoTime();\n+    }\n+\n+    public final synchronized void onSample(long startTime, boolean didDrop) {\n+        long rtt = System.nanoTime() - startTime;\n+        int newLimit = update(rtt, numInflight.decrementAndGet(), didDrop);\n+        if (newLimit != limit) {\n+            limit = newLimit;\n+        }\n+    }\n+\n+    public final int getLimit() {\n+        return limit;\n+    }\n+\n+    private int update(final long rtt, final int inflight, final boolean didDrop) {\n+        final double queueSize = this.queueSize.apply((int)this.estimatedLimit);\n+\n+        this.lastRtt = rtt;\n+        final double shortRtt = (double)rtt;\n+        final double longRtt = this.longRtt.add(rtt);\n+\n+\n+        // If the long RTT is substantially larger than the short RTT then reduce the long RTT measurement.\n+        // This can happen when latency returns to normal after a prolonged prior of excessive load.  Reducing the\n+        // long RTT without waiting for the exponential smoothing helps bring the system back to steady state.\n+        if (longRtt / shortRtt > 2) {\n+            this.longRtt.update(current -> current * 0.95);\n+        }\n+\n+        // Don't grow the limit if we are app limited\n+        if (inflight < estimatedLimit / 2) {\n+            return (int) estimatedLimit;\n+        }\n+\n+        // Rtt could be higher than rtt_noload because of smoothing rtt noload updates\n+        // so set to 1.0 to indicate no queuing.  Otherwise calculate the slope and don't\n+        // allow it to be reduced by more than half to avoid aggressive load-shedding due to\n+        // outliers.\n+        final double gradient = Math.max(0.5, Math.min(1.0, tolerance * longRtt / shortRtt));\n+        double newLimit = estimatedLimit * gradient + queueSize;\n+        newLimit = estimatedLimit * (1 - smoothing) + newLimit * smoothing;\n+        newLimit = Math.max(minLimit, Math.min(maxLimit, newLimit));\n+\n+        if ((int)estimatedLimit != newLimit) {\n+            LOG.debug(\"New limit={} shortRtt={} ms longRtt={} ms queueSize={} gradient={}\",\n+                    (int)newLimit,\n+                    getLastRtt(TimeUnit.MICROSECONDS) / 1000.0,\n+                    getRttNoLoad(TimeUnit.MICROSECONDS) / 1000.0,\n+                    queueSize,\n+                    gradient);\n+        }\n+\n+        estimatedLimit = newLimit;\n+\n+        return (int)estimatedLimit;\n+    }\n+\n+    public long getLastRtt(TimeUnit units) {\n+        return units.convert(lastRtt, TimeUnit.NANOSECONDS);\n+    }\n+\n+    public long getRttNoLoad(TimeUnit units) {\n+        return units.convert((long) longRtt.get(), TimeUnit.NANOSECONDS);\n+    }\n+\n+    @Override\n+    public String toString() {\n+        return \"GradientLimit [limit=\" + (int)estimatedLimit + \"]\";\n+    }\n+\n+    public boolean exceedsLimit() {\n+        return numInflight() > limit;\n+    }\n+\n+    public int numInflight() {\n+        return numInflight.get();\n+    }\n+}"
  },
  {
    "sha": "0507ac91d038482bc21542286b767ecbb1d39c2b",
    "filename": "libs/shared/src/main/java/io/crate/concurrent/limits/ExpAvgMeasurement.java",
    "status": "added",
    "additions": 68,
    "deletions": 0,
    "changes": 68,
    "blob_url": "https://github.com/crate/crate/blob/a45d4e4a7f5ebadd5f2f7a66fef58ddae8735aeb/libs/shared/src/main/java/io/crate/concurrent/limits/ExpAvgMeasurement.java",
    "raw_url": "https://github.com/crate/crate/raw/a45d4e4a7f5ebadd5f2f7a66fef58ddae8735aeb/libs/shared/src/main/java/io/crate/concurrent/limits/ExpAvgMeasurement.java",
    "contents_url": "https://api.github.com/repos/crate/crate/contents/libs/shared/src/main/java/io/crate/concurrent/limits/ExpAvgMeasurement.java?ref=a45d4e4a7f5ebadd5f2f7a66fef58ddae8735aeb",
    "patch": "@@ -0,0 +1,68 @@\n+/**\n+ * Copyright 2018 Netflix, Inc.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package io.crate.concurrent.limits;\n+\n+import java.util.function.DoubleUnaryOperator;\n+\n+public class ExpAvgMeasurement implements Measurement {\n+\n+    private double value = 0.0;\n+    private double sum = 0.0;\n+    private final int window;\n+    private final int warmupWindow;\n+    private int count = 0;\n+\n+    public ExpAvgMeasurement(int window, int warmupWindow) {\n+        this.window = window;\n+        this.warmupWindow = warmupWindow;\n+        this.sum = 0.0;\n+    }\n+\n+    @Override\n+    public double add(double sample) {\n+        if (count < warmupWindow) {\n+            count++;\n+            sum += sample;\n+            value = sum / count;\n+        } else {\n+            double factor = factor(window);\n+            value = value * (1 - factor) + sample * factor;\n+        }\n+        return value;\n+    }\n+\n+    private static double factor(int n) {\n+        return 2.0 / (n + 1);\n+    }\n+\n+    @Override\n+    public double get() {\n+        return value;\n+    }\n+\n+    @Override\n+    public void reset() {\n+        value = 0.0;\n+        count = 0;\n+        sum = 0.0;\n+    }\n+\n+    @Override\n+    public void update(DoubleUnaryOperator operation) {\n+        this.value = operation.applyAsDouble(value);\n+    }\n+}"
  },
  {
    "sha": "2dec085e6c93b854965cc297a3bc0d17041313ab",
    "filename": "libs/shared/src/main/java/io/crate/concurrent/limits/Measurement.java",
    "status": "added",
    "additions": 43,
    "deletions": 0,
    "changes": 43,
    "blob_url": "https://github.com/crate/crate/blob/a45d4e4a7f5ebadd5f2f7a66fef58ddae8735aeb/libs/shared/src/main/java/io/crate/concurrent/limits/Measurement.java",
    "raw_url": "https://github.com/crate/crate/raw/a45d4e4a7f5ebadd5f2f7a66fef58ddae8735aeb/libs/shared/src/main/java/io/crate/concurrent/limits/Measurement.java",
    "contents_url": "https://api.github.com/repos/crate/crate/contents/libs/shared/src/main/java/io/crate/concurrent/limits/Measurement.java?ref=a45d4e4a7f5ebadd5f2f7a66fef58ddae8735aeb",
    "patch": "@@ -0,0 +1,43 @@\n+/**\n+ * Copyright 2018 Netflix, Inc.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package io.crate.concurrent.limits;\n+\n+import java.util.function.DoubleUnaryOperator;\n+\n+/**\n+ * Contract for tracking a measurement such as a minimum or average of a sample set\n+ */\n+public interface Measurement {\n+    /**\n+     * Add a single sample and update the internal state.\n+     * @param sample\n+     * @return True if internal state was updated\n+     */\n+    double add(double sample);\n+\n+    /**\n+     * @return Return the current value\n+     */\n+    double get();\n+\n+    /**\n+     * Reset the internal state as if no samples were ever added\n+     */\n+    void reset();\n+\n+    void update(DoubleUnaryOperator operation);\n+}"
  },
  {
    "sha": "0277c05da80aac9d076d9000ddda1c712090ec24",
    "filename": "server/src/main/java/io/crate/action/LimitedExponentialBackoff.java",
    "status": "modified",
    "additions": 35,
    "deletions": 3,
    "changes": 38,
    "blob_url": "https://github.com/crate/crate/blob/a45d4e4a7f5ebadd5f2f7a66fef58ddae8735aeb/server/src/main/java/io/crate/action/LimitedExponentialBackoff.java",
    "raw_url": "https://github.com/crate/crate/raw/a45d4e4a7f5ebadd5f2f7a66fef58ddae8735aeb/server/src/main/java/io/crate/action/LimitedExponentialBackoff.java",
    "contents_url": "https://api.github.com/repos/crate/crate/contents/server/src/main/java/io/crate/action/LimitedExponentialBackoff.java?ref=a45d4e4a7f5ebadd5f2f7a66fef58ddae8735aeb",
    "patch": "@@ -22,15 +22,20 @@\n \n package io.crate.action;\n \n-import org.elasticsearch.action.bulk.BackoffPolicy;\n-import io.crate.common.unit.TimeValue;\n-\n import java.util.Iterator;\n import java.util.NoSuchElementException;\n+import java.util.concurrent.TimeUnit;\n+\n+import org.elasticsearch.action.bulk.BackoffPolicy;\n+\n+import io.crate.common.unit.TimeValue;\n+import io.crate.concurrent.limits.ConcurrencyLimit;\n \n \n public class LimitedExponentialBackoff extends BackoffPolicy {\n \n+    private static final int MAX_ITERS = 1000;\n+\n     private final int firstDelayInMS;\n     private final int maxIterations;\n     private final int maxDelayInMS;\n@@ -52,6 +57,33 @@ public static BackoffPolicy limitedExponential(int maxDelayInMS) {\n         return new LimitedExponentialBackoff(10, Integer.MAX_VALUE, maxDelayInMS);\n     }\n \n+    public static BackoffPolicy limitedExponential(ConcurrencyLimit concurrencyLimit) {\n+        return new BackoffPolicy() {\n+\n+            int iterations = 0;\n+\n+            @Override\n+            public Iterator<TimeValue> iterator() {\n+                return new Iterator<>() {\n+\n+                    @Override\n+                    public boolean hasNext() {\n+                        return iterations < MAX_ITERS;\n+                    }\n+\n+                    @Override\n+                    public TimeValue next() {\n+                        if (!hasNext()) {\n+                            throw new NoSuchElementException(\"Iterator is exhausted\");\n+                        }\n+                        iterations++;\n+                        return TimeValue.timeValueNanos(concurrencyLimit.getLastRtt(TimeUnit.NANOSECONDS));\n+                    }\n+                };\n+            }\n+        };\n+    }\n+\n     private static class LimitedExponentialBackoffIterator implements Iterator<TimeValue> {\n \n         private static final float FACTOR = 1.8f;"
  },
  {
    "sha": "0a1b3c8542753feb7a719dde975fdddf8665392c",
    "filename": "server/src/main/java/io/crate/execution/engine/collect/BlobShardCollectorProvider.java",
    "status": "modified",
    "additions": 2,
    "deletions": 2,
    "changes": 4,
    "blob_url": "https://github.com/crate/crate/blob/a45d4e4a7f5ebadd5f2f7a66fef58ddae8735aeb/server/src/main/java/io/crate/execution/engine/collect/BlobShardCollectorProvider.java",
    "raw_url": "https://github.com/crate/crate/raw/a45d4e4a7f5ebadd5f2f7a66fef58ddae8735aeb/server/src/main/java/io/crate/execution/engine/collect/BlobShardCollectorProvider.java",
    "contents_url": "https://api.github.com/repos/crate/crate/contents/server/src/main/java/io/crate/execution/engine/collect/BlobShardCollectorProvider.java?ref=a45d4e4a7f5ebadd5f2f7a66fef58ddae8735aeb",
    "patch": "@@ -31,7 +31,7 @@\n import io.crate.execution.dsl.phases.RoutedCollectPhase;\n import io.crate.execution.engine.collect.collectors.BlobOrderedDocCollector;\n import io.crate.execution.engine.collect.collectors.OrderedDocCollector;\n-import io.crate.execution.jobs.NodeJobsCounter;\n+import io.crate.execution.jobs.NodeLimits;\n import io.crate.execution.jobs.SharedShardContext;\n import io.crate.expression.InputFactory;\n import io.crate.expression.reference.doc.blob.BlobReferenceResolver;\n@@ -56,7 +56,7 @@\n     public BlobShardCollectorProvider(BlobShard blobShard,\n                                       ClusterService clusterService,\n                                       Schemas schemas,\n-                                      NodeJobsCounter nodeJobsCounter,\n+                                      NodeLimits nodeJobsCounter,\n                                       CircuitBreakerService circuitBreakerService,\n                                       NodeContext nodeCtx,\n                                       ThreadPool threadPool,"
  },
  {
    "sha": "ac26e5a2cb307ad0cc2663826949405467704fce",
    "filename": "server/src/main/java/io/crate/execution/engine/collect/LuceneShardCollectorProvider.java",
    "status": "modified",
    "additions": 2,
    "deletions": 2,
    "changes": 4,
    "blob_url": "https://github.com/crate/crate/blob/a45d4e4a7f5ebadd5f2f7a66fef58ddae8735aeb/server/src/main/java/io/crate/execution/engine/collect/LuceneShardCollectorProvider.java",
    "raw_url": "https://github.com/crate/crate/raw/a45d4e4a7f5ebadd5f2f7a66fef58ddae8735aeb/server/src/main/java/io/crate/execution/engine/collect/LuceneShardCollectorProvider.java",
    "contents_url": "https://api.github.com/repos/crate/crate/contents/server/src/main/java/io/crate/execution/engine/collect/LuceneShardCollectorProvider.java?ref=a45d4e4a7f5ebadd5f2f7a66fef58ddae8735aeb",
    "patch": "@@ -47,7 +47,7 @@\n import io.crate.execution.engine.collect.collectors.OptimizeQueryForSearchAfter;\n import io.crate.execution.engine.collect.collectors.OrderedDocCollector;\n import io.crate.execution.engine.sort.LuceneSortGenerator;\n-import io.crate.execution.jobs.NodeJobsCounter;\n+import io.crate.execution.jobs.NodeLimits;\n import io.crate.execution.jobs.SharedShardContext;\n import io.crate.expression.InputFactory;\n import io.crate.expression.reference.doc.lucene.CollectorContext;\n@@ -79,7 +79,7 @@\n     public LuceneShardCollectorProvider(Schemas schemas,\n                                         LuceneQueryBuilder luceneQueryBuilder,\n                                         ClusterService clusterService,\n-                                        NodeJobsCounter nodeJobsCounter,\n+                                        NodeLimits nodeJobsCounter,\n                                         CircuitBreakerService circuitBreakerService,\n                                         NodeContext nodeCtx,\n                                         ThreadPool threadPool,"
  },
  {
    "sha": "76b7b927c996930868aefa4c65e4075222633538",
    "filename": "server/src/main/java/io/crate/execution/engine/collect/ShardCollectorProvider.java",
    "status": "modified",
    "additions": 2,
    "deletions": 2,
    "changes": 4,
    "blob_url": "https://github.com/crate/crate/blob/a45d4e4a7f5ebadd5f2f7a66fef58ddae8735aeb/server/src/main/java/io/crate/execution/engine/collect/ShardCollectorProvider.java",
    "raw_url": "https://github.com/crate/crate/raw/a45d4e4a7f5ebadd5f2f7a66fef58ddae8735aeb/server/src/main/java/io/crate/execution/engine/collect/ShardCollectorProvider.java",
    "contents_url": "https://api.github.com/repos/crate/crate/contents/server/src/main/java/io/crate/execution/engine/collect/ShardCollectorProvider.java?ref=a45d4e4a7f5ebadd5f2f7a66fef58ddae8735aeb",
    "patch": "@@ -45,7 +45,7 @@\n import io.crate.execution.engine.pipeline.ProjectionToProjectorVisitor;\n import io.crate.execution.engine.pipeline.ProjectorFactory;\n import io.crate.execution.engine.pipeline.Projectors;\n-import io.crate.execution.jobs.NodeJobsCounter;\n+import io.crate.execution.jobs.NodeLimits;\n import io.crate.execution.jobs.SharedShardContext;\n import io.crate.expression.InputFactory;\n import io.crate.expression.eval.EvaluatingNormalizer;\n@@ -64,7 +64,7 @@\n     ShardCollectorProvider(ClusterService clusterService,\n                            CircuitBreakerService circuitBreakerService,\n                            Schemas schemas,\n-                           NodeJobsCounter nodeJobsCounter,\n+                           NodeLimits nodeJobsCounter,\n                            NodeContext nodeCtx,\n                            ThreadPool threadPool,\n                            Settings settings,"
  },
  {
    "sha": "c90e498ae378be19362f87ec323b5b566006b671",
    "filename": "server/src/main/java/io/crate/execution/engine/collect/sources/CollectSourceResolver.java",
    "status": "modified",
    "additions": 2,
    "deletions": 2,
    "changes": 4,
    "blob_url": "https://github.com/crate/crate/blob/a45d4e4a7f5ebadd5f2f7a66fef58ddae8735aeb/server/src/main/java/io/crate/execution/engine/collect/sources/CollectSourceResolver.java",
    "raw_url": "https://github.com/crate/crate/raw/a45d4e4a7f5ebadd5f2f7a66fef58ddae8735aeb/server/src/main/java/io/crate/execution/engine/collect/sources/CollectSourceResolver.java",
    "contents_url": "https://api.github.com/repos/crate/crate/contents/server/src/main/java/io/crate/execution/engine/collect/sources/CollectSourceResolver.java?ref=a45d4e4a7f5ebadd5f2f7a66fef58ddae8735aeb",
    "patch": "@@ -37,7 +37,7 @@\n import io.crate.execution.engine.collect.CollectTask;\n import io.crate.execution.engine.pipeline.ProjectionToProjectorVisitor;\n import io.crate.execution.engine.pipeline.ProjectorFactory;\n-import io.crate.execution.jobs.NodeJobsCounter;\n+import io.crate.execution.jobs.NodeLimits;\n import io.crate.expression.InputFactory;\n import io.crate.expression.eval.EvaluatingNormalizer;\n import io.crate.metadata.IndexParts;\n@@ -74,7 +74,7 @@\n \n     @Inject\n     public CollectSourceResolver(ClusterService clusterService,\n-                                 NodeJobsCounter nodeJobsCounter,\n+                                 NodeLimits nodeJobsCounter,\n                                  CircuitBreakerService circuitBreakerService,\n                                  NodeContext nodeCtx,\n                                  Settings settings,"
  },
  {
    "sha": "69575f86847adfeca4bacac94422eb360a2ded7d",
    "filename": "server/src/main/java/io/crate/execution/engine/collect/sources/ShardCollectSource.java",
    "status": "modified",
    "additions": 2,
    "deletions": 2,
    "changes": 4,
    "blob_url": "https://github.com/crate/crate/blob/a45d4e4a7f5ebadd5f2f7a66fef58ddae8735aeb/server/src/main/java/io/crate/execution/engine/collect/sources/ShardCollectSource.java",
    "raw_url": "https://github.com/crate/crate/raw/a45d4e4a7f5ebadd5f2f7a66fef58ddae8735aeb/server/src/main/java/io/crate/execution/engine/collect/sources/ShardCollectSource.java",
    "contents_url": "https://api.github.com/repos/crate/crate/contents/server/src/main/java/io/crate/execution/engine/collect/sources/ShardCollectSource.java?ref=a45d4e4a7f5ebadd5f2f7a66fef58ddae8735aeb",
    "patch": "@@ -49,7 +49,7 @@\n import io.crate.execution.engine.pipeline.ProjectorFactory;\n import io.crate.execution.engine.pipeline.Projectors;\n import io.crate.execution.engine.sort.OrderingByPosition;\n-import io.crate.execution.jobs.NodeJobsCounter;\n+import io.crate.execution.jobs.NodeLimits;\n import io.crate.execution.jobs.SharedShardContext;\n import io.crate.execution.jobs.SharedShardContexts;\n import io.crate.expression.InputFactory;\n@@ -165,7 +165,7 @@ public ShardCollectSource(Settings settings,\n                               IndicesService indicesService,\n                               NodeContext nodeCtx,\n                               ClusterService clusterService,\n-                              NodeJobsCounter nodeJobsCounter,\n+                              NodeLimits nodeJobsCounter,\n                               LuceneQueryBuilder luceneQueryBuilder,\n                               ThreadPool threadPool,\n                               TransportActionProvider transportActionProvider,"
  },
  {
    "sha": "faf43e39e82929da3e60cf5ffabab925e6ffcbaf",
    "filename": "server/src/main/java/io/crate/execution/engine/collect/sources/ShardCollectorProviderFactory.java",
    "status": "modified",
    "additions": 3,
    "deletions": 3,
    "changes": 6,
    "blob_url": "https://github.com/crate/crate/blob/a45d4e4a7f5ebadd5f2f7a66fef58ddae8735aeb/server/src/main/java/io/crate/execution/engine/collect/sources/ShardCollectorProviderFactory.java",
    "raw_url": "https://github.com/crate/crate/raw/a45d4e4a7f5ebadd5f2f7a66fef58ddae8735aeb/server/src/main/java/io/crate/execution/engine/collect/sources/ShardCollectorProviderFactory.java",
    "contents_url": "https://api.github.com/repos/crate/crate/contents/server/src/main/java/io/crate/execution/engine/collect/sources/ShardCollectorProviderFactory.java?ref=a45d4e4a7f5ebadd5f2f7a66fef58ddae8735aeb",
    "patch": "@@ -28,7 +28,7 @@\n import io.crate.execution.engine.collect.BlobShardCollectorProvider;\n import io.crate.execution.engine.collect.LuceneShardCollectorProvider;\n import io.crate.execution.engine.collect.ShardCollectorProvider;\n-import io.crate.execution.jobs.NodeJobsCounter;\n+import io.crate.execution.jobs.NodeLimits;\n import io.crate.lucene.LuceneQueryBuilder;\n import io.crate.metadata.NodeContext;\n import io.crate.metadata.Schemas;\n@@ -51,7 +51,7 @@\n \n     private final NodeContext nodeCtx;\n     private final LuceneQueryBuilder luceneQueryBuilder;\n-    private final NodeJobsCounter nodeJobsCounter;\n+    private final NodeLimits nodeJobsCounter;\n     private final BigArrays bigArrays;\n     private final Settings settings;\n     private final CircuitBreakerService circuitBreakerService;\n@@ -65,7 +65,7 @@\n                                   BlobIndicesService blobIndicesService,\n                                   NodeContext nodeCtx,\n                                   LuceneQueryBuilder luceneQueryBuilder,\n-                                  NodeJobsCounter nodeJobsCounter,\n+                                  NodeLimits nodeJobsCounter,\n                                   BigArrays bigArrays) {\n         this.settings = settings;\n         this.circuitBreakerService = circuitBreakerService;"
  },
  {
    "sha": "9c0e36b643c0b1ab589853326220fe7629197414",
    "filename": "server/src/main/java/io/crate/execution/engine/indexing/BatchIteratorBackpressureExecutor.java",
    "status": "modified",
    "additions": 27,
    "deletions": 21,
    "changes": 48,
    "blob_url": "https://github.com/crate/crate/blob/a45d4e4a7f5ebadd5f2f7a66fef58ddae8735aeb/server/src/main/java/io/crate/execution/engine/indexing/BatchIteratorBackpressureExecutor.java",
    "raw_url": "https://github.com/crate/crate/raw/a45d4e4a7f5ebadd5f2f7a66fef58ddae8735aeb/server/src/main/java/io/crate/execution/engine/indexing/BatchIteratorBackpressureExecutor.java",
    "contents_url": "https://api.github.com/repos/crate/crate/contents/server/src/main/java/io/crate/execution/engine/indexing/BatchIteratorBackpressureExecutor.java?ref=a45d4e4a7f5ebadd5f2f7a66fef58ddae8735aeb",
    "patch": "@@ -22,15 +22,6 @@\n \n package io.crate.execution.engine.indexing;\n \n-import io.crate.data.BatchIterator;\n-\n-import org.apache.logging.log4j.LogManager;\n-import org.apache.logging.log4j.Logger;\n-import org.elasticsearch.action.bulk.BackoffPolicy;\n-import io.crate.common.unit.TimeValue;\n-\n-import javax.annotation.Nullable;\n-import java.util.Iterator;\n import java.util.UUID;\n import java.util.concurrent.CompletableFuture;\n import java.util.concurrent.Executor;\n@@ -45,6 +36,13 @@\n import java.util.function.Function;\n import java.util.function.Predicate;\n \n+import javax.annotation.Nullable;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+\n+import io.crate.data.BatchIterator;\n+\n /**\n  * Consumes a BatchIterator, concurrently invoking {@link #execute} on\n  * each item until {@link #pauseConsumption} returns true.\n@@ -64,18 +62,19 @@\n     private final BatchIterator<T> batchIterator;\n     private final Function<T, CompletableFuture<R>> execute;\n     private final ScheduledExecutorService scheduler;\n-    private final Iterator<TimeValue> throttleDelay;\n     private final BinaryOperator<R> combiner;\n     private final Predicate<T> pauseConsumption;\n     private final BiConsumer<R, Throwable> continueConsumptionOrFinish;\n     private final AtomicInteger inFlightExecutions = new AtomicInteger(0);\n     private final CompletableFuture<R> resultFuture = new CompletableFuture<>();\n     private final Semaphore semaphore = new Semaphore(1);\n \n+    private final Function<T, Long> getDelayInMs;\n     private final AtomicReference<R> resultRef;\n     private final AtomicReference<Throwable> failureRef = new AtomicReference<>(null);\n     private volatile boolean consumptionFinished = false;\n \n+\n     /**\n      * @param batchIterator provides the items for {@code execute}\n      * @param execute async function which is called for each item from the batchIterator\n@@ -91,15 +90,16 @@ public BatchIteratorBackpressureExecutor(UUID jobId,\n                                              BinaryOperator<R> combiner,\n                                              R identity,\n                                              Predicate<T> pauseConsumption,\n-                                             BackoffPolicy backoffPolicy) {\n+                                             Function<T, Long> getDelayInMs) {\n+\n         this.jobId = jobId;\n         this.executor = executor;\n         this.batchIterator = batchIterator;\n         this.scheduler = scheduler;\n         this.execute = execute;\n         this.combiner = combiner;\n         this.pauseConsumption = pauseConsumption;\n-        this.throttleDelay = backoffPolicy.iterator();\n+        this.getDelayInMs = getDelayInMs;\n         this.resultRef = new AtomicReference<>(identity);\n         this.continueConsumptionOrFinish = this::continueConsumptionOrFinish;\n     }\n@@ -159,14 +159,17 @@ private void consumeIterator() {\n             while (batchIterator.moveNext()) {\n                 T item = batchIterator.currentElement();\n                 if (pauseConsumption.test(item)) {\n-                    long delayInMs = throttleDelay.next().getMillis();\n-                    if (LOGGER.isDebugEnabled()) {\n-                        LOGGER.debug(\"Pausing consumption jobId={} delayInMs={}\", jobId, delayInMs);\n+                    long delayInMs = getDelayInMs.apply(item);\n+                    if (delayInMs > 0) {\n+                        if (LOGGER.isDebugEnabled()) {\n+                            LOGGER.debug(\"Pausing consumption jobId={} delayInMs={}\", jobId, delayInMs);\n+                        }\n+                        // release semaphore inside resumeConsumption: after throttle delay has passed\n+                        // to make sure callbacks of previously triggered async operations don't resume consumption\n+                        scheduler.schedule(this::resumeConsumption, delayInMs, TimeUnit.MILLISECONDS);\n+                        return;\n                     }\n-                    // release semaphore inside resumeConsumption: after throttle delay has passed\n-                    // to make sure callbacks of previously triggered async operations don't resume consumption\n-                    scheduler.schedule(this::resumeConsumption, delayInMs, TimeUnit.MILLISECONDS);\n-                    return;\n+                    // fall through to execute\n                 }\n                 execute(item);\n             }\n@@ -199,8 +202,11 @@ private void execute(T item) {\n     private void resumeConsumption() {\n         T item = batchIterator.currentElement();\n         if (pauseConsumption.test(item)) {\n-            scheduler.schedule(this::resumeConsumption, throttleDelay.next().getMillis(), TimeUnit.MILLISECONDS);\n-            return;\n+            long delayInMs = getDelayInMs.apply(item);\n+            if (delayInMs > 0) {\n+                scheduler.schedule(this::resumeConsumption, delayInMs, TimeUnit.MILLISECONDS);\n+                return;\n+            }\n         }\n         try {\n             executor.execute(() -> doResumeConsumption(item));"
  },
  {
    "sha": "8b3a6cf1007424811cbe18b45a29907cc211e62f",
    "filename": "server/src/main/java/io/crate/execution/engine/indexing/ColumnIndexWriterProjector.java",
    "status": "modified",
    "additions": 2,
    "deletions": 2,
    "changes": 4,
    "blob_url": "https://github.com/crate/crate/blob/a45d4e4a7f5ebadd5f2f7a66fef58ddae8735aeb/server/src/main/java/io/crate/execution/engine/indexing/ColumnIndexWriterProjector.java",
    "raw_url": "https://github.com/crate/crate/raw/a45d4e4a7f5ebadd5f2f7a66fef58ddae8735aeb/server/src/main/java/io/crate/execution/engine/indexing/ColumnIndexWriterProjector.java",
    "contents_url": "https://api.github.com/repos/crate/crate/contents/server/src/main/java/io/crate/execution/engine/indexing/ColumnIndexWriterProjector.java?ref=a45d4e4a7f5ebadd5f2f7a66fef58ddae8735aeb",
    "patch": "@@ -33,7 +33,7 @@\n import io.crate.execution.dml.upsert.ShardUpsertRequest.DuplicateKeyAction;\n import io.crate.execution.engine.collect.CollectExpression;\n import io.crate.execution.engine.collect.RowShardResolver;\n-import io.crate.execution.jobs.NodeJobsCounter;\n+import io.crate.execution.jobs.NodeLimits;\n import io.crate.expression.InputRow;\n import io.crate.expression.symbol.Assignments;\n import io.crate.expression.symbol.Symbol;\n@@ -59,7 +59,7 @@\n     private final ShardingUpsertExecutor shardingUpsertExecutor;\n \n     public ColumnIndexWriterProjector(ClusterService clusterService,\n-                                      NodeJobsCounter nodeJobsCounter,\n+                                      NodeLimits nodeJobsCounter,\n                                       CircuitBreaker queryCircuitBreaker,\n                                       RamAccounting ramAccounting,\n                                       ScheduledExecutorService scheduler,"
  },
  {
    "sha": "1bad3457c95e80542b4c220f5184ba1fdaa0b88d",
    "filename": "server/src/main/java/io/crate/execution/engine/indexing/IndexWriterProjector.java",
    "status": "modified",
    "additions": 2,
    "deletions": 2,
    "changes": 4,
    "blob_url": "https://github.com/crate/crate/blob/a45d4e4a7f5ebadd5f2f7a66fef58ddae8735aeb/server/src/main/java/io/crate/execution/engine/indexing/IndexWriterProjector.java",
    "raw_url": "https://github.com/crate/crate/raw/a45d4e4a7f5ebadd5f2f7a66fef58ddae8735aeb/server/src/main/java/io/crate/execution/engine/indexing/IndexWriterProjector.java",
    "contents_url": "https://api.github.com/repos/crate/crate/contents/server/src/main/java/io/crate/execution/engine/indexing/IndexWriterProjector.java?ref=a45d4e4a7f5ebadd5f2f7a66fef58ddae8735aeb",
    "patch": "@@ -32,7 +32,7 @@\n import io.crate.execution.dml.upsert.ShardUpsertRequest.DuplicateKeyAction;\n import io.crate.execution.engine.collect.CollectExpression;\n import io.crate.execution.engine.collect.RowShardResolver;\n-import io.crate.execution.jobs.NodeJobsCounter;\n+import io.crate.execution.jobs.NodeLimits;\n import io.crate.expression.symbol.Symbol;\n import io.crate.metadata.ColumnIdent;\n import io.crate.metadata.NodeContext;\n@@ -67,7 +67,7 @@\n     private final ShardingUpsertExecutor shardingUpsertExecutor;\n \n     public IndexWriterProjector(ClusterService clusterService,\n-                                NodeJobsCounter nodeJobsCounter,\n+                                NodeLimits nodeJobsCounter,\n                                 CircuitBreaker queryCircuitBreaker,\n                                 RamAccounting ramAccounting,\n                                 ScheduledExecutorService scheduler,"
  },
  {
    "sha": "edb36de6105faf4680a758536f708c7294513b3e",
    "filename": "server/src/main/java/io/crate/execution/engine/indexing/ShardDMLExecutor.java",
    "status": "modified",
    "additions": 31,
    "deletions": 20,
    "changes": 51,
    "blob_url": "https://github.com/crate/crate/blob/a45d4e4a7f5ebadd5f2f7a66fef58ddae8735aeb/server/src/main/java/io/crate/execution/engine/indexing/ShardDMLExecutor.java",
    "raw_url": "https://github.com/crate/crate/raw/a45d4e4a7f5ebadd5f2f7a66fef58ddae8735aeb/server/src/main/java/io/crate/execution/engine/indexing/ShardDMLExecutor.java",
    "contents_url": "https://api.github.com/repos/crate/crate/contents/server/src/main/java/io/crate/execution/engine/indexing/ShardDMLExecutor.java?ref=a45d4e4a7f5ebadd5f2f7a66fef58ddae8735aeb",
    "patch": "@@ -22,14 +22,14 @@\n \n package io.crate.execution.engine.indexing;\n \n-import static io.crate.execution.jobs.NodeJobsCounter.MAX_NODE_CONCURRENT_OPERATIONS;\n \n import java.util.ArrayList;\n import java.util.List;\n import java.util.UUID;\n import java.util.concurrent.CompletableFuture;\n import java.util.concurrent.Executor;\n import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n import java.util.function.BiConsumer;\n import java.util.function.Function;\n import java.util.function.Predicate;\n@@ -41,11 +41,11 @@\n import org.apache.logging.log4j.LogManager;\n import org.apache.logging.log4j.Logger;\n import org.elasticsearch.action.ActionListener;\n-import org.elasticsearch.action.bulk.BackoffPolicy;\n import org.elasticsearch.cluster.service.ClusterService;\n \n import io.crate.action.FutureActionListener;\n import io.crate.action.LimitedExponentialBackoff;\n+import io.crate.concurrent.limits.ConcurrencyLimit;\n import io.crate.data.BatchIterator;\n import io.crate.data.BatchIterators;\n import io.crate.data.CollectionBucket;\n@@ -55,7 +55,7 @@\n import io.crate.execution.dml.ShardRequest;\n import io.crate.execution.dml.ShardResponse;\n import io.crate.execution.engine.collect.CollectExpression;\n-import io.crate.execution.jobs.NodeJobsCounter;\n+import io.crate.execution.jobs.NodeLimits;\n import io.crate.execution.support.RetryListener;\n \n public class ShardDMLExecutor<TReq extends ShardRequest<TReq, TItem>,\n@@ -66,29 +66,29 @@\n \n     private static final Logger LOGGER = LogManager.getLogger(ShardDMLExecutor.class);\n \n-    private static final BackoffPolicy BACKOFF_POLICY = LimitedExponentialBackoff.limitedExponential(1000);\n     public static final int DEFAULT_BULK_SIZE = 10_000;\n \n     private final UUID jobId;\n     private final int bulkSize;\n     private final ScheduledExecutorService scheduler;\n     private final Executor executor;\n     private final CollectExpression<Row, ?> uidExpression;\n-    private final NodeJobsCounter nodeJobsCounter;\n+    private final NodeLimits nodeLimits;\n     private final Supplier<TReq> requestFactory;\n     private final Function<String, TItem> itemFactory;\n     private final BiConsumer<TReq, ActionListener<ShardResponse>> operation;\n-    private final String localNodeId;\n     private final Collector<ShardResponse, TAcc, TResult> collector;\n     private int numItems = -1;\n \n+    private ClusterService clusterService;\n+\n     public ShardDMLExecutor(UUID jobId,\n                             int bulkSize,\n                             ScheduledExecutorService scheduler,\n                             Executor executor,\n                             CollectExpression<Row, ?> uidExpression,\n                             ClusterService clusterService,\n-                            NodeJobsCounter nodeJobsCounter,\n+                            NodeLimits nodeLimits,\n                             Supplier<TReq> requestFactory,\n                             Function<String, TItem> itemFactory,\n                             BiConsumer<TReq, ActionListener<ShardResponse>> transportAction,\n@@ -99,11 +99,11 @@ public ShardDMLExecutor(UUID jobId,\n         this.scheduler = scheduler;\n         this.executor = executor;\n         this.uidExpression = uidExpression;\n-        this.nodeJobsCounter = nodeJobsCounter;\n+        this.clusterService = clusterService;\n+        this.nodeLimits = nodeLimits;\n         this.requestFactory = requestFactory;\n         this.itemFactory = itemFactory;\n         this.operation = transportAction;\n-        this.localNodeId = getLocalNodeId(clusterService);\n         this.collector = collector;\n     }\n \n@@ -113,25 +113,38 @@ private void addRowToRequest(TReq req, Row row) {\n         req.add(numItems, itemFactory.apply((String) uidExpression.value()));\n     }\n \n+    private String resolveNodeId(TReq request) {\n+        // The primary shard might be moving to another node,\n+        // so this is not 100% accurate but good enough for the congestion control purposes.\n+        return clusterService\n+            .state()\n+            .routingTable()\n+            .shardRoutingTable(request.shardId())\n+            .primaryShard()\n+            .currentNodeId();\n+    }\n+\n     private CompletableFuture<TAcc> executeBatch(TReq request) {\n+        ConcurrencyLimit nodeLimit = nodeLimits.get(resolveNodeId(request));\n+        long startTime = nodeLimit.startSample();\n         FutureActionListener<ShardResponse, TAcc> listener = new FutureActionListener<>((a) -> {\n+            nodeLimit.onSample(startTime, false);\n             TAcc acc = collector.supplier().get();\n             collector.accumulator().accept(acc, a);\n             return acc;\n         });\n-\n-        nodeJobsCounter.increment(localNodeId);\n-        CompletableFuture<TAcc> result = listener.whenComplete((r, f) -> nodeJobsCounter.decrement(localNodeId));\n-        operation.accept(request, withRetry(request, listener));\n-        return result;\n+        operation.accept(request, withRetry(request, nodeLimit, listener));\n+        return listener;\n     }\n \n-    private RetryListener<ShardResponse> withRetry(TReq request, FutureActionListener<ShardResponse, TAcc> listener) {\n+    private RetryListener<ShardResponse> withRetry(TReq request,\n+                                                   ConcurrencyLimit nodeLimit,\n+                                                   FutureActionListener<ShardResponse, TAcc> listener) {\n         return new RetryListener<>(\n             scheduler,\n             l -> operation.accept(request, l),\n             listener,\n-            BACKOFF_POLICY\n+            LimitedExponentialBackoff.limitedExponential(nodeLimit)\n         );\n     }\n \n@@ -143,10 +156,8 @@ private void addRowToRequest(TReq req, Row row) {\n         // as soon as possible. We do not want to throttle based on the targets node counter in such cases.\n         Predicate<TReq> shouldPause = ignored -> true;\n         if (batchIterator.hasLazyResultSet()) {\n-            shouldPause = ignored ->\n-                nodeJobsCounter.getInProgressJobsForNode(localNodeId) >= MAX_NODE_CONCURRENT_OPERATIONS;\n+            shouldPause = req -> nodeLimits.get(resolveNodeId(req)).exceedsLimit();\n         }\n-\n         return new BatchIteratorBackpressureExecutor<>(\n             jobId,\n             scheduler,\n@@ -156,7 +167,7 @@ private void addRowToRequest(TReq req, Row row) {\n             collector.combiner(),\n             collector.supplier().get(),\n             shouldPause,\n-            BACKOFF_POLICY\n+            req -> nodeLimits.get(resolveNodeId(req)).getLastRtt(TimeUnit.MILLISECONDS)\n         ).consumeIteratorAndExecute()\n             .thenApply(collector.finisher());\n     }"
  },
  {
    "sha": "34e9ef73e3be0b8c081237e81fe407ce3043ee2a",
    "filename": "server/src/main/java/io/crate/execution/engine/indexing/ShardingUpsertExecutor.java",
    "status": "modified",
    "additions": 39,
    "deletions": 18,
    "changes": 57,
    "blob_url": "https://github.com/crate/crate/blob/a45d4e4a7f5ebadd5f2f7a66fef58ddae8735aeb/server/src/main/java/io/crate/execution/engine/indexing/ShardingUpsertExecutor.java",
    "raw_url": "https://github.com/crate/crate/raw/a45d4e4a7f5ebadd5f2f7a66fef58ddae8735aeb/server/src/main/java/io/crate/execution/engine/indexing/ShardingUpsertExecutor.java",
    "contents_url": "https://api.github.com/repos/crate/crate/contents/server/src/main/java/io/crate/execution/engine/indexing/ShardingUpsertExecutor.java?ref=a45d4e4a7f5ebadd5f2f7a66fef58ddae8735aeb",
    "patch": "@@ -22,7 +22,6 @@\n \n package io.crate.execution.engine.indexing;\n \n-import static io.crate.execution.jobs.NodeJobsCounter.MAX_NODE_CONCURRENT_OPERATIONS;\n \n import java.util.Iterator;\n import java.util.List;\n@@ -46,7 +45,6 @@\n import org.elasticsearch.action.ActionListener;\n import org.elasticsearch.action.admin.indices.create.CreatePartitionsRequest;\n import org.elasticsearch.action.admin.indices.create.TransportCreatePartitionsAction;\n-import org.elasticsearch.action.bulk.BackoffPolicy;\n import org.elasticsearch.action.bulk.BulkRequestExecutor;\n import org.elasticsearch.action.support.master.AcknowledgedResponse;\n import org.elasticsearch.cluster.service.ClusterService;\n@@ -61,14 +59,16 @@\n import io.crate.breaker.RamAccounting;\n import io.crate.breaker.TypeGuessEstimateRowSize;\n import io.crate.common.unit.TimeValue;\n+import io.crate.concurrent.limits.ConcurrencyLimit;\n import io.crate.data.BatchIterator;\n import io.crate.data.BatchIterators;\n import io.crate.data.Row;\n import io.crate.execution.dml.ShardResponse;\n import io.crate.execution.dml.upsert.ShardUpsertRequest;\n+import io.crate.execution.dml.upsert.ShardUpsertRequest.Item;\n import io.crate.execution.engine.collect.CollectExpression;\n import io.crate.execution.engine.collect.RowShardResolver;\n-import io.crate.execution.jobs.NodeJobsCounter;\n+import io.crate.execution.jobs.NodeLimits;\n import io.crate.execution.support.RetryListener;\n import io.crate.settings.CrateSetting;\n import io.crate.types.DataTypes;\n@@ -80,12 +80,11 @@\n         \"bulk.request_timeout\", new TimeValue(1, TimeUnit.MINUTES),\n         Setting.Property.NodeScope, Setting.Property.Dynamic), DataTypes.STRING);\n \n-    private static final BackoffPolicy BACKOFF_POLICY = LimitedExponentialBackoff.limitedExponential(1000);\n     private static final Logger LOGGER = LogManager.getLogger(ShardingUpsertExecutor.class);\n     private static final double BREAKER_LIMIT_PERCENTAGE = 0.50d;\n \n     private final GroupRowsByShard<ShardUpsertRequest, ShardUpsertRequest.Item> grouper;\n-    private final NodeJobsCounter nodeJobsCounter;\n+    private final NodeLimits nodeLimits;\n     private final ScheduledExecutorService scheduler;\n     private final Executor executor;\n     private final int bulkSize;\n@@ -102,7 +101,7 @@\n     private volatile boolean createPartitionsRequestOngoing = false;\n \n     ShardingUpsertExecutor(ClusterService clusterService,\n-                           NodeJobsCounter nodeJobsCounter,\n+                           NodeLimits nodeJobsCounter,\n                            CircuitBreaker queryCircuitBreaker,\n                            RamAccounting ramAccounting,\n                            ScheduledExecutorService scheduler,\n@@ -121,7 +120,7 @@\n                            int targetTableNumReplicas,\n                            UpsertResultContext upsertResultContext) {\n         this.localNode = clusterService.state().getNodes().getLocalNodeId();\n-        this.nodeJobsCounter = nodeJobsCounter;\n+        this.nodeLimits = nodeJobsCounter;\n         this.queryCircuitBreaker = queryCircuitBreaker;\n         this.scheduler = scheduler;\n         this.executor = executor;\n@@ -200,7 +199,8 @@ private static void collectFailingItems(ShardedRequests<ShardUpsertRequest, Shar\n             it.remove();\n \n             String nodeId = entry.getKey().nodeId;\n-            nodeJobsCounter.increment(nodeId);\n+            ConcurrencyLimit nodeLimit = nodeLimits.get(nodeId);\n+            long startTime = nodeLimit.startSample();\n             ActionListener<ShardResponse> listener =\n                 new ShardResponseActionListener(\n                     nodeId,\n@@ -209,6 +209,7 @@ private static void collectFailingItems(ShardedRequests<ShardUpsertRequest, Shar\n                     upsertResults,\n                     resultCollector.accumulator(),\n                     requests.rowSourceInfos,\n+                    startTime,\n                     resultFuture);\n \n             listener = new RetryListener<>(\n@@ -220,7 +221,7 @@ private static void collectFailingItems(ShardedRequests<ShardUpsertRequest, Shar\n                     requestExecutor.execute(request, l);\n                 },\n                 listener,\n-                BACKOFF_POLICY\n+                LimitedExponentialBackoff.limitedExponential(nodeLimit)\n             );\n             requestExecutor.execute(request, listener);\n         }\n@@ -239,9 +240,16 @@ private static void collectFailingItems(ShardedRequests<ShardUpsertRequest, Shar\n     private boolean shouldPauseOnTargetNodeJobsCounter(ShardedRequests<ShardUpsertRequest, ShardUpsertRequest.Item> requests) {\n         for (ShardLocation shardLocation : requests.itemsByShard.keySet()) {\n             String requestNodeId = shardLocation.nodeId;\n-            if (nodeJobsCounter.getInProgressJobsForNode(requestNodeId) >= MAX_NODE_CONCURRENT_OPERATIONS) {\n+            ConcurrencyLimit nodeLimit = nodeLimits.get(requestNodeId);\n+            if (nodeLimit.exceedsLimit()) {\n                 if (isDebugEnabled) {\n-                    LOGGER.debug(\"reached maximum concurrent operations for node {}\", requestNodeId);\n+                    LOGGER.debug(\n+                        \"reached maximum concurrent operations for node {} (limit={}, rrt={}ms, inflight={})\",\n+                        requestNodeId,\n+                        nodeLimit.getLimit(),\n+                        nodeLimit.getLastRtt(TimeUnit.MILLISECONDS),\n+                        nodeLimit.numInflight()\n+                    );\n                 }\n                 return true;\n             }\n@@ -262,7 +270,7 @@ private boolean shouldPauseOnPartitionCreation(ShardedRequests<ShardUpsertReques\n \n     long computeBulkByteThreshold() {\n         long minAcceptableBytes = ByteSizeUnit.KB.toBytes(64);\n-        long localJobs = Math.max(1, nodeJobsCounter.getInProgressJobsForNode(localNode));\n+        long localJobs = Math.max(1, nodeLimits.get(localNode).numInflight());\n         double memoryRatio = 1.0 / localJobs;\n         long wantedBytes = Math.max(\n             (long) (queryCircuitBreaker.getFree() * BREAKER_LIMIT_PERCENTAGE * memoryRatio), minAcceptableBytes);\n@@ -272,12 +280,13 @@ long computeBulkByteThreshold() {\n \n     @Override\n     public CompletableFuture<? extends Iterable<Row>> apply(BatchIterator<Row> batchIterator) {\n-        nodeJobsCounter.increment(localNode);\n+        final ConcurrencyLimit nodeLimit = nodeLimits.get(localNode);\n+        long startTime = nodeLimit.startSample();\n         long bulkBytesThreshold;\n         try {\n             bulkBytesThreshold = computeBulkByteThreshold();\n         } catch (Throwable t) {\n-            nodeJobsCounter.decrement(localNode);\n+            nodeLimit.onSample(startTime, true);\n             return CompletableFuture.failedFuture(t);\n         }\n         var isUsedBytesOverThreshold = new IsUsedBytesOverThreshold(bulkBytesThreshold);\n@@ -308,15 +317,24 @@ long computeBulkByteThreshold() {\n                 resultCollector.combiner(),\n                 resultCollector.supplier().get(),\n                 shouldPause,\n-                BACKOFF_POLICY\n+                req -> getMaxLastRttInMs(req)\n             );\n         return executor.consumeIteratorAndExecute()\n             .thenApply(upsertResults -> resultCollector.finisher().apply(upsertResults))\n             .whenComplete((res, err) -> {\n-                nodeJobsCounter.decrement(localNode);\n+                nodeLimit.onSample(startTime, false);\n             });\n     }\n \n+    private long getMaxLastRttInMs(ShardedRequests<ShardUpsertRequest, Item> req) {\n+        long rtt = 0;\n+        for (var shardLocation : req.itemsByShard.keySet()) {\n+            String nodeId = shardLocation.nodeId;\n+            rtt = Math.max(rtt, nodeLimits.get(nodeId).getLastRtt(TimeUnit.MILLISECONDS));\n+        }\n+        return rtt;\n+    }\n+\n     private class ShardResponseActionListener implements ActionListener<ShardResponse> {\n         private final String operationNodeId;\n         private final UpsertResultCollector.Accumulator resultAccumulator;\n@@ -325,34 +343,37 @@ long computeBulkByteThreshold() {\n         private final AtomicInteger numRequests;\n         private final AtomicReference<Exception> interrupt;\n         private final CompletableFuture<UpsertResults> upsertResultFuture;\n+        private final long startTime;\n \n         ShardResponseActionListener(String operationNodeId,\n                                     AtomicInteger numRequests,\n                                     AtomicReference<Exception> interrupt,\n                                     UpsertResults upsertResults,\n                                     UpsertResultCollector.Accumulator resultAccumulator,\n                                     List<RowSourceInfo> rowSourceInfos,\n+                                    long startTime,\n                                     CompletableFuture<UpsertResults> upsertResultFuture) {\n             this.operationNodeId = operationNodeId;\n             this.numRequests = numRequests;\n             this.interrupt = interrupt;\n             this.upsertResults = upsertResults;\n             this.resultAccumulator = resultAccumulator;\n             this.rowSourceInfos = rowSourceInfos;\n+            this.startTime = startTime;\n             this.upsertResultFuture = upsertResultFuture;\n         }\n \n         @Override\n         public void onResponse(ShardResponse shardResponse) {\n-            nodeJobsCounter.decrement(operationNodeId);\n+            nodeLimits.get(operationNodeId).onSample(startTime, false);\n             resultAccumulator.accept(upsertResults, shardResponse, rowSourceInfos);\n             maybeSetInterrupt(shardResponse.failure());\n             countdown();\n         }\n \n         @Override\n         public void onFailure(Exception e) {\n-            nodeJobsCounter.decrement(operationNodeId);\n+            nodeLimits.get(operationNodeId).onSample(startTime, true);\n             countdown();\n         }\n "
  },
  {
    "sha": "6766d6b2fc7b097a4c4836f25cb2349119c6df89",
    "filename": "server/src/main/java/io/crate/execution/engine/pipeline/ProjectionToProjectorVisitor.java",
    "status": "modified",
    "additions": 4,
    "deletions": 4,
    "changes": 8,
    "blob_url": "https://github.com/crate/crate/blob/a45d4e4a7f5ebadd5f2f7a66fef58ddae8735aeb/server/src/main/java/io/crate/execution/engine/pipeline/ProjectionToProjectorVisitor.java",
    "raw_url": "https://github.com/crate/crate/raw/a45d4e4a7f5ebadd5f2f7a66fef58ddae8735aeb/server/src/main/java/io/crate/execution/engine/pipeline/ProjectionToProjectorVisitor.java",
    "contents_url": "https://api.github.com/repos/crate/crate/contents/server/src/main/java/io/crate/execution/engine/pipeline/ProjectionToProjectorVisitor.java?ref=a45d4e4a7f5ebadd5f2f7a66fef58ddae8735aeb",
    "patch": "@@ -76,7 +76,7 @@\n import io.crate.execution.engine.sort.SortingProjector;\n import io.crate.execution.engine.sort.SortingTopNProjector;\n import io.crate.execution.engine.window.WindowProjector;\n-import io.crate.execution.jobs.NodeJobsCounter;\n+import io.crate.execution.jobs.NodeLimits;\n import io.crate.execution.support.ThreadPools;\n import io.crate.expression.InputFactory;\n import io.crate.expression.RowFilter;\n@@ -141,7 +141,7 @@\n     private static final int UNBOUNDED_COLLECTOR_THRESHOLD = 10_000;\n \n     private final ClusterService clusterService;\n-    private final NodeJobsCounter nodeJobsCounter;\n+    private final NodeLimits nodeJobsCounter;\n     private final NodeContext nodeCtx;\n     private final ThreadPool threadPool;\n     private final Settings settings;\n@@ -158,7 +158,7 @@\n \n \n     public ProjectionToProjectorVisitor(ClusterService clusterService,\n-                                        NodeJobsCounter nodeJobsCounter,\n+                                        NodeLimits nodeJobsCounter,\n                                         CircuitBreakerService circuitBreakerService,\n                                         NodeContext nodeCtx,\n                                         ThreadPool threadPool,\n@@ -187,7 +187,7 @@ public ProjectionToProjectorVisitor(ClusterService clusterService,\n     }\n \n     public ProjectionToProjectorVisitor(ClusterService clusterService,\n-                                        NodeJobsCounter nodeJobsCounter,\n+                                        NodeLimits nodeJobsCounter,\n                                         CircuitBreakerService circuitBreakerService,\n                                         NodeContext nodeCtx,\n                                         ThreadPool threadPool,"
  },
  {
    "sha": "60da9ed0497019a241539db66ff8538f229d38c9",
    "filename": "server/src/main/java/io/crate/execution/jobs/JobSetup.java",
    "status": "modified",
    "additions": 1,
    "deletions": 1,
    "changes": 2,
    "blob_url": "https://github.com/crate/crate/blob/a45d4e4a7f5ebadd5f2f7a66fef58ddae8735aeb/server/src/main/java/io/crate/execution/jobs/JobSetup.java",
    "raw_url": "https://github.com/crate/crate/raw/a45d4e4a7f5ebadd5f2f7a66fef58ddae8735aeb/server/src/main/java/io/crate/execution/jobs/JobSetup.java",
    "contents_url": "https://api.github.com/repos/crate/crate/contents/server/src/main/java/io/crate/execution/jobs/JobSetup.java?ref=a45d4e4a7f5ebadd5f2f7a66fef58ddae8735aeb",
    "patch": "@@ -150,7 +150,7 @@ public JobSetup(Settings settings,\n                     Schemas schemas,\n                     MapSideDataCollectOperation collectOperation,\n                     ClusterService clusterService,\n-                    NodeJobsCounter nodeJobsCounter,\n+                    NodeLimits nodeJobsCounter,\n                     CircuitBreakerService circuitBreakerService,\n                     CountOperation countOperation,\n                     ThreadPool threadPool,"
  },
  {
    "sha": "118400527738952b23b800c8ced410b3f389a0bf",
    "filename": "server/src/main/java/io/crate/execution/jobs/NodeJobsCounter.java",
    "status": "removed",
    "additions": 0,
    "deletions": 95,
    "changes": 95,
    "blob_url": "https://github.com/crate/crate/blob/a900f95ba96f5a57ca6b6aee615a9af8fcf2348d/server/src/main/java/io/crate/execution/jobs/NodeJobsCounter.java",
    "raw_url": "https://github.com/crate/crate/raw/a900f95ba96f5a57ca6b6aee615a9af8fcf2348d/server/src/main/java/io/crate/execution/jobs/NodeJobsCounter.java",
    "contents_url": "https://api.github.com/repos/crate/crate/contents/server/src/main/java/io/crate/execution/jobs/NodeJobsCounter.java?ref=a900f95ba96f5a57ca6b6aee615a9af8fcf2348d",
    "patch": "@@ -1,95 +0,0 @@\n-/*\n- * Licensed to Crate under one or more contributor license agreements.\n- * See the NOTICE file distributed with this work for additional\n- * information regarding copyright ownership.  Crate licenses this file\n- * to you under the Apache License, Version 2.0 (the \"License\"); you may\n- * not use this file except in compliance with the License.  You may\n- * obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n- * implied.  See the License for the specific language governing\n- * permissions and limitations under the License.\n- *\n- * However, if you have executed another commercial license agreement\n- * with Crate these terms will supersede the license and you may use the\n- * software solely pursuant to the terms of the relevant commercial\n- * agreement.\n- */\n-\n-package io.crate.execution.jobs;\n-\n-import org.elasticsearch.common.inject.Singleton;\n-\n-import javax.annotation.Nullable;\n-import java.util.Map;\n-import java.util.concurrent.ConcurrentHashMap;\n-import java.util.concurrent.atomic.AtomicLong;\n-import java.util.function.BiFunction;\n-\n-/**\n- * Counts how many operations issued from the current node are in progress across the cluster.\n- * If the destination node cannot be determined, it counts the in progress operations towards the unknown node.\n- * Note: one job can span multiple nodes.\n- */\n-@Singleton\n-public class NodeJobsCounter {\n-\n-    /**\n-     * Represents the maximum number of concurrent operations that can be issued towards a node.\n-     */\n-    public static final long MAX_NODE_CONCURRENT_OPERATIONS = 5;\n-\n-    private final AtomicLong unknownNodeCount = new AtomicLong();\n-    // Using single element long[] to avoid autoboxing\n-    private final Map<String, long[]> operationsCountPerNode = new ConcurrentHashMap<>();\n-\n-    private static final BiFunction<String, long[], long[]> INCREMENT_COUNTER_FOR_NODE = (node, count) -> {\n-        if (count == null) {\n-            count = new long[1];\n-            count[0] = 1;\n-        } else {\n-            count[0]++;\n-        }\n-        return count;\n-    };\n-\n-    private static final BiFunction<String, long[], long[]> DECREMENT_COUNTER_FOR_NODE = (id, count) -> {\n-        if (count == null) {\n-            count = new long[1];\n-            count[0] = 0;\n-        } else {\n-            count[0]--;\n-        }\n-        return count;\n-    };\n-\n-\n-    public void increment(@Nullable String nodeId) {\n-        if (nodeId == null) {\n-            unknownNodeCount.incrementAndGet();\n-        } else {\n-            operationsCountPerNode.compute(nodeId, INCREMENT_COUNTER_FOR_NODE);\n-        }\n-    }\n-\n-    public void decrement(@Nullable String nodeId) {\n-        if (nodeId == null) {\n-            unknownNodeCount.decrementAndGet();\n-        } else {\n-            operationsCountPerNode.compute(nodeId, DECREMENT_COUNTER_FOR_NODE);\n-        }\n-    }\n-\n-    public long getInProgressJobsForNode(@Nullable String nodeId) {\n-        if (nodeId == null) {\n-            return unknownNodeCount.get();\n-        } else {\n-            long[] countPerNode = operationsCountPerNode.get(nodeId);\n-            return countPerNode == null ? 0L : countPerNode[0];\n-        }\n-    }\n-}"
  },
  {
    "sha": "5e841181bd690afd34fd64328766633eef447a94",
    "filename": "server/src/main/java/io/crate/execution/jobs/NodeLimits.java",
    "status": "added",
    "additions": 53,
    "deletions": 0,
    "changes": 53,
    "blob_url": "https://github.com/crate/crate/blob/a45d4e4a7f5ebadd5f2f7a66fef58ddae8735aeb/server/src/main/java/io/crate/execution/jobs/NodeLimits.java",
    "raw_url": "https://github.com/crate/crate/raw/a45d4e4a7f5ebadd5f2f7a66fef58ddae8735aeb/server/src/main/java/io/crate/execution/jobs/NodeLimits.java",
    "contents_url": "https://api.github.com/repos/crate/crate/contents/server/src/main/java/io/crate/execution/jobs/NodeLimits.java?ref=a45d4e4a7f5ebadd5f2f7a66fef58ddae8735aeb",
    "patch": "@@ -0,0 +1,53 @@\n+/*\n+ * Licensed to Crate under one or more contributor license agreements.\n+ * See the NOTICE file distributed with this work for additional\n+ * information regarding copyright ownership.  Crate licenses this file\n+ * to you under the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.  You may\n+ * obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n+ * implied.  See the License for the specific language governing\n+ * permissions and limitations under the License.\n+ *\n+ * However, if you have executed another commercial license agreement\n+ * with Crate these terms will supersede the license and you may use the\n+ * software solely pursuant to the terms of the relevant commercial\n+ * agreement.\n+ */\n+\n+package io.crate.execution.jobs;\n+\n+import java.util.Map;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import javax.annotation.Nullable;\n+\n+import org.elasticsearch.common.inject.Singleton;\n+\n+import io.crate.concurrent.limits.ConcurrencyLimit;\n+\n+/**\n+ * Tracks concurrency limits per node\n+ */\n+@Singleton\n+public class NodeLimits {\n+\n+    private final ConcurrencyLimit unknownNodelimit = ConcurrencyLimit.newDefault();\n+    private final Map<String, ConcurrencyLimit> limitsPerNode = new ConcurrentHashMap<>();\n+\n+    public ConcurrencyLimit get(@Nullable String nodeId) {\n+        if (nodeId == null) {\n+            return unknownNodelimit;\n+        }\n+        return limitsPerNode.computeIfAbsent(nodeId, ignored -> ConcurrencyLimit.newDefault());\n+    }\n+\n+    public void nodeDisconnected(String nodeId) {\n+        limitsPerNode.remove(nodeId);\n+    }\n+}"
  },
  {
    "sha": "b5920ffe6f6a4a7b1675949a120d7bdff558ffe5",
    "filename": "server/src/main/java/io/crate/execution/jobs/transport/NodeDisconnectJobMonitorService.java",
    "status": "modified",
    "additions": 6,
    "deletions": 1,
    "changes": 7,
    "blob_url": "https://github.com/crate/crate/blob/a45d4e4a7f5ebadd5f2f7a66fef58ddae8735aeb/server/src/main/java/io/crate/execution/jobs/transport/NodeDisconnectJobMonitorService.java",
    "raw_url": "https://github.com/crate/crate/raw/a45d4e4a7f5ebadd5f2f7a66fef58ddae8735aeb/server/src/main/java/io/crate/execution/jobs/transport/NodeDisconnectJobMonitorService.java",
    "contents_url": "https://api.github.com/repos/crate/crate/contents/server/src/main/java/io/crate/execution/jobs/transport/NodeDisconnectJobMonitorService.java?ref=a45d4e4a7f5ebadd5f2f7a66fef58ddae8735aeb",
    "patch": "@@ -38,10 +38,11 @@\n import org.elasticsearch.transport.TransportConnectionListener;\n import org.elasticsearch.transport.TransportService;\n \n-import io.crate.user.User;\n+import io.crate.execution.jobs.NodeLimits;\n import io.crate.execution.jobs.TasksService;\n import io.crate.execution.jobs.kill.KillJobsRequest;\n import io.crate.execution.jobs.kill.TransportKillJobsNodeAction;\n+import io.crate.user.User;\n \n /**\n  * service that listens to node-disconnected-events and kills jobContexts that were started by the nodes that got disconnected\n@@ -50,16 +51,19 @@\n public class NodeDisconnectJobMonitorService extends AbstractLifecycleComponent implements TransportConnectionListener {\n \n     private final TasksService tasksService;\n+    private final NodeLimits nodeLimits;\n     private final TransportService transportService;\n \n     private final TransportKillJobsNodeAction killJobsNodeAction;\n     private static final Logger LOGGER = LogManager.getLogger(NodeDisconnectJobMonitorService.class);\n \n     @Inject\n     public NodeDisconnectJobMonitorService(TasksService tasksService,\n+                                           NodeLimits nodeLimits,\n                                            TransportService transportService,\n                                            TransportKillJobsNodeAction killJobsNodeAction) {\n         this.tasksService = tasksService;\n+        this.nodeLimits = nodeLimits;\n         this.transportService = transportService;\n         this.killJobsNodeAction = killJobsNodeAction;\n     }\n@@ -84,6 +88,7 @@ public void onNodeConnected(DiscoveryNode node, Transport.Connection connection)\n \n     @Override\n     public void onNodeDisconnected(DiscoveryNode node, Transport.Connection connection) {\n+        nodeLimits.nodeDisconnected(node.getId());\n         killJobsCoordinatedBy(node);\n         broadcastKillToParticipatingNodes(node);\n     }"
  },
  {
    "sha": "e48d62512dfaa63f31c9438281d4ccd0db843855",
    "filename": "server/src/main/java/io/crate/planner/DependencyCarrier.java",
    "status": "modified",
    "additions": 8,
    "deletions": 0,
    "changes": 8,
    "blob_url": "https://github.com/crate/crate/blob/a45d4e4a7f5ebadd5f2f7a66fef58ddae8735aeb/server/src/main/java/io/crate/planner/DependencyCarrier.java",
    "raw_url": "https://github.com/crate/crate/raw/a45d4e4a7f5ebadd5f2f7a66fef58ddae8735aeb/server/src/main/java/io/crate/planner/DependencyCarrier.java",
    "contents_url": "https://api.github.com/repos/crate/crate/contents/server/src/main/java/io/crate/planner/DependencyCarrier.java?ref=a45d4e4a7f5ebadd5f2f7a66fef58ddae8735aeb",
    "patch": "@@ -35,6 +35,7 @@\n import io.crate.execution.ddl.views.TransportDropViewAction;\n import io.crate.execution.dsl.projection.builder.ProjectionBuilder;\n import io.crate.execution.engine.PhasesTaskFactory;\n+import io.crate.execution.jobs.NodeLimits;\n import io.crate.expression.udf.TransportCreateUserDefinedFunctionAction;\n import io.crate.expression.udf.TransportDropUserDefinedFunctionAction;\n import io.crate.metadata.FulltextAnalyzerResolver;\n@@ -76,6 +77,7 @@\n     private final FulltextAnalyzerResolver fulltextAnalyzerResolver;\n     private final RepositoryService repositoryService;\n     private final RepositoryParamValidator repositoryParamValidator;\n+    private final NodeLimits nodeLimits;\n \n     @Inject\n     public DependencyCarrier(Settings settings,\n@@ -85,6 +87,7 @@ public DependencyCarrier(Settings settings,\n                              Schemas schemas,\n                              NodeContext nodeCtx,\n                              ClusterService clusterService,\n+                             NodeLimits nodeLimits,\n                              DCLStatementDispatcher dclStatementDispatcher,\n                              TransportDropTableAction transportDropTableAction,\n                              TransportCreateViewAction createViewAction,\n@@ -105,6 +108,7 @@ public DependencyCarrier(Settings settings,\n         this.schemas = schemas;\n         this.nodeCtx = nodeCtx;\n         this.clusterService = clusterService;\n+        this.nodeLimits = nodeLimits;\n         this.dclStatementDispatcher = dclStatementDispatcher;\n         this.transportDropTableAction = transportDropTableAction;\n         projectionBuilder = new ProjectionBuilder(nodeCtx);\n@@ -212,4 +216,8 @@ public RepositoryService repositoryService() {\n     public TransportAnalyzeAction analyzeAction() {\n         return analyzeAction.get();\n     }\n+\n+    public NodeLimits nodeLimits() {\n+        return nodeLimits;\n+    }\n }"
  },
  {
    "sha": "a16d4c9206967279be2c3f6c8099c8b160611012",
    "filename": "server/src/main/java/io/crate/planner/operators/InsertFromValues.java",
    "status": "modified",
    "additions": 57,
    "deletions": 37,
    "changes": 94,
    "blob_url": "https://github.com/crate/crate/blob/a45d4e4a7f5ebadd5f2f7a66fef58ddae8735aeb/server/src/main/java/io/crate/planner/operators/InsertFromValues.java",
    "raw_url": "https://github.com/crate/crate/raw/a45d4e4a7f5ebadd5f2f7a66fef58ddae8735aeb/server/src/main/java/io/crate/planner/operators/InsertFromValues.java",
    "contents_url": "https://api.github.com/repos/crate/crate/contents/server/src/main/java/io/crate/planner/operators/InsertFromValues.java?ref=a45d4e4a7f5ebadd5f2f7a66fef58ddae8735aeb",
    "patch": "@@ -22,7 +22,46 @@\n \n package io.crate.planner.operators;\n \n+import static io.crate.data.SentinelRow.SENTINEL;\n+import static io.crate.execution.engine.indexing.ShardingUpsertExecutor.BULK_REQUEST_TIMEOUT_SETTING;\n+import static org.elasticsearch.cluster.metadata.IndexMetadata.INDEX_CLOSED_BLOCK;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.function.Function;\n+import java.util.function.Supplier;\n+import java.util.stream.StreamSupport;\n+\n+import javax.annotation.Nullable;\n+\n import com.carrotsearch.hppc.IntArrayList;\n+\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.admin.indices.create.CreatePartitionsRequest;\n+import org.elasticsearch.action.admin.indices.create.TransportCreatePartitionsAction;\n+import org.elasticsearch.action.bulk.BackoffPolicy;\n+import org.elasticsearch.action.support.master.AcknowledgedResponse;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.block.ClusterBlock;\n+import org.elasticsearch.cluster.block.ClusterBlockException;\n+import org.elasticsearch.cluster.metadata.Metadata;\n+import org.elasticsearch.cluster.routing.ShardIterator;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.io.stream.NotSerializableExceptionWrapper;\n+import org.elasticsearch.index.IndexNotFoundException;\n+\n import io.crate.action.FutureActionListener;\n import io.crate.action.LimitedExponentialBackoff;\n import io.crate.analyze.OrderBy;\n@@ -31,6 +70,7 @@\n import io.crate.analyze.relations.TableFunctionRelation;\n import io.crate.breaker.RamAccounting;\n import io.crate.breaker.TypeGuessEstimateRowSize;\n+import io.crate.concurrent.limits.ConcurrencyLimit;\n import io.crate.data.CollectionBucket;\n import io.crate.data.InMemoryBatchIterator;\n import io.crate.data.Input;\n@@ -55,6 +95,7 @@\n import io.crate.execution.engine.indexing.IndexNameResolver;\n import io.crate.execution.engine.indexing.ShardLocation;\n import io.crate.execution.engine.indexing.ShardedRequests;\n+import io.crate.execution.jobs.NodeLimits;\n import io.crate.execution.support.RetryListener;\n import io.crate.expression.InputFactory;\n import io.crate.expression.InputRow;\n@@ -71,41 +112,6 @@\n import io.crate.planner.PlannerContext;\n import io.crate.statistics.TableStats;\n import io.crate.types.DataType;\n-import org.elasticsearch.action.ActionListener;\n-import org.elasticsearch.action.admin.indices.create.CreatePartitionsRequest;\n-import org.elasticsearch.action.admin.indices.create.TransportCreatePartitionsAction;\n-import org.elasticsearch.action.bulk.BackoffPolicy;\n-import org.elasticsearch.action.support.master.AcknowledgedResponse;\n-import org.elasticsearch.cluster.block.ClusterBlock;\n-import org.elasticsearch.cluster.block.ClusterBlockException;\n-import org.elasticsearch.cluster.metadata.Metadata;\n-import org.elasticsearch.cluster.routing.ShardIterator;\n-import org.elasticsearch.cluster.routing.ShardRouting;\n-import org.elasticsearch.cluster.service.ClusterService;\n-import org.elasticsearch.common.io.stream.NotSerializableExceptionWrapper;\n-import org.elasticsearch.index.IndexNotFoundException;\n-\n-import javax.annotation.Nullable;\n-import java.util.ArrayList;\n-import java.util.Arrays;\n-import java.util.Collection;\n-import java.util.HashMap;\n-import java.util.Iterator;\n-import java.util.List;\n-import java.util.Map;\n-import java.util.Set;\n-import java.util.UUID;\n-import java.util.concurrent.CompletableFuture;\n-import java.util.concurrent.ScheduledExecutorService;\n-import java.util.concurrent.atomic.AtomicInteger;\n-import java.util.concurrent.atomic.AtomicReference;\n-import java.util.function.Function;\n-import java.util.function.Supplier;\n-import java.util.stream.StreamSupport;\n-\n-import static io.crate.data.SentinelRow.SENTINEL;\n-import static io.crate.execution.engine.indexing.ShardingUpsertExecutor.BULK_REQUEST_TIMEOUT_SETTING;\n-import static org.elasticsearch.cluster.metadata.IndexMetadata.INDEX_CLOSED_BLOCK;\n \n \n public class InsertFromValues implements LogicalPlan {\n@@ -280,6 +286,8 @@ public void execute(DependencyCarrier dependencies,\n                 shardedRequests,\n                 dependencies.clusterService()).values();\n             return execute(\n+                dependencies.nodeLimits(),\n+                dependencies.clusterService().state(),\n                 shardUpsertRequests,\n                 actionProvider.transportShardUpsertAction(),\n                 dependencies.scheduler());\n@@ -429,6 +437,8 @@ public void execute(DependencyCarrier dependencies,\n                 shardedRequests,\n                 dependencies.clusterService()).values();\n             return execute(\n+                dependencies.nodeLimits(),\n+                dependencies.clusterService().state(),\n                 shardUpsertRequests,\n                 actionProvider.transportShardUpsertAction(),\n                 dependencies.scheduler());\n@@ -621,7 +631,9 @@ private static ShardLocation getShardLocation(String indexName,\n         return shardedRequests.itemsByShard();\n     }\n \n-    private CompletableFuture<ShardResponse.CompressedResult> execute(Collection<ShardUpsertRequest> shardUpsertRequests,\n+    private CompletableFuture<ShardResponse.CompressedResult> execute(NodeLimits nodeLimits,\n+                                                                      ClusterState state,\n+                                                                      Collection<ShardUpsertRequest> shardUpsertRequests,\n                                                                       TransportShardUpsertAction shardUpsertAction,\n                                                                       ScheduledExecutorService scheduler) {\n         ShardResponse.CompressedResult compressedResult = new ShardResponse.CompressedResult();\n@@ -634,10 +646,17 @@ private static ShardLocation getShardLocation(String indexName,\n         AtomicReference<Throwable> lastFailure = new AtomicReference<>(null);\n \n         for (ShardUpsertRequest request : shardUpsertRequests) {\n+            String nodeId = state.routingTable()\n+                .shardRoutingTable(request.shardId())\n+                .primaryShard()\n+                .currentNodeId();\n+            final ConcurrencyLimit nodeLimit = nodeLimits.get(nodeId);\n+            final long startTime = nodeLimit.startSample();\n \n             ActionListener<ShardResponse> listener = new ActionListener<>() {\n                 @Override\n                 public void onResponse(ShardResponse shardResponse) {\n+                    nodeLimit.onSample(startTime, false);\n                     Throwable throwable = shardResponse.failure();\n                     if (throwable == null) {\n                         synchronized (compressedResult) {\n@@ -651,6 +670,7 @@ public void onResponse(ShardResponse shardResponse) {\n \n                 @Override\n                 public void onFailure(Exception e) {\n+                    nodeLimit.onSample(startTime, true);\n                     if (!partitionWasDeleted(e, request.index())) {\n                         synchronized (compressedResult) {\n                             compressedResult.markAsFailed(request.items());\n@@ -687,7 +707,7 @@ private void countdown() {\n                     scheduler,\n                     l -> shardUpsertAction.execute(request, l),\n                     listener,\n-                    BACK_OFF_POLICY\n+                    LimitedExponentialBackoff.limitedExponential(nodeLimit)\n                 )\n             );\n         }"
  },
  {
    "sha": "0aa60b2ed8f1d28066d9fbe75293a148e696d102",
    "filename": "server/src/test/java/io/crate/execution/engine/indexing/BatchIteratorBackpressureExecutorTest.java",
    "status": "modified",
    "additions": 11,
    "deletions": 12,
    "changes": 23,
    "blob_url": "https://github.com/crate/crate/blob/a45d4e4a7f5ebadd5f2f7a66fef58ddae8735aeb/server/src/test/java/io/crate/execution/engine/indexing/BatchIteratorBackpressureExecutorTest.java",
    "raw_url": "https://github.com/crate/crate/raw/a45d4e4a7f5ebadd5f2f7a66fef58ddae8735aeb/server/src/test/java/io/crate/execution/engine/indexing/BatchIteratorBackpressureExecutorTest.java",
    "contents_url": "https://api.github.com/repos/crate/crate/contents/server/src/test/java/io/crate/execution/engine/indexing/BatchIteratorBackpressureExecutorTest.java?ref=a45d4e4a7f5ebadd5f2f7a66fef58ddae8735aeb",
    "patch": "@@ -22,17 +22,6 @@\n \n package io.crate.execution.engine.indexing;\n \n-import io.crate.data.BatchIterator;\n-import io.crate.data.InMemoryBatchIterator;\n-import org.elasticsearch.test.ESTestCase;\n-import io.crate.testing.BatchSimulatingIterator;\n-import org.elasticsearch.action.bulk.BackoffPolicy;\n-import io.crate.common.unit.TimeValue;\n-import org.hamcrest.Matchers;\n-import org.junit.After;\n-import org.junit.Before;\n-import org.junit.Test;\n-\n import java.util.UUID;\n import java.util.concurrent.CompletableFuture;\n import java.util.concurrent.ExecutorService;\n@@ -43,6 +32,16 @@\n import java.util.function.Predicate;\n import java.util.stream.IntStream;\n \n+import org.elasticsearch.test.ESTestCase;\n+import org.hamcrest.Matchers;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import io.crate.data.BatchIterator;\n+import io.crate.data.InMemoryBatchIterator;\n+import io.crate.testing.BatchSimulatingIterator;\n+\n public class BatchIteratorBackpressureExecutorTest extends ESTestCase {\n \n     private ExecutorService executor;\n@@ -84,7 +83,7 @@ public void testPauseOnFirstBatch() throws Exception {\n             (a, b) -> a + b,\n             0,\n             shouldPause,\n-            BackoffPolicy.exponentialBackoff(TimeValue.timeValueNanos(10), 1000)\n+            ignored -> 1L\n         );\n         CompletableFuture<Integer> result = executor.consumeIteratorAndExecute();\n         result.get(10, TimeUnit.SECONDS);"
  },
  {
    "sha": "c30674834d1210c3aff0ef77976d5ba7f43a0ef8",
    "filename": "server/src/test/java/io/crate/execution/engine/indexing/IndexWriterProjectorTest.java",
    "status": "modified",
    "additions": 2,
    "deletions": 2,
    "changes": 4,
    "blob_url": "https://github.com/crate/crate/blob/a45d4e4a7f5ebadd5f2f7a66fef58ddae8735aeb/server/src/test/java/io/crate/execution/engine/indexing/IndexWriterProjectorTest.java",
    "raw_url": "https://github.com/crate/crate/raw/a45d4e4a7f5ebadd5f2f7a66fef58ddae8735aeb/server/src/test/java/io/crate/execution/engine/indexing/IndexWriterProjectorTest.java",
    "contents_url": "https://api.github.com/repos/crate/crate/contents/server/src/test/java/io/crate/execution/engine/indexing/IndexWriterProjectorTest.java?ref=a45d4e4a7f5ebadd5f2f7a66fef58ddae8735aeb",
    "patch": "@@ -33,7 +33,7 @@\n import io.crate.execution.engine.collect.CollectExpression;\n import io.crate.execution.engine.collect.InputCollectExpression;\n import io.crate.execution.engine.pipeline.TableSettingsResolver;\n-import io.crate.execution.jobs.NodeJobsCounter;\n+import io.crate.execution.jobs.NodeLimits;\n import io.crate.expression.symbol.InputColumn;\n import io.crate.expression.symbol.Symbol;\n import io.crate.integrationtests.SQLTransportIntegrationTest;\n@@ -86,7 +86,7 @@ public void testIndexWriter() throws Throwable {\n         ThreadPool threadPool = internalCluster().getInstance(ThreadPool.class);\n         IndexWriterProjector writerProjector = new IndexWriterProjector(\n             clusterService(),\n-            new NodeJobsCounter(),\n+            new NodeLimits(),\n             new NoopCircuitBreaker(\"dummy\"),\n             RamAccounting.NO_ACCOUNTING,\n             threadPool.scheduler(),"
  },
  {
    "sha": "8ef47cf7e95ddc41f3117e708428c72664643eb1",
    "filename": "server/src/test/java/io/crate/execution/engine/indexing/IndexWriterProjectorUnitTest.java",
    "status": "modified",
    "additions": 2,
    "deletions": 2,
    "changes": 4,
    "blob_url": "https://github.com/crate/crate/blob/a45d4e4a7f5ebadd5f2f7a66fef58ddae8735aeb/server/src/test/java/io/crate/execution/engine/indexing/IndexWriterProjectorUnitTest.java",
    "raw_url": "https://github.com/crate/crate/raw/a45d4e4a7f5ebadd5f2f7a66fef58ddae8735aeb/server/src/test/java/io/crate/execution/engine/indexing/IndexWriterProjectorUnitTest.java",
    "contents_url": "https://api.github.com/repos/crate/crate/contents/server/src/test/java/io/crate/execution/engine/indexing/IndexWriterProjectorUnitTest.java?ref=a45d4e4a7f5ebadd5f2f7a66fef58ddae8735aeb",
    "patch": "@@ -29,7 +29,7 @@\n import io.crate.data.RowN;\n import io.crate.execution.engine.collect.CollectExpression;\n import io.crate.execution.engine.collect.InputCollectExpression;\n-import io.crate.execution.jobs.NodeJobsCounter;\n+import io.crate.execution.jobs.NodeLimits;\n import io.crate.expression.symbol.InputColumn;\n import io.crate.expression.symbol.Symbol;\n import io.crate.metadata.ColumnIdent;\n@@ -99,7 +99,7 @@ public void testNullPKValue() throws Throwable {\n         TransportCreatePartitionsAction transportCreatePartitionsAction = mock(TransportCreatePartitionsAction.class);\n         IndexWriterProjector indexWriter = new IndexWriterProjector(\n             clusterService,\n-            new NodeJobsCounter(),\n+            new NodeLimits(),\n             new NoopCircuitBreaker(\"dummy\"),\n             RamAccounting.NO_ACCOUNTING,\n             scheduler,"
  },
  {
    "sha": "6ee5d8ce61d13a7c923c1873688b41a823dfac18",
    "filename": "server/src/test/java/io/crate/execution/engine/pipeline/ProjectingRowConsumerTest.java",
    "status": "modified",
    "additions": 2,
    "deletions": 2,
    "changes": 4,
    "blob_url": "https://github.com/crate/crate/blob/a45d4e4a7f5ebadd5f2f7a66fef58ddae8735aeb/server/src/test/java/io/crate/execution/engine/pipeline/ProjectingRowConsumerTest.java",
    "raw_url": "https://github.com/crate/crate/raw/a45d4e4a7f5ebadd5f2f7a66fef58ddae8735aeb/server/src/test/java/io/crate/execution/engine/pipeline/ProjectingRowConsumerTest.java",
    "contents_url": "https://api.github.com/repos/crate/crate/contents/server/src/test/java/io/crate/execution/engine/pipeline/ProjectingRowConsumerTest.java?ref=a45d4e4a7f5ebadd5f2f7a66fef58ddae8735aeb",
    "patch": "@@ -32,7 +32,7 @@\n import io.crate.execution.dsl.projection.FilterProjection;\n import io.crate.execution.dsl.projection.GroupProjection;\n import io.crate.execution.dsl.projection.WriterProjection;\n-import io.crate.execution.jobs.NodeJobsCounter;\n+import io.crate.execution.jobs.NodeLimits;\n import io.crate.expression.InputFactory;\n import io.crate.expression.eval.EvaluatingNormalizer;\n import io.crate.expression.operator.EqOperator;\n@@ -85,7 +85,7 @@ public void prepare() {\n         memoryManager = new OnHeapMemoryManager(usedBytes -> {});\n         projectorFactory = new ProjectionToProjectorVisitor(\n             clusterService,\n-            new NodeJobsCounter(),\n+            new NodeLimits(),\n             new NoneCircuitBreakerService(),\n             nodeCtx,\n             THREAD_POOL,"
  },
  {
    "sha": "c3e19faecf8642d7dc93433680459981929bfc94",
    "filename": "server/src/test/java/io/crate/execution/engine/pipeline/ProjectionToProjectorVisitorTest.java",
    "status": "modified",
    "additions": 2,
    "deletions": 2,
    "changes": 4,
    "blob_url": "https://github.com/crate/crate/blob/a45d4e4a7f5ebadd5f2f7a66fef58ddae8735aeb/server/src/test/java/io/crate/execution/engine/pipeline/ProjectionToProjectorVisitorTest.java",
    "raw_url": "https://github.com/crate/crate/raw/a45d4e4a7f5ebadd5f2f7a66fef58ddae8735aeb/server/src/test/java/io/crate/execution/engine/pipeline/ProjectionToProjectorVisitorTest.java",
    "contents_url": "https://api.github.com/repos/crate/crate/contents/server/src/test/java/io/crate/execution/engine/pipeline/ProjectionToProjectorVisitorTest.java?ref=a45d4e4a7f5ebadd5f2f7a66fef58ddae8735aeb",
    "patch": "@@ -40,7 +40,7 @@\n import io.crate.execution.engine.aggregation.impl.CountAggregation;\n import io.crate.execution.engine.sort.SortingProjector;\n import io.crate.execution.engine.sort.SortingTopNProjector;\n-import io.crate.execution.jobs.NodeJobsCounter;\n+import io.crate.execution.jobs.NodeLimits;\n import io.crate.expression.InputFactory;\n import io.crate.expression.eval.EvaluatingNormalizer;\n import io.crate.expression.operator.EqOperator;\n@@ -98,7 +98,7 @@ public void prepare() {\n         MockitoAnnotations.initMocks(this);\n         visitor = new ProjectionToProjectorVisitor(\n             clusterService,\n-            new NodeJobsCounter(),\n+            new NodeLimits(),\n             new NoneCircuitBreakerService(),\n             nodeCtx,\n             THREAD_POOL,"
  },
  {
    "sha": "1b153c8b2e491507b4299bd6672773ea4d28ad8e",
    "filename": "server/src/test/java/io/crate/execution/engine/pipeline/ProjectorsTest.java",
    "status": "modified",
    "additions": 2,
    "deletions": 2,
    "changes": 4,
    "blob_url": "https://github.com/crate/crate/blob/a45d4e4a7f5ebadd5f2f7a66fef58ddae8735aeb/server/src/test/java/io/crate/execution/engine/pipeline/ProjectorsTest.java",
    "raw_url": "https://github.com/crate/crate/raw/a45d4e4a7f5ebadd5f2f7a66fef58ddae8735aeb/server/src/test/java/io/crate/execution/engine/pipeline/ProjectorsTest.java",
    "contents_url": "https://api.github.com/repos/crate/crate/contents/server/src/test/java/io/crate/execution/engine/pipeline/ProjectorsTest.java?ref=a45d4e4a7f5ebadd5f2f7a66fef58ddae8735aeb",
    "patch": "@@ -27,7 +27,7 @@\n import io.crate.execution.dsl.projection.FilterProjection;\n import io.crate.execution.dsl.projection.GroupProjection;\n import io.crate.execution.engine.aggregation.GroupingProjector;\n-import io.crate.execution.jobs.NodeJobsCounter;\n+import io.crate.execution.jobs.NodeLimits;\n import io.crate.expression.InputFactory;\n import io.crate.expression.eval.EvaluatingNormalizer;\n import io.crate.expression.symbol.AggregateMode;\n@@ -68,7 +68,7 @@ public void prepare() throws Exception {\n         memoryManager = new OnHeapMemoryManager(bytes -> {});\n         projectorFactory = new ProjectionToProjectorVisitor(\n             clusterService,\n-            new NodeJobsCounter(),\n+            new NodeLimits(),\n             new NoneCircuitBreakerService(),\n             nodeCtx,\n             THREAD_POOL,"
  },
  {
    "sha": "c41e0daa11cf166a424bc970b45f56229f4be389",
    "filename": "server/src/test/java/io/crate/execution/jobs/NodeJobsCounterTest.java",
    "status": "removed",
    "additions": 0,
    "deletions": 77,
    "changes": 77,
    "blob_url": "https://github.com/crate/crate/blob/a900f95ba96f5a57ca6b6aee615a9af8fcf2348d/server/src/test/java/io/crate/execution/jobs/NodeJobsCounterTest.java",
    "raw_url": "https://github.com/crate/crate/raw/a900f95ba96f5a57ca6b6aee615a9af8fcf2348d/server/src/test/java/io/crate/execution/jobs/NodeJobsCounterTest.java",
    "contents_url": "https://api.github.com/repos/crate/crate/contents/server/src/test/java/io/crate/execution/jobs/NodeJobsCounterTest.java?ref=a900f95ba96f5a57ca6b6aee615a9af8fcf2348d",
    "patch": "@@ -1,77 +0,0 @@\n-/*\n- * Licensed to Crate under one or more contributor license agreements.\n- * See the NOTICE file distributed with this work for additional\n- * information regarding copyright ownership.  Crate licenses this file\n- * to you under the Apache License, Version 2.0 (the \"License\"); you may\n- * not use this file except in compliance with the License.  You may\n- * obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n- * implied.  See the License for the specific language governing\n- * permissions and limitations under the License.\n- *\n- * However, if you have executed another commercial license agreement\n- * with Crate these terms will supersede the license and you may use the\n- * software solely pursuant to the terms of the relevant commercial\n- * agreement.\n- */\n-\n-package io.crate.execution.jobs;\n-\n-import org.elasticsearch.test.ESTestCase;\n-import org.junit.Before;\n-import org.junit.Test;\n-\n-import static org.hamcrest.core.Is.is;\n-\n-public class NodeJobsCounterTest extends ESTestCase {\n-\n-    private NodeJobsCounter nodeJobsCounter;\n-\n-    @Before\n-    public void setupJobsTracker() {\n-        nodeJobsCounter = new NodeJobsCounter();\n-    }\n-\n-    @Test\n-    public void testIncrementUpdatesStats() {\n-        nodeJobsCounter.increment(\"node1\");\n-        assertThat(nodeJobsCounter.getInProgressJobsForNode(\"node1\"), is(1L));\n-    }\n-\n-    @Test\n-    public void testDecrementSpecifiedNodeOnly() {\n-        nodeJobsCounter.increment(\"node1\");\n-        nodeJobsCounter.increment(\"node2\");\n-\n-        nodeJobsCounter.decrement(\"node1\");\n-\n-        assertThat(nodeJobsCounter.getInProgressJobsForNode(\"node1\"), is(0L));\n-        assertThat(nodeJobsCounter.getInProgressJobsForNode(\"node2\"), is(1L));\n-    }\n-\n-    @Test\n-    public void testIncrementNullUpdatesStatsForUnidentifiedNode() {\n-        try {\n-            nodeJobsCounter.increment(null);\n-        } catch (Throwable e) {\n-            fail(\"Did not expect exception when attempting to register a job against null node but got: \" +\n-                 e.getMessage());\n-        }\n-        long jobsForNullNode = nodeJobsCounter.getInProgressJobsForNode(null);\n-        assertThat(jobsForNullNode, is(1L));\n-    }\n-\n-    @Test\n-    public void testDecrementForNullDoesntFail() {\n-        try {\n-            nodeJobsCounter.decrement(null);\n-        } catch (Exception e) {\n-            fail(\"Did not expect unregistering a job for a null node to fail but got: \" + e.getMessage());\n-        }\n-    }\n-}"
  }
]
