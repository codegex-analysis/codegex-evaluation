[
  {
    "sha": "e73797880a14531561f320f54397d712aaf5f2a8",
    "filename": "app/build.gradle",
    "status": "modified",
    "additions": 1,
    "deletions": 1,
    "changes": 2,
    "blob_url": "https://github.com/ivang7/fingen/blob/216f9b373a5bf0a297e9496a050033a32424050a/app/build.gradle",
    "raw_url": "https://github.com/ivang7/fingen/raw/216f9b373a5bf0a297e9496a050033a32424050a/app/build.gradle",
    "contents_url": "https://api.github.com/repos/ivang7/fingen/contents/app/build.gradle?ref=216f9b373a5bf0a297e9496a050033a32424050a",
    "patch": "@@ -143,7 +143,7 @@ dependencies {\n     implementation \"com.android.support:support-v13:$support\"\n //    implementation \"com.google.android.gms:play-services-auth:$play\"\n //    implementation \"com.google.android.gms:play-services-maps:$play\"\n-    implementation 'com.dlazaro66.qrcodereaderview:qrcodereaderview:2.0.3'\n+    implementation 'com.google.android.gms:play-services-vision:10.2.4'\n     implementation 'com.dropbox.core:dropbox-core-sdk:3.0.6'\n     implementation 'com.evernote:android-job:1.2.5'\n     implementation 'com.github.angads25:filepicker:1.1.1'"
  },
  {
    "sha": "17d8fc40057e4d7b2f2c63ef3208be7456d8a9d0",
    "filename": "app/src/main/java/com/yoshione/fingen/fts/ActivityScanQR.java",
    "status": "modified",
    "additions": 87,
    "deletions": 52,
    "changes": 139,
    "blob_url": "https://github.com/ivang7/fingen/blob/216f9b373a5bf0a297e9496a050033a32424050a/app/src/main/java/com/yoshione/fingen/fts/ActivityScanQR.java",
    "raw_url": "https://github.com/ivang7/fingen/raw/216f9b373a5bf0a297e9496a050033a32424050a/app/src/main/java/com/yoshione/fingen/fts/ActivityScanQR.java",
    "contents_url": "https://api.github.com/repos/ivang7/fingen/contents/app/src/main/java/com/yoshione/fingen/fts/ActivityScanQR.java?ref=216f9b373a5bf0a297e9496a050033a32424050a",
    "patch": "@@ -6,36 +6,44 @@\n import android.content.Intent;\n import android.content.pm.PackageManager;\n import android.graphics.PointF;\n+import android.hardware.Camera;\n import android.os.Bundle;\n import android.support.annotation.NonNull;\n import android.support.design.widget.Snackbar;\n import android.support.v4.app.ActivityCompat;\n import android.support.v7.app.AlertDialog;\n import android.support.v7.app.AppCompatActivity;\n+import android.util.DisplayMetrics;\n+import android.util.SparseArray;\n+import android.view.SurfaceHolder;\n+import android.view.SurfaceView;\n import android.view.View;\n import android.view.ViewGroup;\n import android.widget.CheckBox;\n-import android.widget.CompoundButton;\n import android.widget.Toast;\n \n-import com.dlazaro66.qrcodereaderview.QRCodeReaderView;\n-import com.dlazaro66.qrcodereaderview.QRCodeReaderView.OnQRCodeReadListener;\n+import com.google.android.gms.vision.Detector;\n+import com.google.android.gms.vision.barcode.Barcode;\n+import com.google.android.gms.vision.barcode.BarcodeDetector;\n import com.yoshione.fingen.R;\n import com.yoshione.fingen.managers.TransactionManager;\n import com.yoshione.fingen.model.Transaction;\n import com.yoshione.fingen.utils.ColorUtils;\n \n+import java.io.IOException;\n import java.util.regex.Matcher;\n import java.util.regex.Pattern;\n \n public class ActivityScanQR extends AppCompatActivity\n-        implements ActivityCompat.OnRequestPermissionsResultCallback, OnQRCodeReadListener {\n+        implements ActivityCompat.OnRequestPermissionsResultCallback {\n \n+    private static final String TAG = \"ActivityScanQR\";\n     private static final int MY_PERMISSION_REQUEST_CAMERA = 0;\n \n     private ViewGroup mainLayout;\n \n-    private QRCodeReaderView qrCodeReaderView;\n+    private CameraSource mCameraSource;\n+    private SurfaceView qrCodeReaderView;\n     private PointsOverlayView pointsOverlayView;\n \n     @Override\n@@ -47,25 +55,21 @@ protected void onCreate(Bundle savedInstanceState) {\n \n         // clipboard worker copied from ActivitySmsList\n         ClipboardManager clipboard = (ClipboardManager) getSystemService(CLIPBOARD_SERVICE);\n-        if (!clipboard.hasPrimaryClip()) return;\n-        ClipData data = clipboard.getPrimaryClip();\n-        ClipData.Item item = data.getItemAt(0);\n-\n-        String text = \"\";\n-        if (item != null) {\n-            try {\n-                text = item.getText().toString();\n-            } catch (Exception e) {\n-                Toast.makeText(this, getString(R.string.err_parse_clipboard), Toast.LENGTH_SHORT).show();\n+        if (clipboard.hasPrimaryClip()) {\n+            ClipData data = clipboard.getPrimaryClip();\n+            ClipData.Item item = data.getItemAt(0);\n+\n+            String text = \"\";\n+            if (item != null) {\n+                try {\n+                    text = item.getText().toString();\n+                } catch (Exception e) {\n+                    Toast.makeText(this, getString(R.string.err_parse_clipboard), Toast.LENGTH_SHORT).show();\n+                }\n             }\n-        }\n-\n-        Pattern pattern = Pattern.compile(\"^t=\\\\d+T\\\\d+&s=[\\\\d\\\\.]{4,12}&fn=\\\\d+&i=\\\\d+&fp=\\\\d+&n=\\\\d$\", Pattern.CASE_INSENSITIVE);\n-        Matcher matcher = pattern.matcher(text);\n \n-        if (ActivityCompat.checkSelfPermission(this, Manifest.permission.CAMERA)\n-                == PackageManager.PERMISSION_GRANTED) {\n-            initQRCodeReaderView();\n+            Pattern pattern = Pattern.compile(\"^t=\\\\d+T\\\\d+&s=[\\\\d\\\\.]{4,12}&fn=\\\\d+&i=\\\\d+&fp=\\\\d+&n=\\\\d$\", Pattern.CASE_INSENSITIVE);\n+            Matcher matcher = pattern.matcher(text);\n \n             if (!text.equals(\"\") && matcher.find()) {\n                 final String qrCode = text;\n@@ -75,28 +79,16 @@ protected void onCreate(Bundle savedInstanceState) {\n                         .setTitle(R.string.ttl_confirm_action)\n                         .setMessage(R.string.msg_use_qr_from_buffer)\n                         .setPositiveButton(R.string.ok, (dialog, which) ->this.onQRCodeRead(qrCode, null))\n-                        .setNegativeButton(R.string.cancel, (dialog, which) -> dialog.dismiss()).show();\n+                        .setNegativeButton(R.string.cancel, (dialog, which) -> dialog.dismiss())\n+                        .show();\n             }\n-        } else {\n-            requestCameraPermission();\n         }\n-    }\n \n-    @Override\n-    protected void onResume() {\n-        super.onResume();\n-\n-        if (qrCodeReaderView != null) {\n-            qrCodeReaderView.startCamera();\n-        }\n-    }\n-\n-    @Override\n-    protected void onPause() {\n-        super.onPause();\n-\n-        if (qrCodeReaderView != null) {\n-            qrCodeReaderView.stopCamera();\n+        if (ActivityCompat.checkSelfPermission(this, Manifest.permission.CAMERA)\n+                == PackageManager.PERMISSION_GRANTED) {\n+            initQRCodeReaderView();\n+        } else {\n+            requestCameraPermission();\n         }\n     }\n \n@@ -123,7 +115,6 @@ public void onRequestPermissionsResult(int requestCode, @NonNull String[] permis\n     // Called when a QR is decoded\n     // \"text\" : the text encoded in QR\n     // \"points\" : points where QR control points are placed\n-    @Override\n     public void onQRCodeRead(String text, PointF[] points) {\n //    resultTextView.setText(text);\n //    pointsOverlayView.setPoints(points);\n@@ -169,18 +160,62 @@ private void initQRCodeReaderView() {\n         CheckBox flashlightCheckBox = content.findViewById(R.id.flashlight_checkbox);\n         pointsOverlayView = content.findViewById(R.id.points_overlay_view);\n \n-        if (getPackageManager().hasSystemFeature(PackageManager.FEATURE_CAMERA_AUTOFOCUS)) {\n-            qrCodeReaderView.setAutofocusInterval(2000L);\n-        }\n-        qrCodeReaderView.setOnQRCodeReadListener(this);\n-        qrCodeReaderView.setBackCamera();\n-        flashlightCheckBox.setOnCheckedChangeListener(new CompoundButton.OnCheckedChangeListener() {\n+        BarcodeDetector barcodeDetector = new BarcodeDetector.Builder(getApplicationContext())\n+                .setBarcodeFormats(Barcode.QR_CODE)\n+                .build();\n+\n+        // Creates and starts the camera.  Note that this uses a higher resolution in comparison\n+        // to other detection examples to enable the barcode detector to detect small barcodes\n+        // at long distances.\n+        DisplayMetrics metrics = new DisplayMetrics();\n+        getWindowManager().getDefaultDisplay().getMetrics(metrics);\n+\n+        CameraSource.Builder builder = new CameraSource.Builder(getApplicationContext(), barcodeDetector)\n+                .setFacing(CameraSource.CAMERA_FACING_BACK)\n+                .setRequestedPreviewSize(metrics.heightPixels, metrics.widthPixels)\n+                .setRequestedFps(24.0f)\n+                .setFocusMode(Camera.Parameters.FOCUS_MODE_MACRO);\n+\n+        mCameraSource = builder.build();\n+\n+        qrCodeReaderView.getHolder().addCallback(new SurfaceHolder.Callback() {\n+            @Override\n+            public void surfaceCreated(SurfaceHolder holder) {\n+                try {\n+                    mCameraSource.start(holder);\n+                } catch (IOException | SecurityException e) {\n+                    e.printStackTrace();\n+                }\n+            }\n+\n+            @Override\n+            public void surfaceChanged(SurfaceHolder holder, int format, int width, int height) {\n+\n+            }\n+\n             @Override\n-            public void onCheckedChanged(CompoundButton compoundButton, boolean isChecked) {\n-                qrCodeReaderView.setTorchEnabled(isChecked);\n+            public void surfaceDestroyed(SurfaceHolder holder) {\n+                mCameraSource.stop();\n             }\n         });\n-        qrCodeReaderView.setQRDecodingEnabled(true);\n-        qrCodeReaderView.startCamera();\n+\n+        barcodeDetector.setProcessor(new Detector.Processor<Barcode>() {\n+            @Override\n+            public void release() {\n+\n+            }\n+\n+            @Override\n+            public void receiveDetections(Detector.Detections<Barcode> detections) {\n+                SparseArray<Barcode> qrCode = detections.getDetectedItems();\n+\n+                if (qrCode.size() != 0) {\n+                    onQRCodeRead(qrCode.valueAt(0).displayValue, null);\n+                }\n+            }\n+        });\n+\n+        qrCodeReaderView.setOnClickListener(view -> mCameraSource.autoFocus(null));\n+        flashlightCheckBox.setOnCheckedChangeListener((compoundButton, isChecked) -> mCameraSource.setFlashMode(isChecked ? Camera.Parameters.FLASH_MODE_TORCH : Camera.Parameters.FLASH_MODE_OFF));\n     }\n }\n\\ No newline at end of file"
  },
  {
    "sha": "38d4d1ea47396623f2f7d351f3de721231a92485",
    "filename": "app/src/main/java/com/yoshione/fingen/fts/CameraSource.java",
    "status": "added",
    "additions": 1212,
    "deletions": 0,
    "changes": 1212,
    "blob_url": "https://github.com/ivang7/fingen/blob/216f9b373a5bf0a297e9496a050033a32424050a/app/src/main/java/com/yoshione/fingen/fts/CameraSource.java",
    "raw_url": "https://github.com/ivang7/fingen/raw/216f9b373a5bf0a297e9496a050033a32424050a/app/src/main/java/com/yoshione/fingen/fts/CameraSource.java",
    "contents_url": "https://api.github.com/repos/ivang7/fingen/contents/app/src/main/java/com/yoshione/fingen/fts/CameraSource.java?ref=216f9b373a5bf0a297e9496a050033a32424050a",
    "patch": "@@ -0,0 +1,1212 @@\n+/*\n+ * Copyright (C) The Android Open Source Project\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.yoshione.fingen.fts;\n+\n+import android.Manifest;\n+import android.annotation.SuppressLint;\n+import android.annotation.TargetApi;\n+import android.content.Context;\n+import android.graphics.ImageFormat;\n+import android.graphics.SurfaceTexture;\n+import android.hardware.Camera;\n+import android.hardware.Camera.CameraInfo;\n+import android.os.Build;\n+import android.os.SystemClock;\n+import android.support.annotation.Nullable;\n+import android.support.annotation.RequiresPermission;\n+import android.support.annotation.StringDef;\n+import android.util.Log;\n+import android.view.Surface;\n+import android.view.SurfaceHolder;\n+import android.view.SurfaceView;\n+import android.view.WindowManager;\n+\n+import com.google.android.gms.common.images.Size;\n+import com.google.android.gms.vision.Detector;\n+import com.google.android.gms.vision.Frame;\n+\n+import java.io.IOException;\n+import java.lang.Thread.State;\n+import java.lang.annotation.Retention;\n+import java.lang.annotation.RetentionPolicy;\n+import java.nio.ByteBuffer;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+\n+// Note: This requires Google Play Services 8.1 or higher, due to using indirect byte buffers for\n+// storing images.\n+\n+/**\n+ * Manages the camera in conjunction with an underlying\n+ * {@link com.google.android.gms.vision.Detector}.  This receives preview frames from the camera at\n+ * a specified rate, sending those frames to the detector as fast as it is able to process those\n+ * frames.\n+ * <p/>\n+ * This camera source makes a best effort to manage processing on preview frames as fast as\n+ * possible, while at the same time minimizing lag.  As such, frames may be dropped if the detector\n+ * is unable to keep up with the rate of frames generated by the camera.  You should use\n+ * {@link CameraSource.Builder#setRequestedFps(float)} to specify a frame rate that works well with\n+ * the capabilities of the camera hardware and the detector options that you have selected.  If CPU\n+ * utilization is higher than you'd like, then you may want to consider reducing FPS.  If the camera\n+ * preview or detector results are too \"jerky\", then you may want to consider increasing FPS.\n+ * <p/>\n+ * The following Android permission is required to use the camera:\n+ * <ul>\n+ * <li>android.permissions.CAMERA</li>\n+ * </ul>\n+ */\n+\n+public class CameraSource {\n+    @SuppressLint(\"InlinedApi\")\n+    public static final int CAMERA_FACING_BACK = CameraInfo.CAMERA_FACING_BACK;\n+    @SuppressLint(\"InlinedApi\")\n+    public static final int CAMERA_FACING_FRONT = CameraInfo.CAMERA_FACING_FRONT;\n+\n+    private static final String TAG = \"OpenCameraSource\";\n+\n+    /**\n+     * The dummy surface texture must be assigned a chosen name.  Since we never use an OpenGL\n+     * context, we can choose any ID we want here.\n+     */\n+    private static final int DUMMY_TEXTURE_NAME = 100;\n+\n+    /**\n+     * If the absolute difference between a preview size aspect ratio and a picture size aspect\n+     * ratio is less than this tolerance, they are considered to be the same aspect ratio.\n+     */\n+    private static final float ASPECT_RATIO_TOLERANCE = 0.01f;\n+\n+    @StringDef({\n+            Camera.Parameters.FOCUS_MODE_CONTINUOUS_PICTURE,\n+            Camera.Parameters.FOCUS_MODE_CONTINUOUS_VIDEO,\n+            Camera.Parameters.FOCUS_MODE_AUTO,\n+            Camera.Parameters.FOCUS_MODE_EDOF,\n+            Camera.Parameters.FOCUS_MODE_FIXED,\n+            Camera.Parameters.FOCUS_MODE_INFINITY,\n+            Camera.Parameters.FOCUS_MODE_MACRO\n+    })\n+    @Retention(RetentionPolicy.SOURCE)\n+    private @interface FocusMode {}\n+\n+    @StringDef({\n+            Camera.Parameters.FLASH_MODE_ON,\n+            Camera.Parameters.FLASH_MODE_OFF,\n+            Camera.Parameters.FLASH_MODE_AUTO,\n+            Camera.Parameters.FLASH_MODE_RED_EYE,\n+            Camera.Parameters.FLASH_MODE_TORCH\n+    })\n+    @Retention(RetentionPolicy.SOURCE)\n+    private @interface FlashMode {}\n+\n+    private Context mContext;\n+\n+    private final Object mCameraLock = new Object();\n+\n+    // Guarded by mCameraLock\n+    private Camera mCamera;\n+\n+    private int mFacing = CAMERA_FACING_BACK;\n+\n+    /**\n+     * Rotation of the device, and thus the associated preview images captured from the device.\n+     * See {@link Frame.Metadata#getRotation()}.\n+     */\n+    private int mRotation;\n+\n+    private Size mPreviewSize;\n+\n+    // These values may be requested by the caller.  Due to hardware limitations, we may need to\n+    // select close, but not exactly the same values for these.\n+    private float mRequestedFps = 30.0f;\n+    private int mRequestedPreviewWidth = 1024;\n+    private int mRequestedPreviewHeight = 768;\n+\n+\n+    private String mFocusMode = null;\n+    private String mFlashMode = null;\n+\n+    // These instances need to be held onto to avoid GC of their underlying resources.  Even though\n+    // these aren't used outside of the method that creates them, they still must have hard\n+    // references maintained to them.\n+    private SurfaceView mDummySurfaceView;\n+    private SurfaceTexture mDummySurfaceTexture;\n+\n+    /**\n+     * Dedicated thread and associated runnable for calling into the detector with frames, as the\n+     * frames become available from the camera.\n+     */\n+    private Thread mProcessingThread;\n+    private FrameProcessingRunnable mFrameProcessor;\n+\n+    /**\n+     * Map to convert between a byte array, received from the camera, and its associated byte\n+     * buffer.  We use byte buffers internally because this is a more efficient way to call into\n+     * native code later (avoids a potential copy).\n+     */\n+    private Map<byte[], ByteBuffer> mBytesToByteBuffer = new HashMap<>();\n+\n+    //==============================================================================================\n+    // Builder\n+    //==============================================================================================\n+\n+    /**\n+     * Builder for configuring and creating an associated camera source.\n+     */\n+    public static class Builder {\n+        private final Detector<?> mDetector;\n+        private CameraSource mCameraSource = new CameraSource();\n+\n+        /**\n+         * Creates a camera source builder with the supplied context and detector.  Camera preview\n+         * images will be streamed to the associated detector upon starting the camera source.\n+         */\n+        public Builder(Context context, Detector<?> detector) {\n+            if (context == null) {\n+                throw new IllegalArgumentException(\"No context supplied.\");\n+            }\n+            if (detector == null) {\n+                throw new IllegalArgumentException(\"No detector supplied.\");\n+            }\n+\n+            mDetector = detector;\n+            mCameraSource.mContext = context;\n+        }\n+\n+        /**\n+         * Sets the requested frame rate in frames per second.  If the exact requested value is not\n+         * not available, the best matching available value is selected.   Default: 30.\n+         */\n+        public Builder setRequestedFps(float fps) {\n+            if (fps <= 0) {\n+                throw new IllegalArgumentException(\"Invalid fps: \" + fps);\n+            }\n+            mCameraSource.mRequestedFps = fps;\n+            return this;\n+        }\n+\n+        public Builder setFocusMode(@FocusMode String mode) {\n+            mCameraSource.mFocusMode = mode;\n+            return this;\n+        }\n+\n+        public Builder setFlashMode(@FlashMode String mode) {\n+            mCameraSource.mFlashMode = mode;\n+            return this;\n+        }\n+\n+        /**\n+         * Sets the desired width and height of the camera frames in pixels.  If the exact desired\n+         * values are not available options, the best matching available options are selected.\n+         * Also, we try to select a preview size which corresponds to the aspect ratio of an\n+         * associated full picture size, if applicable.  Default: 1024x768.\n+         */\n+        public Builder setRequestedPreviewSize(int width, int height) {\n+            // Restrict the requested range to something within the realm of possibility.  The\n+            // choice of 1000000 is a bit arbitrary -- intended to be well beyond resolutions that\n+            // devices can support.  We bound this to avoid int overflow in the code later.\n+            final int MAX = 1000000;\n+            if ((width <= 0) || (width > MAX) || (height <= 0) || (height > MAX)) {\n+                throw new IllegalArgumentException(\"Invalid preview size: \" + width + \"x\" + height);\n+            }\n+            mCameraSource.mRequestedPreviewWidth = width;\n+            mCameraSource.mRequestedPreviewHeight = height;\n+            return this;\n+        }\n+\n+        /**\n+         * Sets the camera to use (either {@link #CAMERA_FACING_BACK} or\n+         * {@link #CAMERA_FACING_FRONT}). Default: back facing.\n+         */\n+        public Builder setFacing(int facing) {\n+            if ((facing != CAMERA_FACING_BACK) && (facing != CAMERA_FACING_FRONT)) {\n+                throw new IllegalArgumentException(\"Invalid camera: \" + facing);\n+            }\n+            mCameraSource.mFacing = facing;\n+            return this;\n+        }\n+\n+        /**\n+         * Creates an instance of the camera source.\n+         */\n+        public CameraSource build() {\n+            mCameraSource.mFrameProcessor = mCameraSource.new FrameProcessingRunnable(mDetector);\n+            return mCameraSource;\n+        }\n+    }\n+\n+    //==============================================================================================\n+    // Bridge Functionality for the Camera1 API\n+    //==============================================================================================\n+\n+    /**\n+     * Callback interface used to signal the moment of actual image capture.\n+     */\n+    public interface ShutterCallback {\n+        /**\n+         * Called as near as possible to the moment when a photo is captured from the sensor. This\n+         * is a good opportunity to play a shutter sound or give other feedback of camera operation.\n+         * This may be some time after the photo was triggered, but some time before the actual data\n+         * is available.\n+         */\n+        void onShutter();\n+    }\n+\n+    /**\n+     * Callback interface used to supply image data from a photo capture.\n+     */\n+    public interface PictureCallback {\n+        /**\n+         * Called when image data is available after a picture is taken.  The format of the data\n+         * is a jpeg binary.\n+         */\n+        void onPictureTaken(byte[] data);\n+    }\n+\n+    /**\n+     * Callback interface used to notify on completion of camera auto focus.\n+     */\n+    public interface AutoFocusCallback {\n+        /**\n+         * Called when the camera auto focus completes.  If the camera\n+         * does not support auto-focus and autoFocus is called,\n+         * onAutoFocus will be called immediately with a fake value of\n+         * <code>success</code> set to <code>true</code>.\n+         * <p/>\n+         * The auto-focus routine does not lock auto-exposure and auto-white\n+         * balance after it completes.\n+         *\n+         * @param success true if focus was successful, false if otherwise\n+         */\n+        void onAutoFocus(boolean success);\n+    }\n+\n+    /**\n+     * Callback interface used to notify on auto focus start and stop.\n+     * <p/>\n+     * <p>This is only supported in continuous autofocus modes -- {@link\n+     * Camera.Parameters#FOCUS_MODE_CONTINUOUS_VIDEO} and {@link\n+     * Camera.Parameters#FOCUS_MODE_CONTINUOUS_PICTURE}. Applications can show\n+     * autofocus animation based on this.</p>\n+     */\n+    public interface AutoFocusMoveCallback {\n+        /**\n+         * Called when the camera auto focus starts or stops.\n+         *\n+         * @param start true if focus starts to move, false if focus stops to move\n+         */\n+        void onAutoFocusMoving(boolean start);\n+    }\n+\n+    //==============================================================================================\n+    // Public\n+    //==============================================================================================\n+\n+    /**\n+     * Stops the camera and releases the resources of the camera and underlying detector.\n+     */\n+    public void release() {\n+        synchronized (mCameraLock) {\n+            stop();\n+            mFrameProcessor.release();\n+        }\n+    }\n+\n+    /**\n+     * Opens the camera and starts sending preview frames to the underlying detector.  The preview\n+     * frames are not displayed.\n+     *\n+     * @throws IOException if the camera's preview texture or display could not be initialized\n+     */\n+    @RequiresPermission(Manifest.permission.CAMERA)\n+    public CameraSource start() throws IOException {\n+        synchronized (mCameraLock) {\n+            if (mCamera != null) {\n+                return this;\n+            }\n+\n+            mCamera = createCamera();\n+\n+            // SurfaceTexture was introduced in Honeycomb (11), so if we are running and\n+            // old version of Android. fall back to use SurfaceView.\n+            if (Build.VERSION.SDK_INT >= Build.VERSION_CODES.HONEYCOMB) {\n+                mDummySurfaceTexture = new SurfaceTexture(DUMMY_TEXTURE_NAME);\n+                mCamera.setPreviewTexture(mDummySurfaceTexture);\n+            } else {\n+                mDummySurfaceView = new SurfaceView(mContext);\n+                mCamera.setPreviewDisplay(mDummySurfaceView.getHolder());\n+            }\n+            mCamera.startPreview();\n+\n+            mProcessingThread = new Thread(mFrameProcessor);\n+            mFrameProcessor.setActive(true);\n+            mProcessingThread.start();\n+        }\n+        return this;\n+    }\n+\n+    /**\n+     * Opens the camera and starts sending preview frames to the underlying detector.  The supplied\n+     * surface holder is used for the preview so frames can be displayed to the user.\n+     *\n+     * @param surfaceHolder the surface holder to use for the preview frames\n+     * @throws IOException if the supplied surface holder could not be used as the preview display\n+     */\n+    @RequiresPermission(Manifest.permission.CAMERA)\n+    public CameraSource start(SurfaceHolder surfaceHolder) throws IOException {\n+        synchronized (mCameraLock) {\n+            if (mCamera != null) {\n+                return this;\n+            }\n+\n+            mCamera = createCamera();\n+            mCamera.setPreviewDisplay(surfaceHolder);\n+            mCamera.startPreview();\n+\n+            mProcessingThread = new Thread(mFrameProcessor);\n+            mFrameProcessor.setActive(true);\n+            mProcessingThread.start();\n+        }\n+        return this;\n+    }\n+\n+    /**\n+     * Closes the camera and stops sending frames to the underlying frame detector.\n+     * <p/>\n+     * This camera source may be restarted again by calling {@link #start()} or\n+     * {@link #start(SurfaceHolder)}.\n+     * <p/>\n+     * Call {@link #release()} instead to completely shut down this camera source and release the\n+     * resources of the underlying detector.\n+     */\n+    public void stop() {\n+        synchronized (mCameraLock) {\n+            mFrameProcessor.setActive(false);\n+            if (mProcessingThread != null) {\n+                try {\n+                    // Wait for the thread to complete to ensure that we can't have multiple threads\n+                    // executing at the same time (i.e., which would happen if we called start too\n+                    // quickly after stop).\n+                    mProcessingThread.join();\n+                } catch (InterruptedException e) {\n+                    Log.d(TAG, \"Frame processing thread interrupted on release.\");\n+                }\n+                mProcessingThread = null;\n+            }\n+\n+            // clear the buffer to prevent oom exceptions\n+            mBytesToByteBuffer.clear();\n+\n+            if (mCamera != null) {\n+                mCamera.stopPreview();\n+                mCamera.setPreviewCallbackWithBuffer(null);\n+                try {\n+                    // We want to be compatible back to Gingerbread, but SurfaceTexture\n+                    // wasn't introduced until Honeycomb.  Since the interface cannot use a SurfaceTexture, if the\n+                    // developer wants to display a preview we must use a SurfaceHolder.  If the developer doesn't\n+                    // want to display a preview we use a SurfaceTexture if we are running at least Honeycomb.\n+\n+                    if (Build.VERSION.SDK_INT >= Build.VERSION_CODES.HONEYCOMB) {\n+                        mCamera.setPreviewTexture(null);\n+\n+                    } else {\n+                        mCamera.setPreviewDisplay(null);\n+                    }\n+                } catch (Exception e) {\n+                    Log.e(TAG, \"Failed to clear camera preview: \" + e);\n+                }\n+                mCamera.release();\n+                mCamera = null;\n+            }\n+        }\n+    }\n+\n+    /**\n+     * Returns the preview size that is currently in use by the underlying camera.\n+     */\n+    public Size getPreviewSize() {\n+        return mPreviewSize;\n+    }\n+\n+    /**\n+     * Returns the selected camera; one of {@link #CAMERA_FACING_BACK} or\n+     * {@link #CAMERA_FACING_FRONT}.\n+     */\n+    public int getCameraFacing() {\n+        return mFacing;\n+    }\n+\n+    public int doZoom(float scale) {\n+        synchronized (mCameraLock) {\n+            if (mCamera == null) {\n+                return 0;\n+            }\n+            int currentZoom = 0;\n+            int maxZoom;\n+            Camera.Parameters parameters = mCamera.getParameters();\n+            if (!parameters.isZoomSupported()) {\n+                Log.w(TAG, \"Zoom is not supported on this device\");\n+                return currentZoom;\n+            }\n+            maxZoom = parameters.getMaxZoom();\n+\n+            currentZoom = parameters.getZoom() + 1;\n+            float newZoom;\n+            if (scale > 1) {\n+                newZoom = currentZoom + scale * (maxZoom / 10);\n+            } else {\n+                newZoom = currentZoom * scale;\n+            }\n+            currentZoom = Math.round(newZoom) - 1;\n+            if (currentZoom < 0) {\n+                currentZoom = 0;\n+            } else if (currentZoom > maxZoom) {\n+                currentZoom = maxZoom;\n+            }\n+            parameters.setZoom(currentZoom);\n+            mCamera.setParameters(parameters);\n+            return currentZoom;\n+        }\n+    }\n+\n+    /**\n+     * Initiates taking a picture, which happens asynchronously.  The camera source should have been\n+     * activated previously with {@link #start()} or {@link #start(SurfaceHolder)}.  The camera\n+     * preview is suspended while the picture is being taken, but will resume once picture taking is\n+     * done.\n+     *\n+     * @param shutter the callback for image capture moment, or null\n+     * @param jpeg    the callback for JPEG image data, or null\n+     */\n+    public void takePicture(ShutterCallback shutter, PictureCallback jpeg) {\n+        synchronized (mCameraLock) {\n+            if (mCamera != null) {\n+                PictureStartCallback startCallback = new PictureStartCallback();\n+                startCallback.mDelegate = shutter;\n+                PictureDoneCallback doneCallback = new PictureDoneCallback();\n+                doneCallback.mDelegate = jpeg;\n+                mCamera.takePicture(startCallback, null, null, doneCallback);\n+            }\n+        }\n+    }\n+\n+    /**\n+     * Gets the current focus mode setting.\n+     *\n+     * @return current focus mode. This value is null if the camera is not yet created. Applications should call {@link\n+     * #autoFocus(AutoFocusCallback)} to start the focus if focus\n+     * mode is FOCUS_MODE_AUTO or FOCUS_MODE_MACRO.\n+     * @see Camera.Parameters#FOCUS_MODE_AUTO\n+     * @see Camera.Parameters#FOCUS_MODE_INFINITY\n+     * @see Camera.Parameters#FOCUS_MODE_MACRO\n+     * @see Camera.Parameters#FOCUS_MODE_FIXED\n+     * @see Camera.Parameters#FOCUS_MODE_EDOF\n+     * @see Camera.Parameters#FOCUS_MODE_CONTINUOUS_VIDEO\n+     * @see Camera.Parameters#FOCUS_MODE_CONTINUOUS_PICTURE\n+     */\n+    @Nullable\n+    @FocusMode\n+    public String getFocusMode() {\n+        return mFocusMode;\n+    }\n+\n+    /**\n+     * Sets the focus mode.\n+     *\n+     * @param mode the focus mode\n+     * @return {@code true} if the focus mode is set, {@code false} otherwise\n+     * @see #getFocusMode()\n+     */\n+    public boolean setFocusMode(@FocusMode String mode) {\n+        synchronized (mCameraLock) {\n+            if (mCamera != null && mode != null) {\n+                Camera.Parameters parameters = mCamera.getParameters();\n+                if (parameters.getSupportedFocusModes().contains(mode)) {\n+                    parameters.setFocusMode(mode);\n+                    mCamera.setParameters(parameters);\n+                    mFocusMode = mode;\n+                    return true;\n+                }\n+            }\n+\n+            return false;\n+        }\n+    }\n+\n+    /**\n+     * Gets the current flash mode setting.\n+     *\n+     * @return current flash mode. null if flash mode setting is not\n+     * supported or the camera is not yet created.\n+     * @see Camera.Parameters#FLASH_MODE_OFF\n+     * @see Camera.Parameters#FLASH_MODE_AUTO\n+     * @see Camera.Parameters#FLASH_MODE_ON\n+     * @see Camera.Parameters#FLASH_MODE_RED_EYE\n+     * @see Camera.Parameters#FLASH_MODE_TORCH\n+     */\n+    @Nullable\n+    @FlashMode\n+    public String getFlashMode() {\n+        return mFlashMode;\n+    }\n+\n+    /**\n+     * Sets the flash mode.\n+     *\n+     * @param mode flash mode.\n+     * @return {@code true} if the flash mode is set, {@code false} otherwise\n+     * @see #getFlashMode()\n+     */\n+    public boolean setFlashMode(@FlashMode String mode) {\n+        synchronized (mCameraLock) {\n+            if (mCamera != null && mode != null) {\n+                Camera.Parameters parameters = mCamera.getParameters();\n+                if (parameters.getSupportedFlashModes().contains(mode)) {\n+                    parameters.setFlashMode(mode);\n+                    mCamera.setParameters(parameters);\n+                    mFlashMode = mode;\n+                    return true;\n+                }\n+            }\n+\n+            return false;\n+        }\n+    }\n+\n+    /**\n+     * Starts camera auto-focus and registers a callback function to run when\n+     * the camera is focused.  This method is only valid when preview is active\n+     * (between {@link #start()} or {@link #start(SurfaceHolder)} and before {@link #stop()} or {@link #release()}).\n+     * <p/>\n+     * <p>Callers should check\n+     * {@link #getFocusMode()} to determine if\n+     * this method should be called. If the camera does not support auto-focus,\n+     * it is a no-op and {@link AutoFocusCallback#onAutoFocus(boolean)}\n+     * callback will be called immediately.\n+     * <p/>\n+     * <p>If the current flash mode is not\n+     * {@link Camera.Parameters#FLASH_MODE_OFF}, flash may be\n+     * fired during auto-focus, depending on the driver and camera hardware.<p>\n+     *\n+     * @param cb the callback to run\n+     * @see #cancelAutoFocus()\n+     */\n+    public void autoFocus(@Nullable AutoFocusCallback cb) {\n+        synchronized (mCameraLock) {\n+            if (mCamera != null) {\n+                CameraAutoFocusCallback autoFocusCallback = null;\n+                if (cb != null) {\n+                    autoFocusCallback = new CameraAutoFocusCallback();\n+                    autoFocusCallback.mDelegate = cb;\n+                }\n+                mCamera.autoFocus(autoFocusCallback);\n+            }\n+        }\n+    }\n+\n+    /**\n+     * Cancels any auto-focus function in progress.\n+     * Whether or not auto-focus is currently in progress,\n+     * this function will return the focus position to the default.\n+     * If the camera does not support auto-focus, this is a no-op.\n+     *\n+     * @see #autoFocus(AutoFocusCallback)\n+     */\n+    public void cancelAutoFocus() {\n+        synchronized (mCameraLock) {\n+            if (mCamera != null) {\n+                mCamera.cancelAutoFocus();\n+            }\n+        }\n+    }\n+\n+    /**\n+     * Sets camera auto-focus move callback.\n+     *\n+     * @param cb the callback to run\n+     * @return {@code true} if the operation is supported (i.e. from Jelly Bean), {@code false} otherwise\n+     */\n+    @TargetApi(Build.VERSION_CODES.JELLY_BEAN)\n+    public boolean setAutoFocusMoveCallback(@Nullable AutoFocusMoveCallback cb) {\n+        if (Build.VERSION.SDK_INT < Build.VERSION_CODES.JELLY_BEAN) {\n+            return false;\n+        }\n+\n+        synchronized (mCameraLock) {\n+            if (mCamera != null) {\n+                CameraAutoFocusMoveCallback autoFocusMoveCallback = null;\n+                if (cb != null) {\n+                    autoFocusMoveCallback = new CameraAutoFocusMoveCallback();\n+                    autoFocusMoveCallback.mDelegate = cb;\n+                }\n+                mCamera.setAutoFocusMoveCallback(autoFocusMoveCallback);\n+            }\n+        }\n+\n+        return true;\n+    }\n+\n+    //==============================================================================================\n+    // Private\n+    //==============================================================================================\n+\n+    /**\n+     * Only allow creation via the builder class.\n+     */\n+    private CameraSource() {\n+    }\n+\n+    /**\n+     * Wraps the camera1 shutter callback so that the deprecated API isn't exposed.\n+     */\n+    private class PictureStartCallback implements Camera.ShutterCallback {\n+        private ShutterCallback mDelegate;\n+\n+        @Override\n+        public void onShutter() {\n+            if (mDelegate != null) {\n+                mDelegate.onShutter();\n+            }\n+        }\n+    }\n+\n+    /**\n+     * Wraps the final callback in the camera sequence, so that we can automatically turn the camera\n+     * preview back on after the picture has been taken.\n+     */\n+    private class PictureDoneCallback implements Camera.PictureCallback {\n+        private PictureCallback mDelegate;\n+\n+        @Override\n+        public void onPictureTaken(byte[] data, Camera camera) {\n+            if (mDelegate != null) {\n+                mDelegate.onPictureTaken(data);\n+            }\n+            synchronized (mCameraLock) {\n+                if (mCamera != null) {\n+                    mCamera.startPreview();\n+                }\n+            }\n+        }\n+    }\n+\n+    /**\n+     * Wraps the camera1 auto focus callback so that the deprecated API isn't exposed.\n+     */\n+    private class CameraAutoFocusCallback implements Camera.AutoFocusCallback {\n+        private AutoFocusCallback mDelegate;\n+\n+        @Override\n+        public void onAutoFocus(boolean success, Camera camera) {\n+            if (mDelegate != null) {\n+                mDelegate.onAutoFocus(success);\n+            }\n+        }\n+    }\n+\n+    /**\n+     * Wraps the camera1 auto focus move callback so that the deprecated API isn't exposed.\n+     */\n+    @TargetApi(Build.VERSION_CODES.JELLY_BEAN)\n+    private class CameraAutoFocusMoveCallback implements Camera.AutoFocusMoveCallback {\n+        private AutoFocusMoveCallback mDelegate;\n+\n+        @Override\n+        public void onAutoFocusMoving(boolean start, Camera camera) {\n+            if (mDelegate != null) {\n+                mDelegate.onAutoFocusMoving(start);\n+            }\n+        }\n+    }\n+\n+    /**\n+     * Opens the camera and applies the user settings.\n+     *\n+     * @throws RuntimeException if the method fails\n+     */\n+    @SuppressLint(\"InlinedApi\")\n+    private Camera createCamera() {\n+        int requestedCameraId = getIdForRequestedCamera(mFacing);\n+        if (requestedCameraId == -1) {\n+            throw new RuntimeException(\"Could not find requested camera.\");\n+        }\n+        Camera camera = Camera.open(requestedCameraId);\n+\n+        SizePair sizePair = selectSizePair(camera, mRequestedPreviewWidth, mRequestedPreviewHeight);\n+        if (sizePair == null) {\n+            throw new RuntimeException(\"Could not find suitable preview size.\");\n+        }\n+        Size pictureSize = sizePair.pictureSize();\n+        mPreviewSize = sizePair.previewSize();\n+\n+        int[] previewFpsRange = selectPreviewFpsRange(camera, mRequestedFps);\n+        if (previewFpsRange == null) {\n+            throw new RuntimeException(\"Could not find suitable preview frames per second range.\");\n+        }\n+\n+        Camera.Parameters parameters = camera.getParameters();\n+\n+        if (pictureSize != null) {\n+            parameters.setPictureSize(pictureSize.getWidth(), pictureSize.getHeight());\n+        }\n+\n+        parameters.setPreviewSize(mPreviewSize.getWidth(), mPreviewSize.getHeight());\n+        parameters.setPreviewFpsRange(\n+                previewFpsRange[Camera.Parameters.PREVIEW_FPS_MIN_INDEX],\n+                previewFpsRange[Camera.Parameters.PREVIEW_FPS_MAX_INDEX]);\n+        parameters.setPreviewFormat(ImageFormat.NV21);\n+\n+        setRotation(camera, parameters, requestedCameraId);\n+\n+        if (mFocusMode != null) {\n+            if (parameters.getSupportedFocusModes().contains(\n+                    mFocusMode)) {\n+                parameters.setFocusMode(mFocusMode);\n+            } else {\n+                Log.i(TAG, \"Camera focus mode: \" + mFocusMode + \" is not supported on this device.\");\n+            }\n+        }\n+\n+        // setting mFocusMode to the one set in the params\n+        mFocusMode = parameters.getFocusMode();\n+\n+        if (mFlashMode != null) {\n+            if (parameters.getSupportedFlashModes().contains(\n+                    mFlashMode)) {\n+                parameters.setFlashMode(mFlashMode);\n+            } else {\n+                Log.i(TAG, \"Camera flash mode: \" + mFlashMode + \" is not supported on this device.\");\n+            }\n+        }\n+\n+        // setting mFlashMode to the one set in the params\n+        mFlashMode = parameters.getFlashMode();\n+\n+        camera.setParameters(parameters);\n+\n+        // Four frame buffers are needed for working with the camera:\n+        //\n+        //   one for the frame that is currently being executed upon in doing detection\n+        //   one for the next pending frame to process immediately upon completing detection\n+        //   two for the frames that the camera uses to populate future preview images\n+        camera.setPreviewCallbackWithBuffer(new CameraPreviewCallback());\n+        camera.addCallbackBuffer(createPreviewBuffer(mPreviewSize));\n+        camera.addCallbackBuffer(createPreviewBuffer(mPreviewSize));\n+        camera.addCallbackBuffer(createPreviewBuffer(mPreviewSize));\n+        camera.addCallbackBuffer(createPreviewBuffer(mPreviewSize));\n+\n+        return camera;\n+    }\n+\n+    /**\n+     * Gets the id for the camera specified by the direction it is facing.  Returns -1 if no such\n+     * camera was found.\n+     *\n+     * @param facing the desired camera (front-facing or rear-facing)\n+     */\n+    private static int getIdForRequestedCamera(int facing) {\n+        CameraInfo cameraInfo = new CameraInfo();\n+        for (int i = 0; i < Camera.getNumberOfCameras(); ++i) {\n+            Camera.getCameraInfo(i, cameraInfo);\n+            if (cameraInfo.facing == facing) {\n+                return i;\n+            }\n+        }\n+        return -1;\n+    }\n+\n+    /**\n+     * Selects the most suitable preview and picture size, given the desired width and height.\n+     * <p/>\n+     * Even though we may only need the preview size, it's necessary to find both the preview\n+     * size and the picture size of the camera together, because these need to have the same aspect\n+     * ratio.  On some hardware, if you would only set the preview size, you will get a distorted\n+     * image.\n+     *\n+     * @param camera        the camera to select a preview size from\n+     * @param desiredWidth  the desired width of the camera preview frames\n+     * @param desiredHeight the desired height of the camera preview frames\n+     * @return the selected preview and picture size pair\n+     */\n+    private static SizePair selectSizePair(Camera camera, int desiredWidth, int desiredHeight) {\n+        List<SizePair> validPreviewSizes = generateValidPreviewSizeList(camera);\n+\n+        // The method for selecting the best size is to minimize the sum of the differences between\n+        // the desired values and the actual values for width and height.  This is certainly not the\n+        // only way to select the best size, but it provides a decent tradeoff between using the\n+        // closest aspect ratio vs. using the closest pixel area.\n+        SizePair selectedPair = null;\n+        int minDiff = Integer.MAX_VALUE;\n+        for (SizePair sizePair : validPreviewSizes) {\n+            Size size = sizePair.previewSize();\n+            int diff = Math.abs(size.getWidth() - desiredWidth) +\n+                    Math.abs(size.getHeight() - desiredHeight);\n+            if (diff < minDiff) {\n+                selectedPair = sizePair;\n+                minDiff = diff;\n+            }\n+        }\n+\n+        return selectedPair;\n+    }\n+\n+    /**\n+     * Stores a preview size and a corresponding same-aspect-ratio picture size.  To avoid distorted\n+     * preview images on some devices, the picture size must be set to a size that is the same\n+     * aspect ratio as the preview size or the preview may end up being distorted.  If the picture\n+     * size is null, then there is no picture size with the same aspect ratio as the preview size.\n+     */\n+    private static class SizePair {\n+        private Size mPreview;\n+        private Size mPicture;\n+\n+        public SizePair(Camera.Size previewSize,\n+                        Camera.Size pictureSize) {\n+            mPreview = new Size(previewSize.width, previewSize.height);\n+            if (pictureSize != null) {\n+                mPicture = new Size(pictureSize.width, pictureSize.height);\n+            }\n+        }\n+\n+        public Size previewSize() {\n+            return mPreview;\n+        }\n+\n+        @SuppressWarnings(\"unused\")\n+        public Size pictureSize() {\n+            return mPicture;\n+        }\n+    }\n+\n+    /**\n+     * Generates a list of acceptable preview sizes.  Preview sizes are not acceptable if there is\n+     * not a corresponding picture size of the same aspect ratio.  If there is a corresponding\n+     * picture size of the same aspect ratio, the picture size is paired up with the preview size.\n+     * <p/>\n+     * This is necessary because even if we don't use still pictures, the still picture size must be\n+     * set to a size that is the same aspect ratio as the preview size we choose.  Otherwise, the\n+     * preview images may be distorted on some devices.\n+     */\n+    private static List<SizePair> generateValidPreviewSizeList(Camera camera) {\n+        Camera.Parameters parameters = camera.getParameters();\n+        List<Camera.Size> supportedPreviewSizes =\n+                parameters.getSupportedPreviewSizes();\n+        List<Camera.Size> supportedPictureSizes =\n+                parameters.getSupportedPictureSizes();\n+        List<SizePair> validPreviewSizes = new ArrayList<>();\n+        for (Camera.Size previewSize : supportedPreviewSizes) {\n+            float previewAspectRatio = (float) previewSize.width / (float) previewSize.height;\n+\n+            // By looping through the picture sizes in order, we favor the higher resolutions.\n+            // We choose the highest resolution in order to support taking the full resolution\n+            // picture later.\n+            for (Camera.Size pictureSize : supportedPictureSizes) {\n+                float pictureAspectRatio = (float) pictureSize.width / (float) pictureSize.height;\n+                if (Math.abs(previewAspectRatio - pictureAspectRatio) < ASPECT_RATIO_TOLERANCE) {\n+                    validPreviewSizes.add(new SizePair(previewSize, pictureSize));\n+                    break;\n+                }\n+            }\n+        }\n+\n+        // If there are no picture sizes with the same aspect ratio as any preview sizes, allow all\n+        // of the preview sizes and hope that the camera can handle it.  Probably unlikely, but we\n+        // still account for it.\n+        if (validPreviewSizes.size() == 0) {\n+            Log.w(TAG, \"No preview sizes have a corresponding same-aspect-ratio picture size\");\n+            for (Camera.Size previewSize : supportedPreviewSizes) {\n+                // The null picture size will let us know that we shouldn't set a picture size.\n+                validPreviewSizes.add(new SizePair(previewSize, null));\n+            }\n+        }\n+\n+        return validPreviewSizes;\n+    }\n+\n+    /**\n+     * Selects the most suitable preview frames per second range, given the desired frames per\n+     * second.\n+     *\n+     * @param camera            the camera to select a frames per second range from\n+     * @param desiredPreviewFps the desired frames per second for the camera preview frames\n+     * @return the selected preview frames per second range\n+     */\n+    private int[] selectPreviewFpsRange(Camera camera, float desiredPreviewFps) {\n+        // The camera API uses integers scaled by a factor of 1000 instead of floating-point frame\n+        // rates.\n+        int desiredPreviewFpsScaled = (int) (desiredPreviewFps * 1000.0f);\n+\n+        // The method for selecting the best range is to minimize the sum of the differences between\n+        // the desired value and the upper and lower bounds of the range.  This may select a range\n+        // that the desired value is outside of, but this is often preferred.  For example, if the\n+        // desired frame rate is 29.97, the range (30, 30) is probably more desirable than the\n+        // range (15, 30).\n+        int[] selectedFpsRange = null;\n+        int minDiff = Integer.MAX_VALUE;\n+        List<int[]> previewFpsRangeList = camera.getParameters().getSupportedPreviewFpsRange();\n+        for (int[] range : previewFpsRangeList) {\n+            int deltaMin = desiredPreviewFpsScaled - range[Camera.Parameters.PREVIEW_FPS_MIN_INDEX];\n+            int deltaMax = desiredPreviewFpsScaled - range[Camera.Parameters.PREVIEW_FPS_MAX_INDEX];\n+            int diff = Math.abs(deltaMin) + Math.abs(deltaMax);\n+            if (diff < minDiff) {\n+                selectedFpsRange = range;\n+                minDiff = diff;\n+            }\n+        }\n+        return selectedFpsRange;\n+    }\n+\n+    /**\n+     * Calculates the correct rotation for the given camera id and sets the rotation in the\n+     * parameters.  It also sets the camera's display orientation and rotation.\n+     *\n+     * @param parameters the camera parameters for which to set the rotation\n+     * @param cameraId   the camera id to set rotation based on\n+     */\n+    private void setRotation(Camera camera, Camera.Parameters parameters, int cameraId) {\n+        WindowManager windowManager =\n+                (WindowManager) mContext.getSystemService(Context.WINDOW_SERVICE);\n+        int degrees = 0;\n+        int rotation = windowManager.getDefaultDisplay().getRotation();\n+        switch (rotation) {\n+            case Surface.ROTATION_0:\n+                degrees = 0;\n+                break;\n+            case Surface.ROTATION_90:\n+                degrees = 90;\n+                break;\n+            case Surface.ROTATION_180:\n+                degrees = 180;\n+                break;\n+            case Surface.ROTATION_270:\n+                degrees = 270;\n+                break;\n+            default:\n+                Log.e(TAG, \"Bad rotation value: \" + rotation);\n+        }\n+\n+        CameraInfo cameraInfo = new CameraInfo();\n+        Camera.getCameraInfo(cameraId, cameraInfo);\n+\n+        int angle;\n+        int displayAngle;\n+        if (cameraInfo.facing == CameraInfo.CAMERA_FACING_FRONT) {\n+            angle = (cameraInfo.orientation + degrees) % 360;\n+            displayAngle = (360 - angle); // compensate for it being mirrored\n+        } else {  // back-facing\n+            angle = (cameraInfo.orientation - degrees + 360) % 360;\n+            displayAngle = angle;\n+        }\n+\n+        // This corresponds to the rotation constants in {@link Frame}.\n+        mRotation = angle / 90;\n+\n+        camera.setDisplayOrientation(displayAngle);\n+        parameters.setRotation(angle);\n+    }\n+\n+    /**\n+     * Creates one buffer for the camera preview callback.  The size of the buffer is based off of\n+     * the camera preview size and the format of the camera image.\n+     *\n+     * @return a new preview buffer of the appropriate size for the current camera settings\n+     */\n+    private byte[] createPreviewBuffer(Size previewSize) {\n+        int bitsPerPixel = ImageFormat.getBitsPerPixel(ImageFormat.NV21);\n+        long sizeInBits = previewSize.getHeight() * previewSize.getWidth() * bitsPerPixel;\n+        int bufferSize = (int) Math.ceil(sizeInBits / 8.0d) + 1;\n+\n+        //\n+        // NOTICE: This code only works when using play services v. 8.1 or higher.\n+        //\n+\n+        // Creating the byte array this way and wrapping it, as opposed to using .allocate(),\n+        // should guarantee that there will be an array to work with.\n+        byte[] byteArray = new byte[bufferSize];\n+        ByteBuffer buffer = ByteBuffer.wrap(byteArray);\n+        if (!buffer.hasArray() || (buffer.array() != byteArray)) {\n+            // I don't think that this will ever happen.  But if it does, then we wouldn't be\n+            // passing the preview content to the underlying detector later.\n+            throw new IllegalStateException(\"Failed to create valid buffer for camera source.\");\n+        }\n+\n+        mBytesToByteBuffer.put(byteArray, buffer);\n+        return byteArray;\n+    }\n+\n+    //==============================================================================================\n+    // Frame processing\n+    //==============================================================================================\n+\n+    /**\n+     * Called when the camera has a new preview frame.\n+     */\n+    private class CameraPreviewCallback implements Camera.PreviewCallback {\n+        @Override\n+        public void onPreviewFrame(byte[] data, Camera camera) {\n+            mFrameProcessor.setNextFrame(data, camera);\n+        }\n+    }\n+\n+    /**\n+     * This runnable controls access to the underlying receiver, calling it to process frames when\n+     * available from the camera.  This is designed to run detection on frames as fast as possible\n+     * (i.e., without unnecessary context switching or waiting on the next frame).\n+     * <p/>\n+     * While detection is running on a frame, new frames may be received from the camera.  As these\n+     * frames come in, the most recent frame is held onto as pending.  As soon as detection and its\n+     * associated processing are done for the previous frame, detection on the mostly recently\n+     * received frame will immediately start on the same thread.\n+     */\n+    private class FrameProcessingRunnable implements Runnable {\n+        private Detector<?> mDetector;\n+        private long mStartTimeMillis = SystemClock.elapsedRealtime();\n+\n+        // This lock guards all of the member variables below.\n+        private final Object mLock = new Object();\n+        private boolean mActive = true;\n+\n+        // These pending variables hold the state associated with the new frame awaiting processing.\n+        private long mPendingTimeMillis;\n+        private int mPendingFrameId = 0;\n+        private ByteBuffer mPendingFrameData;\n+\n+        FrameProcessingRunnable(Detector<?> detector) {\n+            mDetector = detector;\n+        }\n+\n+        /**\n+         * Releases the underlying receiver.  This is only safe to do after the associated thread\n+         * has completed, which is managed in camera source's release method above.\n+         */\n+        @SuppressLint(\"Assert\")\n+        void release() {\n+            assert (mProcessingThread.getState() == State.TERMINATED);\n+            mDetector.release();\n+            mDetector = null;\n+        }\n+\n+        /**\n+         * Marks the runnable as active/not active.  Signals any blocked threads to continue.\n+         */\n+        void setActive(boolean active) {\n+            synchronized (mLock) {\n+                mActive = active;\n+                mLock.notifyAll();\n+            }\n+        }\n+\n+        /**\n+         * Sets the frame data received from the camera.  This adds the previous unused frame buffer\n+         * (if present) back to the camera, and keeps a pending reference to the frame data for\n+         * future use.\n+         */\n+        void setNextFrame(byte[] data, Camera camera) {\n+            synchronized (mLock) {\n+                if (mPendingFrameData != null) {\n+                    camera.addCallbackBuffer(mPendingFrameData.array());\n+                    mPendingFrameData = null;\n+                }\n+\n+                if (!mBytesToByteBuffer.containsKey(data)) {\n+                    Log.d(TAG,\n+                            \"Skipping frame.  Could not find ByteBuffer associated with the image \" +\n+                                    \"data from the camera.\");\n+                    return;\n+                }\n+\n+                // Timestamp and frame ID are maintained here, which will give downstream code some\n+                // idea of the timing of frames received and when frames were dropped along the way.\n+                mPendingTimeMillis = SystemClock.elapsedRealtime() - mStartTimeMillis;\n+                mPendingFrameId++;\n+                mPendingFrameData = mBytesToByteBuffer.get(data);\n+\n+                // Notify the processor thread if it is waiting on the next frame (see below).\n+                mLock.notifyAll();\n+            }\n+        }\n+\n+        /**\n+         * As long as the processing thread is active, this executes detection on frames\n+         * continuously.  The next pending frame is either immediately available or hasn't been\n+         * received yet.  Once it is available, we transfer the frame info to local variables and\n+         * run detection on that frame.  It immediately loops back for the next frame without\n+         * pausing.\n+         * <p/>\n+         * If detection takes longer than the time in between new frames from the camera, this will\n+         * mean that this loop will run without ever waiting on a frame, avoiding any context\n+         * switching or frame acquisition time latency.\n+         * <p/>\n+         * If you find that this is using more CPU than you'd like, you should probably decrease the\n+         * FPS setting above to allow for some idle time in between frames.\n+         */\n+        @Override\n+        public void run() {\n+            Frame outputFrame;\n+            ByteBuffer data;\n+\n+            while (true) {\n+                synchronized (mLock) {\n+                    while (mActive && (mPendingFrameData == null)) {\n+                        try {\n+                            // Wait for the next frame to be received from the camera, since we\n+                            // don't have it yet.\n+                            mLock.wait();\n+                        } catch (InterruptedException e) {\n+                            Log.d(TAG, \"Frame processing loop terminated.\", e);\n+                            return;\n+                        }\n+                    }\n+\n+                    if (!mActive) {\n+                        // Exit the loop once this camera source is stopped or released.  We check\n+                        // this here, immediately after the wait() above, to handle the case where\n+                        // setActive(false) had been called, triggering the termination of this\n+                        // loop.\n+                        return;\n+                    }\n+\n+                    outputFrame = new Frame.Builder()\n+                            .setImageData(mPendingFrameData, mPreviewSize.getWidth(),\n+                                    mPreviewSize.getHeight(), ImageFormat.NV21)\n+                            .setId(mPendingFrameId)\n+                            .setTimestampMillis(mPendingTimeMillis)\n+                            .setRotation(mRotation)\n+                            .build();\n+\n+                    // Hold onto the frame data locally, so that we can use this for detection\n+                    // below.  We need to clear mPendingFrameData to ensure that this buffer isn't\n+                    // recycled back to the camera before we are done using that data.\n+                    data = mPendingFrameData;\n+                    mPendingFrameData = null;\n+                }\n+\n+                // The code below needs to run outside of synchronization, because this will allow\n+                // the camera to add pending frame(s) while we are running detection on the current\n+                // frame.\n+\n+                try {\n+                    mDetector.receiveFrame(outputFrame);\n+                } catch (Throwable t) {\n+                    Log.e(TAG, \"Exception thrown from receiver.\", t);\n+                } finally {\n+                    mCamera.addCallbackBuffer(data.array());\n+                }\n+            }\n+        }\n+    }\n+}"
  },
  {
    "sha": "c44af857f11a9f59e43bb4b9f1d259ca1f380b3b",
    "filename": "app/src/main/java/com/yoshione/fingen/fts/FtsHelper.java",
    "status": "modified",
    "additions": 5,
    "deletions": 1,
    "changes": 6,
    "blob_url": "https://github.com/ivang7/fingen/blob/216f9b373a5bf0a297e9496a050033a32424050a/app/src/main/java/com/yoshione/fingen/fts/FtsHelper.java",
    "raw_url": "https://github.com/ivang7/fingen/raw/216f9b373a5bf0a297e9496a050033a32424050a/app/src/main/java/com/yoshione/fingen/fts/FtsHelper.java",
    "contents_url": "https://api.github.com/repos/ivang7/fingen/contents/app/src/main/java/com/yoshione/fingen/fts/FtsHelper.java?ref=216f9b373a5bf0a297e9496a050033a32424050a",
    "patch": "@@ -144,7 +144,11 @@ public Disposable downloadProductEntryList(final Transaction transaction,\n                                     productEntry.setProductID(product.getID());\n                                     productEntries.add(productEntry);\n                                 }\n-                                downloadProductsListener.onDownload(productEntries, response.body().getDocument().getReceipt().getUser());\n+                                String payee = response.body().getDocument().getReceipt().getUser();\n+                                if (payee == null) {\n+                                    payee = response.body().getDocument().getReceipt().getUserInn();\n+                                }\n+                                downloadProductsListener.onDownload(productEntries, payee);\n                             }\n                             break;\n                         } else {"
  },
  {
    "sha": "6a25d20fdb9093c8175db1dc00d82594026272d4",
    "filename": "app/src/main/res/layout/content_decoder.xml",
    "status": "modified",
    "additions": 1,
    "deletions": 1,
    "changes": 2,
    "blob_url": "https://github.com/ivang7/fingen/blob/216f9b373a5bf0a297e9496a050033a32424050a/app/src/main/res/layout/content_decoder.xml",
    "raw_url": "https://github.com/ivang7/fingen/raw/216f9b373a5bf0a297e9496a050033a32424050a/app/src/main/res/layout/content_decoder.xml",
    "contents_url": "https://api.github.com/repos/ivang7/fingen/contents/app/src/main/res/layout/content_decoder.xml?ref=216f9b373a5bf0a297e9496a050033a32424050a",
    "patch": "@@ -7,7 +7,7 @@\n     tools:activity=\".fts.ActivityScanQR\"\n     >\n \n-  <com.dlazaro66.qrcodereaderview.QRCodeReaderView\n+  <SurfaceView\n       android:id=\"@+id/qrdecoderview\"\n       android:layout_width=\"match_parent\"\n       android:layout_height=\"match_parent\""
  }
]
