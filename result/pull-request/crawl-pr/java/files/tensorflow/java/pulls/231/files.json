[
  {
    "sha": "acbae4dac6b7fd7b9c36ad8546b7f75b03d3db1f",
    "filename": "tensorflow-core/tensorflow-core-api/src/gen/annotations/org/tensorflow/op/Ops.java",
    "status": "modified",
    "additions": 6,
    "deletions": 6,
    "changes": 12,
    "blob_url": "https://github.com/tensorflow/java/blob/98df654a9558d0d41ab35766073f7ad97038d556/tensorflow-core/tensorflow-core-api/src/gen/annotations/org/tensorflow/op/Ops.java",
    "raw_url": "https://github.com/tensorflow/java/raw/98df654a9558d0d41ab35766073f7ad97038d556/tensorflow-core/tensorflow-core-api/src/gen/annotations/org/tensorflow/op/Ops.java",
    "contents_url": "https://api.github.com/repos/tensorflow/java/contents/tensorflow-core/tensorflow-core-api/src/gen/annotations/org/tensorflow/op/Ops.java?ref=98df654a9558d0d41ab35766073f7ad97038d556",
    "patch": "@@ -354,20 +354,20 @@\n \n   public final SparseOps sparse;\n \n-  public final TpuOps tpu;\n-\n   public final BitwiseOps bitwise;\n \n+  public final TpuOps tpu;\n+\n   public final MathOps math;\n \n   public final AudioOps audio;\n \n   public final SignalOps signal;\n \n-  public final TrainOps train;\n-\n   public final QuantizationOps quantization;\n \n+  public final TrainOps train;\n+\n   private final Scope scope;\n \n   private Ops(Scope scope) {\n@@ -385,13 +385,13 @@ private Ops(Scope scope) {\n     random = new RandomOps(this);\n     strings = new StringsOps(this);\n     sparse = new SparseOps(this);\n-    tpu = new TpuOps(this);\n     bitwise = new BitwiseOps(this);\n+    tpu = new TpuOps(this);\n     math = new MathOps(this);\n     audio = new AudioOps(this);\n     signal = new SignalOps(this);\n-    train = new TrainOps(this);\n     quantization = new QuantizationOps(this);\n+    train = new TrainOps(this);\n   }\n \n   /**"
  },
  {
    "sha": "708c7daead686059e5431ec6cd1fecfec565369d",
    "filename": "tensorflow-framework/src/main/java/org/tensorflow/framework/activations/Activation.java",
    "status": "modified",
    "additions": 11,
    "deletions": 17,
    "changes": 28,
    "blob_url": "https://github.com/tensorflow/java/blob/98df654a9558d0d41ab35766073f7ad97038d556/tensorflow-framework/src/main/java/org/tensorflow/framework/activations/Activation.java",
    "raw_url": "https://github.com/tensorflow/java/raw/98df654a9558d0d41ab35766073f7ad97038d556/tensorflow-framework/src/main/java/org/tensorflow/framework/activations/Activation.java",
    "contents_url": "https://api.github.com/repos/tensorflow/java/contents/tensorflow-framework/src/main/java/org/tensorflow/framework/activations/Activation.java?ref=98df654a9558d0d41ab35766073f7ad97038d556",
    "patch": "@@ -18,14 +18,7 @@\n import org.tensorflow.op.Ops;\n import org.tensorflow.types.family.TNumber;\n \n-/**\n- * Abstract base class for Activations\n- *\n- * <p><b>Note:</b> The {@link #tf} attribute must be set prior to invoking the call method. See\n- * {@link #setTF(Ops)} and the constructor {@link #Activation(Ops)}.\n- *\n- * @param <T> the data type of the activation\n- */\n+/** Abstract base class for Activations */\n public abstract class Activation<T extends TNumber> {\n \n   /** The TensorFlow Ops */\n@@ -41,28 +34,29 @@ protected Activation(Ops tf) {\n   }\n \n   /**\n-   * Sets the TensorFlow Ops\n+   * Gets the TensorFlow Ops\n    *\n-   * @param tf the TensorFlow Ops\n+   * @return the TensorFlow Ops\n    */\n-  protected void setTF(Ops tf) {\n-    this.tf = tf;\n+  protected Ops getTF() {\n+    return this.tf;\n   }\n \n   /**\n-   * Gets the TensorFlow Ops\n+   * Sets the TensorFlow Ops\n    *\n-   * @return the TensorFlow Ops\n+   * @param tf the TensorFlow Ops\n    */\n-  protected Ops getTF() {\n-    return this.tf;\n+  protected void setTF(Ops tf) {\n+    this.tf = tf;\n   }\n \n   /**\n    * Gets the calculation operation for the activation.\n    *\n    * @param input the input tensor\n+   * @param <U> the data type of the input and result\n    * @return The operand for the activation\n    */\n-  public abstract Operand<T> call(Operand<T> input);\n+  public abstract <U extends T> Operand<U> call(Operand<U> input);\n }"
  },
  {
    "sha": "00c720c936b827ade02bdb6a16c8ae11168ab331",
    "filename": "tensorflow-framework/src/main/java/org/tensorflow/framework/activations/ELU.java",
    "status": "modified",
    "additions": 9,
    "deletions": 14,
    "changes": 23,
    "blob_url": "https://github.com/tensorflow/java/blob/98df654a9558d0d41ab35766073f7ad97038d556/tensorflow-framework/src/main/java/org/tensorflow/framework/activations/ELU.java",
    "raw_url": "https://github.com/tensorflow/java/raw/98df654a9558d0d41ab35766073f7ad97038d556/tensorflow-framework/src/main/java/org/tensorflow/framework/activations/ELU.java",
    "contents_url": "https://api.github.com/repos/tensorflow/java/contents/tensorflow-framework/src/main/java/org/tensorflow/framework/activations/ELU.java?ref=98df654a9558d0d41ab35766073f7ad97038d556",
    "patch": "@@ -44,11 +44,10 @@\n  *     Operand&lt;TFloat32&gt; result = elu.call(input);\n  * </pre>\n  *\n- * @param <T> the data type of the activation\n  * @see <a href=\"https://arxiv.org/abs/1511.07289\">Clevert et al, 2016, Fast and Accurate Deep\n  *     Network Learning by Exponential Linear Units (ELUs)</a>\n  */\n-public class ELU<T extends TFloating> extends Activation<T> {\n+public class ELU extends Activation<TFloating> {\n \n   private static final double ALPHA_DEFAULT = 1.0;\n \n@@ -76,20 +75,16 @@ public ELU(Ops tf, double alpha) {\n     this.alpha = alpha;\n   }\n \n-  /**\n-   * Gets the calculation operation for the activation.\n-   *\n-   * @param input the input tensor\n-   * @return The operand for the activation\n-   */\n+  /** {@inheritDoc} */\n   @Override\n-  public Operand<T> call(Operand<T> input) {\n+  public <U extends TFloating> Operand<U> call(Operand<U> input) {\n \n-    Operand<T> result = tf.nn.elu(input);\n-    if (alpha == 1.0) return result;\n-    else {\n-      Class<T> inputType = input.type();\n-      Operand<T> y = tf.math.mul(result, tf.dtypes.cast(tf.constant(alpha), inputType));\n+    Operand<U> result = tf.nn.elu(input);\n+    if (alpha == 1.0) {\n+      return result;\n+    } else {\n+      Class<U> inputType = input.type();\n+      Operand<U> y = tf.math.mul(result, tf.dtypes.cast(tf.constant(alpha), inputType));\n       Operand<TBool> cond = tf.math.greater(result, tf.dtypes.cast(tf.constant(0), inputType));\n       return tf.select(cond, result, y);\n     }"
  },
  {
    "sha": "512f96713aa90c6aa0a3c53cde9484b3ce2898c1",
    "filename": "tensorflow-framework/src/main/java/org/tensorflow/framework/activations/Exponential.java",
    "status": "modified",
    "additions": 4,
    "deletions": 4,
    "changes": 8,
    "blob_url": "https://github.com/tensorflow/java/blob/98df654a9558d0d41ab35766073f7ad97038d556/tensorflow-framework/src/main/java/org/tensorflow/framework/activations/Exponential.java",
    "raw_url": "https://github.com/tensorflow/java/raw/98df654a9558d0d41ab35766073f7ad97038d556/tensorflow-framework/src/main/java/org/tensorflow/framework/activations/Exponential.java",
    "contents_url": "https://api.github.com/repos/tensorflow/java/contents/tensorflow-framework/src/main/java/org/tensorflow/framework/activations/Exponential.java?ref=98df654a9558d0d41ab35766073f7ad97038d556",
    "patch": "@@ -30,10 +30,8 @@\n  *   Operand&lt;TFloat32&gt; result = exp.call(input);\n  *   // result is [0.04978707f,  0.36787945f,  1.f,  2.7182817f, 20.085537f]\n  * </pre>\n- *\n- * @param <T> the data type of the activation\n  */\n-public class Exponential<T extends TFloating> extends Activation<T> {\n+public class Exponential extends Activation<TFloating> {\n \n   /**\n    * Creates an Exponential activation.\n@@ -48,10 +46,12 @@ public Exponential(Ops tf) {\n    * Calculates the Exponential activation.\n    *\n    * @param input the input tensor\n+   * @param <U> the data type of the input and result\n    * @return an Operand for the exponential activation: <code>exp(x)</code>.\n    */\n   @Override\n-  public Operand<T> call(Operand<T> input) {\n+  public <U extends TFloating> Operand<U> call(Operand<U> input) {\n+\n     return tf.math.exp(input);\n   }\n }"
  },
  {
    "sha": "abddbd512cf02deb5a96652cfc046d3b4ce2b2bb",
    "filename": "tensorflow-framework/src/main/java/org/tensorflow/framework/activations/GeLU.java",
    "status": "added",
    "additions": 116,
    "deletions": 0,
    "changes": 116,
    "blob_url": "https://github.com/tensorflow/java/blob/98df654a9558d0d41ab35766073f7ad97038d556/tensorflow-framework/src/main/java/org/tensorflow/framework/activations/GeLU.java",
    "raw_url": "https://github.com/tensorflow/java/raw/98df654a9558d0d41ab35766073f7ad97038d556/tensorflow-framework/src/main/java/org/tensorflow/framework/activations/GeLU.java",
    "contents_url": "https://api.github.com/repos/tensorflow/java/contents/tensorflow-framework/src/main/java/org/tensorflow/framework/activations/GeLU.java?ref=98df654a9558d0d41ab35766073f7ad97038d556",
    "patch": "@@ -0,0 +1,116 @@\n+/* Copyright 2020 The TensorFlow Authors. All Rights Reserved.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+=======================================================================*/\n+package org.tensorflow.framework.activations;\n+\n+import org.tensorflow.Operand;\n+import org.tensorflow.op.Ops;\n+import org.tensorflow.types.family.TFloating;\n+\n+import static org.tensorflow.framework.utils.CastHelper.cast;\n+\n+/**\n+ * Applies the Gaussian error linear unit (GELU) activation function.\n+ *\n+ * <p>Gaussian error linear unit (GELU) computes {@code x * P(X <= x)}, where {@code P(X) ~ N(0,\n+ * 1)}. The (GELU) nonlinearity weights inputs by their value, rather than gates inputs by their\n+ * sign as in ReLU. if <code>approximate</code> is <code>true</code> :\n+ *\n+ * <pre>\n+ *     0.5 * x * (1 + tanh(sqrt(2 / pi) * (x + 0.044715 * x^3)))\n+ * </pre>\n+ *\n+ * <p>or, if <code>approximate</code> is <code>false</code>.\n+ *\n+ * <pre>\n+ *     x * P(X &lt;= x) = 0.5 * x * (1 + erf(x / sqrt(2))),\n+ * </pre>\n+ *\n+ * where <code>P(X) ~ N(0, 1)</code>.\n+ *\n+ * @see <a href=\"https://arxiv.org/abs/1606.08415\">Hendrycks, Dan and Gimpel, Kevin, 2016-2020,\n+ *     Gaussian Error Linear Units (GELUs)</a>\n+ */\n+public class GeLU extends Activation<TFloating> {\n+\n+  private final boolean approximate;\n+\n+  /**\n+   * Creates a e Gaussian error linear unit (GELU) activation, with approximate set to false\n+   *\n+   * @param tf The TensorFlow ops\n+   */\n+  public GeLU(Ops tf) {\n+    this(tf, false);\n+  }\n+\n+  /**\n+   * Creates a e Gaussian error linear unit (GELU) activation\n+   *\n+   * @param tf The TensorFlow ops\n+   * @param approximate indicator whether to enable approximation.\n+   */\n+  public GeLU(Ops tf, boolean approximate) {\n+    super(tf);\n+    this.approximate = approximate;\n+  }\n+\n+  /** {@inheritDoc} */\n+  @Override\n+  public <U extends TFloating> Operand<U> call(Operand<U> input) {\n+\n+    Operand<U> point5 = cast(tf, tf.constant(0.5), input.type());\n+    Operand<U> one = cast(tf, tf.constant(1.0), input.type());\n+\n+    if (approximate) {\n+      /*\n+              coeff = math_ops.cast(0.044715, features.dtype)\n+              return 0.5 * features * (\n+                    1.0 + math_ops.tanh(0.7978845608028654 *\n+                              (features + coeff * math_ops.pow(features, 3))))\n+      */\n+      Operand<U> coeff = cast(tf, tf.constant(0.044715), input.type());\n+      // sqrt(2.0 / PI)\n+      Operand<U> sqrtTwoDivPI = cast(tf, tf.constant(0.7978845608028654), input.type());\n+      Operand<U> three = cast(tf, tf.constant(3), input.type());\n+\n+      return tf.math.mul(\n+          point5,\n+          tf.math.mul(\n+              input,\n+              tf.math.add(\n+                  one,\n+                  tf.math.tanh(\n+                      tf.math.mul(\n+                          sqrtTwoDivPI,\n+                          tf.math.add(\n+                              input, tf.math.mul(coeff, tf.math.pow(input, three)) // mul\n+                              ) // add\n+                          ) // mul\n+                      ) // tanh\n+                  ) // add\n+              ) // mul\n+          ); // mul\n+\n+    } else {\n+      /*\n+      return 0.5 * features * (1.0 + math_ops.erf(\n+        features / math_ops.cast(1.4142135623730951, features.dtype)))\n+       */\n+      Operand<U> sqrtTwo = cast(tf, tf.constant(1.4142135623730951), input.type());\n+      return tf.math.mul(\n+          point5, tf.math.mul(input, tf.math.add(one, tf.math.erf(tf.math.div(input, sqrtTwo)))));\n+    }\n+  }\n+}"
  },
  {
    "sha": "6c7323a90cb6cfd194efe1a0cf6dc8b6eda9a705",
    "filename": "tensorflow-framework/src/main/java/org/tensorflow/framework/activations/HardSigmoid.java",
    "status": "modified",
    "additions": 8,
    "deletions": 15,
    "changes": 23,
    "blob_url": "https://github.com/tensorflow/java/blob/98df654a9558d0d41ab35766073f7ad97038d556/tensorflow-framework/src/main/java/org/tensorflow/framework/activations/HardSigmoid.java",
    "raw_url": "https://github.com/tensorflow/java/raw/98df654a9558d0d41ab35766073f7ad97038d556/tensorflow-framework/src/main/java/org/tensorflow/framework/activations/HardSigmoid.java",
    "contents_url": "https://api.github.com/repos/tensorflow/java/contents/tensorflow-framework/src/main/java/org/tensorflow/framework/activations/HardSigmoid.java?ref=98df654a9558d0d41ab35766073f7ad97038d556",
    "patch": "@@ -16,7 +16,7 @@\n \n import org.tensorflow.Operand;\n import org.tensorflow.op.Ops;\n-import org.tensorflow.types.family.TFloating;\n+import org.tensorflow.types.family.TNumber;\n \n /**\n  * Hard sigmoid activation.\n@@ -40,10 +40,8 @@\n  *     Operand&lt;TFloat32&gt; result = hardSigmoid.call(input);\n  *     // result is [0.f , 0.3f, 0.5f, 0.7f, 1.f]\n  * </pre>\n- *\n- * @param <T> the data type of the result\n  */\n-public class HardSigmoid<T extends TFloating> extends Activation<T> {\n+public class HardSigmoid extends Activation<TNumber> {\n \n   /**\n    * Creates Hard sigmoid activation.\n@@ -54,19 +52,14 @@ public HardSigmoid(Ops tf) {\n     super(tf);\n   }\n \n-  /**\n-   * Gets the calculation operation for the activation.\n-   *\n-   * @param input the input tensor\n-   * @return The operand for the activation\n-   */\n+  /** {@inheritDoc} */\n   @Override\n-  public Operand<T> call(Operand<T> input) {\n-    Class<T> inputType = input.type();\n-    Operand<T> point2 = tf.dtypes.cast(tf.constant(0.2), inputType);\n-    Operand<T> point5 = tf.dtypes.cast(tf.constant(0.5), inputType);\n+  public <U extends TNumber> Operand<U> call(Operand<U> input) {\n+    Class<U> inputType = input.type();\n+    Operand<U> point2 = tf.dtypes.cast(tf.constant(0.2), inputType);\n+    Operand<U> point5 = tf.dtypes.cast(tf.constant(0.5), inputType);\n \n-    Operand<T> x = tf.math.add(tf.math.mul(input, point2), point5);\n+    Operand<U> x = tf.math.add(tf.math.mul(input, point2), point5);\n     return tf.clipByValue(\n         x, tf.dtypes.cast(tf.constant(0), inputType), tf.dtypes.cast(tf.constant(1), inputType));\n   }"
  },
  {
    "sha": "dcda76db6bfe831feaa367ed0bac6d666c6b2fc0",
    "filename": "tensorflow-framework/src/main/java/org/tensorflow/framework/activations/Linear.java",
    "status": "modified",
    "additions": 4,
    "deletions": 4,
    "changes": 8,
    "blob_url": "https://github.com/tensorflow/java/blob/98df654a9558d0d41ab35766073f7ad97038d556/tensorflow-framework/src/main/java/org/tensorflow/framework/activations/Linear.java",
    "raw_url": "https://github.com/tensorflow/java/raw/98df654a9558d0d41ab35766073f7ad97038d556/tensorflow-framework/src/main/java/org/tensorflow/framework/activations/Linear.java",
    "contents_url": "https://api.github.com/repos/tensorflow/java/contents/tensorflow-framework/src/main/java/org/tensorflow/framework/activations/Linear.java?ref=98df654a9558d0d41ab35766073f7ad97038d556",
    "patch": "@@ -19,9 +19,9 @@\n import org.tensorflow.types.family.TNumber;\n \n /**\n- * Linear activation function  (pass-through).\n+ * Linear activation function (pass-through).\n  *\n- * <p>The linear activation returns its input. It is also known as the Identity activation function.</p>\n+ * <p>The linear activation returns its input. It is also known as the Identity activation function.\n  *\n  * <p>For example:\n  *\n@@ -33,7 +33,7 @@\n  *    // result is [-3.0f,-1.0f, 0.0f,1.0f,3.0f]\n  * </pre>\n  */\n-public class Linear<U extends TNumber> extends Activation<U> {\n+public class Linear extends Activation<TNumber> {\n \n   /**\n    * Creates a linear activation.\n@@ -46,7 +46,7 @@ public Linear(Ops tf) {\n \n   /** {@inheritDoc} */\n   @Override\n-  public Operand<U> call(Operand<U> input) {\n+  public <U extends TNumber> Operand<U> call(Operand<U> input) {\n     return input;\n   }\n }"
  },
  {
    "sha": "409015a1203c74119e89cd2064c6b9adb2fd9fe1",
    "filename": "tensorflow-framework/src/main/java/org/tensorflow/framework/activations/ReLU.java",
    "status": "modified",
    "additions": 7,
    "deletions": 9,
    "changes": 16,
    "blob_url": "https://github.com/tensorflow/java/blob/98df654a9558d0d41ab35766073f7ad97038d556/tensorflow-framework/src/main/java/org/tensorflow/framework/activations/ReLU.java",
    "raw_url": "https://github.com/tensorflow/java/raw/98df654a9558d0d41ab35766073f7ad97038d556/tensorflow-framework/src/main/java/org/tensorflow/framework/activations/ReLU.java",
    "contents_url": "https://api.github.com/repos/tensorflow/java/contents/tensorflow-framework/src/main/java/org/tensorflow/framework/activations/ReLU.java?ref=98df654a9558d0d41ab35766073f7ad97038d556",
    "patch": "@@ -55,10 +55,8 @@\n  *     result = relu.call(input);\n  *     // result is [-0.f, -0.f,  0.f,  0.f, 10.f]\n  * </pre>\n- *\n- * @param <T> the data type of the result\n  */\n-public class ReLU<T extends TNumber> extends Activation<T> {\n+public class ReLU extends Activation<TNumber> {\n \n   public static final float ALPHA_DEFAULT = 0.0f;\n   public static final float MAX_VALUE_DEFAULT = Float.NaN;\n@@ -96,11 +94,11 @@ public ReLU(Ops tf, float alpha, float maxValue, float threshold) {\n \n   /** {@inheritDoc} */\n   @Override\n-  public Operand<T> call(Operand<T> input) {\n-    Class<T> inputType = input.type();\n+  public <U extends TNumber> Operand<U> call(Operand<U> input) {\n+    Class<U> inputType = input.type();\n \n     boolean clipMax = !Float.isNaN(maxValue);\n-    Operand<T> negativePart = null;\n+    Operand<U> negativePart = null;\n     if (alpha != 0) {\n       if (Float.isNaN(maxValue) && threshold == 0) {\n         return tf.nn.leakyRelu(input, LeakyRelu.alpha(alpha));\n@@ -114,7 +112,7 @@ public ReLU(Ops tf, float alpha, float maxValue, float threshold) {\n       }\n     }\n \n-    Operand<T> lInput;\n+    Operand<U> lInput;\n     if (threshold != 0) {\n       // computes input for input > threshold else 0\n       Greater greater = tf.math.greater(input, tf.dtypes.cast(tf.constant(threshold), inputType));\n@@ -127,8 +125,8 @@ public ReLU(Ops tf, float alpha, float maxValue, float threshold) {\n       lInput = tf.nn.relu(input);\n     }\n     if (clipMax) {\n-      Operand<T> lmaxValue = tf.dtypes.cast(tf.constant(maxValue), inputType);\n-      Operand<T> zero = tf.dtypes.cast(tf.constant(0), inputType);\n+      Operand<U> lmaxValue = tf.dtypes.cast(tf.constant(maxValue), inputType);\n+      Operand<U> zero = tf.dtypes.cast(tf.constant(0), inputType);\n       lInput = tf.clipByValue(lInput, zero, lmaxValue);\n     }\n "
  },
  {
    "sha": "7955144abbbf92c8f74af26603d734532aee0d33",
    "filename": "tensorflow-framework/src/main/java/org/tensorflow/framework/activations/SELU.java",
    "status": "modified",
    "additions": 3,
    "deletions": 9,
    "changes": 12,
    "blob_url": "https://github.com/tensorflow/java/blob/98df654a9558d0d41ab35766073f7ad97038d556/tensorflow-framework/src/main/java/org/tensorflow/framework/activations/SELU.java",
    "raw_url": "https://github.com/tensorflow/java/raw/98df654a9558d0d41ab35766073f7ad97038d556/tensorflow-framework/src/main/java/org/tensorflow/framework/activations/SELU.java",
    "contents_url": "https://api.github.com/repos/tensorflow/java/contents/tensorflow-framework/src/main/java/org/tensorflow/framework/activations/SELU.java?ref=98df654a9558d0d41ab35766073f7ad97038d556",
    "patch": "@@ -42,10 +42,9 @@\n  * <p><b>Notes: </b> To be used together with the {@link\n  * org.tensorflow.framework.initializers.LeCun} initializer with Normal Distribution.\n  *\n- * @param <T> the data type of the activation\n  * @see <a href=\"https://arxiv.org/abs/1706.02515\">Klambauer et al., 2017</a>\n  */\n-public class SELU<T extends TFloating> extends Activation<T> {\n+public class SELU extends Activation<TFloating> {\n \n   /**\n    * Creates a Scaled Exponential Linear Unit (SELU) activation.\n@@ -56,14 +55,9 @@ public SELU(Ops tf) {\n     super(tf);\n   }\n \n-  /**\n-   * Gets the calculation operation for the activation.\n-   *\n-   * @param input the input tensor\n-   * @return The operand for the activation\n-   */\n+  /** {@inheritDoc} */\n   @Override\n-  public Operand<T> call(Operand<T> input) {\n+  public <U extends TFloating> Operand<U> call(Operand<U> input) {\n     return tf.nn.selu(input);\n   }\n }"
  },
  {
    "sha": "a89b6119d02b7202b8e39eaca9a6a3b579c41e34",
    "filename": "tensorflow-framework/src/main/java/org/tensorflow/framework/activations/Sigmoid.java",
    "status": "modified",
    "additions": 3,
    "deletions": 10,
    "changes": 13,
    "blob_url": "https://github.com/tensorflow/java/blob/98df654a9558d0d41ab35766073f7ad97038d556/tensorflow-framework/src/main/java/org/tensorflow/framework/activations/Sigmoid.java",
    "raw_url": "https://github.com/tensorflow/java/raw/98df654a9558d0d41ab35766073f7ad97038d556/tensorflow-framework/src/main/java/org/tensorflow/framework/activations/Sigmoid.java",
    "contents_url": "https://api.github.com/repos/tensorflow/java/contents/tensorflow-framework/src/main/java/org/tensorflow/framework/activations/Sigmoid.java?ref=98df654a9558d0d41ab35766073f7ad97038d556",
    "patch": "@@ -38,10 +38,8 @@\n  *     // result is [2.0611537e-09f, 2.6894143e-01f,\n  *     //                 5.0000000e-01f,7.3105860e-01f, 1.f]\n  * </pre>\n- *\n- * @param <T> the data type of the activation\n  */\n-public class Sigmoid<T extends TFloating> extends Activation<T> {\n+public class Sigmoid extends Activation<TFloating> {\n \n   /**\n    * Creates a Sigmoid activation.\n@@ -52,14 +50,9 @@ public Sigmoid(Ops tf) {\n     super(tf);\n   }\n \n-  /**\n-   * Gets the calculation operation for the activation.\n-   *\n-   * @param input the input tensor\n-   * @return The operand for the activation\n-   */\n+  /** {@inheritDoc} */\n   @Override\n-  public Operand<T> call(Operand<T> input) {\n+  public <U extends TFloating> Operand<U> call(Operand<U> input) {\n     return tf.math.sigmoid(input);\n   }\n }"
  },
  {
    "sha": "309cdd68b8b78b1a5d11f521bec20ebb2218425e",
    "filename": "tensorflow-framework/src/main/java/org/tensorflow/framework/activations/Softmax.java",
    "status": "modified",
    "additions": 5,
    "deletions": 12,
    "changes": 17,
    "blob_url": "https://github.com/tensorflow/java/blob/98df654a9558d0d41ab35766073f7ad97038d556/tensorflow-framework/src/main/java/org/tensorflow/framework/activations/Softmax.java",
    "raw_url": "https://github.com/tensorflow/java/raw/98df654a9558d0d41ab35766073f7ad97038d556/tensorflow-framework/src/main/java/org/tensorflow/framework/activations/Softmax.java",
    "contents_url": "https://api.github.com/repos/tensorflow/java/contents/tensorflow-framework/src/main/java/org/tensorflow/framework/activations/Softmax.java?ref=98df654a9558d0d41ab35766073f7ad97038d556",
    "patch": "@@ -35,10 +35,8 @@\n  * <p>The softmax of each vector x is computed as: <code>exp(x) / tf.sum(exp(x))</code>.\n  *\n  * <p>The input values in are the log-odds of the resulting probability.\n- *\n- * @param <T> the data type of the activation\n  */\n-public class Softmax<T extends TFloating> extends Activation<T> {\n+public class Softmax extends Activation<TFloating> {\n \n   private static final int AXIS_DEFAULT = -1;\n \n@@ -65,23 +63,18 @@ public Softmax(Ops tf, int axis) {\n     this.axis = axis;\n   }\n \n-  /**\n-   * Gets the calculation operation for the activation.\n-   *\n-   * @param input the input tensor\n-   * @return The operand for the activation\n-   */\n+  /** {@inheritDoc} */\n   @Override\n-  public Operand<T> call(Operand<T> input) {\n+  public <U extends TFloating> Operand<U> call(Operand<U> input) {\n     Shape shape = input.shape();\n     int numDimensions = shape.numDimensions();\n     if (numDimensions == 2) {\n       return tf.nn.softmax(input);\n     } else {\n-      Operand<T> e =\n+      Operand<U> e =\n           tf.math.exp(\n               tf.math.sub(input, tf.reduceMax(input, tf.constant(axis), ReduceMax.keepDims(true))));\n-      Operand<T> s = tf.reduceSum(e, tf.constant(axis), ReduceSum.keepDims(true));\n+      Operand<U> s = tf.reduceSum(e, tf.constant(axis), ReduceSum.keepDims(true));\n       return tf.math.div(e, s);\n     }\n   }"
  },
  {
    "sha": "0eb703aad9f44f3cf14e4ac8ff43437515361645",
    "filename": "tensorflow-framework/src/main/java/org/tensorflow/framework/activations/Softplus.java",
    "status": "modified",
    "additions": 3,
    "deletions": 8,
    "changes": 11,
    "blob_url": "https://github.com/tensorflow/java/blob/98df654a9558d0d41ab35766073f7ad97038d556/tensorflow-framework/src/main/java/org/tensorflow/framework/activations/Softplus.java",
    "raw_url": "https://github.com/tensorflow/java/raw/98df654a9558d0d41ab35766073f7ad97038d556/tensorflow-framework/src/main/java/org/tensorflow/framework/activations/Softplus.java",
    "contents_url": "https://api.github.com/repos/tensorflow/java/contents/tensorflow-framework/src/main/java/org/tensorflow/framework/activations/Softplus.java?ref=98df654a9558d0d41ab35766073f7ad97038d556",
    "patch": "@@ -32,7 +32,7 @@\n  *     //                 1.3132616e+00f, 2.0000000e+01f]\n  * </pre>\n  */\n-public class Softplus<T extends TFloating> extends Activation<T> {\n+public class Softplus extends Activation<TFloating> {\n \n   /**\n    * Creates a Softplus activation function.\n@@ -43,14 +43,9 @@ public Softplus(Ops tf) {\n     super(tf);\n   }\n \n-  /**\n-   * Gets the calculation operation for the activation.\n-   *\n-   * @param input the input tensor\n-   * @return The operand for the activation\n-   */\n+  /** {@inheritDoc} */\n   @Override\n-  public Operand<T> call(Operand<T> input) {\n+  public <U extends TFloating> Operand<U> call(Operand<U> input) {\n     return tf.math.softplus(input);\n   }\n }"
  },
  {
    "sha": "0a7754258df242d90c4fd03cb24291e1a5a59ee1",
    "filename": "tensorflow-framework/src/main/java/org/tensorflow/framework/activations/Softsign.java",
    "status": "modified",
    "additions": 3,
    "deletions": 10,
    "changes": 13,
    "blob_url": "https://github.com/tensorflow/java/blob/98df654a9558d0d41ab35766073f7ad97038d556/tensorflow-framework/src/main/java/org/tensorflow/framework/activations/Softsign.java",
    "raw_url": "https://github.com/tensorflow/java/raw/98df654a9558d0d41ab35766073f7ad97038d556/tensorflow-framework/src/main/java/org/tensorflow/framework/activations/Softsign.java",
    "contents_url": "https://api.github.com/repos/tensorflow/java/contents/tensorflow-framework/src/main/java/org/tensorflow/framework/activations/Softsign.java?ref=98df654a9558d0d41ab35766073f7ad97038d556",
    "patch": "@@ -30,10 +30,8 @@\n  *     Operand&lt;TFloat32&gt; result = softsign.call(input);\n  *     // result is [-0.5f, 0.f, 0.5f]\n  * </pre>\n- *\n- * @param <T> the data type of the activation\n  */\n-public class Softsign<T extends TFloating> extends Activation<T> {\n+public class Softsign extends Activation<TFloating> {\n \n   /**\n    * Creates a Softsign activation.\n@@ -44,14 +42,9 @@ public Softsign(Ops tf) {\n     super(tf);\n   }\n \n-  /**\n-   * Gets the calculation operation for the activation.\n-   *\n-   * @param input the input tensor\n-   * @return The operand for the activation\n-   */\n+  /** {@inheritDoc} */\n   @Override\n-  public Operand<T> call(Operand<T> input) {\n+  public <U extends TFloating> Operand<U> call(Operand<U> input) {\n     return tf.nn.softsign(input);\n   }\n }"
  },
  {
    "sha": "eb43a21f28502a35799ae7cdd3c134b811efdda1",
    "filename": "tensorflow-framework/src/main/java/org/tensorflow/framework/activations/Swish.java",
    "status": "modified",
    "additions": 2,
    "deletions": 3,
    "changes": 5,
    "blob_url": "https://github.com/tensorflow/java/blob/98df654a9558d0d41ab35766073f7ad97038d556/tensorflow-framework/src/main/java/org/tensorflow/framework/activations/Swish.java",
    "raw_url": "https://github.com/tensorflow/java/raw/98df654a9558d0d41ab35766073f7ad97038d556/tensorflow-framework/src/main/java/org/tensorflow/framework/activations/Swish.java",
    "contents_url": "https://api.github.com/repos/tensorflow/java/contents/tensorflow-framework/src/main/java/org/tensorflow/framework/activations/Swish.java?ref=98df654a9558d0d41ab35766073f7ad97038d556",
    "patch": "@@ -37,10 +37,9 @@\n  *\n  * </pre>\n  *\n- * @param <T> the data type of the activation\n  * @see <a href=\"https://arxiv.org/abs/1710.05941\">Ramachandran et al., 2017</a>\n  */\n-public class Swish<T extends TFloating> extends Activation<T> {\n+public class Swish extends Activation<TFloating> {\n \n   /**\n    * Creates a Swish activation, <code>swish(x) = x * sigmoid(x)</code>.\n@@ -57,7 +56,7 @@ public Swish(Ops tf) {\n \n   /** {@inheritDoc} */\n   @Override\n-  public Operand<T> call(Operand<T> input) {\n+  public <U extends TFloating> Operand<U> call(Operand<U> input) {\n \n     // TODO Python Keras returns a \"grad\", which is an optimization not implemented in Java.\n     return tf.math.mul(input, tf.math.sigmoid(input));"
  },
  {
    "sha": "145561b912937c77d639f968ded12427b4f491ff",
    "filename": "tensorflow-framework/src/main/java/org/tensorflow/framework/activations/Tanh.java",
    "status": "modified",
    "additions": 2,
    "deletions": 4,
    "changes": 6,
    "blob_url": "https://github.com/tensorflow/java/blob/98df654a9558d0d41ab35766073f7ad97038d556/tensorflow-framework/src/main/java/org/tensorflow/framework/activations/Tanh.java",
    "raw_url": "https://github.com/tensorflow/java/raw/98df654a9558d0d41ab35766073f7ad97038d556/tensorflow-framework/src/main/java/org/tensorflow/framework/activations/Tanh.java",
    "contents_url": "https://api.github.com/repos/tensorflow/java/contents/tensorflow-framework/src/main/java/org/tensorflow/framework/activations/Tanh.java?ref=98df654a9558d0d41ab35766073f7ad97038d556",
    "patch": "@@ -30,10 +30,8 @@\n  *     Operand&lt;TFloat32&gt; result = tanh.call(input);\n  *     // result = [-0.9950547f, -0.7615942f,  0.f,  0.7615942f,  0.9950547f]\n  * </pre>\n- *\n- * @param <T> the data type of the activation\n  */\n-public class Tanh<T extends TFloating> extends Activation<T> {\n+public class Tanh extends Activation<TFloating> {\n \n   /**\n    * Creates a Hyperbolic tangent activation.\n@@ -46,7 +44,7 @@ public Tanh(Ops tf) {\n \n   /** {@inheritDoc} */\n   @Override\n-  public Operand<T> call(Operand<T> input) {\n+  public <U extends TFloating> Operand<U> call(Operand<U> input) {\n     return tf.math.tanh(input);\n   }\n }"
  },
  {
    "sha": "739f9f55c553138111034270edad7da28723a6f1",
    "filename": "tensorflow-framework/src/main/java/org/tensorflow/framework/constraints/Constraint.java",
    "status": "modified",
    "additions": 2,
    "deletions": 0,
    "changes": 2,
    "blob_url": "https://github.com/tensorflow/java/blob/98df654a9558d0d41ab35766073f7ad97038d556/tensorflow-framework/src/main/java/org/tensorflow/framework/constraints/Constraint.java",
    "raw_url": "https://github.com/tensorflow/java/raw/98df654a9558d0d41ab35766073f7ad97038d556/tensorflow-framework/src/main/java/org/tensorflow/framework/constraints/Constraint.java",
    "contents_url": "https://api.github.com/repos/tensorflow/java/contents/tensorflow-framework/src/main/java/org/tensorflow/framework/constraints/Constraint.java?ref=98df654a9558d0d41ab35766073f7ad97038d556",
    "patch": "@@ -41,7 +41,9 @@ public Constraint(Ops tf) {\n    * Applies the constraint against the provided weights\n    *\n    * @param weights the weights\n+   * @param <T> the data the weights and result\n    * @return the constrained weights\n+   *\n    */\n   public abstract <T extends TNumber> Operand<T> call(Operand<T> weights);\n "
  },
  {
    "sha": "3f2ebe58cb4c7ffbc038e560d5aa9debedf08d09",
    "filename": "tensorflow-framework/src/main/java/org/tensorflow/framework/initializers/Constant.java",
    "status": "modified",
    "additions": 20,
    "deletions": 57,
    "changes": 77,
    "blob_url": "https://github.com/tensorflow/java/blob/98df654a9558d0d41ab35766073f7ad97038d556/tensorflow-framework/src/main/java/org/tensorflow/framework/initializers/Constant.java",
    "raw_url": "https://github.com/tensorflow/java/raw/98df654a9558d0d41ab35766073f7ad97038d556/tensorflow-framework/src/main/java/org/tensorflow/framework/initializers/Constant.java",
    "contents_url": "https://api.github.com/repos/tensorflow/java/contents/tensorflow-framework/src/main/java/org/tensorflow/framework/initializers/Constant.java?ref=98df654a9558d0d41ab35766073f7ad97038d556",
    "patch": "@@ -16,11 +16,11 @@\n \n import org.tensorflow.Operand;\n import org.tensorflow.op.Ops;\n-import org.tensorflow.types.TBool;\n import org.tensorflow.types.TInt64;\n-import org.tensorflow.types.family.TNumber;\n import org.tensorflow.types.family.TType;\n \n+import static org.tensorflow.framework.utils.CastHelper.cast;\n+\n /**\n  * Initializer that generates tensors with a constant value.\n  *\n@@ -33,76 +33,39 @@\n  *              initializer.call(tf.constant(Shape.of(2,2)), TFloat32.class);\n  * </pre>\n  *\n- * @param <T> The Type for the call operation\n+ * <p>Only scalar values are allowed. The constant value provided must be convertible to the data\n+ * type requested when calling the initializer.\n  */\n-public class Constant<T extends TType> extends BaseInitializer<T> {\n-\n-  private final double doubleValue;\n-  private final long longValue;\n-  private final boolean booleanValue;\n-  private final ValueType valueType;\n+public class Constant extends BaseInitializer<TType> {\n \n-  /**\n-   * Creates an Initializer that generates tensors with a constant value.\n-   *\n-   * @param tf the TensorFlow Ops\n-   * @param value a long value used for the constant.\n-   */\n-  public Constant(Ops tf, long value) {\n-    super(tf);\n-    longValue = value;\n-    doubleValue = 0;\n-    booleanValue = false;\n-    valueType = ValueType.LONG;\n-  }\n+  private final Operand<? extends TType> value;\n \n   /**\n    * Creates an Initializer that generates tensors with a constant value.\n    *\n    * @param tf the TensorFlow Ops\n-   * @param value a double value used for the constant.\n+   * @param value the value used for the constant.\n+   * @throws IllegalArgumentException if value is not a scalar.\n    */\n-  public Constant(Ops tf, double value) {\n+  public Constant(Ops tf, Operand<? extends TType> value) {\n     super(tf);\n-    doubleValue = value;\n-    longValue = 0;\n-    booleanValue = false;\n-    valueType = ValueType.DOUBLE;\n+    if (!value.shape().isScalar()) {\n+      throw new IllegalArgumentException(\"value must be scalar, got shape : \" + value.shape());\n+    }\n+    this.value = value;\n   }\n \n   /**\n-   * Creates an Initializer that generates tensors with a constant value.\n+   * Generates the operation used to perform the initialization.\n    *\n-   * @param tf the TensorFlow Ops\n-   * @param value a boolean value used for the constant.\n+   * @param dims the shape dimensions\n+   * @param type the data type of tensor\n+   * @param <U> The data Type for initializer operation\n+   * @return An operand for the initialization.\n    */\n-  public Constant(Ops tf, boolean value) {\n-    super(tf);\n-    booleanValue = value;\n-    doubleValue = 0;\n-    longValue = 0;\n-    valueType = ValueType.BOOLEAN;\n-  }\n-\n-  /** {@inheritDoc} */\n   @Override\n-  public Operand<T> call(Operand<TInt64> dims, Class<T> type) {\n-    if (!TNumber.class.isAssignableFrom(type) && type != TBool.class) {\n-      throw new IllegalArgumentException(\"Tensor type must be numeric or boolean: \" + type.getSimpleName());\n-    }\n-    switch (valueType) {\n-      case LONG:\n-        return tf.fill(dims, tf.dtypes.cast(tf.constant(longValue), type));\n-      case DOUBLE:\n-        return tf.fill(dims, tf.dtypes.cast(tf.constant(doubleValue), type));\n-      default:\n-        return tf.fill(dims, tf.dtypes.cast(tf.constant(booleanValue), type));\n-    }\n-  }\n+  public <U extends TType> Operand<U> call(Operand<TInt64> dims, Class<U> type) {\n \n-  private enum ValueType {\n-    LONG,\n-    DOUBLE,\n-    BOOLEAN\n+    return tf.fill(dims, cast(tf, value, type));\n   }\n }"
  },
  {
    "sha": "5a3c291785fe7cb7b248627c721716e2f687794d",
    "filename": "tensorflow-framework/src/main/java/org/tensorflow/framework/initializers/Glorot.java",
    "status": "modified",
    "additions": 4,
    "deletions": 4,
    "changes": 8,
    "blob_url": "https://github.com/tensorflow/java/blob/98df654a9558d0d41ab35766073f7ad97038d556/tensorflow-framework/src/main/java/org/tensorflow/framework/initializers/Glorot.java",
    "raw_url": "https://github.com/tensorflow/java/raw/98df654a9558d0d41ab35766073f7ad97038d556/tensorflow-framework/src/main/java/org/tensorflow/framework/initializers/Glorot.java",
    "contents_url": "https://api.github.com/repos/tensorflow/java/contents/tensorflow-framework/src/main/java/org/tensorflow/framework/initializers/Glorot.java?ref=98df654a9558d0d41ab35766073f7ad97038d556",
    "patch": "@@ -16,7 +16,6 @@\n package org.tensorflow.framework.initializers;\n \n import org.tensorflow.op.Ops;\n-import org.tensorflow.types.family.TFloating;\n \n /**\n  * The Glorot initializer, also called Xavier initializer.\n@@ -58,16 +57,17 @@\n  * </pre>\n  *\n  * <p><b>NOTE:</b>\n+ *\n  * <p>For a GlorotNormal equivalent initializer, use {@link\n  * VarianceScaling.Distribution#TRUNCATED_NORMAL} for the distribution parameter.\n+ *\n  * <p>For a GlorotUniform equivalent initializer, use {@link VarianceScaling.Distribution#UNIFORM}\n  * for the distribution parameter.\n  *\n- * @param <T> The TType for the call operation\n  * @see VarianceScaling.Distribution\n  * @see <a href=\"http://proceedings.mlr.press/v9/glorot10a.html\">Glorot et al., 2010</a>\n  */\n-public class Glorot<T extends TFloating> extends VarianceScaling<T> {\n+public class Glorot extends VarianceScaling {\n \n   public static final double SCALE = 1.0;\n \n@@ -77,7 +77,7 @@\n    * @param tf the TensorFlow Ops\n    * @param distribution The distribution type for the Glorot initializer.\n    * @param seed the seed for random number generation. An initializer created with a given seed\n-   *     will always produce the same random tensor for a given shape and dtype.\n+   *     will always produce the same random tensor for a given shape and data type.\n    * @see VarianceScaling.Distribution\n    */\n   public Glorot(Ops tf, Distribution distribution, long seed) {"
  },
  {
    "sha": "ac64e449265cc89a21609baf7d59ab07d8c2c5c8",
    "filename": "tensorflow-framework/src/main/java/org/tensorflow/framework/initializers/He.java",
    "status": "modified",
    "additions": 6,
    "deletions": 6,
    "changes": 12,
    "blob_url": "https://github.com/tensorflow/java/blob/98df654a9558d0d41ab35766073f7ad97038d556/tensorflow-framework/src/main/java/org/tensorflow/framework/initializers/He.java",
    "raw_url": "https://github.com/tensorflow/java/raw/98df654a9558d0d41ab35766073f7ad97038d556/tensorflow-framework/src/main/java/org/tensorflow/framework/initializers/He.java",
    "contents_url": "https://api.github.com/repos/tensorflow/java/contents/tensorflow-framework/src/main/java/org/tensorflow/framework/initializers/He.java?ref=98df654a9558d0d41ab35766073f7ad97038d556",
    "patch": "@@ -15,7 +15,6 @@\n package org.tensorflow.framework.initializers;\n \n import org.tensorflow.op.Ops;\n-import org.tensorflow.types.family.TFloating;\n \n /**\n  * He initializer.\n@@ -53,17 +52,18 @@\n  * </pre>\n  *\n  * <p><b>NOTE:</b>\n+ *\n  * <p>For an HeNormal equivalent initializer, use {@link\n  * VarianceScaling.Distribution#TRUNCATED_NORMAL} for the distribution parameter.\n- * <p>For an HeUniform equivalent initializer, use {@link VarianceScaling.Distribution#UNIFORM}\n- * for the distribution parameter.\n  *\n- * @param <T> The TType for the call operation\n+ * <p>For an HeUniform equivalent initializer, use {@link VarianceScaling.Distribution#UNIFORM} for\n+ * the distribution parameter.\n+ *\n  * @see <a\n  *     href=\"https://www.cv-foundation.org/openaccess/content_iccv_2015/html/He_Delving_Deep_into_ICCV_2015_paper.html\">He\n  *     et al., 2015</a>\n  */\n-public class He<T extends TFloating> extends VarianceScaling<T> {\n+public class He extends VarianceScaling {\n \n   public static final double SCALE = 2.0;\n \n@@ -73,7 +73,7 @@\n    * @param tf the TensorFlow Ops\n    * @param distribution The distribution type for the He initializer.\n    * @param seed the seed for random number generation. An initializer created with a given seed\n-   *     will always produce the same random tensor for a given shape and dtype.\n+   *     will always produce the same random tensor for a given shape and data type.\n    * @see VarianceScaling.Distribution\n    */\n   public He(Ops tf, Distribution distribution, long seed) {"
  },
  {
    "sha": "2b1ccf00baeb4aa19ae82bfc074704e770e366cf",
    "filename": "tensorflow-framework/src/main/java/org/tensorflow/framework/initializers/Identity.java",
    "status": "modified",
    "additions": 10,
    "deletions": 10,
    "changes": 20,
    "blob_url": "https://github.com/tensorflow/java/blob/98df654a9558d0d41ab35766073f7ad97038d556/tensorflow-framework/src/main/java/org/tensorflow/framework/initializers/Identity.java",
    "raw_url": "https://github.com/tensorflow/java/raw/98df654a9558d0d41ab35766073f7ad97038d556/tensorflow-framework/src/main/java/org/tensorflow/framework/initializers/Identity.java",
    "contents_url": "https://api.github.com/repos/tensorflow/java/contents/tensorflow-framework/src/main/java/org/tensorflow/framework/initializers/Identity.java?ref=98df654a9558d0d41ab35766073f7ad97038d556",
    "patch": "@@ -21,6 +21,8 @@\n import org.tensorflow.types.TInt64;\n import org.tensorflow.types.family.TFloating;\n \n+import static org.tensorflow.framework.utils.CastHelper.cast;\n+\n /**\n  * Initializer that generates the identity matrix.\n  *\n@@ -34,10 +36,8 @@\n  *     Operand&lt;TFloat32&gt; values =\n  *             initializer.call(tf.constant(Shape.of(2,2)), TFloat32.class);\n  * </pre>\n- *\n- * @param <T> The TType for the call operation\n  */\n-public class Identity<T extends TFloating> extends BaseInitializer<T> {\n+public class Identity extends BaseInitializer<TFloating> {\n   public static final double GAIN_DEFAULT = 1.0;\n \n   private final double gain;\n@@ -65,7 +65,7 @@ public Identity(Ops tf, double gain) {\n \n   /** {@inheritDoc} */\n   @Override\n-  public Operand<T> call(Operand<TInt64> dims, Class<T> type) {\n+  public <U extends TFloating> Operand<U> call(Operand<TInt64> dims, Class<U> type) {\n     Shape shape = ShapeUtils.toShape(tf.scope(), dims);\n     if (shape.numDimensions() != 2) {\n       throw new IllegalArgumentException(\"2D matrix required, got \" + shape.numDimensions());\n@@ -74,10 +74,10 @@ public Identity(Ops tf, double gain) {\n     long diagSize = Math.min(shape.size(0), shape.size(1));\n     Shape diagShape = Shape.of(diagSize);\n \n-    Operand<T> op;\n-    Operand<T> zero = tf.dtypes.cast(tf.constant(0), type);\n-    Operand<T> diagOnes =\n-        tf.fill(tf.constant(diagShape.asArray()), tf.dtypes.cast(tf.constant(1.0), type));\n+    Operand<U> op;\n+    Operand<U> zero = cast(tf, tf.constant(0), type);\n+    Operand<U> diagOnes =\n+        tf.fill(tf.constant(diagShape.asArray()), cast(tf, tf.constant(1.0), type));\n     if (isSquare) {\n       op =\n           tf.linalg.matrixDiag(\n@@ -87,10 +87,10 @@ public Identity(Ops tf, double gain) {\n               tf.constant((int) shape.size(1)),\n               zero);\n     } else {\n-      Operand<T> zeroMatrix = tf.zeros(dims, type);\n+      Operand<U> zeroMatrix = tf.zeros(dims, type);\n       op = tf.linalg.matrixSetDiag(zeroMatrix, diagOnes, tf.constant(0));\n     }\n \n-    return tf.math.mul(op, tf.dtypes.cast(tf.constant(gain), type));\n+    return tf.math.mul(op, cast(tf, tf.constant(gain), type));\n   }\n }"
  },
  {
    "sha": "2f30bc5e99dc857c451594932b5571a6a4e07059",
    "filename": "tensorflow-framework/src/main/java/org/tensorflow/framework/initializers/Initializer.java",
    "status": "modified",
    "additions": 4,
    "deletions": 7,
    "changes": 11,
    "blob_url": "https://github.com/tensorflow/java/blob/98df654a9558d0d41ab35766073f7ad97038d556/tensorflow-framework/src/main/java/org/tensorflow/framework/initializers/Initializer.java",
    "raw_url": "https://github.com/tensorflow/java/raw/98df654a9558d0d41ab35766073f7ad97038d556/tensorflow-framework/src/main/java/org/tensorflow/framework/initializers/Initializer.java",
    "contents_url": "https://api.github.com/repos/tensorflow/java/contents/tensorflow-framework/src/main/java/org/tensorflow/framework/initializers/Initializer.java?ref=98df654a9558d0d41ab35766073f7ad97038d556",
    "patch": "@@ -18,19 +18,16 @@\n import org.tensorflow.types.TInt64;\n import org.tensorflow.types.family.TType;\n \n-/**\n- * An interface for Initializers\n- *\n- * @param <T> The data Type for initializer operation\n- */\n+/** An interface for Initializers */\n public interface Initializer<T extends TType> {\n \n   /**\n    * Generates the operation used to perform the initialization.\n    *\n    * @param dims the shape dimensions\n-   * @param type the type of tensor\n+   * @param type the data type of tensor\n+   * @param <U> The data Type for initializer operation\n    * @return An operand for the initialization.\n    */\n-  Operand<T> call(Operand<TInt64> dims, Class<T> type);\n+  <U extends T> Operand<U> call(Operand<TInt64> dims, Class<U> type);\n }"
  },
  {
    "sha": "b82f40918c085f4cbb8042cfadf57e0d7fccf772",
    "filename": "tensorflow-framework/src/main/java/org/tensorflow/framework/initializers/LeCun.java",
    "status": "modified",
    "additions": 5,
    "deletions": 6,
    "changes": 11,
    "blob_url": "https://github.com/tensorflow/java/blob/98df654a9558d0d41ab35766073f7ad97038d556/tensorflow-framework/src/main/java/org/tensorflow/framework/initializers/LeCun.java",
    "raw_url": "https://github.com/tensorflow/java/raw/98df654a9558d0d41ab35766073f7ad97038d556/tensorflow-framework/src/main/java/org/tensorflow/framework/initializers/LeCun.java",
    "contents_url": "https://api.github.com/repos/tensorflow/java/contents/tensorflow-framework/src/main/java/org/tensorflow/framework/initializers/LeCun.java?ref=98df654a9558d0d41ab35766073f7ad97038d556",
    "patch": "@@ -15,7 +15,6 @@\n package org.tensorflow.framework.initializers;\n \n import org.tensorflow.op.Ops;\n-import org.tensorflow.types.family.TFloating;\n \n /**\n  * LeCun normal initializer.\n@@ -27,7 +26,7 @@\n  * stddev = sqrt(1 / fanIn)</code> where <code>fanIn</code> is the number of input units in the\n  * weight tensor.\n  *\n- * <p>If the distribution is UNIFORM, itraws samples from a uniform distribution within <code>\n+ * <p>If the distribution is UNIFORM, it draws samples from a uniform distribution within <code>\n  * [-limit, limit]</code>, where <code>limit = Math.sqrt(3 / fanIn)</code> (<code>fanIn</code> is\n  * the number of input units in the weight tensor)\n  *\n@@ -59,30 +58,30 @@\n  *\n  * <p><b>NOTE:</b> *\n  *\n- * <p>For a LeCunNormal equivalent initializer, use {@link VarianceScaling.Distribution#TRUNCATED_NORMAL} for the distribution parameter. *\n+ * <p>For a LeCunNormal equivalent initializer, use {@link\n+ * VarianceScaling.Distribution#TRUNCATED_NORMAL} for the distribution parameter. *\n  *\n  * <p>For a LeCunUniform equivalent initializer, use {@link VarianceScaling.Distribution#UNIFORM} *\n  * for the distribution parameter. *\n  *\n  * <p>\n  *\n- * @param <T> The TType for the call operation\n  * @see <a\n  *     href=\"https://papers.nips.cc/paper/6698-self-normalizing-neural-networks\">Self-Normalizing\n  *     Neural Networks, Klambauer et al., 2017</a>\n  * @see <a href=\"http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf\">Efficient Backprop, Lecun et\n  *     al., 1998</a>\n  * @see VarianceScaling.Distribution\n  */\n-public class LeCun<T extends TFloating> extends VarianceScaling<T> {\n+public class LeCun extends VarianceScaling {\n \n   /**\n    * Creates a LeCunNormal Initializer\n    *\n    * @param tf the TensorFlow Ops\n    * @param distribution The distribution type for the Glorot initializer.\n    * @param seed the seed for random number generation. An initializer created with a given seed\n-   *     will always produce the same random tensor for a given shape and dtype.\n+   *     will always produce the same random tensor for a given shape and data type.\n    */\n   public LeCun(Ops tf, Distribution distribution, long seed) {\n     super(tf, 1.0, Mode.FAN_IN, distribution, seed);"
  },
  {
    "sha": "5cf8c7a8033268efd61f6ba35c4c768a04b0105b",
    "filename": "tensorflow-framework/src/main/java/org/tensorflow/framework/initializers/Ones.java",
    "status": "modified",
    "additions": 17,
    "deletions": 7,
    "changes": 24,
    "blob_url": "https://github.com/tensorflow/java/blob/98df654a9558d0d41ab35766073f7ad97038d556/tensorflow-framework/src/main/java/org/tensorflow/framework/initializers/Ones.java",
    "raw_url": "https://github.com/tensorflow/java/raw/98df654a9558d0d41ab35766073f7ad97038d556/tensorflow-framework/src/main/java/org/tensorflow/framework/initializers/Ones.java",
    "contents_url": "https://api.github.com/repos/tensorflow/java/contents/tensorflow-framework/src/main/java/org/tensorflow/framework/initializers/Ones.java?ref=98df654a9558d0d41ab35766073f7ad97038d556",
    "patch": "@@ -21,6 +21,8 @@\n import org.tensorflow.types.family.TNumber;\n import org.tensorflow.types.family.TType;\n \n+import static org.tensorflow.framework.utils.CastHelper.cast;\n+\n /**\n  * Initializer that generates tensors initialized to 1.\n  *\n@@ -32,10 +34,8 @@\n  *      Operand&lt;TFloat32&gt; values =\n  *              initializer.call(tf.constant(Shape.of(2,2)), TFloat32.class);\n  * </pre>\n- *\n- * @param <T> The TType for the call operation\n  */\n-public class Ones<T extends TType> extends BaseInitializer<T> {\n+public class Ones extends BaseInitializer<TType> {\n \n   /**\n    * Creates an Initializer that sets all values to one.\n@@ -55,12 +55,22 @@ public Ones(Ops tf) {\n     super(tf);\n   }\n \n-  /** {@inheritDoc} */\n+  /**\n+   * Generates the operation used to perform the initialization.\n+   *\n+   * @param dims the shape dimensions\n+   * @param type the data type of tensor\n+   * @param <U> The data Type for initializer operation\n+   * @return An operand for the initialization.\n+   * @throws IllegalArgumentException if the data type is not a TNumber or TBool\n+   */\n   @Override\n-  public Operand<T> call(Operand<TInt64> dims, Class<T> type) {\n+  public <U extends TType> Operand<U> call(Operand<TInt64> dims, Class<U> type) {\n     if (!TNumber.class.isAssignableFrom(type) && type != TBool.class) {\n-      throw new IllegalArgumentException(\"Tensor type must be numeric or boolean: \" + type.getSimpleName());\n+      throw new IllegalArgumentException(\n+          \"Tensor type must be numeric or boolean: \" + type.getSimpleName());\n     }\n-    return tf.fill(dims, tf.dtypes.cast(tf.constant(1.0), type));\n+\n+    return tf.fill(dims, cast(tf, tf.constant(1), type));\n   }\n }"
  },
  {
    "sha": "14f1049d038ab7579056bf230856fd84ab404388",
    "filename": "tensorflow-framework/src/main/java/org/tensorflow/framework/initializers/Orthogonal.java",
    "status": "modified",
    "additions": 19,
    "deletions": 15,
    "changes": 34,
    "blob_url": "https://github.com/tensorflow/java/blob/98df654a9558d0d41ab35766073f7ad97038d556/tensorflow-framework/src/main/java/org/tensorflow/framework/initializers/Orthogonal.java",
    "raw_url": "https://github.com/tensorflow/java/raw/98df654a9558d0d41ab35766073f7ad97038d556/tensorflow-framework/src/main/java/org/tensorflow/framework/initializers/Orthogonal.java",
    "contents_url": "https://api.github.com/repos/tensorflow/java/contents/tensorflow-framework/src/main/java/org/tensorflow/framework/initializers/Orthogonal.java?ref=98df654a9558d0d41ab35766073f7ad97038d556",
    "patch": "@@ -23,6 +23,8 @@\n import org.tensorflow.types.TInt64;\n import org.tensorflow.types.family.TFloating;\n \n+import static org.tensorflow.framework.utils.CastHelper.cast;\n+\n /**\n  * Initializer that generates an orthogonal matrix.\n  *\n@@ -44,10 +46,8 @@\n  *      Operand&lt;TFloat32&gt; values =\n  *              initializer.call(tf.constant(Shape.of(2,2)), TFloat32.class);\n  * </pre>\n- *\n- * @param <T> The TType for the call operation\n  */\n-public class Orthogonal<T extends TFloating> extends BaseInitializer<T> {\n+public class Orthogonal extends BaseInitializer<TFloating> {\n \n   public static final double GAIN_DEFAULT = 1.0;\n \n@@ -59,7 +59,7 @@\n    *\n    * @param tf the TensorFlow Ops\n    * @param seed the seed for random number generation. An initializer created with a given seed\n-   *     will always produce the same random tensor for a given shape and dtype.\n+   *     will always produce the same random tensor for a given shape and data type.\n    */\n   public Orthogonal(Ops tf, long seed) {\n     this(tf, GAIN_DEFAULT, seed);\n@@ -71,7 +71,7 @@ public Orthogonal(Ops tf, long seed) {\n    * @param tf the TensorFlow Ops\n    * @param gain the gain to be applied to the Matrix.\n    * @param seed the seed for random number generation. An initializer created with a given seed\n-   *     will always produce the same random tensor for a given shape and dtype.\n+   *     will always produce the same random tensor for a given shape and data type.\n    */\n   public Orthogonal(Ops tf, double gain, long seed) {\n     super(tf);\n@@ -81,7 +81,8 @@ public Orthogonal(Ops tf, double gain, long seed) {\n \n   /** {@inheritDoc} */\n   @Override\n-  public Operand<T> call(Operand<TInt64> dims, Class<T> type) {\n+  public <U extends TFloating> Operand<U> call(Operand<TInt64> dims, Class<U> type) {\n+\n     Shape dimsShape = ShapeUtils.toShape(tf.scope(), dims);\n     if (dimsShape.numDimensions() < 2) {\n       throw new IllegalArgumentException(\n@@ -94,17 +95,20 @@ public Orthogonal(Ops tf, double gain, long seed) {\n     long numCols = dimsShape.size(i);\n     Shape flatShape = Shape.of(Math.max(numRows, numCols), Math.min(numRows, numCols));\n     long[] seeds = {seed, 0};\n-    Operand<T> op =\n+    Operand<U> op =\n         tf.random.statelessRandomNormal(tf.constant(flatShape), tf.constant(seeds), type);\n+\n     Qr.Options qrOptions = Qr.fullMatrices(false);\n-    Qr<T> qrOp = tf.linalg.qr(op, qrOptions);\n-    Output<T> qo = qrOp.q();\n-    Output<T> ro = qrOp.r();\n-    Operand<T> diagOp =\n-        tf.linalg.matrixDiagPart(ro, tf.constant(0), tf.dtypes.cast(tf.constant(0), type));\n-    Operand<T> qop = tf.math.mul(qo, tf.math.sign(diagOp));\n-    if (numRows < numCols) qop = tf.linalg.transpose(qop, null);\n+    Qr<U> qrOp = tf.linalg.qr(op, qrOptions);\n+    Output<U> qo = qrOp.q();\n+    Output<U> ro = qrOp.r();\n+    Operand<U> diagOp =\n+        tf.linalg.matrixDiagPart(ro, tf.constant(0), cast(tf, tf.constant(0), op.type()));\n+    Operand<U> qop = tf.math.mul(qo, tf.math.sign(diagOp));\n+    if (numRows < numCols) {\n+      qop = tf.linalg.transpose(qop, null);\n+    }\n \n-    return tf.math.mul(qop, tf.dtypes.cast(tf.constant(this.gain), type));\n+    return tf.math.mul(qop, cast(tf, tf.constant(this.gain), op.type()));\n   }\n }"
  },
  {
    "sha": "6b90ed3985d9abe0159117aee1cba1c9e47d2362",
    "filename": "tensorflow-framework/src/main/java/org/tensorflow/framework/initializers/RandomNormal.java",
    "status": "modified",
    "additions": 15,
    "deletions": 10,
    "changes": 25,
    "blob_url": "https://github.com/tensorflow/java/blob/98df654a9558d0d41ab35766073f7ad97038d556/tensorflow-framework/src/main/java/org/tensorflow/framework/initializers/RandomNormal.java",
    "raw_url": "https://github.com/tensorflow/java/raw/98df654a9558d0d41ab35766073f7ad97038d556/tensorflow-framework/src/main/java/org/tensorflow/framework/initializers/RandomNormal.java",
    "contents_url": "https://api.github.com/repos/tensorflow/java/contents/tensorflow-framework/src/main/java/org/tensorflow/framework/initializers/RandomNormal.java?ref=98df654a9558d0d41ab35766073f7ad97038d556",
    "patch": "@@ -19,6 +19,8 @@\n import org.tensorflow.types.TInt64;\n import org.tensorflow.types.family.TFloating;\n \n+import static org.tensorflow.framework.utils.CastHelper.cast;\n+\n /**\n  * Initializer that generates tensors with a normal distribution.\n  *\n@@ -31,10 +33,8 @@\n  *     Operand&lt;TFloat32&gt; values =\n  *              initializer.call(tf.constant(Shape.of(2,2)), TFloat32.class);\n  * </pre>\n- *\n- * @param <T> The TType for the call operation\n  */\n-public class RandomNormal<T extends TFloating> extends BaseInitializer<T> {\n+public class RandomNormal extends BaseInitializer<TFloating> {\n \n   public static final double MEAN_DEFAULT = 0.0;\n   public static final double STDDEV_DEFAULT = 1.0;\n@@ -49,7 +49,7 @@\n    *\n    * @param tf the TensorFlow Ops\n    * @param seed the seed for random number generation. An initializer created with a given seed\n-   *     will always produce the same random tensor for a given shape and dtype.\n+   *     will always produce the same random tensor for a given shape and data type.\n    */\n   public RandomNormal(Ops tf, long seed) {\n     this(tf, MEAN_DEFAULT, STDDEV_DEFAULT, seed);\n@@ -61,7 +61,7 @@ public RandomNormal(Ops tf, long seed) {\n    * @param tf the TensorFlow Ops\n    * @param mean Mean of the random values to generate.\n    * @param seed the seed for random number generation. An initializer created with a given seed\n-   *     will always produce the same random tensor for a given shape and dtype.\n+   *     will always produce the same random tensor for a given shape and data type.\n    */\n   public RandomNormal(Ops tf, double mean, long seed) {\n     this(tf, mean, STDDEV_DEFAULT, seed);\n@@ -74,21 +74,26 @@ public RandomNormal(Ops tf, double mean, long seed) {\n    * @param mean Mean of the random values to generate.\n    * @param stddev Standard deviation of the random values to generate.\n    * @param seed the seed for random number generation. An initializer created with a given seed\n-   *     will always produce the same random tensor for a given shape and dtype.\n+   *     will always produce the same random tensor for a given shape and data type.\n+   * @throws IllegalArgumentException if standard deviation is less than 0.\n    */\n   public RandomNormal(Ops tf, double mean, double stddev, long seed) {\n     super(tf);\n+    if (stddev < 0) {\n+      throw new IllegalArgumentException(\n+          \"Standard deviation (stddev) cannot be less than 0, got \" + stddev);\n+    }\n     this.mean = mean;\n     this.stddev = stddev;\n     this.seed = seed;\n   }\n \n   /** {@inheritDoc} */\n   @Override\n-  public Operand<T> call(Operand<TInt64> dims, Class<T> type) {\n+  public <U extends TFloating> Operand<U> call(Operand<TInt64> dims, Class<U> type) {\n     long[] seeds = {seed, 0};\n-    Operand<T> distOp = tf.random.statelessRandomNormal(dims, tf.constant(seeds), type);\n-    Operand<T> op = tf.math.mul(distOp, tf.dtypes.cast(tf.constant(this.stddev), type));\n-    return tf.math.add(op, tf.dtypes.cast(tf.constant(mean), type));\n+    Operand<U> distOp = tf.random.statelessRandomNormal(dims, tf.constant(seeds), type);\n+    Operand<U> op = tf.math.mul(distOp, cast(tf, tf.constant(this.stddev), type));\n+    return tf.math.add(op, cast(tf, tf.constant(mean), distOp.type()));\n   }\n }"
  },
  {
    "sha": "c0ebce135e9f4ce09d69f5b426477d5a7fae3519",
    "filename": "tensorflow-framework/src/main/java/org/tensorflow/framework/initializers/RandomUniform.java",
    "status": "modified",
    "additions": 15,
    "deletions": 14,
    "changes": 29,
    "blob_url": "https://github.com/tensorflow/java/blob/98df654a9558d0d41ab35766073f7ad97038d556/tensorflow-framework/src/main/java/org/tensorflow/framework/initializers/RandomUniform.java",
    "raw_url": "https://github.com/tensorflow/java/raw/98df654a9558d0d41ab35766073f7ad97038d556/tensorflow-framework/src/main/java/org/tensorflow/framework/initializers/RandomUniform.java",
    "contents_url": "https://api.github.com/repos/tensorflow/java/contents/tensorflow-framework/src/main/java/org/tensorflow/framework/initializers/RandomUniform.java?ref=98df654a9558d0d41ab35766073f7ad97038d556",
    "patch": "@@ -21,6 +21,8 @@\n import org.tensorflow.types.family.TIntegral;\n import org.tensorflow.types.family.TNumber;\n \n+import static org.tensorflow.framework.utils.CastHelper.cast;\n+\n /**\n  * Initializer that generates tensors with a uniform distribution.\n  *\n@@ -33,10 +35,8 @@\n  *     Operand&lt;TFloat32&gt; values =\n  *              initializer.call(tf.constant(Shape.of(2,2)), TFloat32.class);\n  * </pre>\n- *\n- * @param <T> The TType for the call operation\n  */\n-public class RandomUniform<T extends TNumber> extends BaseInitializer<T> {\n+public class RandomUniform extends BaseInitializer<TNumber> {\n \n   public static final double MINVAL_DEFAULT = -0.05;\n   public static final double MAXVAL_DEFAULT = 0.05;\n@@ -46,12 +46,12 @@\n   private final long seed;\n \n   /**\n-   * Creates a RandomUniform initializer using {@link #MINVAL_DEFAULT} for the minval and\n-   * {@link #MAXVAL_DEFAULT} for the maxval\n+   * Creates a RandomUniform initializer using {@link #MINVAL_DEFAULT} for the minval and {@link\n+   * #MAXVAL_DEFAULT} for the maxval\n    *\n    * @param tf the TensorFlow Ops\n    * @param seed the seed for random number generation. An initializer created with a given seed\n-   *     will always produce the same random tensor for a given shape and dtype.\n+   *     will always produce the same random tensor for a given shape and data type.\n    */\n   public RandomUniform(Ops tf, long seed) {\n     this(tf, MINVAL_DEFAULT, MAXVAL_DEFAULT, seed);\n@@ -64,7 +64,7 @@ public RandomUniform(Ops tf, long seed) {\n    * @param minval Lower bound of the range of random values to generate (inclusive).\n    * @param maxval Upper bound of the range of random values to generate (exclusive).\n    * @param seed the seed for random number generation. An initializer created with a given seed\n-   *     will always produce the same random tensor for a given shape and dtype.\n+   *     will always produce the same random tensor for a given shape and data type.\n    */\n   public RandomUniform(Ops tf, double minval, double maxval, long seed) {\n     super(tf);\n@@ -75,26 +75,27 @@ public RandomUniform(Ops tf, double minval, double maxval, long seed) {\n \n   /** {@inheritDoc} */\n   @Override\n-  public Operand<T> call(Operand<TInt64> dims, Class<T> type) {\n-    Operand<T> distOp;\n+  public <U extends TNumber> Operand<U> call(Operand<TInt64> dims, Class<U> type) {\n+    Operand<U> distOp;\n     if (TIntegral.class.isAssignableFrom(type)) {\n       RandomUniformInt.Options options = RandomUniformInt.seed(this.seed);\n       distOp =\n           tf.random.randomUniformInt(\n               dims,\n-              tf.dtypes.cast(tf.constant(this.minval), type),\n-              tf.dtypes.cast(tf.constant(this.maxval), type),\n+              cast(tf, tf.constant(this.minval), type),\n+              cast(tf, tf.constant(this.maxval), type),\n               options);\n     } else {\n       long[] seeds = {seed, 0};\n       distOp = tf.random.statelessRandomUniform(dims, tf.constant(seeds), type);\n       if (this.minval == 0) {\n         if (this.maxval != 1.0) {\n-          distOp = tf.math.mul(distOp, tf.dtypes.cast(tf.constant(this.maxval), type));\n+          distOp = tf.math.mul(distOp, cast(tf, tf.constant(this.maxval), distOp.type()));\n         }\n       } else {\n-        distOp = tf.math.mul(distOp, tf.dtypes.cast(tf.constant(this.maxval - this.minval), type));\n-        distOp = tf.math.add(distOp, tf.dtypes.cast(tf.constant(this.minval), type));\n+        distOp =\n+            tf.math.mul(distOp, cast(tf, tf.constant(this.maxval - this.minval), distOp.type()));\n+        distOp = tf.math.add(distOp, cast(tf, tf.constant(this.minval), distOp.type()));\n       }\n     }\n     return distOp;"
  },
  {
    "sha": "eaf94663993e157a2fd6452c5689bda03cb50573",
    "filename": "tensorflow-framework/src/main/java/org/tensorflow/framework/initializers/TruncatedNormal.java",
    "status": "modified",
    "additions": 10,
    "deletions": 10,
    "changes": 20,
    "blob_url": "https://github.com/tensorflow/java/blob/98df654a9558d0d41ab35766073f7ad97038d556/tensorflow-framework/src/main/java/org/tensorflow/framework/initializers/TruncatedNormal.java",
    "raw_url": "https://github.com/tensorflow/java/raw/98df654a9558d0d41ab35766073f7ad97038d556/tensorflow-framework/src/main/java/org/tensorflow/framework/initializers/TruncatedNormal.java",
    "contents_url": "https://api.github.com/repos/tensorflow/java/contents/tensorflow-framework/src/main/java/org/tensorflow/framework/initializers/TruncatedNormal.java?ref=98df654a9558d0d41ab35766073f7ad97038d556",
    "patch": "@@ -19,6 +19,8 @@\n import org.tensorflow.types.TInt64;\n import org.tensorflow.types.family.TFloating;\n \n+import static org.tensorflow.framework.utils.CastHelper.cast;\n+\n /**\n  * Initializer that generates a truncated normal distribution.\n  *\n@@ -31,10 +33,8 @@\n  *     Operand&lt;TFloat32&gt; values =\n  *              initializer.call(tf.constant(Shape.of(2,2)), TFloat32.class);\n  * </pre>\n- *\n- * @param <T> The TType for the call operation\n  */\n-public class TruncatedNormal<T extends TFloating> extends BaseInitializer<T> {\n+public class TruncatedNormal extends BaseInitializer<TFloating> {\n \n   public static final double MEAN_DEFAULT = 0.0;\n   public static final double STDDEV_DEFAULT = 0.05;\n@@ -49,7 +49,7 @@\n    *\n    * @param tf the TensorFlow Ops\n    * @param seed the seed for random number generation. An initializer created with a given seed\n-   *     will always produce the same random tensor for a given shape and dtype.\n+   *     will always produce the same random tensor for a given shape and data type.\n    */\n   public TruncatedNormal(Ops tf, long seed) {\n     this(tf, MEAN_DEFAULT, STDDEV_DEFAULT, seed);\n@@ -62,7 +62,7 @@ public TruncatedNormal(Ops tf, long seed) {\n    * @param mean Mean of the random values to generate.\n    * @param stddev Standard deviation of the random values to generate.\n    * @param seed the seed for random number generation. An initializer created with a given seed\n-   *     will always produce the same random tensor for a given shape and dtype.\n+   *     will always produce the same random tensor for a given shape and data type.\n    */\n   public TruncatedNormal(Ops tf, double mean, double stddev, long seed) {\n     super(tf);\n@@ -73,11 +73,11 @@ public TruncatedNormal(Ops tf, double mean, double stddev, long seed) {\n \n   /** {@inheritDoc} */\n   @Override\n-  public Operand<T> call(Operand<TInt64> dims, Class<T> type) {\n-    long[] seeds = {seed,0};\n-    Operand<T> distOp = tf.random.statelessTruncatedNormal(dims, tf.constant(seeds), type);\n+  public <U extends TFloating> Operand<U> call(Operand<TInt64> dims, Class<U> type) {\n+    long[] seeds = {seed, 0};\n+    Operand<U> distOp = tf.random.statelessTruncatedNormal(dims, tf.constant(seeds), type);\n     return tf.math.add(\n-        tf.math.mul(distOp, tf.dtypes.cast(tf.constant(stddev), type)),\n-        tf.dtypes.cast(tf.constant(mean), type));\n+        tf.math.mul(distOp, cast(tf, tf.constant(stddev), distOp.type())),\n+        cast(tf, tf.constant(mean), distOp.type()));\n   }\n }"
  },
  {
    "sha": "299d719c7c3e85d9054454333811f33826fd8e38",
    "filename": "tensorflow-framework/src/main/java/org/tensorflow/framework/initializers/VarianceScaling.java",
    "status": "modified",
    "additions": 11,
    "deletions": 11,
    "changes": 22,
    "blob_url": "https://github.com/tensorflow/java/blob/98df654a9558d0d41ab35766073f7ad97038d556/tensorflow-framework/src/main/java/org/tensorflow/framework/initializers/VarianceScaling.java",
    "raw_url": "https://github.com/tensorflow/java/raw/98df654a9558d0d41ab35766073f7ad97038d556/tensorflow-framework/src/main/java/org/tensorflow/framework/initializers/VarianceScaling.java",
    "contents_url": "https://api.github.com/repos/tensorflow/java/contents/tensorflow-framework/src/main/java/org/tensorflow/framework/initializers/VarianceScaling.java?ref=98df654a9558d0d41ab35766073f7ad97038d556",
    "patch": "@@ -21,11 +21,13 @@\n import org.tensorflow.types.TInt64;\n import org.tensorflow.types.family.TFloating;\n \n+import static org.tensorflow.framework.utils.CastHelper.cast;\n+\n /**\n  * Initializer capable of adapting its scale to the shape of weights tensors.\n  *\n- * <p>With <code>distribution=TRUNCATED_NORMAL or NORMAL</code>, samples are drawn from\n- * a truncated/untruncated normal distribution with a mean of zero and a standard deviation (after\n+ * <p>With <code>distribution=TRUNCATED_NORMAL or NORMAL</code>, samples are drawn from a\n+ * truncated/untruncated normal distribution with a mean of zero and a standard deviation (after\n  * truncation, if used) <code>stddev = Math.sqrt(scale / n)</code>, where <code>n</code> is:\n  *\n  * <ul>\n@@ -49,11 +51,10 @@\n  *          initializer.call(tf.constant(Shape.of(2,2)), TFloat32.class);\n  * </pre>\n  *\n- * @param <T> The TType for the call operation\n  * @see VarianceScaling.Mode\n  * @see VarianceScaling.Distribution\n  */\n-public class VarianceScaling<T extends TFloating> extends BaseInitializer<T> {\n+public class VarianceScaling extends BaseInitializer<TFloating> {\n \n   public static final double SCALE_DEFAULT = 1.0;\n   public static final Mode MODE_DEFAULT = Mode.FAN_IN;\n@@ -64,7 +65,6 @@\n   private final Distribution distribution;\n   private final long seed;\n \n-\n   /**\n    * Creates a VarianceScaling Initializer\n    *\n@@ -97,7 +97,7 @@ public VarianceScaling(Ops tf, double scale, Mode mode, Distribution distributio\n \n   /** {@inheritDoc} */\n   @Override\n-  public Operand<T> call(Operand<TInt64> dims, Class<T> type) {\n+  public <U extends TFloating> Operand<U> call(Operand<TInt64> dims, Class<U> type) {\n     Shape shape = ShapeUtils.toShape(this.tf.scope(), dims);\n     double lscale = this.scale;\n     double[] fans /* fanIn, fanOut */ = computeFans(shape);\n@@ -112,25 +112,25 @@ public VarianceScaling(Ops tf, double scale, Mode mode, Distribution distributio\n         lscale /= Math.max(1., (fans[0] + fans[1]) / 2.);\n         break;\n     }\n-    Operand<T> distOp;\n-    Operand<T> mulOp = null;\n+    Operand<U> distOp;\n+    Operand<U> mulOp = null;\n     double stddev;\n     long[] seeds = {seed, 0};\n     switch (distribution) {\n       case TRUNCATED_NORMAL:\n         distOp = tf.random.statelessTruncatedNormal(dims, tf.constant(seeds), type);\n         stddev = Math.sqrt(lscale) / .87962566103423978;\n-        mulOp = tf.math.mul(distOp, tf.dtypes.cast(tf.constant(stddev), type));\n+        mulOp = tf.math.mul(distOp, cast(tf, tf.constant(stddev), type));\n         break;\n       case NORMAL:\n         distOp = tf.random.statelessRandomNormal(dims, tf.constant(seeds), type);\n         stddev = Math.sqrt(lscale);\n-        mulOp = tf.math.mul(distOp, tf.dtypes.cast(tf.constant(stddev), type));\n+        mulOp = tf.math.mul(distOp, cast(tf, tf.constant(stddev), type));\n         break;\n       case UNIFORM:\n         distOp = tf.random.statelessRandomUniform(dims, tf.constant(seeds), type);\n         stddev = Math.sqrt(3.0 * lscale);\n-        mulOp = tf.math.mul(distOp, tf.dtypes.cast(tf.constant(stddev), type));\n+        mulOp = tf.math.mul(distOp, cast(tf, tf.constant(stddev), type));\n         break;\n     }\n     return mulOp;"
  },
  {
    "sha": "b6487dc10cdb5199f37c72430107a16ee26b6f3f",
    "filename": "tensorflow-framework/src/main/java/org/tensorflow/framework/initializers/Zeros.java",
    "status": "modified",
    "additions": 18,
    "deletions": 5,
    "changes": 23,
    "blob_url": "https://github.com/tensorflow/java/blob/98df654a9558d0d41ab35766073f7ad97038d556/tensorflow-framework/src/main/java/org/tensorflow/framework/initializers/Zeros.java",
    "raw_url": "https://github.com/tensorflow/java/raw/98df654a9558d0d41ab35766073f7ad97038d556/tensorflow-framework/src/main/java/org/tensorflow/framework/initializers/Zeros.java",
    "contents_url": "https://api.github.com/repos/tensorflow/java/contents/tensorflow-framework/src/main/java/org/tensorflow/framework/initializers/Zeros.java?ref=98df654a9558d0d41ab35766073f7ad97038d556",
    "patch": "@@ -16,7 +16,9 @@\n \n import org.tensorflow.Operand;\n import org.tensorflow.op.Ops;\n+import org.tensorflow.types.TBool;\n import org.tensorflow.types.TInt64;\n+import org.tensorflow.types.family.TNumber;\n import org.tensorflow.types.family.TType;\n \n /**\n@@ -30,10 +32,8 @@\n  *      Operand&lt;TFloat32&gt; values =\n  *              initializer.call(tf.constant(Shape.of(2,2)), TFloat32.class);\n  * </pre>\n- *\n- * @param <T> The TType for the call operation\n  */\n-public class Zeros<T extends TType> extends BaseInitializer<T> {\n+public class Zeros extends BaseInitializer<TType> {\n \n   /**\n    * Creates an Initializer that sets all values to one.\n@@ -44,8 +44,21 @@ public Zeros(Ops tf) {\n     super(tf);\n   }\n \n+  /**\n+   * Generates the operation used to perform the initialization.\n+   *\n+   * @param dims the shape dimensions\n+   * @param type the data type of tensor\n+   * @param <U> The data Type for initializer operation\n+   * @return An operand for the initialization.\n+   * @throws IllegalArgumentException if the data type is not a TNumber or TBool\n+   */\n   @Override\n-  public Operand<T> call(Operand<TInt64> dims, Class<T> dtype) {\n-    return tf.zeros(dims, dtype);\n+  public <U extends TType> Operand<U> call(Operand<TInt64> dims, Class<U> type) {\n+    if (!TNumber.class.isAssignableFrom(type) && type != TBool.class) {\n+      throw new IllegalArgumentException(\n+          \"Tensor type must be numeric or boolean: \" + type.getSimpleName());\n+    }\n+    return tf.zeros(dims, type);\n   }\n }"
  },
  {
    "sha": "22604a02c08ca82905c368aadf191172018cee14",
    "filename": "tensorflow-framework/src/test/java/org/tensorflow/framework/activations/ELUTest.java",
    "status": "modified",
    "additions": 3,
    "deletions": 7,
    "changes": 10,
    "blob_url": "https://github.com/tensorflow/java/blob/98df654a9558d0d41ab35766073f7ad97038d556/tensorflow-framework/src/test/java/org/tensorflow/framework/activations/ELUTest.java",
    "raw_url": "https://github.com/tensorflow/java/raw/98df654a9558d0d41ab35766073f7ad97038d556/tensorflow-framework/src/test/java/org/tensorflow/framework/activations/ELUTest.java",
    "contents_url": "https://api.github.com/repos/tensorflow/java/contents/tensorflow-framework/src/test/java/org/tensorflow/framework/activations/ELUTest.java?ref=98df654a9558d0d41ab35766073f7ad97038d556",
    "patch": "@@ -21,8 +21,6 @@\n import org.tensorflow.types.TFloat32;\n import org.tensorflow.types.TFloat64;\n \n-import static org.junit.jupiter.api.Assertions.assertThrows;\n-\n /** @author Jim Clarke */\n public class ELUTest {\n \n@@ -42,8 +40,6 @@ public void setUp() {}\n   @AfterEach\n   public void tearDown() {}\n \n-\n-\n   /** Test of ELU call method */\n   @Test\n   public void testCallFloat() {\n@@ -52,7 +48,7 @@ public void testCallFloat() {\n     for (TestSession.Mode tfMode : tfModes)\n       try (TestSession session = TestSession.createTestSession(tfMode)) {\n         Ops tf = session.getTF();\n-        ELU<TFloat32> instance = new ELU<>(tf);\n+        ELU instance = new ELU(tf);\n         Operand<TFloat32> result = instance.call(tf.constant(input));\n         session.evaluate(expected, result);\n       }\n@@ -66,7 +62,7 @@ public void testCallDouble() {\n     for (TestSession.Mode tfMode : tfModes)\n       try (TestSession session = TestSession.createTestSession(tfMode)) {\n         Ops tf = session.getTF();\n-        ELU<TFloat64> instance = new ELU<>(tf);\n+        ELU instance = new ELU(tf);\n         Operand<TFloat64> result = instance.call(tf.constant(input));\n         session.evaluate(expected, result);\n       }\n@@ -80,7 +76,7 @@ public void testAlpha() {\n     for (TestSession.Mode tfMode : tfModes)\n       try (TestSession session = TestSession.createTestSession(tfMode)) {\n         Ops tf = session.getTF();\n-        ELU<TFloat64> instance = new ELU<>(tf, 2.0f);\n+        ELU instance = new ELU(tf, 2.0f);\n         Operand<TFloat64> result = instance.call(tf.constant(input));\n         session.evaluate(expected, result);\n       }"
  }
]
