[
  {
    "sha": "0c0bb428ca56c6f67d43e1c083fdfb4bdf72f153",
    "filename": "core/src/main/scala/kafka/log/LocalLog.scala",
    "status": "modified",
    "additions": 27,
    "deletions": 140,
    "changes": 167,
    "blob_url": "https://github.com/kowshik/kafka/blob/759a7c70ac223c5abed1e21202db238838a54231/core/src/main/scala/kafka/log/LocalLog.scala",
    "raw_url": "https://github.com/kowshik/kafka/raw/759a7c70ac223c5abed1e21202db238838a54231/core/src/main/scala/kafka/log/LocalLog.scala",
    "contents_url": "https://api.github.com/repos/kowshik/kafka/contents/core/src/main/scala/kafka/log/LocalLog.scala?ref=759a7c70ac223c5abed1e21202db238838a54231",
    "patch": "@@ -27,7 +27,6 @@ import java.util.regex.Pattern\n \n import kafka.common.LogSegmentOffsetOverflowException\n import kafka.metrics.KafkaMetricsGroup\n-import kafka.server.epoch.LeaderEpochFileCache\n import kafka.server.{FetchDataInfo, LogDirFailureChannel, LogOffsetMetadata}\n import kafka.utils.{CoreUtils, Logging, Scheduler, threadsafe}\n import org.apache.kafka.common.{KafkaException, TopicPartition}\n@@ -270,7 +269,7 @@ class LocalLog(@volatile private var _dir: File,\n    * Get the largest log segment with a base offset less than or equal to the given offset, if one exists.\n    * @return the optional log segment\n    */\n-  private[log]  def floorLogSegment(offset: Long): Option[LogSegment] = {\n+  private[log] def floorLogSegment(offset: Long): Option[LogSegment] = {\n     Option(segments.floorEntry(offset)).map(_.getValue)\n   }\n \n@@ -333,8 +332,7 @@ class LocalLog(@volatile private var _dir: File,\n    *\n    * @param logStartOffset the log start offset\n    * @param maxProducerIdExpirationMs The maximum amount of time to wait before a producer id is considered expired\n-   * @param producerStateManager The ProducerStateManager instance\n-   * @param leaderEpochCache The LeaderEpochFileCache instance\n+   * @param recoverSegmentCallback Callback to invoke when attempting to recover a segment\n    *\n    * @return the list of deleted segments\n    *\n@@ -343,8 +341,7 @@ class LocalLog(@volatile private var _dir: File,\n    */\n   private[log] def loadSegments(logStartOffset: Long,\n                                 maxProducerIdExpirationMs: Int,\n-                                producerStateManager: ProducerStateManager,\n-                                leaderEpochCache: Option[LeaderEpochFileCache]): Seq[LogSegment] = {\n+                                recoverSegmentCallback: LogSegment => Int): Seq[LogSegment] = {\n     // first do a pass through the files in the log directory and remove any temporary files\n     // and find any interrupted swap operations\n     val swapFiles = removeTempFilesAndCollectSwapFiles()\n@@ -358,24 +355,20 @@ class LocalLog(@volatile private var _dir: File,\n       // call to loadSegmentFiles().\n       logSegments.foreach(_.close())\n       segments.clear()\n-      loadSegmentFiles(logStartOffset, maxProducerIdExpirationMs)\n+      loadSegmentFiles(logStartOffset, maxProducerIdExpirationMs, recoverSegmentCallback)\n     })\n \n     val deletedSegments = ListBuffer[LogSegment]()\n \n     // Finally, complete any interrupted swap operations. To be crash-safe,\n     // log files that are replaced by the swap segment should be renamed to .deleted\n     // before the swap file is restored as the new segment file.\n-    deletedSegments ++= completeSwapOperations(swapFiles, logStartOffset, maxProducerIdExpirationMs)\n+    deletedSegments ++= completeSwapOperations(swapFiles, logStartOffset, maxProducerIdExpirationMs, recoverSegmentCallback)\n \n     if (!dir.getAbsolutePath.endsWith(DeleteDirSuffix)) {\n-      val (deleted, nextOffset) = retryOnOffsetOverflow(\n-        {\n-          recoverLog(logStartOffset,\n-                     maxProducerIdExpirationMs,\n-                     producerStateManager,\n-                     leaderEpochCache)\n-        })\n+      val (deleted, nextOffset) = retryOnOffsetOverflow {\n+        recoverLog(logStartOffset, maxProducerIdExpirationMs, recoverSegmentCallback)\n+      }\n       deletedSegments ++= deleted\n \n       // reset the index size of the currently active log segment to allow more entries\n@@ -401,35 +394,33 @@ class LocalLog(@volatile private var _dir: File,\n    *\n    * @param logStartOffset the log start offset\n    * @param maxProducerIdExpirationMs The maximum amount of time to wait before a producer id is considered expired\n-   * @param producerStateManager The ProducerStateManager instance\n-   * @param leaderEpochCache The LeaderEpochFileCache instance\n+   * @param recoverSegmentCallback Callback to invoke when attempting to recover a segment\n    *\n    * @return the list of deleted segments and the next offset\n    *\n    * @throws LogSegmentOffsetOverflowException if we encountered a legacy segment with offset overflow\n    */\n   private[log] def recoverLog(logStartOffset: Long,\n                               maxProducerIdExpirationMs: Int,\n-                              producerStateManager: ProducerStateManager,\n-                              leaderEpochCache: Option[LeaderEpochFileCache]): (List[LogSegment], Long) = {\n+                              recoverSegmentCallback: LogSegment => Int): (List[LogSegment], Long) = {\n     val deleted = scala.collection.mutable.ListBuffer[LogSegment]()\n     /** return the log end offset if valid */\n     def deleteSegmentsIfLogStartGreaterThanLogEnd(): Option[Long] = {\n       if (logSegments.nonEmpty) {\n         val logEndOffset = activeSegment.readNextOffset\n-        if (logEndOffset >= logStartOffset)\n+        if (logEndOffset >= logStartOffset) {\n           Some(logEndOffset)\n-        else {\n+        } else {\n           warn(s\"Deleting all segments because logEndOffset ($logEndOffset) is smaller than logStartOffset ($logStartOffset). \" +\n             \"This could happen if segment files were deleted from the file system.\")\n           val toDelete = logSegments.toList\n           removeAndDeleteSegments(logSegments, asyncDelete = true, LogRecovery)\n           deleted ++= toDelete\n-          leaderEpochCache.foreach(_.clearAndFlush())\n-          producerStateManager.truncateFullyAndStartAt(logStartOffset)\n           None\n         }\n-      } else None\n+      } else {\n+        None\n+      }\n     }\n \n     // if we have the clean shutdown marker, skip recovery\n@@ -442,7 +433,7 @@ class LocalLog(@volatile private var _dir: File,\n         info(s\"Recovering unflushed segment ${segment.baseOffset}\")\n         val truncatedBytes =\n           try {\n-            recoverSegment(logStartOffset, segment, maxProducerIdExpirationMs, leaderEpochCache)\n+            recoverSegmentCallback(segment)\n           } catch {\n             case _: InvalidOffsetException =>\n               val startOffset = segment.baseOffset\n@@ -503,7 +494,9 @@ class LocalLog(@volatile private var _dir: File,\n    *\n    * @throws LogSegmentOffsetOverflowException if the log directory contains a segment with messages that overflow the index offset\n    */\n-  private[log] def loadSegmentFiles(logStartOffset: Long, maxProducerIdExpirationMs: Int): Unit = {\n+  private[log] def loadSegmentFiles(logStartOffset: Long,\n+                                    maxProducerIdExpirationMs: Int,\n+                                    recoverSegmentCallback: LogSegment => Int): Unit = {\n     // load segments in ascending order because transactional data from one segment may depend on the\n     // segments that come before it\n     for (file <- dir.listFiles.sortBy(_.getName) if file.isFile) {\n@@ -530,42 +523,17 @@ class LocalLog(@volatile private var _dir: File,\n           case _: NoSuchFileException =>\n             error(s\"Could not find offset index file corresponding to log file ${segment.log.file.getAbsolutePath}, \" +\n               \"recovering segment and rebuilding index files...\")\n-            recoverSegment(logStartOffset, segment, maxProducerIdExpirationMs)\n+            recoverSegmentCallback(segment)\n           case e: CorruptIndexException =>\n             warn(s\"Found a corrupted index file corresponding to log file ${segment.log.file.getAbsolutePath} due \" +\n               s\"to ${e.getMessage}}, recovering segment and rebuilding index files...\")\n-            recoverSegment(logStartOffset, segment, maxProducerIdExpirationMs)\n+            recoverSegmentCallback(segment)\n         }\n         addSegment(segment)\n       }\n     }\n   }\n \n-  /**\n-   * Recover the given segment.\n-   *\n-   * @param logStartOffset the log start offset\n-   * @param segment Segment to recover\n-   * @param maxProducerIdExpirationMs The maximum amount of time to wait before a producer id is considered expired\n-   * @param leaderEpochCache Optional cache for updating the leader epoch during recovery\n-   *\n-   * @return The number of bytes truncated from the segment\n-   *\n-   * @throws LogSegmentOffsetOverflowException if the segment contains messages that cause index offset overflow\n-   */\n-  private[log] def recoverSegment(logStartOffset: Long,\n-                                  segment: LogSegment,\n-                                  maxProducerIdExpirationMs: Int,\n-                                  leaderEpochCache: Option[LeaderEpochFileCache] = None): Int = {\n-    val producerStateManager = new ProducerStateManager(topicPartition, dir, maxProducerIdExpirationMs)\n-    rebuildProducerState(logStartOffset, segment.baseOffset, reloadFromCleanShutdown = false, producerStateManager)\n-    val bytesTruncated = segment.recover(producerStateManager, leaderEpochCache)\n-    // once we have recovered the segment's data, take a snapshot to ensure that we won't\n-    // need to reload the same segment again while recovering another segment.\n-    producerStateManager.takeSnapshot()\n-    bytesTruncated\n-  }\n-\n   /**\n    * This method does not need to convert IOException to KafkaStorageException because it is only called before all logs\n    * are loaded.\n@@ -578,7 +546,8 @@ class LocalLog(@volatile private var _dir: File,\n    */\n   private[log] def completeSwapOperations(swapFiles: Set[File],\n                                           logStartOffset: Long,\n-                                          maxProducerIdExpirationMs: Int): Seq[LogSegment] = {\n+                                          maxProducerIdExpirationMs: Int,\n+                                          recoverSegmentCallback: LogSegment => Int): Seq[LogSegment] = {\n     val deletedSegments = ListBuffer[LogSegment]()\n     for (swapFile <- swapFiles) {\n       val logFile = new File(CoreUtils.replaceSuffix(swapFile.getPath, SwapFileSuffix, \"\"))\n@@ -589,7 +558,7 @@ class LocalLog(@volatile private var _dir: File,\n         time = time,\n         fileSuffix = SwapFileSuffix)\n       info(s\"Found log file ${swapFile.getPath} from interrupted swap operation, repairing.\")\n-      recoverSegment(logStartOffset, swapSegment, maxProducerIdExpirationMs)\n+      recoverSegmentCallback(swapSegment)\n \n       // We create swap files for two cases:\n       // (1) Log cleaning where multiple segments are merged into one, and\n@@ -1239,90 +1208,6 @@ class LocalLog(@volatile private var _dir: File,\n     activeSegment.truncateTo(targetOffset)\n     deletable.toSeq\n   }\n-\n-  // Rebuild producer state until lastOffset. This method may be called from the recovery code path, and thus must be\n-  // free of all side-effects, i.e. it must not update any log-specific state.\n-  def rebuildProducerState(logStartOffset: Long,\n-                           lastOffset: Long,\n-                           reloadFromCleanShutdown: Boolean,\n-                           producerStateManager: ProducerStateManager): Unit = {\n-    checkIfMemoryMappedBufferClosed()\n-    val segments = logSegments\n-    val offsetsToSnapshot =\n-      if (segments.nonEmpty) {\n-        val nextLatestSegmentBaseOffset = lowerSegment(segments.last.baseOffset).map(_.baseOffset)\n-        Seq(nextLatestSegmentBaseOffset, Some(segments.last.baseOffset), Some(lastOffset))\n-      } else {\n-        Seq(Some(lastOffset))\n-      }\n-    info(s\"Loading producer state till offset $lastOffset with message format version ${recordVersion.value}\")\n-\n-    // We want to avoid unnecessary scanning of the log to build the producer state when the broker is being\n-    // upgraded. The basic idea is to use the absence of producer snapshot files to detect the upgrade case,\n-    // but we have to be careful not to assume too much in the presence of broker failures. The two most common\n-    // upgrade cases in which we expect to find no snapshots are the following:\n-    //\n-    // 1. The broker has been upgraded, but the topic is still on the old message format.\n-    // 2. The broker has been upgraded, the topic is on the new message format, and we had a clean shutdown.\n-    //\n-    // If we hit either of these cases, we skip producer state loading and write a new snapshot at the log end\n-    // offset (see below). The next time the log is reloaded, we will load producer state using this snapshot\n-    // (or later snapshots). Otherwise, if there is no snapshot file, then we have to rebuild producer state\n-    // from the first segment.\n-    if (recordVersion.value < RecordBatch.MAGIC_VALUE_V2 ||\n-      (producerStateManager.latestSnapshotOffset.isEmpty && reloadFromCleanShutdown)) {\n-      // To avoid an expensive scan through all of the segments, we take empty snapshots from the start of the\n-      // last two segments and the last offset. This should avoid the full scan in the case that the log needs\n-      // truncation.\n-      offsetsToSnapshot.flatten.foreach { offset =>\n-        producerStateManager.updateMapEndOffset(offset)\n-        producerStateManager.takeSnapshot()\n-      }\n-    } else {\n-      info(s\"Reloading from producer snapshot and rebuilding producer state from offset $lastOffset\")\n-      val isEmptyBeforeTruncation = producerStateManager.isEmpty && producerStateManager.mapEndOffset >= lastOffset\n-      val producerStateLoadStart = time.milliseconds()\n-      producerStateManager.truncateAndReload(logStartOffset, lastOffset, time.milliseconds())\n-      val segmentRecoveryStart = time.milliseconds()\n-\n-      // Only do the potentially expensive reloading if the last snapshot offset is lower than the log end\n-      // offset (which would be the case on first startup) and there were active producers prior to truncation\n-      // (which could be the case if truncating after initial loading). If there weren't, then truncating\n-      // shouldn't change that fact (although it could cause a producerId to expire earlier than expected),\n-      // and we can skip the loading. This is an optimization for users which are not yet using\n-      // idempotent/transactional features yet.\n-      if (lastOffset > producerStateManager.mapEndOffset && !isEmptyBeforeTruncation) {\n-        val segmentOfLastOffset = floorLogSegment(lastOffset)\n-\n-        logSegments(producerStateManager.mapEndOffset, lastOffset).foreach { segment =>\n-          val startOffset = Utils.max(segment.baseOffset, producerStateManager.mapEndOffset, logStartOffset)\n-          producerStateManager.updateMapEndOffset(startOffset)\n-\n-          if (offsetsToSnapshot.contains(Some(segment.baseOffset)))\n-            producerStateManager.takeSnapshot()\n-\n-          val maxPosition = if (segmentOfLastOffset.contains(segment)) {\n-            Option(segment.translateOffset(lastOffset))\n-              .map(_.position)\n-              .getOrElse(segment.size)\n-          } else {\n-            segment.size\n-          }\n-\n-          val fetchDataInfo = segment.read(startOffset,\n-            maxSize = Int.MaxValue,\n-            maxPosition = maxPosition,\n-            minOneMessage = false)\n-          if (fetchDataInfo != null)\n-            loadProducersFromRecords(producerStateManager, fetchDataInfo.records)\n-        }\n-      }\n-      producerStateManager.updateMapEndOffset(lastOffset)\n-      producerStateManager.takeSnapshot()\n-      info(s\"Producer state recovery took ${producerStateLoadStart - segmentRecoveryStart}ms for snapshot load \" +\n-        s\"and ${time.milliseconds() - segmentRecoveryStart}ms for segment recovery from offset $lastOffset\")\n-    }\n-  }\n }\n \n /**\n@@ -1527,7 +1412,8 @@ object LocalLog {\n   private def isLogFile(file: File): Boolean =\n     file.getPath.endsWith(LogFileSuffix)\n \n-  private def loadProducersFromRecords(producerStateManager: ProducerStateManager, records: Records): Unit = {\n+  // TODO: move to Log\n+  private[log] def loadProducersFromRecords(producerStateManager: ProducerStateManager, records: Records): Unit = {\n     val loadedProducers = mutable.Map.empty[Long, ProducerAppendInfo]\n     val completedTxns = ListBuffer.empty[CompletedTxn]\n     records.batches.forEach { batch =>\n@@ -1545,6 +1431,7 @@ object LocalLog {\n     completedTxns.foreach(producerStateManager.completeTxn)\n   }\n \n+  // TODO: move to Log\n   def updateProducers(producerStateManager: ProducerStateManager,\n                       batch: RecordBatch,\n                       producers: mutable.Map[Long, ProducerAppendInfo],"
  },
  {
    "sha": "d24826d3fb87c89c766862c289cddf5719ad55c0",
    "filename": "core/src/main/scala/kafka/log/Log.scala",
    "status": "modified",
    "additions": 118,
    "deletions": 5,
    "changes": 123,
    "blob_url": "https://github.com/kowshik/kafka/blob/759a7c70ac223c5abed1e21202db238838a54231/core/src/main/scala/kafka/log/Log.scala",
    "raw_url": "https://github.com/kowshik/kafka/raw/759a7c70ac223c5abed1e21202db238838a54231/core/src/main/scala/kafka/log/Log.scala",
    "contents_url": "https://api.github.com/repos/kowshik/kafka/contents/core/src/main/scala/kafka/log/Log.scala?ref=759a7c70ac223c5abed1e21202db238838a54231",
    "patch": "@@ -21,10 +21,10 @@ import java.io.{File, IOException}\n import java.nio.file.Files\n import java.util.Optional\n import java.util.concurrent.TimeUnit\n-\n import kafka.api.{ApiVersion, KAFKA_0_10_0_IV0}\n import kafka.common.{LongRef, OffsetsOutOfOrderException, UnexpectedAppendOffsetException}\n import kafka.log.AppendOrigin.RaftLeader\n+import kafka.log.LocalLog.loadProducersFromRecords\n import kafka.message.{BrokerCompressionCodec, CompressionCodec, NoCompressionCodec}\n import kafka.metrics.KafkaMetricsGroup\n import kafka.server.checkpoints.LeaderEpochCheckpointFile\n@@ -38,7 +38,7 @@ import org.apache.kafka.common.record._\n import org.apache.kafka.common.requests.ListOffsetsRequest\n import org.apache.kafka.common.requests.OffsetsForLeaderEpochResponse.UNDEFINED_EPOCH_OFFSET\n import org.apache.kafka.common.requests.ProduceResponse.RecordError\n-import org.apache.kafka.common.utils.Time\n+import org.apache.kafka.common.utils.{Time, Utils}\n import org.apache.kafka.common.{InvalidRecordException, KafkaException, TopicPartition, Uuid}\n \n import scala.jdk.CollectionConverters._\n@@ -588,7 +588,7 @@ class Log(val localLog: LocalLog,\n \n   private def loadProducerState(lastOffset: Long, reloadFromCleanShutdown: Boolean): Unit = lock synchronized {\n     lock synchronized {\n-      localLog.rebuildProducerState(logStartOffset, lastOffset, reloadFromCleanShutdown, producerStateManager)\n+      rebuildProducerState(logStartOffset, lastOffset, reloadFromCleanShutdown, producerStateManager)\n     }\n     maybeIncrementFirstUnstableOffset()\n   }\n@@ -1563,7 +1563,7 @@ class Log(val localLog: LocalLog,\n     localLog.updateLogEndOffset(endOffset)\n     localLog.updateRecoveryPoint(math.min(recoveryPoint, endOffset))\n     lock synchronized {\n-      localLog.rebuildProducerState(logStartOffset, endOffset, reloadFromCleanShutdown = false, producerStateManager)\n+      rebuildProducerState(logStartOffset, endOffset, reloadFromCleanShutdown = false, producerStateManager)\n     }\n     updateHighWatermark(math.min(highWatermark, endOffset))\n   }\n@@ -1614,11 +1614,124 @@ class Log(val localLog: LocalLog,\n \n   private[log] def loadSegments(): Unit = {\n     lock synchronized {\n-      val deletedSegments = localLog.loadSegments(logStartOffset, maxProducerIdExpirationMs, producerStateManager, leaderEpochCache)\n+      val deletedSegments = localLog.loadSegments(logStartOffset, maxProducerIdExpirationMs, recoverSegment)\n       scheduleProducerSnapshotDeletion(deletedSegments)\n     }\n   }\n \n+  private def recoverSegment(segment: LogSegment): Int = {\n+    recoverSegment(logStartOffset, segment, maxProducerIdExpirationMs, leaderEpochCache)\n+  }\n+\n+  /**\n+   * Recover the given segment.\n+   *\n+   * @param logStartOffset the log start offset\n+   * @param segment Segment to recover\n+   * @param maxProducerIdExpirationMs The maximum amount of time to wait before a producer id is considered expired\n+   * @param leaderEpochCache Optional cache for updating the leader epoch during recovery\n+   *\n+   * @return The number of bytes truncated from the segment\n+   *\n+   * @throws LogSegmentOffsetOverflowException if the segment contains messages that cause index offset overflow\n+   */\n+  private[log] def recoverSegment(logStartOffset: Long,\n+                                  segment: LogSegment,\n+                                  maxProducerIdExpirationMs: Int,\n+                                  leaderEpochCache: Option[LeaderEpochFileCache] = None): Int = {\n+    val producerStateManager = new ProducerStateManager(topicPartition, dir, maxProducerIdExpirationMs)\n+    rebuildProducerState(logStartOffset, segment.baseOffset, reloadFromCleanShutdown = false, producerStateManager)\n+    val bytesTruncated = segment.recover(producerStateManager, leaderEpochCache)\n+    // once we have recovered the segment's data, take a snapshot to ensure that we won't\n+    // need to reload the same segment again while recovering another segment.\n+    producerStateManager.takeSnapshot()\n+    bytesTruncated\n+  }\n+\n+  // Rebuild producer state until lastOffset. This method may be called from the recovery code path, and thus must be\n+  // free of all side-effects, i.e. it must not update any log-specific state.\n+  def rebuildProducerState(logStartOffset: Long,\n+                           lastOffset: Long,\n+                           reloadFromCleanShutdown: Boolean,\n+                           producerStateManager: ProducerStateManager): Unit = {\n+    localLog.checkIfMemoryMappedBufferClosed()\n+    val segments = logSegments\n+    val offsetsToSnapshot =\n+      if (segments.nonEmpty) {\n+        val nextLatestSegmentBaseOffset = localLog.lowerSegment(segments.last.baseOffset).map(_.baseOffset)\n+        Seq(nextLatestSegmentBaseOffset, Some(segments.last.baseOffset), Some(lastOffset))\n+      } else {\n+        Seq(Some(lastOffset))\n+      }\n+    info(s\"Loading producer state till offset $lastOffset with message format version ${recordVersion.value}\")\n+\n+    // We want to avoid unnecessary scanning of the log to build the producer state when the broker is being\n+    // upgraded. The basic idea is to use the absence of producer snapshot files to detect the upgrade case,\n+    // but we have to be careful not to assume too much in the presence of broker failures. The two most common\n+    // upgrade cases in which we expect to find no snapshots are the following:\n+    //\n+    // 1. The broker has been upgraded, but the topic is still on the old message format.\n+    // 2. The broker has been upgraded, the topic is on the new message format, and we had a clean shutdown.\n+    //\n+    // If we hit either of these cases, we skip producer state loading and write a new snapshot at the log end\n+    // offset (see below). The next time the log is reloaded, we will load producer state using this snapshot\n+    // (or later snapshots). Otherwise, if there is no snapshot file, then we have to rebuild producer state\n+    // from the first segment.\n+    if (recordVersion.value < RecordBatch.MAGIC_VALUE_V2 ||\n+      (producerStateManager.latestSnapshotOffset.isEmpty && reloadFromCleanShutdown)) {\n+      // To avoid an expensive scan through all of the segments, we take empty snapshots from the start of the\n+      // last two segments and the last offset. This should avoid the full scan in the case that the log needs\n+      // truncation.\n+      offsetsToSnapshot.flatten.foreach { offset =>\n+        producerStateManager.updateMapEndOffset(offset)\n+        producerStateManager.takeSnapshot()\n+      }\n+    } else {\n+      info(s\"Reloading from producer snapshot and rebuilding producer state from offset $lastOffset\")\n+      val isEmptyBeforeTruncation = producerStateManager.isEmpty && producerStateManager.mapEndOffset >= lastOffset\n+      val producerStateLoadStart = time.milliseconds()\n+      producerStateManager.truncateAndReload(logStartOffset, lastOffset, time.milliseconds())\n+      val segmentRecoveryStart = time.milliseconds()\n+\n+      // Only do the potentially expensive reloading if the last snapshot offset is lower than the log end\n+      // offset (which would be the case on first startup) and there were active producers prior to truncation\n+      // (which could be the case if truncating after initial loading). If there weren't, then truncating\n+      // shouldn't change that fact (although it could cause a producerId to expire earlier than expected),\n+      // and we can skip the loading. This is an optimization for users which are not yet using\n+      // idempotent/transactional features yet.\n+      if (lastOffset > producerStateManager.mapEndOffset && !isEmptyBeforeTruncation) {\n+        val segmentOfLastOffset = localLog.floorLogSegment(lastOffset)\n+\n+        logSegments(producerStateManager.mapEndOffset, lastOffset).foreach { segment =>\n+          val startOffset = Utils.max(segment.baseOffset, producerStateManager.mapEndOffset, logStartOffset)\n+          producerStateManager.updateMapEndOffset(startOffset)\n+\n+          if (offsetsToSnapshot.contains(Some(segment.baseOffset)))\n+            producerStateManager.takeSnapshot()\n+\n+          val maxPosition = if (segmentOfLastOffset.contains(segment)) {\n+            Option(segment.translateOffset(lastOffset))\n+              .map(_.position)\n+              .getOrElse(segment.size)\n+          } else {\n+            segment.size\n+          }\n+\n+          val fetchDataInfo = segment.read(startOffset,\n+            maxSize = Int.MaxValue,\n+            maxPosition = maxPosition,\n+            minOneMessage = false)\n+          if (fetchDataInfo != null)\n+            loadProducersFromRecords(producerStateManager, fetchDataInfo.records)\n+        }\n+      }\n+      producerStateManager.updateMapEndOffset(lastOffset)\n+      producerStateManager.takeSnapshot()\n+      info(s\"Producer state recovery took ${producerStateLoadStart - segmentRecoveryStart}ms for snapshot load \" +\n+        s\"and ${time.milliseconds() - segmentRecoveryStart}ms for segment recovery from offset $lastOffset\")\n+    }\n+  }\n+\n   /**\n    * Swap one or more new local segment in place and delete one or more existing local segments in a crash-safe manner.\n    * The old segments will be asynchronously deleted."
  }
]
