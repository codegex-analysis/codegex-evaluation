[
  {
    "sha": "10e408227ec5f007a1ed97990041dd324fcc2315",
    "filename": "src/main/java/evaluation/ClassifierResultsAnalysis.java",
    "status": "modified",
    "additions": 30,
    "deletions": 45,
    "changes": 75,
    "blob_url": "https://github.com/uea-machine-learning/tsml/blob/e4daa1bb76d3d19b08eadc544feab3b600cc5b0c/src/main/java/evaluation/ClassifierResultsAnalysis.java",
    "raw_url": "https://github.com/uea-machine-learning/tsml/raw/e4daa1bb76d3d19b08eadc544feab3b600cc5b0c/src/main/java/evaluation/ClassifierResultsAnalysis.java",
    "contents_url": "https://api.github.com/repos/uea-machine-learning/tsml/contents/src/main/java/evaluation/ClassifierResultsAnalysis.java?ref=e4daa1bb76d3d19b08eadc544feab3b600cc5b0c",
    "patch": "@@ -250,13 +250,13 @@ public static void performFullEvaluation(\n         if (compResourceSummaries != null) {\r\n             compMetrics.add(PerformanceMetric.buildTime);\r\n             compMetrics.add(testTimeMetric);\r\n+            compMetrics.add(PerformanceMetric.totalBuildPlusEstimateTime);\r\n+            compMetrics.add(PerformanceMetric.extraTimeForEstimate);\r\n             compMetrics.add(memoryMaxMetric);\r\n+\r\n             compMetrics.add(PerformanceMetric.buildTimeBenchmarked);\r\n             compMetrics.add(benchmarkedTestTimeMetric);\r\n-\r\n-            compMetrics.add(PerformanceMetric.totalBuildPlusEstimateTime);\r\n             compMetrics.add(PerformanceMetric.totalBuildPlusEstimateTimeBenchmarked);\r\n-            compMetrics.add(PerformanceMetric.extraTimeForEstimate);\r\n             compMetrics.add(PerformanceMetric.extraTimeForEstimateBenchmarked);\r\n \r\n             for (int j = compResourceSummaries.size()-1; j >= 0; j--) {\r\n@@ -872,29 +872,27 @@ public static String dsetGroups_buildAccsTableString(Map<String, double[]> group\n         // NOTE: getting train timings from test files intentionally ( train.. = ..sliceSplit(\"test\")..), avoids check for whether we're actually loading in\r\n         // train files in comparison set up. build times should be same in both trainFoldX and testFoldX file anyway\r\n \r\n-\r\n         double[][][] trainTimes = results.sliceSplit(\"test\").retrieveDoubles(trainTimeMetric.getter)[0];\r\n         String[] trainResStr = null;\r\n         if (trainTimes != null)\r\n             trainResStr = eval_metricOnSplit(timingsOutPath, filename, null, trainLabel, trainTimeMetric, trainTimes, cnames, dsets, dsetGroupings);\r\n \r\n-\r\n         double[][][] testTimes = results.sliceSplit(\"test\").retrieveDoubles(testTimeMetric.getter)[0];\r\n         String[] testResStr = null;\r\n         if (testTimes != null)\r\n             testResStr = eval_metricOnSplit(timingsOutPath, filename, null, testLabel, testTimeMetric, testTimes, cnames, dsets, dsetGroupings);\r\n \r\n-\r\n-        double[][][] estimateTimes1 = results.sliceSplit(\"test\").retrieveDoubles(PerformanceMetric.totalBuildPlusEstimateTime.getter)[0];\r\n         String[] estimateResStr1 = null;\r\n-        if (estimateTimes1 != null)\r\n-            estimateResStr1 = eval_metricOnSplit(timingsOutPath, filename, null, estimateLabel, PerformanceMetric.totalBuildPlusEstimateTime, estimateTimes1, cnames, dsets, dsetGroupings);\r\n-\r\n-\r\n-        double[][][] estimateTimes2 = results.sliceSplit(\"test\").retrieveDoubles(PerformanceMetric.extraTimeForEstimate.getter)[0];\r\n         String[] estimateResStr2 = null;\r\n-        if (estimateTimes2 != null)\r\n-            estimateResStr2 = eval_metricOnSplit(timingsOutPath, filename, null, estimateLabel, PerformanceMetric.extraTimeForEstimate, estimateTimes2, cnames, dsets, dsetGroupings);\r\n+        if (Arrays.asList(results.getSplits()).contains(\"train\")) {\r\n+            double[][][] estimateTimes1 = results.sliceSplit(\"train\").retrieveDoubles(PerformanceMetric.totalBuildPlusEstimateTime.getter)[0];\r\n+            if (estimateTimes1 != null)\r\n+                estimateResStr1 = eval_metricOnSplit(timingsOutPath, filename, null, estimateLabel, PerformanceMetric.totalBuildPlusEstimateTime, estimateTimes1, cnames, dsets, dsetGroupings);\r\n+\r\n+            double[][][] estimateTimes2 = results.sliceSplit(\"train\").retrieveDoubles(PerformanceMetric.extraTimeForEstimate.getter)[0];\r\n+            if (estimateTimes2 != null)\r\n+                estimateResStr2 = eval_metricOnSplit(timingsOutPath, filename, null, estimateLabel, PerformanceMetric.extraTimeForEstimate, estimateTimes2, cnames, dsets, dsetGroupings);\r\n+        }\r\n \r\n         String memoryOutPath = outPath + \"MaxMemory/\"; //special case for timings\r\n         new File(memoryOutPath).mkdirs();\r\n@@ -941,16 +939,17 @@ public static String dsetGroups_buildAccsTableString(Map<String, double[]> group\n         }\r\n \r\n \r\n-        double[][][] estimateTimes1 = results.sliceSplit(\"test\").retrieveDoubles(PerformanceMetric.totalBuildPlusEstimateTimeBenchmarked.getter)[0];\r\n         String[] estimateResStr1 = null;\r\n-        if (estimateTimes1 != null)\r\n-            estimateResStr1 = eval_metricOnSplit(outPath, filename, null, estimateLabel, PerformanceMetric.totalBuildPlusEstimateTimeBenchmarked, estimateTimes1, cnames, dsets, dsetGroupings);\r\n-\r\n-\r\n-        double[][][] estimateTimes2 = results.sliceSplit(\"test\").retrieveDoubles(PerformanceMetric.extraTimeForEstimateBenchmarked.getter)[0];\r\n         String[] estimateResStr2 = null;\r\n-        if (estimateTimes2 != null)\r\n-            estimateResStr2 = eval_metricOnSplit(outPath, filename, null, estimateLabel, PerformanceMetric.extraTimeForEstimateBenchmarked, estimateTimes2, cnames, dsets, dsetGroupings);\r\n+        if (Arrays.asList(results.getSplits()).contains(\"train\")) {\r\n+            double[][][] estimateTimes1 = results.sliceSplit(\"train\").retrieveDoubles(PerformanceMetric.totalBuildPlusEstimateTimeBenchmarked.getter)[0];\r\n+            if (estimateTimes1 != null)\r\n+                estimateResStr1 = eval_metricOnSplit(outPath, filename, null, estimateLabel, PerformanceMetric.totalBuildPlusEstimateTimeBenchmarked, estimateTimes1, cnames, dsets, dsetGroupings);\r\n+\r\n+            double[][][] estimateTimes2 = results.sliceSplit(\"train\").retrieveDoubles(PerformanceMetric.extraTimeForEstimateBenchmarked.getter)[0];\r\n+            if (estimateTimes2 != null)\r\n+                estimateResStr2 = eval_metricOnSplit(outPath, filename, null, estimateLabel, PerformanceMetric.extraTimeForEstimateBenchmarked, estimateTimes2, cnames, dsets, dsetGroupings);\r\n+        }\r\n \r\n         return new String[][] { trainResStr, testResStr, estimateResStr1, estimateResStr2 };\r\n     }\r\n@@ -984,13 +983,9 @@ protected static void matlab_buildCompResourcesDias(List<PerformanceMetric> metr\n \r\n         for (PerformanceMetric metric : metrics) {\r\n \r\n-            String diaFolder = expRootDirectory + \"/\" + (metric.name.toLowerCase().contains(\"benchmark\") ? computationalDiaFolderName_benchmark : computationalDiaFolderName_raw) + \"/\";\r\n+            String diaFolder = expRootDirectory + \"/\" + (metric.name.toLowerCase().contains(PerformanceMetric.benchmarkSuffix) ? computationalDiaFolderName_benchmark : computationalDiaFolderName_raw) + \"/\";\r\n \r\n-            String evalSet = metric.equals(PerformanceMetric.totalTestTime) || metric.equals(testTimeMetric) ||\r\n-                            metric.equals(PerformanceMetric.totalTestTimeBenchmarked) || metric.equals(benchmarkedTestTimeMetric)\r\n-                            || metric.equals(memoryMaxMetric)\r\n-                    ? testLabel\r\n-                    : trainLabel;\r\n+            String evalSet = metric.defaultSplit;\r\n             String filenameNoExtension = fileNameBuild_avgsFile(evalSet, metric).replace(\".csv\", \"\");\r\n \r\n             String ylabel = metric.equals(memoryMaxMetric) ?\r\n@@ -1563,24 +1558,14 @@ protected static void jxl_buildResultsSpreadsheet(String basePath, String expNam\n         jxl_copyCSVIntoSheet(summarySheet, summaryCSV);\r\n \r\n         for (int i = 0; i < metrics.size(); i++) {\r\n-            if (metrics.get(i).equals(PerformanceMetric.buildTime))\r\n-                jxl_buildStatSheets_timings(wb, basePath, metrics.get(i), i, trainLabel, \"RAW\");\r\n-            else if (metrics.get(i).equals(testTimeMetric))\r\n-                jxl_buildStatSheets_timings(wb, basePath, metrics.get(i), i, testLabel, \"RAW\");\r\n-            else if (metrics.get(i).equals(PerformanceMetric.extraTimeForEstimate))\r\n-                jxl_buildStatSheets_timings(wb, basePath, metrics.get(i), i, estimateLabel, \"RAW\");\r\n-            else if (metrics.get(i).equals(PerformanceMetric.totalBuildPlusEstimateTime))\r\n-                jxl_buildStatSheets_timings(wb, basePath, metrics.get(i), i, estimateLabel, \"RAW\");\r\n-            else if (metrics.get(i).equals(PerformanceMetric.buildTimeBenchmarked))\r\n-                jxl_buildStatSheets_timings(wb, basePath, metrics.get(i), i, trainLabel, \"BENCHMARKED\");\r\n-            else if (metrics.get(i).equals(benchmarkedTestTimeMetric))\r\n-                jxl_buildStatSheets_timings(wb, basePath, metrics.get(i), i, testLabel, \"BENCHMARKED\");\r\n-            else if (metrics.get(i).equals(PerformanceMetric.extraTimeForEstimateBenchmarked))\r\n-                jxl_buildStatSheets_timings(wb, basePath, metrics.get(i), i, estimateLabel, \"BENCHMARKED\");\r\n-            else if (metrics.get(i).equals(PerformanceMetric.totalBuildPlusEstimateTimeBenchmarked))\r\n-                jxl_buildStatSheets_timings(wb, basePath, metrics.get(i), i, estimateLabel, \"BENCHMARKED\");\r\n-            else\r\n+            if (PerformanceMetric.getAllTimingStatistics().contains(metrics.get(i))) {\r\n+                String benchmarkSuff = metrics.get(i).benchmarked ? \"BENCHMARKED\" : \"RAW\";\r\n+                String splitLabel = metrics.get(i).defaultSplit;\r\n+                jxl_buildStatSheets_timings(wb, basePath, metrics.get(i), i, splitLabel, benchmarkSuff);\r\n+            }\r\n+            else {\r\n                 jxl_buildStatSheets(wb, basePath, metrics.get(i), i);\r\n+            }\r\n         }\r\n \r\n         try {\r"
  },
  {
    "sha": "2d9e19c1c22647f2c54008f0c89bd47c7558196e",
    "filename": "src/main/java/evaluation/MultipleClassifierEvaluation.java",
    "status": "modified",
    "additions": 4,
    "deletions": 8,
    "changes": 12,
    "blob_url": "https://github.com/uea-machine-learning/tsml/blob/e4daa1bb76d3d19b08eadc544feab3b600cc5b0c/src/main/java/evaluation/MultipleClassifierEvaluation.java",
    "raw_url": "https://github.com/uea-machine-learning/tsml/raw/e4daa1bb76d3d19b08eadc544feab3b600cc5b0c/src/main/java/evaluation/MultipleClassifierEvaluation.java",
    "contents_url": "https://api.github.com/repos/uea-machine-learning/tsml/contents/src/main/java/evaluation/MultipleClassifierEvaluation.java?ref=e4daa1bb76d3d19b08eadc544feab3b600cc5b0c",
    "patch": "@@ -16,10 +16,9 @@\n  */\n package evaluation;\n \n-import evaluation.storage.ClassifierResults;\n import ResultsProcessing.MatlabController;\n import evaluation.storage.ClassifierResultsCollection;\n-import experiments.data.DatasetLists;\n+\n import java.io.File;\n import java.io.FileNotFoundException;\n import java.io.FilenameFilter;\n@@ -29,11 +28,8 @@\n import java.util.List;\n import java.util.Map;\n import java.util.Scanner;\n-import java.util.function.Consumer;\n-import java.util.function.Function;\n+\n import utilities.DebugPrinting;\n-import utilities.ErrorReport;\n-import utilities.generic_storage.Pair;\n \n /**\n  * This essentially just wraps ClassifierResultsAnalysis.performFullEvaluation(...) in a nicer to use way. Will be updated over time\n@@ -76,7 +72,7 @@ handle incomplete results (e.g random folds missing), more matlab figures over t\n     private Map<String, Map<String, String[]>> datasetGroupings; // Map<GroupingMethodTitle(e.g \"ByNumAtts\"), Map<GroupTitle(e.g \"<100\"), dsetsInGroup(must be subset of datasets)>>\n     private ClassifierResultsCollection resultsCollection;\n     private int numFolds;\n-    private ArrayList<PerformanceMetric> metrics;\n+    private List<PerformanceMetric> metrics;\n     \n     /**\n      * if true, the relevant .m files must be located in the netbeans project directory\n@@ -381,7 +377,7 @@ public MultipleClassifierEvaluation setUseAccuracyOnly() {\n     }\n     \n     public MultipleClassifierEvaluation setUseAllStatistics() {\n-        metrics = PerformanceMetric.getAllStatistics();\n+        metrics = PerformanceMetric.getAllPredictionStatistics();\n         return this;\n     }\n "
  },
  {
    "sha": "ed48676b703b14a4e2a1ab6068472e34dcde4177",
    "filename": "src/main/java/evaluation/PerformanceMetric.java",
    "status": "modified",
    "additions": 75,
    "deletions": 34,
    "changes": 109,
    "blob_url": "https://github.com/uea-machine-learning/tsml/blob/e4daa1bb76d3d19b08eadc544feab3b600cc5b0c/src/main/java/evaluation/PerformanceMetric.java",
    "raw_url": "https://github.com/uea-machine-learning/tsml/raw/e4daa1bb76d3d19b08eadc544feab3b600cc5b0c/src/main/java/evaluation/PerformanceMetric.java",
    "contents_url": "https://api.github.com/repos/uea-machine-learning/tsml/contents/src/main/java/evaluation/PerformanceMetric.java?ref=e4daa1bb76d3d19b08eadc544feab3b600cc5b0c",
    "patch": "@@ -19,6 +19,7 @@\n \n import evaluation.storage.ClassifierResults;\n import java.util.ArrayList;\n+import java.util.List;\n import java.util.function.Function;\n \n /**\n@@ -40,10 +41,14 @@\n  */\n public class PerformanceMetric {\n \n+    public static final String benchmarkSuffix = \"_BM\";\n+\n     public String name;\n     public Function<ClassifierResults, Double> getter;\n     public boolean takeMean;\n     public boolean maximise;\n+    public boolean benchmarked; // for timings\n+    public String defaultSplit; // mainly for timing split descriptors, e.g. build time = train, pred times = test\n     \n     /**\n      * currently only used for the pairwise scatter diagrams in the pipeline, \n@@ -54,12 +59,14 @@\n      */\n     public String comparisonDescriptor;\n     \n-    public PerformanceMetric(String metricName, Function<ClassifierResults, Double> getScore, boolean takeMean, boolean maximised, String comparisonDescriptor) {\n+    public PerformanceMetric(String metricName, Function<ClassifierResults, Double> getScore, boolean takeMean, boolean maximised, String comparisonDescriptor, boolean benchmarked, String defaultSplit) {\n         this.name = metricName;\n         this.getter = getScore;\n         this.takeMean = takeMean;\n         this.maximise = maximised;\n         this.comparisonDescriptor = comparisonDescriptor;\n+        this.benchmarked = benchmarked;\n+        this.defaultSplit = defaultSplit;\n     }\n     \n     public double getScore(ClassifierResults res) {\n@@ -72,47 +79,49 @@ public String toString() {\n     \n     private static final boolean min = false, max = true;\n     private static final boolean median = false, mean = true;\n+    private static final boolean isBenchmarked = true, isNotBenchmarked = false;\n     private static final String better = \"better\", worse = \"worse\", slower = \"slower\", faster = \"faster\";\n+    private static final String train = \"train\", test = \"test\", estimate = \"estimate\";\n     \n-    public static PerformanceMetric acc             = new PerformanceMetric(\"ACC\", ClassifierResults.GETTER_Accuracy,                    mean, max,   better);\n-    public static PerformanceMetric balacc          = new PerformanceMetric(\"BALACC\", ClassifierResults.GETTER_BalancedAccuracy,         mean, max,   better);\n-    public static PerformanceMetric AUROC           = new PerformanceMetric(\"AUROC\", ClassifierResults.GETTER_AUROC,                     mean, max,   better);\n-    public static PerformanceMetric NLL             = new PerformanceMetric(\"NLL\", ClassifierResults.GETTER_NLL,                         mean, min,   worse);\n-    public static PerformanceMetric F1              = new PerformanceMetric(\"F1\", ClassifierResults.GETTER_F1,                           mean, max,   better);\n-    public static PerformanceMetric MCC             = new PerformanceMetric(\"MCC\", ClassifierResults.GETTER_MCC,                         mean, max,   better);\n-    public static PerformanceMetric precision       = new PerformanceMetric(\"Prec\", ClassifierResults.GETTER_Precision,                  mean, max,   better);\n-    public static PerformanceMetric recall          = new PerformanceMetric(\"Recall\", ClassifierResults.GETTER_Recall,                   mean, max,   better);\n-    public static PerformanceMetric sensitivity     = new PerformanceMetric(\"Sens\", ClassifierResults.GETTER_Sensitivity,                mean, max,   better);\n-    public static PerformanceMetric specificity     = new PerformanceMetric(\"Spec\", ClassifierResults.GETTER_Specificity,                mean, max,   better);\n-\n-    public static PerformanceMetric buildTime       = new PerformanceMetric(\"TrainTimes\", ClassifierResults.GETTER_buildTimeDoubleMillis,         median, min, slower);\n-    public static PerformanceMetric totalTestTime   = new PerformanceMetric(\"TestTimes\", ClassifierResults.GETTER_totalTestTimeDoubleMillis,      median, min, slower);\n-    public static PerformanceMetric avgTestPredTime = new PerformanceMetric(\"AvgPredTimes\", ClassifierResults.GETTER_avgTestPredTimeDoubleMillis, median, min, slower);\n-    public static PerformanceMetric fromScratchEstimateTime = new PerformanceMetric(\"FromScratchEstimateTimes\", ClassifierResults.GETTER_fromScratchEstimateTimeDoubleMillis, median, min, slower);\n-    public static PerformanceMetric totalBuildPlusEstimateTime = new PerformanceMetric(\"TotalBuildPlusEstimateTimes\", ClassifierResults.GETTER_totalBuildPlusEstimateTimeDoubleMillis, median, min, slower);\n-    public static PerformanceMetric extraTimeForEstimate = new PerformanceMetric(\"ExtraTimeForEstimates\", ClassifierResults.GETTER_additionalTimeForEstimateDoubleMillis, median, min, slower);\n-\n-    public static PerformanceMetric buildTimeBenchmarked = new PerformanceMetric(\"TrainTimesBenchmarked\", ClassifierResults.GETTER_buildTimeDoubleMillisBenchmarked,         median, min, slower);\n-    public static PerformanceMetric totalTestTimeBenchmarked = new PerformanceMetric(\"TestTimesBenchmarked\", ClassifierResults.GETTER_totalTestTimeDoubleMillisBenchmarked,      median, min, slower);\n-    public static PerformanceMetric avgTestPredTimeBenchmarked = new PerformanceMetric(\"AvgPredTimesBenchmarked\", ClassifierResults.GETTER_avgTestPredTimeDoubleMillisBenchmarked, median, min, slower);\n-    public static PerformanceMetric fromScratchEstimateTimeBenchmarked = new PerformanceMetric(\"FromScratchEstimateTimesBenchmarked\", ClassifierResults.GETTER_fromScratchEstimateTimeDoubleMillisBenchmarked, median, min, slower);\n-    public static PerformanceMetric totalBuildPlusEstimateTimeBenchmarked = new PerformanceMetric(\"TotalBuildPlusEstimateTimesBenchmarked\", ClassifierResults.GETTER_totalBuildPlusEstimateTimeDoubleMillisBenchmarked, median, min, slower);\n-    public static PerformanceMetric extraTimeForEstimateBenchmarked = new PerformanceMetric(\"ExtraTimeForEstimatesBenchmarked\", ClassifierResults.GETTER_additionalTimeForEstimateDoubleMillisBenchmarked, median, min, slower);\n-\n-    public static PerformanceMetric benchmarkTime = new PerformanceMetric(\"BenchmarkTimes\", ClassifierResults.GETTER_benchmarkTime, median, min, slower);\n-    public static PerformanceMetric memory          = new PerformanceMetric(\"MaxMemory\", ClassifierResults.GETTER_MemoryMB,                median, min,   worse);\n-\n-    public static PerformanceMetric earliness       = new PerformanceMetric(\"Earliness\", ClassifierResults.GETTER_Earliness,             mean, min,   worse);\n-    public static PerformanceMetric harmonicMean    = new PerformanceMetric(\"HarmonicMean\", ClassifierResults.GETTER_HarmonicMean,       mean, max,   better);\n+    public static PerformanceMetric acc             = new PerformanceMetric(\"ACC\", ClassifierResults.GETTER_Accuracy,                    mean, max,   better, isNotBenchmarked, test);\n+    public static PerformanceMetric balacc          = new PerformanceMetric(\"BALACC\", ClassifierResults.GETTER_BalancedAccuracy,         mean, max,   better, isNotBenchmarked, test);\n+    public static PerformanceMetric AUROC           = new PerformanceMetric(\"AUROC\", ClassifierResults.GETTER_AUROC,                     mean, max,   better, isNotBenchmarked, test);\n+    public static PerformanceMetric NLL             = new PerformanceMetric(\"NLL\", ClassifierResults.GETTER_NLL,                         mean, min,   worse, isNotBenchmarked, test);\n+    public static PerformanceMetric F1              = new PerformanceMetric(\"F1\", ClassifierResults.GETTER_F1,                           mean, max,   better, isNotBenchmarked, test);\n+    public static PerformanceMetric MCC             = new PerformanceMetric(\"MCC\", ClassifierResults.GETTER_MCC,                         mean, max,   better, isNotBenchmarked, test);\n+    public static PerformanceMetric precision       = new PerformanceMetric(\"Prec\", ClassifierResults.GETTER_Precision,                  mean, max,   better, isNotBenchmarked, test);\n+    public static PerformanceMetric recall          = new PerformanceMetric(\"Recall\", ClassifierResults.GETTER_Recall,                   mean, max,   better, isNotBenchmarked, test);\n+    public static PerformanceMetric sensitivity     = new PerformanceMetric(\"Sens\", ClassifierResults.GETTER_Sensitivity,                mean, max,   better, isNotBenchmarked, test);\n+    public static PerformanceMetric specificity     = new PerformanceMetric(\"Spec\", ClassifierResults.GETTER_Specificity,                mean, max,   better, isNotBenchmarked, test);\n+\n+    public static PerformanceMetric buildTime       = new PerformanceMetric(\"TrainTimes\", ClassifierResults.GETTER_buildTimeDoubleMillis,         median, min, slower, isNotBenchmarked, train);\n+    public static PerformanceMetric totalTestTime   = new PerformanceMetric(\"TestTimes\", ClassifierResults.GETTER_totalTestTimeDoubleMillis,      median, min, slower, isNotBenchmarked, test);\n+    public static PerformanceMetric avgTestPredTime = new PerformanceMetric(\"AvgPredTimes\", ClassifierResults.GETTER_avgTestPredTimeDoubleMillis, median, min, slower, isNotBenchmarked, test);\n+    public static PerformanceMetric fromScratchEstimateTime = new PerformanceMetric(\"FromScratchEstTimes\", ClassifierResults.GETTER_fromScratchEstimateTimeDoubleMillis, median, min, slower, isNotBenchmarked, estimate);\n+    public static PerformanceMetric totalBuildPlusEstimateTime = new PerformanceMetric(\"BuildAndEstTimes\", ClassifierResults.GETTER_totalBuildPlusEstimateTimeDoubleMillis, median, min, slower, isNotBenchmarked, estimate);\n+    public static PerformanceMetric extraTimeForEstimate = new PerformanceMetric(\"ExtraTimeForEst\", ClassifierResults.GETTER_additionalTimeForEstimateDoubleMillis, median, min, slower, isNotBenchmarked, estimate);\n+\n+    public static PerformanceMetric buildTimeBenchmarked = new PerformanceMetric(\"TrainTimes\"+benchmarkSuffix, ClassifierResults.GETTER_buildTimeDoubleMillisBenchmarked,         median, min, slower, isBenchmarked, train);\n+    public static PerformanceMetric totalTestTimeBenchmarked = new PerformanceMetric(\"TestTimes\"+benchmarkSuffix, ClassifierResults.GETTER_totalTestTimeDoubleMillisBenchmarked,      median, min, slower, isBenchmarked, test);\n+    public static PerformanceMetric avgTestPredTimeBenchmarked = new PerformanceMetric(\"AvgPredTimes\"+benchmarkSuffix, ClassifierResults.GETTER_avgTestPredTimeDoubleMillisBenchmarked, median, min, slower, isBenchmarked, test);\n+    public static PerformanceMetric fromScratchEstimateTimeBenchmarked = new PerformanceMetric(\"FromScratchEstTimes\"+benchmarkSuffix, ClassifierResults.GETTER_fromScratchEstimateTimeDoubleMillisBenchmarked, median, min, slower, isBenchmarked, estimate);\n+    public static PerformanceMetric totalBuildPlusEstimateTimeBenchmarked = new PerformanceMetric(\"BuildAndEstTimes\"+benchmarkSuffix, ClassifierResults.GETTER_totalBuildPlusEstimateTimeDoubleMillisBenchmarked, median, min, slower, isBenchmarked, estimate);\n+    public static PerformanceMetric extraTimeForEstimateBenchmarked = new PerformanceMetric(\"ExtraTimeForEst\"+benchmarkSuffix, ClassifierResults.GETTER_additionalTimeForEstimateDoubleMillisBenchmarked, median, min, slower, isBenchmarked, estimate);\n+\n+    public static PerformanceMetric benchmarkTime   = new PerformanceMetric(\"BenchmarkTimes\", ClassifierResults.GETTER_benchmarkTime, median, min, slower, isNotBenchmarked, train);\n+    public static PerformanceMetric memory          = new PerformanceMetric(\"MaxMemory\", ClassifierResults.GETTER_MemoryMB,                median, min,   worse, isNotBenchmarked, train);\n+\n+    public static PerformanceMetric earliness       = new PerformanceMetric(\"Earliness\", ClassifierResults.GETTER_Earliness,             mean, min,   worse, isNotBenchmarked, test);\n+    public static PerformanceMetric harmonicMean    = new PerformanceMetric(\"HarmonicMean\", ClassifierResults.GETTER_HarmonicMean,       mean, max,   better, isNotBenchmarked, test);\n \n     \n-    public static ArrayList<PerformanceMetric> getAccuracyStatistic() { \n+    public static List<PerformanceMetric> getAccuracyStatistic() {\n         ArrayList<PerformanceMetric> stats = new ArrayList<>();\n         stats.add(acc);\n         return stats;\n     }\n     \n-    public static ArrayList<PerformanceMetric> getDefaultStatistics() { \n+    public static List<PerformanceMetric> getDefaultStatistics() {\n         ArrayList<PerformanceMetric> stats = new ArrayList<>();\n         stats.add(acc);\n         stats.add(balacc);\n@@ -121,7 +130,7 @@ public String toString() {\n         return stats;\n     }\n         \n-    public static ArrayList<PerformanceMetric> getAllStatistics() { \n+    public static List<PerformanceMetric> getAllPredictionStatistics() {\n         ArrayList<PerformanceMetric> stats = new ArrayList<>();\n         stats.add(acc);\n         stats.add(balacc);\n@@ -141,4 +150,36 @@ public String toString() {\n \n         return stats;\n     }\n+\n+    public static List<PerformanceMetric> getAllTimingStatistics() {\n+        List<PerformanceMetric> stats = getBenchmarkedTimingStatistics();\n+        stats.addAll(getNonBenchmarkedTimingStatistics());\n+\n+        return stats;\n+    }\n+\n+    public static List<PerformanceMetric> getBenchmarkedTimingStatistics() {\n+        ArrayList<PerformanceMetric> stats = new ArrayList<>();\n+        stats.add(buildTimeBenchmarked);\n+        stats.add(totalTestTimeBenchmarked);\n+        stats.add(avgTestPredTimeBenchmarked);\n+        stats.add(fromScratchEstimateTimeBenchmarked);\n+        stats.add(totalBuildPlusEstimateTimeBenchmarked);\n+        stats.add(extraTimeForEstimateBenchmarked);\n+\n+        return stats;\n+    }\n+\n+\n+    public static List<PerformanceMetric> getNonBenchmarkedTimingStatistics() {\n+        ArrayList<PerformanceMetric> stats = new ArrayList<>();\n+        stats.add(buildTime);\n+        stats.add(totalTestTime);\n+        stats.add(avgTestPredTime);\n+        stats.add(fromScratchEstimateTime);\n+        stats.add(totalBuildPlusEstimateTime);\n+        stats.add(extraTimeForEstimate);\n+\n+        return stats;\n+    }\n }"
  },
  {
    "sha": "30fd53e0dc16b72633718c53cca3ab8e52177b41",
    "filename": "src/main/java/evaluation/storage/ClassifierResultsCollection.java",
    "status": "modified",
    "additions": 14,
    "deletions": 12,
    "changes": 26,
    "blob_url": "https://github.com/uea-machine-learning/tsml/blob/e4daa1bb76d3d19b08eadc544feab3b600cc5b0c/src/main/java/evaluation/storage/ClassifierResultsCollection.java",
    "raw_url": "https://github.com/uea-machine-learning/tsml/raw/e4daa1bb76d3d19b08eadc544feab3b600cc5b0c/src/main/java/evaluation/storage/ClassifierResultsCollection.java",
    "contents_url": "https://api.github.com/repos/uea-machine-learning/tsml/contents/src/main/java/evaluation/storage/ClassifierResultsCollection.java?ref=e4daa1bb76d3d19b08eadc544feab3b600cc5b0c",
    "patch": "@@ -533,16 +533,18 @@ private static int find(int[] arr, int k) {\n     private static String buildFileName(String baseReadPath, String classifier, String dataset, String split, int fold) { \n         return baseReadPath + classifier + \"/Predictions/\" + dataset + \"/\" + split + \"Fold\" + fold + \".csv\";\n     }\n-    \n-    private static void throwSliceError(String str, String[] arr, String key) throws Exception {\n-        throw new Exception(\"SLICE ERROR: Attempted to slice \" + str + \" by \" + key + \" but that does not exist in \" + Arrays.toString(arr));\n-    }\n-    \n-    private static void throwSliceError(String str, int[] arr, int key) throws Exception {\n-        throw new Exception(\"SLICE ERROR: Attempted to slice \" + str + \" by \" + key + \" but that does not exist in \" + Arrays.toString(arr));\n+\n+    public class SliceException extends Exception {\n+        public SliceException(String str, String[] arr, String key) {\n+            super(\"SLICE ERROR: Attempted to slice \" + str + \" by \" + key + \" but that does not exist in \" + Arrays.toString(arr));\n+        }\n+\n+        public SliceException(String str, int[] arr, int key) {\n+            super(\"SLICE ERROR: Attempted to slice \" + str + \" by \" + key + \" but that does not exist in \" + Arrays.toString(arr));\n+        }\n+\n     }\n     \n-    \n     /**\n      * Loads the splits, classifiers, datasets, and folds specified from disk into memory\n      * subject to the options set. \n@@ -766,7 +768,7 @@ public ClassifierResultsCollection sliceSplits(String[] splitsToSlice) throws Ex\n         //perform existence checks before allocating the mem\n         for (String split : splitsToSlice)\n             if (find(splits, split) == -1)\n-                throwSliceError(\"splits\", splits, split);\n+                throw new SliceException(\"splits\", splits, split);\n         \n         //copy across the results, for splits it's nice and easy\n         ClassifierResults[][][][] subResults = new ClassifierResults[splitsToSlice.length][][][];\n@@ -816,7 +818,7 @@ public ClassifierResultsCollection sliceClassifiers(String[] classifiersToSlice)\n             String classifier = classifiersToSlice[i];\n             origClassifierIds[i] = find(classifierNamesInStorage, classifier);\n             if (origClassifierIds[i] == -1)\n-                throwSliceError(\"classifiers\", classifierNamesInStorage, classifier);\n+                throw new SliceException(\"classifiers\", classifierNamesInStorage, classifier);\n             else {\n                 keptNamesStorage[i] = classifierNamesInStorage[origClassifierIds[i]];\n                 keptNamesOutput[i] = classifierNamesInOutput[origClassifierIds[i]];\n@@ -864,7 +866,7 @@ public ClassifierResultsCollection sliceDatasets(String[] datasetsToSlice) throw\n         //perform existence checks before allocating the mem\n         for (String dataset : datasetsToSlice)\n             if (find(datasetNamesInStorage, dataset) == -1)\n-                throwSliceError(\"datasets\", datasetNamesInStorage, dataset);\n+                throw new SliceException(\"datasets\", datasetNamesInStorage, dataset);\n                 \n         //copy across the results\n         ClassifierResults[][][][] subResults = new ClassifierResults[numSplits][numClassifiers][datasetsToSlice.length][];\n@@ -920,7 +922,7 @@ public ClassifierResultsCollection sliceFolds(int[] foldsToSlice) throws Excepti\n         //perform existence checks before allocating the mem\n         for (int fold : foldsToSlice)\n             if (find(folds, fold) == -1)\n-                throwSliceError(\"folds\", folds, fold);\n+                throw new SliceException(\"folds\", folds, fold);\n                 \n         //copy across the results\n         ClassifierResults[][][][] subResults = new ClassifierResults[numSplits][numClassifiers][numDatasets][foldsToSlice.length];"
  },
  {
    "sha": "52d09dff399e3a85c1da4062d4f9656590db6065",
    "filename": "src/main/java/experiments/BasicReproductionTests.java",
    "status": "modified",
    "additions": 1,
    "deletions": 1,
    "changes": 2,
    "blob_url": "https://github.com/uea-machine-learning/tsml/blob/e4daa1bb76d3d19b08eadc544feab3b600cc5b0c/src/main/java/experiments/BasicReproductionTests.java",
    "raw_url": "https://github.com/uea-machine-learning/tsml/raw/e4daa1bb76d3d19b08eadc544feab3b600cc5b0c/src/main/java/experiments/BasicReproductionTests.java",
    "contents_url": "https://api.github.com/repos/uea-machine-learning/tsml/contents/src/main/java/experiments/BasicReproductionTests.java?ref=e4daa1bb76d3d19b08eadc544feab3b600cc5b0c",
    "patch": "@@ -410,7 +410,7 @@ public static boolean testBuildCAWPEPaper_AllResultsForFigure3() throws Exceptio\n         StringBuilder sb = new StringBuilder();\n         while (scan.hasNext()) {\n             String t = scan.nextLine();\n-            if (t.contains(\"AvgPredTimesBenchmarked:\"))\n+            if (t.contains(\"ExtraTimeForEst\")) //this is now the first timing metric, these can't be reliably reproduced ofc so ignore\n                 break;\n             sb.append(t).append(\"\\n\");\n         }"
  },
  {
    "sha": "2f8f603d6f87c44fcbd92a2184ccef6282713a86",
    "filename": "src/main/java/experiments/Experiments.java",
    "status": "modified",
    "additions": 4,
    "deletions": 2,
    "changes": 6,
    "blob_url": "https://github.com/uea-machine-learning/tsml/blob/e4daa1bb76d3d19b08eadc544feab3b600cc5b0c/src/main/java/experiments/Experiments.java",
    "raw_url": "https://github.com/uea-machine-learning/tsml/raw/e4daa1bb76d3d19b08eadc544feab3b600cc5b0c/src/main/java/experiments/Experiments.java",
    "contents_url": "https://api.github.com/repos/uea-machine-learning/tsml/contents/src/main/java/experiments/Experiments.java?ref=e4daa1bb76d3d19b08eadc544feab3b600cc5b0c",
    "patch": "@@ -547,8 +547,10 @@ just return getTrainResults(), contains the timings and other maybe useful metai\n \n         //todo just enforce nanos everywhere, this is ridiculous. this needs overhaul\n \n+        long estimateToUpdateWith = 0; // no estimate by default\n+        long timingToUpdateWith = buildTime; //the timing that experiments measured by default\n+\n         if (exp.generateErrorEstimateOnTrainSet) { //want timings and full predictions\n-            long timingToUpdateWith = buildTime; //the timing that experiments measured by default\n             TimeUnit timeUnitToUpdateWith = expTimeUnit;\n             String paras = \"No parameter info\";\n \n@@ -569,7 +571,7 @@ just return getTrainResults(), contains the timings and other maybe useful metai\n             }\n \n             timingToUpdateWith = trainResults.getTimeUnit().convert(timingToUpdateWith, timeUnitToUpdateWith);\n-            long estimateToUpdateWith = trainResults.getTimeUnit().convert(trainResults.getErrorEstimateTime(), timeUnitToUpdateWith);\n+            estimateToUpdateWith = trainResults.getTimeUnit().convert(trainResults.getErrorEstimateTime(), timeUnitToUpdateWith);\n \n             //update the externally produced results with the appropriate timing\n             trainResults.setBuildTime(timingToUpdateWith);"
  },
  {
    "sha": "405e4eea555cd1577554c3a0c8b36dc522420249",
    "filename": "src/main/java/machine_learning/classifiers/ensembles/AbstractEnsemble.java",
    "status": "modified",
    "additions": 1,
    "deletions": 0,
    "changes": 1,
    "blob_url": "https://github.com/uea-machine-learning/tsml/blob/e4daa1bb76d3d19b08eadc544feab3b600cc5b0c/src/main/java/machine_learning/classifiers/ensembles/AbstractEnsemble.java",
    "raw_url": "https://github.com/uea-machine-learning/tsml/raw/e4daa1bb76d3d19b08eadc544feab3b600cc5b0c/src/main/java/machine_learning/classifiers/ensembles/AbstractEnsemble.java",
    "contents_url": "https://api.github.com/repos/uea-machine-learning/tsml/contents/src/main/java/machine_learning/classifiers/ensembles/AbstractEnsemble.java?ref=e4daa1bb76d3d19b08eadc544feab3b600cc5b0c",
    "patch": "@@ -945,6 +945,7 @@ public void buildClassifier(Instances data) throws Exception {\n         //time unit has been set in estimateEnsemblePerformance(data);\n         trainResults.turnOffZeroTimingsErrors();\n         trainResults.setBuildTime(buildTime);\n+        trainResults.setBuildPlusEstimateTime(buildTime + trainResults.getErrorEstimateTime());\n         trainResults.turnOnZeroTimingsErrors();\n                 \n         this.testInstCounter = 0; //prep for start of testing"
  }
]
