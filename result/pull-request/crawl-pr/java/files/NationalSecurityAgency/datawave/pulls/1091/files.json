[
  {
    "sha": "c8b9d883f7f0bbddf04cdb28d76cf36ce961b023",
    "filename": "warehouse/ingest-core/src/main/java/datawave/ingest/mapreduce/job/reduce/AggregatingReducer.java",
    "status": "modified",
    "additions": 9,
    "deletions": 1,
    "changes": 10,
    "blob_url": "https://github.com/NationalSecurityAgency/datawave/blob/3d8f1147e929e67ff993eb9cd4e73b0c773edaf5/warehouse/ingest-core/src/main/java/datawave/ingest/mapreduce/job/reduce/AggregatingReducer.java",
    "raw_url": "https://github.com/NationalSecurityAgency/datawave/raw/3d8f1147e929e67ff993eb9cd4e73b0c773edaf5/warehouse/ingest-core/src/main/java/datawave/ingest/mapreduce/job/reduce/AggregatingReducer.java",
    "contents_url": "https://api.github.com/repos/NationalSecurityAgency/datawave/contents/warehouse/ingest-core/src/main/java/datawave/ingest/mapreduce/job/reduce/AggregatingReducer.java?ref=3d8f1147e929e67ff993eb9cd4e73b0c773edaf5",
    "patch": "@@ -376,7 +376,9 @@ public CustomColumnToClassMapping(Integer priority, Map<String,String> opts) {\n             for (Entry<String,String> entry : opts.entrySet()) {\n                 String column = entry.getKey();\n                 \n-                final String className = entry.getValue();\n+                final String val = entry.getValue().trim();\n+                int spaceIdx = val.indexOf(' ');\n+                final String className = spaceIdx < 0 ? val : val.substring(0, spaceIdx);\n                 \n                 Pair<Text,Text> pcic;\n                 if (ALL_CF_STR.equals(column)) {\n@@ -392,6 +394,12 @@ public CustomColumnToClassMapping(Integer priority, Map<String,String> opts) {\n                     \n                     agg = clazz.newInstance();\n                     \n+                    if (spaceIdx > 0) {\n+                        final String encodedOpts = val.substring(spaceIdx + 1);\n+                        Map<String,String> aggOpts = Splitter.on(';').trimResults().withKeyValueSeparator('=').split(encodedOpts);\n+                        agg.validateOptions(aggOpts);\n+                    }\n+                    \n                 } catch (InstantiationException | IllegalAccessException | ClassNotFoundException e) {\n                     throw new RuntimeException(e);\n                 }"
  },
  {
    "sha": "7bca0725bb8c31d06d0e69297cc562f00ebb1a48",
    "filename": "warehouse/ingest-core/src/main/java/datawave/ingest/table/aggregator/GlobalIndexUidAggregator.java",
    "status": "modified",
    "additions": 79,
    "deletions": 27,
    "changes": 106,
    "blob_url": "https://github.com/NationalSecurityAgency/datawave/blob/3d8f1147e929e67ff993eb9cd4e73b0c773edaf5/warehouse/ingest-core/src/main/java/datawave/ingest/table/aggregator/GlobalIndexUidAggregator.java",
    "raw_url": "https://github.com/NationalSecurityAgency/datawave/raw/3d8f1147e929e67ff993eb9cd4e73b0c773edaf5/warehouse/ingest-core/src/main/java/datawave/ingest/table/aggregator/GlobalIndexUidAggregator.java",
    "contents_url": "https://api.github.com/repos/NationalSecurityAgency/datawave/contents/warehouse/ingest-core/src/main/java/datawave/ingest/table/aggregator/GlobalIndexUidAggregator.java?ref=3d8f1147e929e67ff993eb9cd4e73b0c773edaf5",
    "patch": "@@ -1,25 +1,43 @@\n package datawave.ingest.table.aggregator;\n \n+import java.io.IOException;\n import java.util.HashSet;\n import java.util.Iterator;\n+import java.util.Map;\n \n+import org.apache.accumulo.core.client.IteratorSetting;\n import org.apache.accumulo.core.data.Key;\n import org.apache.accumulo.core.data.Value;\n-import org.apache.log4j.Logger;\n+import org.apache.accumulo.core.iterators.IteratorEnvironment;\n+import org.apache.accumulo.core.iterators.SortedKeyValueIterator;\n \n import com.google.protobuf.InvalidProtocolBufferException;\n \n import datawave.ingest.protobuf.Uid;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n /**\n  * Implementation of an Aggregator that aggregates objects of the type Uid.List. This is an optimization for the shardIndex and shardReverseIndex, where the\n  * list of UIDs for events will be maintained in the global index for low cardinality terms.\n- * \n- * \n- * \n+ *\n+ * Although this combiner allows the max UIDs kept to be configured, anyone using this feature should consider the impact of using it once data has been loaded\n+ * into the system. Decreasing the max size will likely cause UID lists to be purged as they exceed the new max UID count. Increasing the max UID could is also\n+ * unlikely to work as one would expect since any lists that already had their UIDs purged and the ignore flag set won't start collecting UIDs even if the\n+ * previous count is less than the new max UID count. In practice, the main intent for this feature is to configure a new cluster with a different max UID count\n+ * (without having to re-compile the code). With the caveats mentioned, it could be used on a system with data loaded, for example if a new data type becomes\n+ * available and one wished to increase the max UID count while data for other data types is relatively stable or the side effects of the change don't matter.\n+ *\n+ * When this class is used with {@link datawave.iterators.PropogatingIterator}, one must be aware that this class is not actually used as a combiner but rather\n+ * is only used for its {@link #reset()} and {@link #aggregate()} methods. PropogatingIterator allows combiner options to be passed, which means when this class\n+ * is used with PropogatingIterator one could change the max UID count. However, if that option is used it should be noted that the base\n+ * {@link org.apache.accumulo.core.iterators.Combiner} option validation is used and therefore the option \"all\" must also be set to \"true\" or the \"columns\" must\n+ * be set in order to pass option validation. While set, the \"all\" or \"columns\" option will have no effect when used with PropogatingIterator since only the\n+ * {@link #reset()} and {@link #aggregate()} methods are invoked.\n  */\n public class GlobalIndexUidAggregator extends PropogatingCombiner {\n-    private static final Logger log = Logger.getLogger(GlobalIndexUidAggregator.class);\n+    private static final Logger log = LoggerFactory.getLogger(GlobalIndexUidAggregator.class);\n+    private static final String MAX_UIDS_OPT = \"maxuids\";\n     private Uid.List.Builder builder = Uid.List.newBuilder();\n     \n     /**\n@@ -28,14 +46,6 @@\n      */\n     private HashSet<String> uids = new HashSet<>();\n     \n-    public GlobalIndexUidAggregator(int max) {\n-        this.maxUids = max;\n-    }\n-    \n-    public GlobalIndexUidAggregator() {\n-        this.maxUids = MAX;\n-    }\n-    \n     /**\n      * List of UIDs to remove.\n      */\n@@ -76,6 +86,14 @@ public GlobalIndexUidAggregator() {\n      */\n     protected HashSet<String> tempSet;\n     \n+    public GlobalIndexUidAggregator(int max) {\n+        this.maxUids = max;\n+    }\n+    \n+    public GlobalIndexUidAggregator() {\n+        this.maxUids = MAX;\n+    }\n+    \n     public Value aggregate() {\n         \n         // as a backup, we remove the intersection of the UID sets\n@@ -99,16 +117,14 @@ public Value aggregate() {\n             uids.removeAll(quarantinedIds);\n             \n             if (!releasedUids.isEmpty()) {\n-                if (log.isDebugEnabled())\n-                    log.debug(\"Adding released UIDS\");\n+                log.debug(\"Adding released UIDS\");\n                 uids.addAll(releasedUids);\n             }\n             \n             builder.addAllUID(uids);\n         }\n         \n-        if (log.isDebugEnabled())\n-            log.debug(\"Propogating: \" + propogate);\n+        log.debug(\"Propogating: {}\", propogate);\n         \n         // clear all removals\n         builder.clearREMOVEDUID();\n@@ -118,8 +134,7 @@ public Value aggregate() {\n             builder.addAllREMOVEDUID(uidsToRemove);\n             builder.addAllQUARANTINEUID(quarantinedIds);\n         }\n-        if (log.isDebugEnabled())\n-            log.debug(\"Building aggregate. Count is \" + count + \", uids.size() is \" + uids.size() + \". builder size is \" + builder.getUIDList().size());\n+        log.debug(\"Building aggregate. Count is {}, uids.size() is {}. builder size is {}\", count, uids.size(), builder.getUIDList().size());\n         return new Value(builder.build().toByteArray());\n         \n     }\n@@ -138,7 +153,7 @@ public Value aggregate() {\n     @Override\n     public Value reduce(Key key, Iterator<Value> iter) {\n         if (log.isTraceEnabled())\n-            log.trace(\"has next ? \" + iter.hasNext());\n+            log.trace(\"has next ? {}\", iter.hasNext());\n         while (iter.hasNext()) {\n             \n             Value value = iter.next();\n@@ -155,8 +170,7 @@ public Value reduce(Key key, Iterator<Value> iter) {\n                  */\n                 if (v.getIGNORE()) {\n                     seenIgnore = true;\n-                    if (log.isDebugEnabled())\n-                        log.debug(\"SeenIgnore is true. Skipping collections\");\n+                    log.debug(\"SeenIgnore is true. Skipping collections\");\n                 }\n                 \n                 // if delta > 0, we are collecting the uid list\n@@ -183,8 +197,7 @@ public Value reduce(Key key, Iterator<Value> iter) {\n                         \n                     }\n                     \n-                    if (log.isDebugEnabled())\n-                        log.debug(\"Adding uids \" + delta + \" \" + count);\n+                    log.debug(\"Adding uids {} {}\", delta, count);\n                     \n                     // if our delta is < 0, then we can remove, iff seenIgnore is false. If it is true, there is no need to proceed with removals\n                 } else if (delta < 0 && !seenIgnore) {\n@@ -229,8 +242,7 @@ public Value reduce(Key key, Iterator<Value> iter) {\n     }\n     \n     public void reset() {\n-        if (log.isDebugEnabled())\n-            log.debug(\"Resetting GlobalIndexUidAggregator\");\n+        log.debug(\"Resetting GlobalIndexUidAggregator\");\n         count = 0;\n         seenIgnore = false;\n         builder = Uid.List.newBuilder();\n@@ -258,7 +270,7 @@ public boolean propogateKey() {\n         uidsCopy.removeAll(uidsToRemove);\n         \n         if (log.isDebugEnabled()) {\n-            log.debug(count + \" \" + uids.size() + \" \" + uidsToRemove.size() + \" \" + uidsCopy.size() + \" removing \" + (count == 0 && uidsCopy.isEmpty()));\n+            log.debug(\"{} {} {} {} removing {}\", count, uids.size(), uidsToRemove.size(), uidsCopy.size(), (count == 0 && uidsCopy.isEmpty()));\n         }\n         \n         // if <= 0 and uids is empty, we can safely remove\n@@ -268,4 +280,44 @@ public boolean propogateKey() {\n             return true;\n     }\n     \n+    @Override\n+    public IteratorOptions describeOptions() {\n+        IteratorOptions io = super.describeOptions();\n+        io.addNamedOption(MAX_UIDS_OPT, \"The maximum number of UIDs to keep in the list. Default is \" + MAX + \".\");\n+        return io;\n+    }\n+    \n+    @Override\n+    public boolean validateOptions(Map<String,String> options) {\n+        boolean valid = super.validateOptions(options);\n+        if (valid) {\n+            if (options.containsKey(MAX_UIDS_OPT)) {\n+                maxUids = Integer.parseInt(options.get(MAX_UIDS_OPT));\n+                if (maxUids <= 0) {\n+                    throw new IllegalArgumentException(\"Max UIDs must be greater than 0.\");\n+                }\n+            }\n+        }\n+        return valid;\n+    }\n+    \n+    @Override\n+    public SortedKeyValueIterator<Key,Value> deepCopy(IteratorEnvironment env) {\n+        GlobalIndexUidAggregator copy = (GlobalIndexUidAggregator) super.deepCopy(env);\n+        copy.maxUids = maxUids;\n+        // Not copying other fields that are all cleared in the reset() method.\n+        return copy;\n+    }\n+    \n+    @Override\n+    public void init(SortedKeyValueIterator<Key,Value> source, Map<String,String> options, IteratorEnvironment env) throws IOException {\n+        super.init(source, options, env);\n+        if (options.containsKey(MAX_UIDS_OPT)) {\n+            maxUids = Integer.parseInt(options.get(MAX_UIDS_OPT));\n+        }\n+    }\n+    \n+    public static void setMaxUidsOpt(IteratorSetting is, int maxUids) {\n+        is.addOption(MAX_UIDS_OPT, Integer.toString(maxUids));\n+    }\n }"
  },
  {
    "sha": "d8285e3f6f5cdd0add478872be04d5764697cad1",
    "filename": "warehouse/ingest-core/src/main/java/datawave/iterators/PropogatingIterator.java",
    "status": "modified",
    "additions": 31,
    "deletions": 52,
    "changes": 83,
    "blob_url": "https://github.com/NationalSecurityAgency/datawave/blob/3d8f1147e929e67ff993eb9cd4e73b0c773edaf5/warehouse/ingest-core/src/main/java/datawave/iterators/PropogatingIterator.java",
    "raw_url": "https://github.com/NationalSecurityAgency/datawave/raw/3d8f1147e929e67ff993eb9cd4e73b0c773edaf5/warehouse/ingest-core/src/main/java/datawave/iterators/PropogatingIterator.java",
    "contents_url": "https://api.github.com/repos/NationalSecurityAgency/datawave/contents/warehouse/ingest-core/src/main/java/datawave/iterators/PropogatingIterator.java?ref=3d8f1147e929e67ff993eb9cd4e73b0c773edaf5",
    "patch": "@@ -1,6 +1,7 @@\n package datawave.iterators;\n \n import com.google.common.base.Preconditions;\n+import com.google.common.base.Splitter;\n import com.google.common.collect.Maps;\n import datawave.ingest.table.aggregator.PropogatingCombiner;\n import org.apache.accumulo.core.data.ArrayByteSequence;\n@@ -16,13 +17,13 @@\n import org.apache.accumulo.core.iterators.OptionDescriber;\n import org.apache.accumulo.core.iterators.SortedKeyValueIterator;\n import org.apache.accumulo.core.iterators.conf.ColumnToClassMapping;\n-import org.apache.log4j.Logger;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n import java.io.IOException;\n import java.util.Collection;\n import java.util.Collections;\n import java.util.Map;\n-import java.util.Map.Entry;\n \n /**\n  * Purpose: Handle arbitrary propogating aggregations.\n@@ -39,7 +40,7 @@\n     \n     public static final String ATTRIBUTE_DESCRIPTION = \"Aggregators apply aggregating functions to values with identical keys. You can specify the column family. DEFAULT matches the default locality group\";\n     \n-    public static final String UNNAMED_OPTION_DESCRIPTION = \"<Column Family>  <Combiner>\";\n+    public static final String UNNAMED_OPTION_DESCRIPTION = \"<Column Family> <Combiner> <optional: combOpt1=comVal1;combOpt2=combVal2...>\";\n     \n     public static final String AGGREGATOR_DEFAULT = \"DEFAULT\";\n     \n@@ -79,17 +80,12 @@\n     protected PropogatingCombiner defaultAgg = null;\n     protected Map<ByteSequence,PropogatingCombiner> aggMap;\n     \n-    /**\n-     * variable to determine if we should propogate deletes\n-     */\n-    private boolean shouldPropogate;\n-    \n     /**\n      * Combiner options so that we can effectively deep copy\n      */\n     protected Map<String,String> options = Maps.newHashMap();\n     \n-    private static final Logger log = Logger.getLogger(PropogatingIterator.class);\n+    private static final Logger log = LoggerFactory.getLogger(PropogatingIterator.class);\n     \n     /**\n      * Deep copy implementation\n@@ -100,9 +96,6 @@ public PropogatingIterator deepCopy(IteratorEnvironment env) {\n     \n     /**\n      * Private constructor.\n-     * \n-     * @param other\n-     * @param env\n      */\n     private PropogatingIterator(PropogatingIterator other, IteratorEnvironment env) {\n         iterator = other.iterator.deepCopy(env);\n@@ -121,11 +114,8 @@ public PropogatingIterator() {\n     \n     /**\n      * Aggregates the same partial key.\n-     * \n-     * @return\n-     * @throws IOException\n      */\n-    private boolean aggregateRowColumn() throws IOException {\n+    private boolean aggregateRowColumn() {\n         // this function assumes that first value is not delete\n         \n         workKey.set(iterator.getTopKey());\n@@ -139,22 +129,18 @@ private boolean aggregateRowColumn() throws IOException {\n         // always propogate deletes\n         if (aggr != null) {\n             \n-            if (log.isTraceEnabled()) {\n-                log.trace(\"aggregator is not null\");\n-            }\n+            log.trace(\"aggregator is not null\");\n             \n             // reset the state of the combiner.\n             aggr.reset();\n             \n             aggregatedValue = aggr.reduce(keyToAggregate, new ValueCombiner(iterator));\n             \n             if (aggr.propogateKey() || workKey.isDeleted()) {\n-                if (log.isTraceEnabled())\n-                    log.trace(\"propogating \" + workKey);\n+                log.trace(\"propogating {}\", workKey);\n                 aggrKey = workKey;\n             } else {\n-                if (log.isTraceEnabled())\n-                    log.trace(\"Not propogating \" + workKey);\n+                log.trace(\"Not propogating {}\", workKey);\n                 return false;\n             }\n         }\n@@ -171,28 +157,20 @@ private PropogatingCombiner getAggregator(Key key) {\n         PropogatingCombiner aggr = aggMap.get(key.getColumnFamilyData());\n         \n         if (null == aggr) {\n-            if (log.isTraceEnabled()) {\n-                log.trace(\"using the default aggregator\");\n-            }\n+            log.trace(\"using the default aggregator\");\n             aggr = defaultAgg;\n         }\n         \n-        if (log.isTraceEnabled()) {\n-            log.trace(\"Key is \" + key);\n-        }\n+        log.trace(\"Key is {}\", key);\n         \n-        if (log.isTraceEnabled()) {\n-            log.trace(key + \"agg == \" + (aggr == null) + \" \" + key.isDeleted());\n-        }\n+        log.trace(\"{}agg == {} {}\", key, (aggr == null), key.isDeleted());\n         return aggr;\n     }\n     \n     /**\n      * Find Top method, will attempt to aggregate, iff an aggregator is specified\n-     * \n-     * @throws IOException\n      */\n-    private void findTop() throws IOException {\n+    private void findTop() {\n         // check if aggregation is needed\n         while (iterator.hasTop() && !aggregateRowColumn())\n             ;\n@@ -201,12 +179,8 @@ private void findTop() throws IOException {\n     \n     /**\n      * SKVI Constructor\n-     * \n-     * @param iterator\n-     * @param Aggregators\n-     * @throws IOException\n      */\n-    public PropogatingIterator(SortedKeyValueIterator<Key,Value> iterator, ColumnToClassMapping<Combiner> Aggregators) throws IOException {\n+    public PropogatingIterator(SortedKeyValueIterator<Key,Value> iterator, ColumnToClassMapping<Combiner> Aggregators) {\n         this.iterator = iterator;\n         findTop();\n     }\n@@ -294,7 +268,7 @@ public void init(SortedKeyValueIterator<Key,Value> source, Map<String,String> op\n     @Override\n     public IteratorOptions describeOptions() {\n         \n-        return new IteratorOptions(ATTRIBUTE_NAME, ATTRIBUTE_DESCRIPTION, defaultMapOptions, Collections.singletonList(\"<ColumnFamily> <Combiner>\"));\n+        return new IteratorOptions(ATTRIBUTE_NAME, ATTRIBUTE_DESCRIPTION, defaultMapOptions, Collections.singletonList(UNNAMED_OPTION_DESCRIPTION));\n     }\n     \n     @Override\n@@ -303,24 +277,29 @@ public boolean validateOptions(Map<String,String> options) {\n         Preconditions.checkNotNull(env);\n         Preconditions.checkNotNull(options);\n         \n-        shouldPropogate = !(env.getIteratorScope() == IteratorScope.majc && env.isFullMajorCompaction());\n-        \n-        PropogatingCombiner propAgg = null;\n+        boolean shouldPropogate = !(env.getIteratorScope() == IteratorScope.majc && env.isFullMajorCompaction());\n         \n-        for (Entry<String,String> familyOption : options.entrySet()) {\n-            Object agg = createAggregator(familyOption.getValue());\n+        options.forEach((name, value) -> {\n+            value = value.trim();\n+            int sepIdx = value.indexOf(' ');\n+            String aggClass = (sepIdx < 0) ? value : value.substring(0, sepIdx);\n+            Object agg = createAggregator(aggClass);\n             if (agg instanceof PropogatingCombiner) {\n-                propAgg = PropogatingCombiner.class.cast(agg);\n+                PropogatingCombiner propAgg = (PropogatingCombiner) agg;\n+                if (sepIdx > 0) {\n+                    String encodedOpts = value.substring(sepIdx + 1);\n+                    Map<String,String> aggOpts = Splitter.on(';').trimResults().withKeyValueSeparator('=').split(encodedOpts);\n+                    propAgg.validateOptions(aggOpts);\n+                }\n                 propAgg.setPropogate(shouldPropogate);\n-                if (familyOption.getKey().equals(AGGREGATOR_DEFAULT) || familyOption.getKey().equals(AGGREGATOR_DEFAULT_OPT)) {\n-                    if (log.isTraceEnabled())\n-                        log.debug(\"Default aggregator is \" + propAgg.getClass());\n+                if (name.equals(AGGREGATOR_DEFAULT) || name.equals(AGGREGATOR_DEFAULT_OPT)) {\n+                    log.trace(\"Default aggregator is {}\", propAgg.getClass());\n                     defaultAgg = propAgg;\n                 } else {\n-                    aggMap.put(new ArrayByteSequence(familyOption.getKey().getBytes()), propAgg);\n+                    aggMap.put(new ArrayByteSequence(name.getBytes()), propAgg);\n                 }\n             }\n-        }\n+        });\n         return true;\n     }\n     "
  },
  {
    "sha": "61a23b6bee5626ad8433e78b7a096ebc6a18cec0",
    "filename": "warehouse/ingest-core/src/test/java/datawave/iterators/PropogatingIteratorTest.java",
    "status": "modified",
    "additions": 47,
    "deletions": 2,
    "changes": 49,
    "blob_url": "https://github.com/NationalSecurityAgency/datawave/blob/3d8f1147e929e67ff993eb9cd4e73b0c773edaf5/warehouse/ingest-core/src/test/java/datawave/iterators/PropogatingIteratorTest.java",
    "raw_url": "https://github.com/NationalSecurityAgency/datawave/raw/3d8f1147e929e67ff993eb9cd4e73b0c773edaf5/warehouse/ingest-core/src/test/java/datawave/iterators/PropogatingIteratorTest.java",
    "contents_url": "https://api.github.com/repos/NationalSecurityAgency/datawave/contents/warehouse/ingest-core/src/test/java/datawave/iterators/PropogatingIteratorTest.java?ref=3d8f1147e929e67ff993eb9cd4e73b0c773edaf5",
    "patch": "@@ -38,12 +38,19 @@\n     private static final String FIELD_TO_AGGREGATE = \"UUID\";\n     private static final long TIMESTAMP = 1349541830;\n     \n+    private void validateOverfullUidList(Value topValue, int count) throws InvalidProtocolBufferException {\n+        Uid.List v = Uid.List.parseFrom(topValue.get());\n+        \n+        Assert.assertEquals(count, v.getCOUNT());\n+        Assert.assertEquals(0, v.getUIDList().size());\n+    }\n+    \n     private void validateUids(Value topValue, String... uids) throws InvalidProtocolBufferException {\n         Uid.List v = Uid.List.parseFrom(topValue.get());\n         \n         Assert.assertEquals(uids.length, v.getCOUNT());\n         for (String uid : uids) {\n-            v.getUIDList().contains(uid);\n+            Assert.assertTrue(uid + \" missing from UIDs list\", v.getUIDList().contains(uid));\n         }\n     }\n     \n@@ -52,7 +59,7 @@ private void validateRemoval(Value topValue, String... uids) throws InvalidProto\n         \n         Assert.assertEquals(-uids.length, v.getCOUNT());\n         for (String uid : uids) {\n-            v.getREMOVEDUIDList().contains(uid);\n+            Assert.assertTrue(uid + \" missing from Removed UIDs list\", v.getREMOVEDUIDList().contains(uid));\n         }\n     }\n     \n@@ -214,6 +221,44 @@ public void testAggregateFour() throws IOException {\n         \n     }\n     \n+    @Test\n+    public void testAggregateOptions() throws IOException {\n+        TreeMultimap<Key,Value> map = TreeMultimap.create();\n+        \n+        map.put(newKey(SHARD, FIELD_TO_AGGREGATE, \"abc\"), new Value(createValueWithUid(\"abc.1\").build().toByteArray()));\n+        map.put(newKey(SHARD, FIELD_TO_AGGREGATE, \"abc\"), new Value(createValueWithUid(\"abc.2\").build().toByteArray()));\n+        map.put(newKey(SHARD, FIELD_TO_AGGREGATE, \"abc\"), new Value(createValueWithUid(\"abc.3\").build().toByteArray()));\n+        map.put(newKey(SHARD, FIELD_TO_AGGREGATE, \"abc\"), new Value(createValueWithUid(\"abc.4\").build().toByteArray()));\n+        \n+        map.put(newKey(SHARD, FIELD_TO_AGGREGATE, \"abd\"), new Value(createValueWithUid(\"abc.3\").build().toByteArray()));\n+        \n+        SortedMultiMapIterator data = new SortedMultiMapIterator(map);\n+        \n+        PropogatingIterator iter = new PropogatingIterator();\n+        Map<String,String> options = Maps.newHashMap();\n+        \n+        String encodedOptions = \"all=true;maxuids=2\";\n+        options.put(PropogatingIterator.AGGREGATOR_DEFAULT, GlobalIndexUidAggregator.class.getCanonicalName() + \" \" + encodedOptions);\n+        \n+        IteratorEnvironment env = new MockIteratorEnvironment(false);\n+        \n+        iter.init(data, options, env);\n+        \n+        iter.seek(new Range(), Collections.emptyList(), false);\n+        \n+        Assert.assertTrue(iter.hasTop());\n+        \n+        Key topKey = iter.getTopKey();\n+        \n+        Assert.assertEquals(newKey(SHARD, FIELD_TO_AGGREGATE, \"abc\"), topKey);\n+        validateOverfullUidList(iter.getTopValue(), 4);\n+        iter.next();\n+        topKey = iter.getTopKey();\n+        Assert.assertEquals(newKey(SHARD, FIELD_TO_AGGREGATE, \"abd\"), topKey);\n+        validateUids(iter.getTopValue(), \"abc.3\");\n+        \n+    }\n+    \n     @Test(expected = NullPointerException.class)\n     public void testNullOptions() throws IOException {\n         "
  }
]
