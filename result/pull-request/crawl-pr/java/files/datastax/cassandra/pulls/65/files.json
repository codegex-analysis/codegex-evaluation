[
  {
    "sha": "18ad56be4a9cee8b28f70b52539f4ed6ddadce3c",
    "filename": "README.asc",
    "status": "modified",
    "additions": 2,
    "deletions": 2,
    "changes": 4,
    "blob_url": "https://github.com/datastax/cassandra/blob/782ad0aa1ea82a157aee5cfc9def7fac3ef00dac/README.asc",
    "raw_url": "https://github.com/datastax/cassandra/raw/782ad0aa1ea82a157aee5cfc9def7fac3ef00dac/README.asc",
    "contents_url": "https://api.github.com/repos/datastax/cassandra/contents/README.asc?ref=782ad0aa1ea82a157aee5cfc9def7fac3ef00dac",
    "patch": "@@ -22,8 +22,8 @@ and running, and demonstrate some simple reads and writes. For a more-complete g\n \n First, we'll unpack our archive:\n \n-  $ tar -zxvf apache-cassandra-$VERSION.tar.gz\n-  $ cd apache-cassandra-$VERSION\n+  $ tar -zxvf dse-db-$VERSION.tar.gz\n+  $ cd dse-db-$VERSION\n \n After that we start the server. Running the startup script with the -f argument will cause\n Cassandra to remain in the foreground and log to standard out; it can be stopped with ctrl-C."
  },
  {
    "sha": "c3ded52b6921e050958f22d573ab5d0c2bfcb601",
    "filename": "bin/cassandra.in.sh",
    "status": "modified",
    "additions": 6,
    "deletions": 6,
    "changes": 12,
    "blob_url": "https://github.com/datastax/cassandra/blob/782ad0aa1ea82a157aee5cfc9def7fac3ef00dac/bin/cassandra.in.sh",
    "raw_url": "https://github.com/datastax/cassandra/raw/782ad0aa1ea82a157aee5cfc9def7fac3ef00dac/bin/cassandra.in.sh",
    "contents_url": "https://api.github.com/repos/datastax/cassandra/contents/bin/cassandra.in.sh?ref=782ad0aa1ea82a157aee5cfc9def7fac3ef00dac",
    "patch": "@@ -30,10 +30,10 @@ CLASSPATH=\"$CASSANDRA_CONF\"\n # compiled classes. NOTE: This isn't needed by the startup script,\n # it's just used here in constructing the classpath.\n if [ -d $CASSANDRA_HOME/build ] ; then\n-    #cassandra_bin=\"$CASSANDRA_HOME/build/classes/main\"\n-    cassandra_bin=`ls -1 $CASSANDRA_HOME/build/apache-cassandra*.jar`\n+    #dse_db_bin=\"$CASSANDRA_HOME/build/classes/main\"\n+    dse_db_bin=`ls -1 $CASSANDRA_HOME/build/dse-db*.jar`\n \n-    CLASSPATH=\"$CLASSPATH:$cassandra_bin\"\n+    CLASSPATH=\"$CLASSPATH:$dse_db_bin\"\n fi\n \n # the default location for commitlogs, sstables, and saved caches\n@@ -112,16 +112,16 @@ JAVA_VERSION=11\n if [ \"$JVM_VERSION\" = \"1.8.0\" ]  ; then\n     JVM_PATCH_VERSION=${jvmver#*_}\n     if [ \"$JVM_VERSION\" \\< \"1.8\" ] || [ \"$JVM_VERSION\" \\> \"1.8.2\" ] ; then\n-        echo \"Cassandra 4.0 requires either Java 8 (update 151 or newer) or Java 11 (or newer). Java $JVM_VERSION is not supported.\"\n+        echo \"DSE DB 4.0 requires either Java 8 (update 151 or newer) or Java 11 (or newer). Java $JVM_VERSION is not supported.\"\n         exit 1;\n     fi\n     if [ \"$JVM_PATCH_VERSION\" -lt 151 ] ; then\n-        echo \"Cassandra 4.0 requires either Java 8 (update 151 or newer) or Java 11 (or newer). Java 8 update $JVM_PATCH_VERSION is not supported.\"\n+        echo \"DSE DB 4.0 requires either Java 8 (update 151 or newer) or Java 11 (or newer). Java 8 update $JVM_PATCH_VERSION is not supported.\"\n         exit 1;\n     fi\n     JAVA_VERSION=8\n elif [ \"$JVM_VERSION\" \\< \"11\" ] ; then\n-    echo \"Cassandra 4.0 requires either Java 8 (update 151 or newer) or Java 11 (or newer).\"\n+    echo \"DSE DB 4.0 requires either Java 8 (update 151 or newer) or Java 11 (or newer).\"\n     exit 1;\n fi\n "
  },
  {
    "sha": "743db5226b9f84f2acf66e3e8e36c595220c49f4",
    "filename": "build.xml",
    "status": "modified",
    "additions": 53,
    "deletions": 39,
    "changes": 92,
    "blob_url": "https://github.com/datastax/cassandra/blob/782ad0aa1ea82a157aee5cfc9def7fac3ef00dac/build.xml",
    "raw_url": "https://github.com/datastax/cassandra/raw/782ad0aa1ea82a157aee5cfc9def7fac3ef00dac/build.xml",
    "contents_url": "https://api.github.com/repos/datastax/cassandra/contents/build.xml?ref=782ad0aa1ea82a157aee5cfc9def7fac3ef00dac",
    "patch": "@@ -17,7 +17,7 @@\n  ~ specific language governing permissions and limitations\n  ~ under the License.\n  -->\n-<project basedir=\".\" default=\"jar\" name=\"apache-cassandra\"\n+<project basedir=\".\" default=\"jar\" name=\"dse-db\"\n          xmlns:artifact=\"antlib:org.apache.maven.artifact.ant\"\n          xmlns:if=\"ant:if\"\n          xmlns:unless=\"ant:unless\">\n@@ -28,9 +28,9 @@\n \n     <!-- default version and SCM information -->\n     <property name=\"base.version\" value=\"4.0-beta5\"/>\n-    <property name=\"scm.connection\" value=\"scm:https://gitbox.apache.org/repos/asf/cassandra.git\"/>\n-    <property name=\"scm.developerConnection\" value=\"scm:https://gitbox.apache.org/repos/asf/cassandra.git\"/>\n-    <property name=\"scm.url\" value=\"https://gitbox.apache.org/repos/asf?p=cassandra.git;a=tree\"/>\n+    <property name=\"scm.connection\" value=\"scm:git:ssh://git@github.com:datastax/cassandra.git\"/>\n+    <property name=\"scm.developerConnection\" value=\"scm:git:ssh://git@github.com:datastax/cassandra.git\"/>\n+    <property name=\"scm.url\" value=\"scm:git:ssh://git@github.com:datastax/cassandra.git\"/>\n \n     <!-- directory details -->\n     <property name=\"basedir\" value=\".\"/>\n@@ -88,14 +88,14 @@\n               value=\"https://repo.maven.apache.org/maven2/org/apache/maven/maven-ant-tasks\" />\n     <!-- details of how and which Maven repository we publish to -->\n     <property name=\"maven.version\" value=\"3.0.3\" />\n-    <condition property=\"maven-repository-url\" value=\"https://repository.apache.org/service/local/staging/deploy/maven2\">\n+    <condition property=\"maven-repository-url\" value=\"https://repo.sjc.dsinternal.org/artifactory/datastax-releases-local\">\n       <isset property=\"release\"/>\n     </condition>\n-    <condition property=\"maven-repository-id\" value=\"apache.releases.https\">\n+    <condition property=\"maven-repository-id\" value=\"datastax.releases.https\">\n       <isset property=\"release\"/>\n     </condition>\n-    <property name=\"maven-repository-url\" value=\"https://repository.apache.org/content/repositories/snapshots\"/>\n-    <property name=\"maven-repository-id\" value=\"apache.snapshots.https\"/>\n+    <property name=\"maven-repository-url\" value=\"https://repo.sjc.dsinternal.org/artifactory/datastax-snapshots-local\"/>\n+    <property name=\"maven-repository-id\" value=\"datastax.snapshots.https\"/>\n \n     <property name=\"test.timeout\" value=\"240000\" />\n     <property name=\"test.memory.timeout\" value=\"480000\" />\n@@ -293,7 +293,7 @@\n     <sequential>\n       <javadoc destdir=\"@{destdir}\" author=\"true\" version=\"true\" use=\"true\"\n         windowtitle=\"${ant.project.name} API\" classpathref=\"cassandra.classpath\"\n-        bottom=\"Copyright &amp;copy; 2009-2021 The Apache Software Foundation\"\n+        bottom=\"Copyright &amp;copy; 2009-2021 The Apache Software Foundation; All changes to the original code are Copyright DataStax, Inc.\"\n         useexternalfile=\"yes\" encoding=\"UTF-8\" failonerror=\"false\"\n         maxmemory=\"256m\" additionalparam=\"${jdk11-javadoc-exports}\">\n         <filesets/>\n@@ -526,8 +526,8 @@\n             <arg value=\"-q\" />\n             <arg value=\"org.apache.maven.plugins:maven-gpg-plugin:1.6:sign-and-deploy-file\" />\n             <arg value=\"-Dfile=@{file}\" />\n-            <arg value=\"-DgroupId=org.apache.cassandra\" />\n-            <arg value=\"-DartifactId=cassandra-parent\" />\n+            <arg value=\"-DgroupId=com.datastax.dse\" />\n+            <arg value=\"-DartifactId=dse-db-parent\" />\n             <arg value=\"-Dversion=${version}\" />\n             <!-- intentionally dummy out the deploy step -->\n             <arg value=\"-Durl=file:///tmp/\" />\n@@ -546,14 +546,14 @@\n             description=\"Define dependencies and dependency versions\">\n       <!-- The parent pom defines the versions of all dependencies -->\n       <artifact:pom id=\"parent-pom\"\n-                    groupId=\"org.apache.cassandra\"\n-                    artifactId=\"cassandra-parent\"\n+                    groupId=\"com.datastax.dse\"\n+                    artifactId=\"dse-db-parent\"\n                     packaging=\"pom\"\n                     version=\"${version}\"\n-                    url=\"https://cassandra.apache.org\"\n-                    name=\"Apache Cassandra\"\n+                    url=\"https://datastax.com\"\n+                    name=\"Datastax DB\"\n                     inceptionYear=\"2009\"\n-                    description=\"The Apache Cassandra Project develops a highly scalable second-generation distributed database, bringing together Dynamo's fully distributed design and Bigtable's ColumnFamily-based data model.\">\n+                    description=\"The Apache Cassandra Project develops a highly scalable second-generation distributed database. DataStax, Inc. provides additional improvements on top of Apache Cassandra\">\n \n         <!-- Inherit from the ASF template pom file, ref http://maven.apache.org/pom/asf/ -->\n         <parent groupId=\"org.apache\" artifactId=\"apache\" version=\"22\"/>\n@@ -625,7 +625,7 @@\n           <dependency groupId=\"org.openjdk.jmh\" artifactId=\"jmh-core\" version=\"1.21\"/>\n           <dependency groupId=\"org.openjdk.jmh\" artifactId=\"jmh-generator-annprocess\" version=\"1.21\"/>\n \n-          <dependency groupId=\"org.apache.cassandra\" artifactId=\"cassandra-all\" version=\"${version}\" />\n+          <dependency groupId=\"com.datastax.dse\" artifactId=\"dse-db-all\" version=\"${version}\" />\n           <dependency groupId=\"io.dropwizard.metrics\" artifactId=\"metrics-core\" version=\"3.1.5\" />\n           <dependency groupId=\"io.dropwizard.metrics\" artifactId=\"metrics-jvm\" version=\"3.1.5\" />\n           <dependency groupId=\"com.addthis.metrics\" artifactId=\"reporter-config3\" version=\"3.0.3\" />\n@@ -682,7 +682,10 @@\n           <!-- when updating assertj, make sure to also update the corresponding junit-bom dependency -->\n           <dependency groupId=\"org.assertj\" artifactId=\"assertj-core\" version=\"3.15.0\"/>\n           <dependency groupId=\"org.awaitility\" artifactId=\"awaitility\" version=\"4.0.3\" />\n-\n+          <dependency groupId=\"org.agrona\" artifactId=\"agrona\" version=\"0.9.26\" />\n+          <dependency groupId=\"org.apache.lucene\" artifactId=\"lucene-core\" version=\"7.5.0\" />\n+          <dependency groupId=\"com.carrotsearch.randomizedtesting\" artifactId=\"randomizedtesting-runner\" version=\"2.1.2\" />\n+          <dependency groupId=\"org.hamcrest\" artifactId=\"hamcrest-all\" version=\"1.3\" />\n         </dependencyManagement>\n         <developer id=\"adelapena\" name=\"Andres de la PeÃ±a\"/>\n         <developer id=\"alakshman\" name=\"Avinash Lakshman\"/>\n@@ -735,8 +738,8 @@\n       <!-- each dependency set then defines the subset of the dependencies for that dependency set -->\n       <artifact:pom id=\"build-deps-pom\"\n                     artifactId=\"cassandra-build-deps\">\n-        <parent groupId=\"org.apache.cassandra\"\n-                artifactId=\"cassandra-parent\"\n+        <parent groupId=\"com.datastax.dse\"\n+                artifactId=\"dse-db-parent\"\n                 version=\"${version}\"/>\n         <dependency groupId=\"junit\" artifactId=\"junit\"/>\n         <dependency groupId=\"org.mockito\" artifactId=\"mockito-core\" />\n@@ -772,13 +775,16 @@\n         <dependency groupId=\"org.junit\" artifactId=\"junit-bom\" version=\"5.6.0\" type=\"pom\"/>\n         <dependency groupId=\"org.assertj\" artifactId=\"assertj-core\"/>\n         <dependency groupId=\"org.awaitility\" artifactId=\"awaitility\"/>\n+        <dependency groupId=\"org.apache.lucene\" artifactId=\"lucene-core\" version=\"7.5.0\" />\n+        <dependency groupId=\"com.carrotsearch.randomizedtesting\" artifactId=\"randomizedtesting-runner\" version=\"2.1.2\" />\n+        <dependency groupId=\"org.hamcrest\" artifactId=\"hamcrest-all\" version=\"1.3\" />\n       </artifact:pom>\n       <!-- this build-deps-pom-sources \"artifact\" is the same as build-deps-pom but only with those\n            artifacts that have \"-source.jar\" files -->\n       <artifact:pom id=\"build-deps-pom-sources\"\n                     artifactId=\"cassandra-build-deps\">\n-        <parent groupId=\"org.apache.cassandra\"\n-                artifactId=\"cassandra-parent\"\n+        <parent groupId=\"com.datastax.dse\"\n+                artifactId=\"dse-db-parent\"\n                 version=\"${version}\"/>\n         <dependency groupId=\"junit\" artifactId=\"junit\"/>\n         <dependency groupId=\"org.mockito\" artifactId=\"mockito-core\" />\n@@ -800,8 +806,8 @@\n \n       <artifact:pom id=\"coverage-deps-pom\"\n                     artifactId=\"cassandra-coverage-deps\">\n-        <parent groupId=\"org.apache.cassandra\"\n-                artifactId=\"cassandra-parent\"\n+        <parent groupId=\"com.datastax.dse\"\n+                artifactId=\"dse-db-parent\"\n                 version=\"${version}\"/>\n         <dependency groupId=\"org.jacoco\" artifactId=\"org.jacoco.agent\"/>\n         <dependency groupId=\"org.jacoco\" artifactId=\"org.jacoco.ant\" />\n@@ -813,19 +819,19 @@\n \n       <artifact:pom id=\"test-deps-pom\"\n                     artifactId=\"cassandra-test-deps\">\n-        <parent groupId=\"org.apache.cassandra\"\n-                artifactId=\"cassandra-parent\"\n+        <parent groupId=\"com.datastax.dse\"\n+                artifactId=\"dse-db-parent\"\n                 version=\"${version}\"/>\n       </artifact:pom>\n \n       <!-- now the pom's for artifacts being deployed to Maven Central -->\n \n       <artifact:pom id=\"all-pom\"\n-                    artifactId=\"cassandra-all\"\n-                    url=\"https://cassandra.apache.org\"\n-                    name=\"Apache Cassandra\">\n-        <parent groupId=\"org.apache.cassandra\"\n-                artifactId=\"cassandra-parent\"\n+                    artifactId=\"dse-db-all\"\n+                    url=\"https://datastax.com\"\n+                    name=\"DataStax DB\">\n+        <parent groupId=\"com.datastax.dse\"\n+                artifactId=\"dse-db-parent\"\n                 version=\"${version}\"/>\n         <scm connection=\"${scm.connection}\" developerConnection=\"${scm.developerConnection}\" url=\"${scm.url}\"/>\n         <dependency groupId=\"org.xerial.snappy\" artifactId=\"snappy-java\"/>\n@@ -857,7 +863,11 @@\n         <dependency groupId=\"ch.qos.logback\" artifactId=\"logback-core\"/>\n         <dependency groupId=\"ch.qos.logback\" artifactId=\"logback-classic\"/>\n \n-        <!-- don't need hadoop classes to run, but if you use the hadoop stuff -->\n+        <dependency groupId=\"org.apache.lucene\" artifactId=\"lucene-core\" version=\"7.5.0\" />\n+        <dependency groupId=\"com.carrotsearch.randomizedtesting\" artifactId=\"randomizedtesting-runner\" version=\"2.1.2\" />\n+        <dependency groupId=\"org.hamcrest\" artifactId=\"hamcrest-all\" version=\"1.3\" />\n+\n+          <!-- don't need hadoop classes to run, but if you use the hadoop stuff -->\n         <dependency groupId=\"org.apache.hadoop\" artifactId=\"hadoop-core\" optional=\"true\"/>\n         <dependency groupId=\"org.apache.hadoop\" artifactId=\"hadoop-minicluster\" optional=\"true\"/>\n \n@@ -898,6 +908,10 @@\n         <dependency groupId=\"org.gridkit.lab\" artifactId=\"jvm-attach-api\" />\n         <dependency groupId=\"com.beust\" artifactId=\"jcommander\" />\n         <dependency groupId=\"org.gridkit.jvmtool\" artifactId=\"sjk-json\"/>\n+        <dependency groupId=\"org.agrona\" artifactId=\"agrona\"/>\n+        <dependency groupId=\"org.apache.lucene\" artifactId=\"lucene-core\" version=\"7.5.0\" />\n+        <dependency groupId=\"com.carrotsearch.randomizedtesting\" artifactId=\"randomizedtesting-runner\" version=\"2.1.2\" />\n+        <dependency groupId=\"org.hamcrest\" artifactId=\"hamcrest-all\" version=\"1.3\" />\n \n         <!-- sasi deps -->\n         <dependency groupId=\"de.jflex\" artifactId=\"jflex\" />\n@@ -1155,7 +1169,7 @@\n     -->\n     <target name=\"_main-jar\"\n             depends=\"build\"\n-            description=\"Assemble Cassandra JAR files\">\n+            description=\"Assemble DSE DB JAR files\">\n       <mkdir dir=\"${build.classes.main}/META-INF\" />\n       <copy file=\"LICENSE.txt\"\n             tofile=\"${build.classes.main}/META-INF/LICENSE.txt\"/>\n@@ -1169,16 +1183,16 @@\n         <manifest>\n         <!-- <section name=\"org/apache/cassandra/infrastructure\"> -->\n           <attribute name=\"Multi-Release\" value=\"true\"/>\n-          <attribute name=\"Implementation-Title\" value=\"Cassandra\"/>\n+          <attribute name=\"Implementation-Title\" value=\"DSE DB\"/>\n           <attribute name=\"Implementation-Version\" value=\"${version}\"/>\n-          <attribute name=\"Implementation-Vendor\" value=\"Apache\"/>\n+          <attribute name=\"Implementation-Vendor\" value=\"DataStax\"/>\n         <!-- </section> -->\n         </manifest>\n       </jar>\n     </target>\n     <target name=\"jar\"\n             depends=\"_main-jar, build-test, stress-build, fqltool-build, write-poms\"\n-            description=\"Assemble Cassandra JAR files\">\n+            description=\"Assemble DSE DB JAR files\">\n       <!-- Stress jar -->\n       <manifest file=\"${stress.manifest}\">\n         <attribute name=\"Built-By\" value=\"Pavel Yaskevich\"/>\n@@ -1204,7 +1218,7 @@\n     <!--\n         The javadoc-jar target makes cassandra-javadoc.jar output required for publishing to Maven central repository.\n     -->\n-    <target name=\"javadoc-jar\" depends=\"javadoc\" description=\"Assemble Cassandra JavaDoc JAR file\">\n+    <target name=\"javadoc-jar\" depends=\"javadoc\" description=\"Assemble DSE DB JavaDoc JAR file\">\n       <jar jarfile=\"${build.dir}/${final.name}-javadoc.jar\" basedir=\"${javadoc.dir}\"/>\n       <!-- javadoc task always rebuilds so might as well remove the generated docs to prevent\n            being pulled into the distribution by accident -->\n@@ -1214,7 +1228,7 @@\n     <!--\n         The sources-jar target makes cassandra-sources.jar output required for publishing to Maven central repository.\n     -->\n-    <target name=\"sources-jar\" depends=\"init\" description=\"Assemble Cassandra Sources JAR file\">\n+    <target name=\"sources-jar\" depends=\"init\" description=\"Assemble DSE DB Sources JAR file\">\n       <jar jarfile=\"${build.dir}/${final.name}-sources.jar\">\n         <fileset dir=\"${build.src.java}\" defaultexcludes=\"yes\">\n           <include name=\"org/apache/**/*.java\"/>\n@@ -1285,7 +1299,7 @@\n \n     <!-- creates release tarballs -->\n     <target name=\"artifacts\" depends=\"_artifacts-init\"\n-            description=\"Create Cassandra release artifacts\">\n+            description=\"Create DSE DB release artifacts\">\n       <tar compression=\"gzip\" longfile=\"gnu\"\n         destfile=\"${build.dir}/${final.name}-bin.tar.gz\">\n "
  },
  {
    "sha": "ec7b56e53a35cda749915d4a18120d2e60a2e291",
    "filename": "doc/source/development/dependencies.rst",
    "status": "modified",
    "additions": 2,
    "deletions": 2,
    "changes": 4,
    "blob_url": "https://github.com/datastax/cassandra/blob/782ad0aa1ea82a157aee5cfc9def7fac3ef00dac/doc/source/development/dependencies.rst",
    "raw_url": "https://github.com/datastax/cassandra/raw/782ad0aa1ea82a157aee5cfc9def7fac3ef00dac/doc/source/development/dependencies.rst",
    "contents_url": "https://api.github.com/repos/datastax/cassandra/contents/doc/source/development/dependencies.rst?ref=782ad0aa1ea82a157aee5cfc9def7fac3ef00dac",
    "patch": "@@ -47,7 +47,7 @@ Troubleshooting and conflict resolution\n Here are some useful commands that may help you out resolving conflicts.\n \n * ``ant realclean`` - gets rid of the build directory, including build artifacts.\n-* ``mvn dependency:tree -f build/apache-cassandra-*-SNAPSHOT.pom -Dverbose -Dincludes=org.slf4j`` - shows transitive dependency tree for artifacts, e.g. org.slf4j. In case the command above fails due to a missing parent pom file, try running ``ant mvn-install``.\n-* ``rm ~/.m2/repository/org/apache/cassandra/apache-cassandra/`` - removes cached local Cassandra maven artifacts\n+* ``mvn dependency:tree -f build/dse-db-*-SNAPSHOT.pom -Dverbose -Dincludes=org.slf4j`` - shows transitive dependency tree for artifacts, e.g. org.slf4j. In case the command above fails due to a missing parent pom file, try running ``ant mvn-install``.\n+* ``rm ~/.m2/repository/com/datastax/dse/dse-db/`` - removes cached local Cassandra maven artifacts\n \n "
  },
  {
    "sha": "b129057cf6233954c9fbc327841c2e3ac7a5e71a",
    "filename": "lib/agrona-0.9.26.jar",
    "status": "added",
    "additions": 0,
    "deletions": 0,
    "changes": 0,
    "blob_url": "https://github.com/datastax/cassandra/blob/782ad0aa1ea82a157aee5cfc9def7fac3ef00dac/lib/agrona-0.9.26.jar",
    "raw_url": "https://github.com/datastax/cassandra/raw/782ad0aa1ea82a157aee5cfc9def7fac3ef00dac/lib/agrona-0.9.26.jar",
    "contents_url": "https://api.github.com/repos/datastax/cassandra/contents/lib/agrona-0.9.26.jar?ref=782ad0aa1ea82a157aee5cfc9def7fac3ef00dac"
  },
  {
    "sha": "27ff85aa183a80f7370b908e837721a02f33b5da",
    "filename": "lib/licenses/agrona-0.9.26.txt",
    "status": "added",
    "additions": 202,
    "deletions": 0,
    "changes": 202,
    "blob_url": "https://github.com/datastax/cassandra/blob/782ad0aa1ea82a157aee5cfc9def7fac3ef00dac/lib/licenses/agrona-0.9.26.txt",
    "raw_url": "https://github.com/datastax/cassandra/raw/782ad0aa1ea82a157aee5cfc9def7fac3ef00dac/lib/licenses/agrona-0.9.26.txt",
    "contents_url": "https://api.github.com/repos/datastax/cassandra/contents/lib/licenses/agrona-0.9.26.txt?ref=782ad0aa1ea82a157aee5cfc9def7fac3ef00dac",
    "patch": "@@ -0,0 +1,202 @@\n+Apache License\n+                           Version 2.0, January 2004\n+                        http://www.apache.org/licenses/\n+\n+   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n+\n+   1. Definitions.\n+\n+      \"License\" shall mean the terms and conditions for use, reproduction,\n+      and distribution as defined by Sections 1 through 9 of this document.\n+\n+      \"Licensor\" shall mean the copyright owner or entity authorized by\n+      the copyright owner that is granting the License.\n+\n+      \"Legal Entity\" shall mean the union of the acting entity and all\n+      other entities that control, are controlled by, or are under common\n+      control with that entity. For the purposes of this definition,\n+      \"control\" means (i) the power, direct or indirect, to cause the\n+      direction or management of such entity, whether by contract or\n+      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n+      outstanding shares, or (iii) beneficial ownership of such entity.\n+\n+      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n+      exercising permissions granted by this License.\n+\n+      \"Source\" form shall mean the preferred form for making modifications,\n+      including but not limited to software source code, documentation\n+      source, and configuration files.\n+\n+      \"Object\" form shall mean any form resulting from mechanical\n+      transformation or translation of a Source form, including but\n+      not limited to compiled object code, generated documentation,\n+      and conversions to other media types.\n+\n+      \"Work\" shall mean the work of authorship, whether in Source or\n+      Object form, made available under the License, as indicated by a\n+      copyright notice that is included in or attached to the work\n+      (an example is provided in the Appendix below).\n+\n+      \"Derivative Works\" shall mean any work, whether in Source or Object\n+      form, that is based on (or derived from) the Work and for which the\n+      editorial revisions, annotations, elaborations, or other modifications\n+      represent, as a whole, an original work of authorship. For the purposes\n+      of this License, Derivative Works shall not include works that remain\n+      separable from, or merely link (or bind by name) to the interfaces of,\n+      the Work and Derivative Works thereof.\n+\n+      \"Contribution\" shall mean any work of authorship, including\n+      the original version of the Work and any modifications or additions\n+      to that Work or Derivative Works thereof, that is intentionally\n+      submitted to Licensor for inclusion in the Work by the copyright owner\n+      or by an individual or Legal Entity authorized to submit on behalf of\n+      the copyright owner. For the purposes of this definition, \"submitted\"\n+      means any form of electronic, verbal, or written communication sent\n+      to the Licensor or its representatives, including but not limited to\n+      communication on electronic mailing lists, source code control systems,\n+      and issue tracking systems that are managed by, or on behalf of, the\n+      Licensor for the purpose of discussing and improving the Work, but\n+      excluding communication that is conspicuously marked or otherwise\n+      designated in writing by the copyright owner as \"Not a Contribution.\"\n+\n+      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n+      on behalf of whom a Contribution has been received by Licensor and\n+      subsequently incorporated within the Work.\n+\n+   2. Grant of Copyright License. Subject to the terms and conditions of\n+      this License, each Contributor hereby grants to You a perpetual,\n+      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n+      copyright license to reproduce, prepare Derivative Works of,\n+      publicly display, publicly perform, sublicense, and distribute the\n+      Work and such Derivative Works in Source or Object form.\n+\n+   3. Grant of Patent License. Subject to the terms and conditions of\n+      this License, each Contributor hereby grants to You a perpetual,\n+      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n+      (except as stated in this section) patent license to make, have made,\n+      use, offer to sell, sell, import, and otherwise transfer the Work,\n+      where such license applies only to those patent claims licensable\n+      by such Contributor that are necessarily infringed by their\n+      Contribution(s) alone or by combination of their Contribution(s)\n+      with the Work to which such Contribution(s) was submitted. If You\n+      institute patent litigation against any entity (including a\n+      cross-claim or counterclaim in a lawsuit) alleging that the Work\n+      or a Contribution incorporated within the Work constitutes direct\n+      or contributory patent infringement, then any patent licenses\n+      granted to You under this License for that Work shall terminate\n+      as of the date such litigation is filed.\n+\n+   4. Redistribution. You may reproduce and distribute copies of the\n+      Work or Derivative Works thereof in any medium, with or without\n+      modifications, and in Source or Object form, provided that You\n+      meet the following conditions:\n+\n+      (a) You must give any other recipients of the Work or\n+          Derivative Works a copy of this License; and\n+\n+      (b) You must cause any modified files to carry prominent notices\n+          stating that You changed the files; and\n+\n+      (c) You must retain, in the Source form of any Derivative Works\n+          that You distribute, all copyright, patent, trademark, and\n+          attribution notices from the Source form of the Work,\n+          excluding those notices that do not pertain to any part of\n+          the Derivative Works; and\n+\n+      (d) If the Work includes a \"NOTICE\" text file as part of its\n+          distribution, then any Derivative Works that You distribute must\n+          include a readable copy of the attribution notices contained\n+          within such NOTICE file, excluding those notices that do not\n+          pertain to any part of the Derivative Works, in at least one\n+          of the following places: within a NOTICE text file distributed\n+          as part of the Derivative Works; within the Source form or\n+          documentation, if provided along with the Derivative Works; or,\n+          within a display generated by the Derivative Works, if and\n+          wherever such third-party notices normally appear. The contents\n+          of the NOTICE file are for informational purposes only and\n+          do not modify the License. You may add Your own attribution\n+          notices within Derivative Works that You distribute, alongside\n+          or as an addendum to the NOTICE text from the Work, provided\n+          that such additional attribution notices cannot be construed\n+          as modifying the License.\n+\n+      You may add Your own copyright statement to Your modifications and\n+      may provide additional or different license terms and conditions\n+      for use, reproduction, or distribution of Your modifications, or\n+      for any such Derivative Works as a whole, provided Your use,\n+      reproduction, and distribution of the Work otherwise complies with\n+      the conditions stated in this License.\n+\n+   5. Submission of Contributions. Unless You explicitly state otherwise,\n+      any Contribution intentionally submitted for inclusion in the Work\n+      by You to the Licensor shall be under the terms and conditions of\n+      this License, without any additional terms or conditions.\n+      Notwithstanding the above, nothing herein shall supersede or modify\n+      the terms of any separate license agreement you may have executed\n+      with Licensor regarding such Contributions.\n+\n+   6. Trademarks. This License does not grant permission to use the trade\n+      names, trademarks, service marks, or product names of the Licensor,\n+      except as required for reasonable and customary use in describing the\n+      origin of the Work and reproducing the content of the NOTICE file.\n+\n+   7. Disclaimer of Warranty. Unless required by applicable law or\n+      agreed to in writing, Licensor provides the Work (and each\n+      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n+      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n+      implied, including, without limitation, any warranties or conditions\n+      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n+      PARTICULAR PURPOSE. You are solely responsible for determining the\n+      appropriateness of using or redistributing the Work and assume any\n+      risks associated with Your exercise of permissions under this License.\n+\n+   8. Limitation of Liability. In no event and under no legal theory,\n+      whether in tort (including negligence), contract, or otherwise,\n+      unless required by applicable law (such as deliberate and grossly\n+      negligent acts) or agreed to in writing, shall any Contributor be\n+      liable to You for damages, including any direct, indirect, special,\n+      incidental, or consequential damages of any character arising as a\n+      result of this License or out of the use or inability to use the\n+      Work (including but not limited to damages for loss of goodwill,\n+      work stoppage, computer failure or malfunction, or any and all\n+      other commercial damages or losses), even if such Contributor\n+      has been advised of the possibility of such damages.\n+\n+   9. Accepting Warranty or Additional Liability. While redistributing\n+      the Work or Derivative Works thereof, You may choose to offer,\n+      and charge a fee for, acceptance of support, warranty, indemnity,\n+      or other liability obligations and/or rights consistent with this\n+      License. However, in accepting such obligations, You may act only\n+      on Your own behalf and on Your sole responsibility, not on behalf\n+      of any other Contributor, and only if You agree to indemnify,\n+      defend, and hold each Contributor harmless for any liability\n+      incurred by, or claims asserted against, such Contributor by reason\n+      of your accepting any such warranty or additional liability.\n+\n+   END OF TERMS AND CONDITIONS\n+\n+   APPENDIX: How to apply the Apache License to your work.\n+\n+      To apply the Apache License to your work, attach the following\n+      boilerplate notice, with the fields enclosed by brackets \"{}\"\n+      replaced with your own identifying information. (Don't include\n+      the brackets!)  The text should be enclosed in the appropriate\n+      comment syntax for the file format. We also recommend that a\n+      file or class name and description of purpose be included on the\n+      same \"printed page\" as the copyright notice for easier\n+      identification within third-party archives.\n+\n+   Copyright {yyyy} {name of copyright owner}\n+\n+   Licensed under the Apache License, Version 2.0 (the \"License\");\n+   you may not use this file except in compliance with the License.\n+   You may obtain a copy of the License at\n+\n+       https://www.apache.org/licenses/LICENSE-2.0\n+\n+   Unless required by applicable law or agreed to in writing, software\n+   distributed under the License is distributed on an \"AS IS\" BASIS,\n+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+   See the License for the specific language governing permissions and\n+   limitations under the License.\n+"
  },
  {
    "sha": "0e9ae9d5a46f00c4a62112d835d9ce3083ecc9d0",
    "filename": "lib/lucene-core-7.5.0.jar",
    "status": "added",
    "additions": 0,
    "deletions": 0,
    "changes": 0,
    "blob_url": "https://github.com/datastax/cassandra/blob/782ad0aa1ea82a157aee5cfc9def7fac3ef00dac/lib/lucene-core-7.5.0.jar",
    "raw_url": "https://github.com/datastax/cassandra/raw/782ad0aa1ea82a157aee5cfc9def7fac3ef00dac/lib/lucene-core-7.5.0.jar",
    "contents_url": "https://api.github.com/repos/datastax/cassandra/contents/lib/lucene-core-7.5.0.jar?ref=782ad0aa1ea82a157aee5cfc9def7fac3ef00dac"
  },
  {
    "sha": "2beaabed7fe34e2918d292406f4f517ac69e3180",
    "filename": "src/java/org/apache/cassandra/config/Config.java",
    "status": "modified",
    "additions": 2,
    "deletions": 0,
    "changes": 2,
    "blob_url": "https://github.com/datastax/cassandra/blob/782ad0aa1ea82a157aee5cfc9def7fac3ef00dac/src/java/org/apache/cassandra/config/Config.java",
    "raw_url": "https://github.com/datastax/cassandra/raw/782ad0aa1ea82a157aee5cfc9def7fac3ef00dac/src/java/org/apache/cassandra/config/Config.java",
    "contents_url": "https://api.github.com/repos/datastax/cassandra/contents/src/java/org/apache/cassandra/config/Config.java?ref=782ad0aa1ea82a157aee5cfc9def7fac3ef00dac",
    "patch": "@@ -513,6 +513,8 @@\n      */\n     public volatile double range_tombstone_list_growth_factor = 1.5;\n \n+    public StorageAttachedIndexOptions sai_options = new StorageAttachedIndexOptions();\n+\n     /**\n      * @deprecated migrate to {@link DatabaseDescriptor#isClientInitialized()}\n      */"
  },
  {
    "sha": "10f95e23e243da1758270bc9bf9ac187fb4c6154",
    "filename": "src/java/org/apache/cassandra/config/DatabaseDescriptor.java",
    "status": "modified",
    "additions": 50,
    "deletions": 32,
    "changes": 82,
    "blob_url": "https://github.com/datastax/cassandra/blob/782ad0aa1ea82a157aee5cfc9def7fac3ef00dac/src/java/org/apache/cassandra/config/DatabaseDescriptor.java",
    "raw_url": "https://github.com/datastax/cassandra/raw/782ad0aa1ea82a157aee5cfc9def7fac3ef00dac/src/java/org/apache/cassandra/config/DatabaseDescriptor.java",
    "contents_url": "https://api.github.com/repos/datastax/cassandra/contents/src/java/org/apache/cassandra/config/DatabaseDescriptor.java?ref=782ad0aa1ea82a157aee5cfc9def7fac3ef00dac",
    "patch": "@@ -154,8 +154,8 @@\n     public static volatile boolean allowUnlimitedConcurrentValidations = Boolean.getBoolean(\"cassandra.allow_unlimited_concurrent_validations\");\n \n     private static Function<CommitLog, AbstractCommitLogSegmentManager> commitLogSegmentMgrProvider = c -> DatabaseDescriptor.isCDCEnabled()\n-                                       ? new CommitLogSegmentManagerCDC(c, DatabaseDescriptor.getCommitLogLocation())\n-                                       : new CommitLogSegmentManagerStandard(c, DatabaseDescriptor.getCommitLogLocation());\n+                                                                                                           ? new CommitLogSegmentManagerCDC(c, DatabaseDescriptor.getCommitLogLocation())\n+                                                                                                           : new CommitLogSegmentManagerStandard(c, DatabaseDescriptor.getCommitLogLocation());\n \n     public static void daemonInitialization() throws ConfigurationException\n     {\n@@ -757,10 +757,10 @@ else if (conf.repair_session_space_in_mb > (int) (Runtime.getRuntime().maxMemory\n \n         if (conf.commitlog_segment_size_in_mb <= 0)\n             throw new ConfigurationException(\"commitlog_segment_size_in_mb must be positive, but was \"\n-                    + conf.commitlog_segment_size_in_mb, false);\n+                                             + conf.commitlog_segment_size_in_mb, false);\n         else if (conf.commitlog_segment_size_in_mb >= 2048)\n             throw new ConfigurationException(\"commitlog_segment_size_in_mb must be smaller than 2048, but was \"\n-                    + conf.commitlog_segment_size_in_mb, false);\n+                                             + conf.commitlog_segment_size_in_mb, false);\n \n         if (conf.max_mutation_size_in_kb == null)\n             conf.max_mutation_size_in_kb = conf.commitlog_segment_size_in_mb * 1024 / 2;\n@@ -787,7 +787,7 @@ else if (conf.commitlog_segment_size_in_mb * 1024 < 2 * conf.max_mutation_size_i\n             throw new ConfigurationException(\"max_value_size_in_mb must be positive\", false);\n         else if (conf.max_value_size_in_mb >= 2048)\n             throw new ConfigurationException(\"max_value_size_in_mb must be smaller than 2048, but was \"\n-                    + conf.max_value_size_in_mb, false);\n+                                             + conf.max_value_size_in_mb, false);\n \n         switch (conf.disk_optimization_strategy)\n         {\n@@ -833,8 +833,8 @@ else if (conf.max_value_size_in_mb >= 2048)\n         else\n         {\n             conf.internode_max_message_size_in_bytes =\n-                Math.min(conf.internode_application_receive_queue_reserve_endpoint_capacity_in_bytes,\n-                         conf.internode_application_send_queue_reserve_endpoint_capacity_in_bytes);\n+            Math.min(conf.internode_application_receive_queue_reserve_endpoint_capacity_in_bytes,\n+                     conf.internode_application_send_queue_reserve_endpoint_capacity_in_bytes);\n         }\n \n         validateMaxConcurrentAutoUpgradeTasksConf(conf.max_concurrent_automatic_sstable_upgrades);\n@@ -1038,44 +1038,44 @@ static void checkForLowestAcceptedTimeouts(Config conf)\n     {\n         if(conf.read_request_timeout_in_ms < LOWEST_ACCEPTED_TIMEOUT)\n         {\n-           logInfo(\"read_request_timeout_in_ms\", conf.read_request_timeout_in_ms, LOWEST_ACCEPTED_TIMEOUT);\n-           conf.read_request_timeout_in_ms = LOWEST_ACCEPTED_TIMEOUT;\n+            logInfo(\"read_request_timeout_in_ms\", conf.read_request_timeout_in_ms, LOWEST_ACCEPTED_TIMEOUT);\n+            conf.read_request_timeout_in_ms = LOWEST_ACCEPTED_TIMEOUT;\n         }\n \n         if(conf.range_request_timeout_in_ms < LOWEST_ACCEPTED_TIMEOUT)\n         {\n-           logInfo(\"range_request_timeout_in_ms\", conf.range_request_timeout_in_ms, LOWEST_ACCEPTED_TIMEOUT);\n-           conf.range_request_timeout_in_ms = LOWEST_ACCEPTED_TIMEOUT;\n+            logInfo(\"range_request_timeout_in_ms\", conf.range_request_timeout_in_ms, LOWEST_ACCEPTED_TIMEOUT);\n+            conf.range_request_timeout_in_ms = LOWEST_ACCEPTED_TIMEOUT;\n         }\n \n         if(conf.request_timeout_in_ms < LOWEST_ACCEPTED_TIMEOUT)\n         {\n-           logInfo(\"request_timeout_in_ms\", conf.request_timeout_in_ms, LOWEST_ACCEPTED_TIMEOUT);\n-           conf.request_timeout_in_ms = LOWEST_ACCEPTED_TIMEOUT;\n+            logInfo(\"request_timeout_in_ms\", conf.request_timeout_in_ms, LOWEST_ACCEPTED_TIMEOUT);\n+            conf.request_timeout_in_ms = LOWEST_ACCEPTED_TIMEOUT;\n         }\n \n         if(conf.write_request_timeout_in_ms < LOWEST_ACCEPTED_TIMEOUT)\n         {\n-           logInfo(\"write_request_timeout_in_ms\", conf.write_request_timeout_in_ms, LOWEST_ACCEPTED_TIMEOUT);\n-           conf.write_request_timeout_in_ms = LOWEST_ACCEPTED_TIMEOUT;\n+            logInfo(\"write_request_timeout_in_ms\", conf.write_request_timeout_in_ms, LOWEST_ACCEPTED_TIMEOUT);\n+            conf.write_request_timeout_in_ms = LOWEST_ACCEPTED_TIMEOUT;\n         }\n \n         if(conf.cas_contention_timeout_in_ms < LOWEST_ACCEPTED_TIMEOUT)\n         {\n-           logInfo(\"cas_contention_timeout_in_ms\", conf.cas_contention_timeout_in_ms, LOWEST_ACCEPTED_TIMEOUT);\n-           conf.cas_contention_timeout_in_ms = LOWEST_ACCEPTED_TIMEOUT;\n+            logInfo(\"cas_contention_timeout_in_ms\", conf.cas_contention_timeout_in_ms, LOWEST_ACCEPTED_TIMEOUT);\n+            conf.cas_contention_timeout_in_ms = LOWEST_ACCEPTED_TIMEOUT;\n         }\n \n         if(conf.counter_write_request_timeout_in_ms < LOWEST_ACCEPTED_TIMEOUT)\n         {\n-           logInfo(\"counter_write_request_timeout_in_ms\", conf.counter_write_request_timeout_in_ms, LOWEST_ACCEPTED_TIMEOUT);\n-           conf.counter_write_request_timeout_in_ms = LOWEST_ACCEPTED_TIMEOUT;\n+            logInfo(\"counter_write_request_timeout_in_ms\", conf.counter_write_request_timeout_in_ms, LOWEST_ACCEPTED_TIMEOUT);\n+            conf.counter_write_request_timeout_in_ms = LOWEST_ACCEPTED_TIMEOUT;\n         }\n \n         if(conf.truncate_request_timeout_in_ms < LOWEST_ACCEPTED_TIMEOUT)\n         {\n-           logInfo(\"truncate_request_timeout_in_ms\", conf.truncate_request_timeout_in_ms, LOWEST_ACCEPTED_TIMEOUT);\n-           conf.truncate_request_timeout_in_ms = LOWEST_ACCEPTED_TIMEOUT;\n+            logInfo(\"truncate_request_timeout_in_ms\", conf.truncate_request_timeout_in_ms, LOWEST_ACCEPTED_TIMEOUT);\n+            conf.truncate_request_timeout_in_ms = LOWEST_ACCEPTED_TIMEOUT;\n         }\n     }\n \n@@ -1285,8 +1285,8 @@ public static void setPermissionsValidity(int timeout)\n     public static int getPermissionsUpdateInterval()\n     {\n         return conf.permissions_update_interval_in_ms == -1\n-             ? conf.permissions_validity_in_ms\n-             : conf.permissions_update_interval_in_ms;\n+               ? conf.permissions_validity_in_ms\n+               : conf.permissions_update_interval_in_ms;\n     }\n \n     public static void setPermissionsUpdateInterval(int updateInterval)\n@@ -1317,8 +1317,8 @@ public static void setRolesValidity(int validity)\n     public static int getRolesUpdateInterval()\n     {\n         return conf.roles_update_interval_in_ms == -1\n-             ? conf.roles_validity_in_ms\n-             : conf.roles_update_interval_in_ms;\n+               ? conf.roles_validity_in_ms\n+               : conf.roles_update_interval_in_ms;\n     }\n \n     public static void setRolesUpdateInterval(int interval)\n@@ -1939,11 +1939,11 @@ public static void setFlushCompression(Config.FlushCompression compression)\n         conf.flush_compression = compression;\n     }\n \n-   /**\n-    * Maximum number of buffers in the compression pool. The default value is 3, it should not be set lower than that\n-    * (one segment in compression, one written to, one in reserve); delays in compression may cause the log to use\n-    * more, depending on how soon the sync policy stops all writing threads.\n-    */\n+    /**\n+     * Maximum number of buffers in the compression pool. The default value is 3, it should not be set lower than that\n+     * (one segment in compression, one written to, one in reserve); delays in compression may cause the log to use\n+     * more, depending on how soon the sync policy stops all writing threads.\n+     */\n     public static int getCommitLogMaxCompressionBuffersInPool()\n     {\n         return conf.commitlog_max_compression_buffers_in_pool;\n@@ -2473,7 +2473,7 @@ public static File getHintsDirectory()\n     public static File getSerializedCachePath(CacheType cacheType, String version, String extension)\n     {\n         String name = cacheType.toString()\n-                + (version == null ? \"\" : '-' + version + '.' + extension);\n+                      + (version == null ? \"\" : '-' + version + '.' + extension);\n         return new File(conf.saved_caches_directory, name);\n     }\n \n@@ -3110,7 +3110,7 @@ private static void validateMaxConcurrentAutoUpgradeTasksConf(int value)\n         if (value > getConcurrentCompactors())\n             logger.warn(\"max_concurrent_automatic_sstable_upgrades ({}) is larger than concurrent_compactors ({})\", value, getConcurrentCompactors());\n     }\n-    \n+\n     public static AuditLogOptions getAuditLoggingOptions()\n     {\n         return conf.audit_logging_options;\n@@ -3366,5 +3366,23 @@ public static void setKeyspaceCountWarnThreshold(int value)\n         conf.keyspace_count_warn_threshold = value;\n     }\n \n+    public static int getSAISegmentWriteBufferSpace()\n+    {\n+        return conf.sai_options.segment_write_buffer_space_mb;\n+    }\n \n+    public static void setSAISegmentWriteBufferSpace(int bufferSpace)\n+    {\n+        conf.sai_options.segment_write_buffer_space_mb = bufferSpace;\n+    }\n+\n+    public static double getSAIZeroCopyUsedThreshold()\n+    {\n+        return conf.sai_options.zerocopy_used_threshold;\n+    }\n+\n+    public static void setSAIZeroCopyUsedThreshold(double threshold)\n+    {\n+        conf.sai_options.zerocopy_used_threshold = threshold;\n+    }\n }"
  },
  {
    "sha": "84e8d8aee1308ab28ddbfc0c4adbed04d3fac27d",
    "filename": "src/java/org/apache/cassandra/config/StorageAttachedIndexOptions.java",
    "status": "added",
    "additions": 64,
    "deletions": 0,
    "changes": 64,
    "blob_url": "https://github.com/datastax/cassandra/blob/782ad0aa1ea82a157aee5cfc9def7fac3ef00dac/src/java/org/apache/cassandra/config/StorageAttachedIndexOptions.java",
    "raw_url": "https://github.com/datastax/cassandra/raw/782ad0aa1ea82a157aee5cfc9def7fac3ef00dac/src/java/org/apache/cassandra/config/StorageAttachedIndexOptions.java",
    "contents_url": "https://api.github.com/repos/datastax/cassandra/contents/src/java/org/apache/cassandra/config/StorageAttachedIndexOptions.java?ref=782ad0aa1ea82a157aee5cfc9def7fac3ef00dac",
    "patch": "@@ -0,0 +1,64 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.cassandra.config;\n+\n+import com.google.common.base.Objects;\n+\n+import org.apache.cassandra.exceptions.ConfigurationException;\n+\n+public class StorageAttachedIndexOptions\n+{\n+    public static final int DEFAULT_SEGMENT_BUFFER_MB = 1024;\n+    public static final double DEFAULT_ZEROCOPY_USED_THRESHOLD = 0.3;\n+\n+    private static final int MAXIMUM_SEGMENT_BUFFER_MB = 32768;\n+\n+    public int segment_write_buffer_space_mb = DEFAULT_SEGMENT_BUFFER_MB;\n+    public double zerocopy_used_threshold = DEFAULT_ZEROCOPY_USED_THRESHOLD;\n+\n+    public void validate()\n+    {\n+        if ((segment_write_buffer_space_mb < 0) || (segment_write_buffer_space_mb > MAXIMUM_SEGMENT_BUFFER_MB))\n+        {\n+            throw new ConfigurationException(\"Invalid value for segment_write_buffer_space_mb. \" +\n+                                             \"Value must be a positive integer less than 32768\");\n+        }\n+\n+        if ((zerocopy_used_threshold < 0.0) || (zerocopy_used_threshold > 1.0))\n+        {\n+            throw new ConfigurationException(\"Invalid value for zero_copy_used_threshold. \" +\n+                                             \"Value must be between 0.0 and 1.0\");\n+        }\n+    }\n+\n+    @Override\n+    public boolean equals(Object o)\n+    {\n+        if (this == o) return true;\n+        if (o == null || getClass() != o.getClass()) return false;\n+        StorageAttachedIndexOptions that = (StorageAttachedIndexOptions) o;\n+        return Objects.equal(segment_write_buffer_space_mb, that.segment_write_buffer_space_mb) &&\n+               Objects.equal(zerocopy_used_threshold, that.zerocopy_used_threshold);\n+    }\n+\n+    @Override\n+    public int hashCode()\n+    {\n+        return Objects.hashCode(segment_write_buffer_space_mb, zerocopy_used_threshold);\n+    }\n+}"
  },
  {
    "sha": "421b44684e6dec5348c51b253efa6937642bf7db",
    "filename": "src/java/org/apache/cassandra/cql3/CQL3Type.java",
    "status": "modified",
    "additions": 1,
    "deletions": 1,
    "changes": 2,
    "blob_url": "https://github.com/datastax/cassandra/blob/782ad0aa1ea82a157aee5cfc9def7fac3ef00dac/src/java/org/apache/cassandra/cql3/CQL3Type.java",
    "raw_url": "https://github.com/datastax/cassandra/raw/782ad0aa1ea82a157aee5cfc9def7fac3ef00dac/src/java/org/apache/cassandra/cql3/CQL3Type.java",
    "contents_url": "https://api.github.com/repos/datastax/cassandra/contents/src/java/org/apache/cassandra/cql3/CQL3Type.java?ref=782ad0aa1ea82a157aee5cfc9def7fac3ef00dac",
    "patch": "@@ -196,7 +196,7 @@ public String toCQLLiteral(ByteBuffer buffer, ProtocolVersion version)\n \n             StringBuilder target = new StringBuilder();\n             buffer = buffer.duplicate();\n-            int size = CollectionSerializer.readCollectionSize(buffer, version);\n+            int size = CollectionSerializer.readCollectionSize(buffer, ByteBufferAccessor.instance, version);\n             buffer.position(buffer.position() + CollectionSerializer.sizeOfCollectionSize(size, version));\n \n             switch (type.kind)"
  },
  {
    "sha": "356f52bbfacdf319d9611c2ecdc5ce6d232b78ee",
    "filename": "src/java/org/apache/cassandra/cql3/Operator.java",
    "status": "modified",
    "additions": 15,
    "deletions": 6,
    "changes": 21,
    "blob_url": "https://github.com/datastax/cassandra/blob/782ad0aa1ea82a157aee5cfc9def7fac3ef00dac/src/java/org/apache/cassandra/cql3/Operator.java",
    "raw_url": "https://github.com/datastax/cassandra/raw/782ad0aa1ea82a157aee5cfc9def7fac3ef00dac/src/java/org/apache/cassandra/cql3/Operator.java",
    "contents_url": "https://api.github.com/repos/datastax/cassandra/contents/src/java/org/apache/cassandra/cql3/Operator.java?ref=782ad0aa1ea82a157aee5cfc9def7fac3ef00dac",
    "patch": "@@ -298,12 +298,12 @@ public int getValue()\n      */\n     public static Operator readFrom(DataInput input) throws IOException\n     {\n-          int b = input.readInt();\n-          for (Operator operator : values())\n-              if (operator.b == b)\n-                  return operator;\n+        int b = input.readInt();\n+        for (Operator operator : values())\n+            if (operator.b == b)\n+                return operator;\n \n-          throw new IOException(String.format(\"Cannot resolve Relation.Type from binary representation: %s\", b));\n+        throw new IOException(String.format(\"Cannot resolve Relation.Type from binary representation: %s\", b));\n     }\n \n     /**\n@@ -316,6 +316,15 @@ public int serializedSize()\n         return 4;\n     }\n \n+    /**\n+     * Checks if this operator is a like operator.\n+     * @return {@code true} if this operator is a like operator, {@code false} otherwise.\n+     */\n+    public boolean isLike()\n+    {\n+        return this == LIKE_PREFIX || this == LIKE_CONTAINS || this == LIKE_SUFFIX || this == LIKE_MATCHES;\n+    }\n+\n     /**\n      * Checks if this operator is a slice operator.\n      * @return {@code true} if this operator is a slice operator, {@code false} otherwise.\n@@ -328,7 +337,7 @@ public boolean isSlice()\n     @Override\n     public String toString()\n     {\n-         return this.name();\n+        return this.name();\n     }\n \n     /**"
  },
  {
    "sha": "6a52c5b815bb848b1f7565333cdeb92805e827d2",
    "filename": "src/java/org/apache/cassandra/cql3/SingleColumnRelation.java",
    "status": "modified",
    "additions": 5,
    "deletions": 15,
    "changes": 20,
    "blob_url": "https://github.com/datastax/cassandra/blob/782ad0aa1ea82a157aee5cfc9def7fac3ef00dac/src/java/org/apache/cassandra/cql3/SingleColumnRelation.java",
    "raw_url": "https://github.com/datastax/cassandra/raw/782ad0aa1ea82a157aee5cfc9def7fac3ef00dac/src/java/org/apache/cassandra/cql3/SingleColumnRelation.java",
    "contents_url": "https://api.github.com/repos/datastax/cassandra/contents/src/java/org/apache/cassandra/cql3/SingleColumnRelation.java?ref=782ad0aa1ea82a157aee5cfc9def7fac3ef00dac",
    "patch": "@@ -116,7 +116,7 @@ protected Term toTerm(List<? extends ColumnSpecification> receivers,\n                           Raw raw,\n                           String keyspace,\n                           VariableSpecifications boundNames)\n-                          throws InvalidRequestException\n+    throws InvalidRequestException\n     {\n         assert receivers.size() == 1;\n \n@@ -172,10 +172,10 @@ public boolean equals(Object o)\n \n         SingleColumnRelation scr = (SingleColumnRelation) o;\n         return Objects.equals(entity, scr.entity)\n-            && Objects.equals(relationType, scr.relationType)\n-            && Objects.equals(mapKey, scr.mapKey)\n-            && Objects.equals(value, scr.value)\n-            && Objects.equals(inValues, scr.inValues);\n+               && Objects.equals(relationType, scr.relationType)\n+               && Objects.equals(mapKey, scr.mapKey)\n+               && Objects.equals(value, scr.value)\n+               && Objects.equals(inValues, scr.inValues);\n     }\n \n     @Override\n@@ -274,16 +274,6 @@ protected Restriction newLikeRestriction(TableMetadata table, VariableSpecificat\n     {\n         ColumnSpecification receiver = columnDef;\n \n-        if (isIN())\n-        {\n-            // We only allow IN on the row key and the clustering key so far, never on non-PK columns, and this even if\n-            // there's an index\n-            // Note: for backward compatibility reason, we conside a IN of 1 value the same as a EQ, so we let that\n-            // slide.\n-            checkFalse(!columnDef.isPrimaryKeyColumn() && !canHaveOnlyOneValue(),\n-                       \"IN predicates on non-primary-key columns (%s) is not yet supported\", columnDef.name);\n-        }\n-\n         checkFalse(isContainsKey() && !(receiver.type instanceof MapType), \"Cannot use CONTAINS KEY on non-map column %s\", receiver.name);\n         checkFalse(isContains() && !(receiver.type.isCollection()), \"Cannot use CONTAINS on non-collection column %s\", receiver.name);\n "
  },
  {
    "sha": "6e028c274d31f94e4f3731e29d9d821472201eb7",
    "filename": "src/java/org/apache/cassandra/cql3/Tuples.java",
    "status": "modified",
    "additions": 4,
    "deletions": 3,
    "changes": 7,
    "blob_url": "https://github.com/datastax/cassandra/blob/782ad0aa1ea82a157aee5cfc9def7fac3ef00dac/src/java/org/apache/cassandra/cql3/Tuples.java",
    "raw_url": "https://github.com/datastax/cassandra/raw/782ad0aa1ea82a157aee5cfc9def7fac3ef00dac/src/java/org/apache/cassandra/cql3/Tuples.java",
    "contents_url": "https://api.github.com/repos/datastax/cassandra/contents/src/java/org/apache/cassandra/cql3/Tuples.java?ref=782ad0aa1ea82a157aee5cfc9def7fac3ef00dac",
    "patch": "@@ -154,14 +154,14 @@ public Value(ByteBuffer[] elements)\n \n         public static Value fromSerialized(ByteBuffer bytes, TupleType type)\n         {\n-            ByteBuffer[] values = type.split(bytes);\n+            ByteBuffer[] values = type.split(ByteBufferAccessor.instance, bytes);\n             if (values.length > type.size())\n             {\n                 throw new InvalidRequestException(String.format(\n                         \"Tuple value contained too many fields (expected %s, got %s)\", type.size(), values.length));\n             }\n \n-            return new Value(type.split(bytes));\n+            return new Value(type.split(ByteBufferAccessor.instance, bytes));\n         }\n \n         public ByteBuffer get(ProtocolVersion protocolVersion)\n@@ -272,7 +272,8 @@ public static InValue fromSerialized(ByteBuffer value, ListType type, QueryOptio\n                 // type.split(bytes)\n                 List<List<ByteBuffer>> elements = new ArrayList<>(l.size());\n                 for (Object element : l)\n-                    elements.add(Arrays.asList(tupleType.split(type.getElementsType().decompose(element))));\n+                    elements.add(Arrays.asList(tupleType.split(ByteBufferAccessor.instance,\n+                                                               type.getElementsType().decompose(element))));\n                 return new InValue(elements);\n             }\n             catch (MarshalException e)"
  },
  {
    "sha": "a63420fca3cd3a4d14c4993286bcf303eae51d20",
    "filename": "src/java/org/apache/cassandra/cql3/UserTypes.java",
    "status": "modified",
    "additions": 1,
    "deletions": 1,
    "changes": 2,
    "blob_url": "https://github.com/datastax/cassandra/blob/782ad0aa1ea82a157aee5cfc9def7fac3ef00dac/src/java/org/apache/cassandra/cql3/UserTypes.java",
    "raw_url": "https://github.com/datastax/cassandra/raw/782ad0aa1ea82a157aee5cfc9def7fac3ef00dac/src/java/org/apache/cassandra/cql3/UserTypes.java",
    "contents_url": "https://api.github.com/repos/datastax/cassandra/contents/src/java/org/apache/cassandra/cql3/UserTypes.java?ref=782ad0aa1ea82a157aee5cfc9def7fac3ef00dac",
    "patch": "@@ -217,7 +217,7 @@ public Value(UserType type, ByteBuffer[] elements)\n         public static Value fromSerialized(ByteBuffer bytes, UserType type)\n         {\n             type.validate(bytes);\n-            return new Value(type, type.split(bytes));\n+            return new Value(type, type.split(ByteBufferAccessor.instance, bytes));\n         }\n \n         public ByteBuffer get(ProtocolVersion protocolVersion)"
  },
  {
    "sha": "8e34f6ecc2a3063e88034e925c16abba283a0cd4",
    "filename": "src/java/org/apache/cassandra/cql3/conditions/ColumnCondition.java",
    "status": "modified",
    "additions": 8,
    "deletions": 2,
    "changes": 10,
    "blob_url": "https://github.com/datastax/cassandra/blob/782ad0aa1ea82a157aee5cfc9def7fac3ef00dac/src/java/org/apache/cassandra/cql3/conditions/ColumnCondition.java",
    "raw_url": "https://github.com/datastax/cassandra/raw/782ad0aa1ea82a157aee5cfc9def7fac3ef00dac/src/java/org/apache/cassandra/cql3/conditions/ColumnCondition.java",
    "contents_url": "https://api.github.com/repos/datastax/cassandra/contents/src/java/org/apache/cassandra/cql3/conditions/ColumnCondition.java?ref=782ad0aa1ea82a157aee5cfc9def7fac3ef00dac",
    "patch": "@@ -612,10 +612,16 @@ private ByteBuffer rowValue(Row row)\n                 return cell == null ? null : cell.buffer();\n             }\n \n-            Cell<?> cell = getCell(row, column);\n+            // getCell returns Cell<?>, which requires a method call to properly convert.\n+            return getCellBuffer(getCell(row, column), userType);\n+        }\n+\n+        private <V> ByteBuffer getCellBuffer(Cell<V> cell, UserType userType)\n+        {\n             return cell == null\n                       ? null\n-                      : userType.split(cell.buffer())[userType.fieldPosition(field)];\n+                      : ByteBufferAccessor.instance.convert(userType.split(cell.accessor(), cell.value())[userType.fieldPosition(field)],\n+                                                            cell.accessor());\n         }\n \n         private boolean isSatisfiedBy(ByteBuffer rowValue)"
  },
  {
    "sha": "d5d153e5e797b7b4cd3bf0df493b1d5d083842d1",
    "filename": "src/java/org/apache/cassandra/cql3/restrictions/ClusteringColumnRestrictions.java",
    "status": "modified",
    "additions": 80,
    "deletions": 93,
    "changes": 173,
    "blob_url": "https://github.com/datastax/cassandra/blob/782ad0aa1ea82a157aee5cfc9def7fac3ef00dac/src/java/org/apache/cassandra/cql3/restrictions/ClusteringColumnRestrictions.java",
    "raw_url": "https://github.com/datastax/cassandra/raw/782ad0aa1ea82a157aee5cfc9def7fac3ef00dac/src/java/org/apache/cassandra/cql3/restrictions/ClusteringColumnRestrictions.java",
    "contents_url": "https://api.github.com/repos/datastax/cassandra/contents/src/java/org/apache/cassandra/cql3/restrictions/ClusteringColumnRestrictions.java?ref=782ad0aa1ea82a157aee5cfc9def7fac3ef00dac",
    "patch": "@@ -27,6 +27,7 @@\n import org.apache.cassandra.db.filter.RowFilter;\n import org.apache.cassandra.exceptions.InvalidRequestException;\n import org.apache.cassandra.index.IndexRegistry;\n+import org.apache.cassandra.service.QueryState;\n import org.apache.cassandra.utils.btree.BTreeSet;\n \n import static org.apache.cassandra.cql3.statements.RequestValidations.checkFalse;\n@@ -42,71 +43,22 @@\n      */\n     protected final ClusteringComparator comparator;\n \n-    /**\n-     * <code>true</code> if filtering is allowed for this restriction, <code>false</code> otherwise\n-     */\n-    private final boolean allowFiltering;\n-\n-    public ClusteringColumnRestrictions(TableMetadata table)\n-    {\n-        this(table, false);\n-    }\n-\n-    public ClusteringColumnRestrictions(TableMetadata table, boolean allowFiltering)\n-    {\n-        this(table.comparator, new RestrictionSet(), allowFiltering);\n-    }\n-\n     private ClusteringColumnRestrictions(ClusteringComparator comparator,\n-                                         RestrictionSet restrictionSet,\n-                                         boolean allowFiltering)\n+                                         RestrictionSet restrictionSet)\n     {\n         super(restrictionSet);\n         this.comparator = comparator;\n-        this.allowFiltering = allowFiltering;\n-    }\n-\n-    public ClusteringColumnRestrictions mergeWith(Restriction restriction) throws InvalidRequestException\n-    {\n-        SingleRestriction newRestriction = (SingleRestriction) restriction;\n-        RestrictionSet newRestrictionSet = restrictions.addRestriction(newRestriction);\n-\n-        if (!isEmpty() && !allowFiltering)\n-        {\n-            SingleRestriction lastRestriction = restrictions.lastRestriction();\n-            ColumnMetadata lastRestrictionStart = lastRestriction.getFirstColumn();\n-            ColumnMetadata newRestrictionStart = restriction.getFirstColumn();\n-\n-            checkFalse(lastRestriction.isSlice() && newRestrictionStart.position() > lastRestrictionStart.position(),\n-                       \"Clustering column \\\"%s\\\" cannot be restricted (preceding column \\\"%s\\\" is restricted by a non-EQ relation)\",\n-                       newRestrictionStart.name,\n-                       lastRestrictionStart.name);\n-\n-            if (newRestrictionStart.position() < lastRestrictionStart.position() && newRestriction.isSlice())\n-                throw invalidRequest(\"PRIMARY KEY column \\\"%s\\\" cannot be restricted (preceding column \\\"%s\\\" is restricted by a non-EQ relation)\",\n-                                     restrictions.nextColumn(newRestrictionStart).name,\n-                                     newRestrictionStart.name);\n-        }\n-\n-        return new ClusteringColumnRestrictions(this.comparator, newRestrictionSet, allowFiltering);\n-    }\n-\n-    private boolean hasMultiColumnSlice()\n-    {\n-        for (SingleRestriction restriction : restrictions)\n-        {\n-            if (restriction.isMultiColumn() && restriction.isSlice())\n-                return true;\n-        }\n-        return false;\n     }\n \n     public NavigableSet<Clustering<?>> valuesAsClustering(QueryOptions options) throws InvalidRequestException\n     {\n         MultiCBuilder builder = MultiCBuilder.create(comparator, hasIN());\n-        for (SingleRestriction r : restrictions)\n+        List<SingleRestriction> restrictions = restrictions();\n+        for (int i = 0; i < restrictions.size(); i++)\n         {\n+            SingleRestriction r = restrictions.get(i);\n             r.appendTo(builder, options);\n+\n             if (builder.hasMissingElements())\n                 break;\n         }\n@@ -115,11 +67,14 @@ private boolean hasMultiColumnSlice()\n \n     public NavigableSet<ClusteringBound<?>> boundsAsClustering(Bound bound, QueryOptions options) throws InvalidRequestException\n     {\n-        MultiCBuilder builder = MultiCBuilder.create(comparator, hasIN() || hasMultiColumnSlice());\n+        List<SingleRestriction> restrictionsList = restrictions();\n+\n+        MultiCBuilder builder = MultiCBuilder.create(comparator, hasIN() || restrictions.hasMultiColumnSlice());\n         int keyPosition = 0;\n \n-        for (SingleRestriction r : restrictions)\n+        for (int i = 0; i < restrictionsList.size(); i++)\n         {\n+            SingleRestriction r = restrictionsList.get(i);\n             if (handleInFilter(r, keyPosition))\n                 break;\n \n@@ -144,50 +99,20 @@ private boolean hasMultiColumnSlice()\n         return builder.buildBound(bound.isStart(), true);\n     }\n \n-    /**\n-     * Checks if any of the underlying restriction is a CONTAINS or CONTAINS KEY.\n-     *\n-     * @return <code>true</code> if any of the underlying restriction is a CONTAINS or CONTAINS KEY,\n-     * <code>false</code> otherwise\n-     */\n-    public final boolean hasContains()\n-    {\n-        for (SingleRestriction restriction : restrictions)\n-        {\n-            if (restriction.isContains())\n-                return true;\n-        }\n-        return false;\n-    }\n-\n-    /**\n-     * Checks if any of the underlying restriction is a slice restrictions.\n-     *\n-     * @return <code>true</code> if any of the underlying restriction is a slice restrictions,\n-     * <code>false</code> otherwise\n-     */\n-    public final boolean hasSlice()\n-    {\n-        for (SingleRestriction restriction : restrictions)\n-        {\n-            if (restriction.isSlice())\n-                return true;\n-        }\n-        return false;\n-    }\n-\n     /**\n      * Checks if underlying restrictions would require filtering\n      *\n      * @return <code>true</code> if any underlying restrictions require filtering, <code>false</code>\n      * otherwise\n      */\n-    public final boolean needFiltering()\n+    public boolean needFiltering()\n     {\n         int position = 0;\n \n-        for (SingleRestriction restriction : restrictions)\n+        List<SingleRestriction> restrictions = restrictions();\n+        for (int i = 0; i < restrictions.size(); i++)\n         {\n+            SingleRestriction restriction = restrictions.get(i);\n             if (handleInFilter(restriction, position))\n                 return true;\n \n@@ -198,18 +123,20 @@ public final boolean needFiltering()\n     }\n \n     @Override\n-    public void addRowFilterTo(RowFilter filter,\n+    public void addToRowFilter(RowFilter filter,\n                                IndexRegistry indexRegistry,\n                                QueryOptions options) throws InvalidRequestException\n     {\n         int position = 0;\n \n-        for (SingleRestriction restriction : restrictions)\n+        List<SingleRestriction> restrictions = restrictions();\n+        for (int i = 0; i < restrictions.size(); i++)\n         {\n+            SingleRestriction restriction = restrictions.get(i);\n             // We ignore all the clustering columns that can be handled by slices.\n             if (handleInFilter(restriction, position) || restriction.hasSupportingIndex(indexRegistry))\n             {\n-                restriction.addRowFilterTo(filter, indexRegistry, options);\n+                restriction.addToRowFilter(filter, indexRegistry, options);\n                 continue;\n             }\n \n@@ -223,4 +150,64 @@ private boolean handleInFilter(SingleRestriction restriction, int index)\n         return restriction.isContains() || restriction.isLIKE() || index != restriction.getFirstColumn().position();\n     }\n \n+    public static ClusteringColumnRestrictions.Builder builder(TableMetadata table, boolean allowFiltering)\n+    {\n+        return new Builder(table, allowFiltering, null);\n+    }\n+\n+    public static ClusteringColumnRestrictions.Builder builder(TableMetadata table, boolean allowFiltering, IndexRegistry indexRegistry)\n+    {\n+        return new Builder(table, allowFiltering, indexRegistry);\n+    }\n+\n+    public static class Builder\n+    {\n+        private final TableMetadata table;\n+        private final boolean allowFiltering;\n+        private final IndexRegistry indexRegistry;\n+\n+        private final RestrictionSet.Builder restrictions = RestrictionSet.builder();\n+\n+        private Builder(TableMetadata table, boolean allowFiltering, IndexRegistry indexRegistry)\n+        {\n+            this.table = table;\n+            this.allowFiltering = allowFiltering;\n+            this.indexRegistry = indexRegistry;\n+        }\n+\n+        public ClusteringColumnRestrictions.Builder addRestriction(Restriction restriction)\n+        {\n+            SingleRestriction newRestriction = (SingleRestriction) restriction;\n+            boolean isEmpty = restrictions.isEmpty();\n+\n+            if (!isEmpty && !allowFiltering && (indexRegistry == null || !newRestriction.hasSupportingIndex(indexRegistry)))\n+            {\n+                SingleRestriction lastRestriction = restrictions.lastRestriction();\n+                ColumnMetadata lastRestrictionStart = lastRestriction.getFirstColumn();\n+                ColumnMetadata newRestrictionStart = newRestriction.getFirstColumn();\n+                restrictions.addRestriction(newRestriction);\n+\n+                checkFalse(lastRestriction.isSlice() && newRestrictionStart.position() > lastRestrictionStart.position(),\n+                           \"Clustering column \\\"%s\\\" cannot be restricted (preceding column \\\"%s\\\" is restricted by a non-EQ relation)\",\n+                           newRestrictionStart.name,\n+                           lastRestrictionStart.name);\n+\n+                if (newRestrictionStart.position() < lastRestrictionStart.position() && newRestriction.isSlice())\n+                    throw invalidRequest(\"PRIMARY KEY column \\\"%s\\\" cannot be restricted (preceding column \\\"%s\\\" is restricted by a non-EQ relation)\",\n+                                         restrictions.nextColumn(newRestrictionStart).name,\n+                                         newRestrictionStart.name);\n+            }\n+            else\n+            {\n+                restrictions.addRestriction(newRestriction);\n+            }\n+\n+            return this;\n+        }\n+\n+        public ClusteringColumnRestrictions build()\n+        {\n+            return new ClusteringColumnRestrictions(table.comparator, restrictions.build());\n+        }\n+    }\n }"
  },
  {
    "sha": "f9c7fc0dd9d95d21f098eb029c5503550f34e36e",
    "filename": "src/java/org/apache/cassandra/cql3/restrictions/CustomIndexExpression.java",
    "status": "modified",
    "additions": 12,
    "deletions": 0,
    "changes": 12,
    "blob_url": "https://github.com/datastax/cassandra/blob/782ad0aa1ea82a157aee5cfc9def7fac3ef00dac/src/java/org/apache/cassandra/cql3/restrictions/CustomIndexExpression.java",
    "raw_url": "https://github.com/datastax/cassandra/raw/782ad0aa1ea82a157aee5cfc9def7fac3ef00dac/src/java/org/apache/cassandra/cql3/restrictions/CustomIndexExpression.java",
    "contents_url": "https://api.github.com/repos/datastax/cassandra/contents/src/java/org/apache/cassandra/cql3/restrictions/CustomIndexExpression.java?ref=782ad0aa1ea82a157aee5cfc9def7fac3ef00dac",
    "patch": "@@ -22,6 +22,7 @@\n import org.apache.cassandra.cql3.*;\n import org.apache.cassandra.db.filter.RowFilter;\n import org.apache.cassandra.db.marshal.AbstractType;\n+import org.apache.cassandra.index.Index;\n import org.apache.cassandra.schema.TableMetadata;\n \n public class CustomIndexExpression\n@@ -55,6 +56,17 @@ public void addToRowFilter(RowFilter filter, TableMetadata table, QueryOptions o\n                                         value.bindAndGet(options));\n     }\n \n+    public boolean needsFiltering(Index.Group indexGroup)\n+    {\n+        String indexName = targetIndex.getName();\n+\n+        for (Index index : indexGroup.getIndexes())\n+            if (index.getIndexMetadata().name.equals(indexName))\n+                return false;\n+\n+        return true;\n+    }\n+\n     @Override\n     public String toString()\n     {"
  },
  {
    "sha": "10608b85c1c2131496530e8e93b08191c6e1d194",
    "filename": "src/java/org/apache/cassandra/cql3/restrictions/IndexRestrictions.java",
    "status": "modified",
    "additions": 164,
    "deletions": 18,
    "changes": 182,
    "blob_url": "https://github.com/datastax/cassandra/blob/782ad0aa1ea82a157aee5cfc9def7fac3ef00dac/src/java/org/apache/cassandra/cql3/restrictions/IndexRestrictions.java",
    "raw_url": "https://github.com/datastax/cassandra/raw/782ad0aa1ea82a157aee5cfc9def7fac3ef00dac/src/java/org/apache/cassandra/cql3/restrictions/IndexRestrictions.java",
    "contents_url": "https://api.github.com/repos/datastax/cassandra/contents/src/java/org/apache/cassandra/cql3/restrictions/IndexRestrictions.java?ref=782ad0aa1ea82a157aee5cfc9def7fac3ef00dac",
    "patch": "@@ -19,48 +19,136 @@\n package org.apache.cassandra.cql3.restrictions;\n \n import java.util.ArrayList;\n+import java.util.Collections;\n import java.util.List;\n \n import org.apache.cassandra.cql3.QualifiedName;\n+import org.apache.cassandra.index.Index;\n+import org.apache.cassandra.index.IndexRegistry;\n import org.apache.cassandra.schema.TableMetadata;\n import org.apache.cassandra.exceptions.InvalidRequestException;\n-import org.apache.commons.lang3.builder.ToStringBuilder;\n-import org.apache.commons.lang3.builder.ToStringStyle;\n \n-public class IndexRestrictions\n+import static org.apache.cassandra.cql3.statements.RequestValidations.invalidRequest;\n+\n+public final class IndexRestrictions\n {\n+    /**\n+     * The empty {@code IndexRestrictions}.\n+     */\n+    private static final IndexRestrictions EMPTY_RESTRICTIONS = new IndexRestrictions(Collections.EMPTY_LIST, Collections.EMPTY_LIST);\n+\n     public static final String INDEX_NOT_FOUND = \"Invalid index expression, index %s not found for %s\";\n     public static final String INVALID_INDEX = \"Target index %s cannot be used to query %s\";\n     public static final String CUSTOM_EXPRESSION_NOT_SUPPORTED = \"Index %s does not support custom expressions\";\n     public static final String NON_CUSTOM_INDEX_IN_EXPRESSION = \"Only CUSTOM indexes may be used in custom index expressions, %s is not valid\";\n     public static final String MULTIPLE_EXPRESSIONS = \"Multiple custom index expressions in a single query are not supported\";\n \n-    private final List<Restrictions> regularRestrictions = new ArrayList<>();\n-    private final List<CustomIndexExpression> customExpressions = new ArrayList<>();\n+    private final List<Restrictions> regularRestrictions;\n+    private final List<CustomIndexExpression> externalRestrictions;\n \n-    public void add(Restrictions restrictions)\n+    private IndexRestrictions(List<Restrictions> regularRestrictions, List<CustomIndexExpression> externalExpressions)\n     {\n-        regularRestrictions.add(restrictions);\n+        this.regularRestrictions = regularRestrictions;\n+        this.externalRestrictions = externalExpressions;\n     }\n \n-    public void add(CustomIndexExpression expression)\n+    /**\n+     * Returns an empty {@code IndexRestrictions}.\n+     * @return an empty {@code IndexRestrictions}\n+     */\n+    public static IndexRestrictions of()\n     {\n-        customExpressions.add(expression);\n+        return EMPTY_RESTRICTIONS;\n+    }\n+\n+    /**\n+     * Creates a new {@code IndexRestrictions.Builder} instance.\n+     * @return a new {@code IndexRestrictions.Builder} instance.\n+     */\n+    public static Builder builder()\n+    {\n+        return new IndexRestrictions.Builder();\n     }\n \n     public boolean isEmpty()\n     {\n-        return regularRestrictions.isEmpty() && customExpressions.isEmpty();\n+        return regularRestrictions.isEmpty() && externalRestrictions.isEmpty();\n     }\n \n+    /**\n+     * Returns the regular restrictions.\n+     * @return the regular restrictions\n+     */\n     public List<Restrictions> getRestrictions()\n     {\n         return regularRestrictions;\n     }\n \n-    public List<CustomIndexExpression> getCustomIndexExpressions()\n+    /**\n+     * Returns the external restrictions.\n+     * @return the external restrictions\n+     */\n+    public List<CustomIndexExpression> getExternalExpressions()\n+    {\n+        return externalRestrictions;\n+    }\n+\n+    /**\n+     * Returns the number of restrictions in external expression and regular restrictions.\n+     * @return Returns the number of restrictions in external expression and regular restrictions.\n+     */\n+    private int numOfSupportedRestrictions()\n     {\n-        return customExpressions;\n+        int numberOfRestrictions = getExternalExpressions().size();\n+        for (Restrictions restrictions : getRestrictions())\n+            numberOfRestrictions += restrictions.size();\n+\n+        return numberOfRestrictions;\n+    }\n+\n+    /**\n+     * Returns whether these restrictions would need filtering if the specified index registry were used.\n+     *\n+     * @param indexRegistry an index registry\n+     * @param hasClusteringColumnRestrictions {@code true} if there are restricted clustering columns\n+     * @param hasMultipleContains {@code true} if there are multiple \"contains\" restrictions\n+     * @return {@code true} if this would need filtering if {@code indexRegistry} were used, {@code false} otherwise\n+     */\n+    public boolean needFiltering(IndexRegistry indexRegistry, boolean hasClusteringColumnRestrictions, boolean hasMultipleContains)\n+    {\n+        // We need filtering if any clustering columns have restrictions that are not supported\n+        // by their indexes.\n+        if (numOfSupportedRestrictions() == 0)\n+            return hasClusteringColumnRestrictions;\n+\n+        for (Index.Group group : indexRegistry.listIndexGroups())\n+            if (!needFiltering(group, hasMultipleContains))\n+                return false;\n+\n+        return true;\n+    }\n+\n+    /**\n+     * Returns whether these restrictions would need filtering if the specified index group were used.\n+     *\n+     * @param indexGroup an index group\n+     * @param hasMultipleContains {@code true} if there are multiple \"contains\" restrictions\n+     * @return {@code true} if this would need filtering if {@code indexGroup} were used, {@code false} otherwise\n+     */\n+    private boolean needFiltering(Index.Group indexGroup, boolean hasMultipleContains)\n+    {\n+        if (hasMultipleContains && !indexGroup.supportsMultipleContains())\n+            return true;\n+\n+        for (Restrictions restrictions : regularRestrictions)\n+            if (restrictions.needsFiltering(indexGroup))\n+                return true;\n+\n+        for (CustomIndexExpression restriction : externalRestrictions)\n+            if (restriction.needsFiltering(indexGroup))\n+                return true;\n+\n+        return false;\n     }\n \n     static InvalidRequestException invalidIndex(QualifiedName indexName, TableMetadata table)\n@@ -75,17 +163,75 @@ static InvalidRequestException indexNotFound(QualifiedName indexName, TableMetad\n \n     static InvalidRequestException nonCustomIndexInExpression(QualifiedName indexName)\n     {\n-        return new InvalidRequestException(String.format(NON_CUSTOM_INDEX_IN_EXPRESSION, indexName.getName()));\n+        return invalidRequest(NON_CUSTOM_INDEX_IN_EXPRESSION, indexName.getName());\n     }\n \n     static InvalidRequestException customExpressionNotSupported(QualifiedName indexName)\n     {\n-        return new InvalidRequestException(String.format(CUSTOM_EXPRESSION_NOT_SUPPORTED, indexName.getName()));\n+        return invalidRequest(CUSTOM_EXPRESSION_NOT_SUPPORTED, indexName.getName());\n     }\n-    \n-    @Override\n-    public String toString()\n+\n+    /**\n+     * Builder for IndexRestrictions.\n+     */\n+    public static final class Builder\n     {\n-        return ToStringBuilder.reflectionToString(this, ToStringStyle.SHORT_PREFIX_STYLE);\n+        /**\n+         * Builder for the regular restrictions.\n+         */\n+        private List<Restrictions> regularRestrictions = new ArrayList<>();\n+\n+        /**\n+         * Builder for the custom expressions.\n+         */\n+        private List<CustomIndexExpression> externalRestrictions = new ArrayList<>();\n+\n+        private Builder() {}\n+\n+        /**\n+         * Adds the specified restrictions.\n+         *\n+         * @param restrictions the restrictions to add\n+         * @return this {@code Builder}\n+         */\n+        public Builder add(Restrictions restrictions)\n+        {\n+            regularRestrictions.add(restrictions);\n+            return this;\n+        }\n+\n+        /**\n+         * Adds the restrictions and custom expressions from the specified {@code IndexRestrictions}.\n+         *\n+         * @param restrictions the restrictions and custom expressions to add\n+         * @return this {@code Builder}\n+         */\n+        public Builder add(IndexRestrictions restrictions)\n+        {\n+            regularRestrictions.addAll(restrictions.regularRestrictions);\n+            externalRestrictions.addAll(restrictions.externalRestrictions);\n+            return this;\n+        }\n+\n+        /**\n+         * Adds the specified index expression.\n+         *\n+         * @param restriction the index expression to add\n+         * @return this {@code Builder}\n+         */\n+        public Builder add(CustomIndexExpression restriction)\n+        {\n+            externalRestrictions.add(restriction);\n+            return this;\n+        }\n+\n+        /**\n+         * Builds a new {@code IndexRestrictions} instance\n+         * @return a new {@code IndexRestrictions} instance\n+         */\n+        public IndexRestrictions build()\n+        {\n+            return new IndexRestrictions(Collections.unmodifiableList(regularRestrictions), Collections.unmodifiableList(externalRestrictions));\n+        }\n     }\n }"
  },
  {
    "sha": "77d8220b4f8c64fd4971db63914d12cc9b75677c",
    "filename": "src/java/org/apache/cassandra/cql3/restrictions/MultiColumnRestriction.java",
    "status": "modified",
    "additions": 46,
    "deletions": 30,
    "changes": 76,
    "blob_url": "https://github.com/datastax/cassandra/blob/782ad0aa1ea82a157aee5cfc9def7fac3ef00dac/src/java/org/apache/cassandra/cql3/restrictions/MultiColumnRestriction.java",
    "raw_url": "https://github.com/datastax/cassandra/raw/782ad0aa1ea82a157aee5cfc9def7fac3ef00dac/src/java/org/apache/cassandra/cql3/restrictions/MultiColumnRestriction.java",
    "contents_url": "https://api.github.com/repos/datastax/cassandra/contents/src/java/org/apache/cassandra/cql3/restrictions/MultiColumnRestriction.java?ref=782ad0aa1ea82a157aee5cfc9def7fac3ef00dac",
    "patch": "@@ -78,7 +78,7 @@ public final SingleRestriction mergeWith(SingleRestriction otherRestriction)\n     {\n         // We want to allow query like: (b,c) > (?, ?) AND b < ?\n         if (!otherRestriction.isMultiColumn()\n-                && ((SingleColumnRestriction) otherRestriction).canBeConvertedToMultiColumnRestriction())\n+            && ((SingleColumnRestriction) otherRestriction).canBeConvertedToMultiColumnRestriction())\n         {\n             return doMergeWith(((SingleColumnRestriction) otherRestriction).toMultiColumnRestriction());\n         }\n@@ -114,8 +114,27 @@ protected final String getColumnsInCommons(Restriction otherRestriction)\n     public final boolean hasSupportingIndex(IndexRegistry indexRegistry)\n     {\n         for (Index index : indexRegistry.listIndexes())\n-           if (isSupportedBy(index))\n-               return true;\n+            if (isSupportingIndex(index))\n+                return true;\n+        return false;\n+    }\n+\n+    @Override\n+    public boolean needsFiltering(Index.Group indexGroup)\n+    {\n+        for (ColumnMetadata column : columnDefs)\n+            if (!isSupportedBy(indexGroup, column))\n+                return true;\n+\n+        return false;\n+    }\n+\n+    private boolean isSupportedBy(Index.Group indexGroup, ColumnMetadata column)\n+    {\n+        for (Index index : indexGroup.getIndexes())\n+            if (isSupportedBy(index, column))\n+                return true;\n+\n         return false;\n     }\n \n@@ -126,7 +145,16 @@ public final boolean hasSupportingIndex(IndexRegistry indexRegistry)\n      * @return <code>true</code> this type of restriction is supported by the specified index,\n      * <code>false</code> otherwise.\n      */\n-    protected abstract boolean isSupportedBy(Index index);\n+    private boolean isSupportingIndex(Index index)\n+    {\n+        for (ColumnMetadata column : columnDefs)\n+            if (isSupportedBy(index, column))\n+                return true;\n+\n+        return false;\n+    }\n+\n+    protected abstract boolean isSupportedBy(Index index, ColumnMetadata def);\n \n     public static class EQRestriction extends MultiColumnRestriction\n     {\n@@ -164,12 +192,9 @@ public SingleRestriction doMergeWith(SingleRestriction otherRestriction)\n         }\n \n         @Override\n-        protected boolean isSupportedBy(Index index)\n+        protected boolean isSupportedBy(Index index, ColumnMetadata column)\n         {\n-            for(ColumnMetadata column : columnDefs)\n-                if (index.supportsExpression(column, Operator.EQ))\n-                    return true;\n-            return false;\n+            return index.supportsExpression(column, Operator.EQ);\n         }\n \n         @Override\n@@ -186,7 +211,7 @@ public MultiCBuilder appendTo(MultiCBuilder builder, QueryOptions options)\n         }\n \n         @Override\n-        public final void addRowFilterTo(RowFilter filter, IndexRegistry indexRegistry, QueryOptions options)\n+        public final void addToRowFilter(RowFilter filter, IndexRegistry indexRegistry, QueryOptions options)\n         {\n             Tuples.Value t = ((Tuples.Value) value.bind(options));\n             List<ByteBuffer> values = t.getElements();\n@@ -234,16 +259,13 @@ public SingleRestriction doMergeWith(SingleRestriction otherRestriction)\n         }\n \n         @Override\n-        protected boolean isSupportedBy(Index index)\n+        protected boolean isSupportedBy(Index index, ColumnMetadata column)\n         {\n-            for (ColumnMetadata column: columnDefs)\n-                if (index.supportsExpression(column, Operator.IN))\n-                    return true;\n-            return false;\n+            return index.supportsExpression(column, Operator.IN);\n         }\n \n         @Override\n-        public final void addRowFilterTo(RowFilter filter,\n+        public final void addToRowFilter(RowFilter filter,\n                                          IndexRegistry indexRegistry,\n                                          QueryOptions options)\n         {\n@@ -416,12 +438,9 @@ public MultiCBuilder appendBoundTo(MultiCBuilder builder, Bound bound, QueryOpti\n         }\n \n         @Override\n-        protected boolean isSupportedBy(Index index)\n+        protected boolean isSupportedBy(Index index, ColumnMetadata column)\n         {\n-            for(ColumnMetadata def : columnDefs)\n-                if (slice.isSupportedBy(def, index))\n-                    return true;\n-            return false;\n+            return slice.isSupportedBy(column, index);\n         }\n \n         @Override\n@@ -452,7 +471,7 @@ public SingleRestriction doMergeWith(SingleRestriction otherRestriction)\n             if (!getFirstColumn().equals(otherRestriction.getFirstColumn()))\n             {\n                 ColumnMetadata column = getFirstColumn().position() > otherRestriction.getFirstColumn().position()\n-                        ? getFirstColumn() : otherRestriction.getFirstColumn();\n+                                        ? getFirstColumn() : otherRestriction.getFirstColumn();\n \n                 throw invalidRequest(\"Column \\\"%s\\\" cannot be restricted by two inequalities not starting with the same column\",\n                                      column.name);\n@@ -472,7 +491,7 @@ public SingleRestriction doMergeWith(SingleRestriction otherRestriction)\n         }\n \n         @Override\n-        public final void addRowFilterTo(RowFilter filter,\n+        public final void addToRowFilter(RowFilter filter,\n                                          IndexRegistry indexRegistry,\n                                          QueryOptions options)\n         {\n@@ -546,12 +565,9 @@ public SingleRestriction doMergeWith(SingleRestriction otherRestriction)\n         }\n \n         @Override\n-        protected boolean isSupportedBy(Index index)\n+        protected boolean isSupportedBy(Index index, ColumnMetadata column)\n         {\n-            for(ColumnMetadata column : columnDefs)\n-                if (index.supportsExpression(column, Operator.IS_NOT))\n-                    return true;\n-            return false;\n+            return index.supportsExpression(column, Operator.IS_NOT);\n         }\n \n         @Override\n@@ -561,12 +577,12 @@ public MultiCBuilder appendTo(MultiCBuilder builder, QueryOptions options)\n         }\n \n         @Override\n-        public final void addRowFilterTo(RowFilter filter, IndexRegistry indexRegistry, QueryOptions options)\n+        public final void addToRowFilter(RowFilter filter, IndexRegistry indexRegistry, QueryOptions options)\n         {\n             throw new UnsupportedOperationException(\"Secondary indexes do not support IS NOT NULL restrictions\");\n         }\n     }\n-    \n+\n     @Override\n     public String toString()\n     {"
  },
  {
    "sha": "4dbbb70b90fae8abcd4737733c3d206292af061e",
    "filename": "src/java/org/apache/cassandra/cql3/restrictions/PartitionKeySingleRestrictionSet.java",
    "status": "modified",
    "additions": 81,
    "deletions": 32,
    "changes": 113,
    "blob_url": "https://github.com/datastax/cassandra/blob/782ad0aa1ea82a157aee5cfc9def7fac3ef00dac/src/java/org/apache/cassandra/cql3/restrictions/PartitionKeySingleRestrictionSet.java",
    "raw_url": "https://github.com/datastax/cassandra/raw/782ad0aa1ea82a157aee5cfc9def7fac3ef00dac/src/java/org/apache/cassandra/cql3/restrictions/PartitionKeySingleRestrictionSet.java",
    "contents_url": "https://api.github.com/repos/datastax/cassandra/contents/src/java/org/apache/cassandra/cql3/restrictions/PartitionKeySingleRestrictionSet.java?ref=782ad0aa1ea82a157aee5cfc9def7fac3ef00dac",
    "patch": "@@ -18,15 +18,17 @@\n package org.apache.cassandra.cql3.restrictions;\n \n import java.nio.ByteBuffer;\n-import java.util.*;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n \n import org.apache.cassandra.schema.TableMetadata;\n import org.apache.cassandra.cql3.QueryOptions;\n import org.apache.cassandra.cql3.statements.Bound;\n import org.apache.cassandra.db.ClusteringComparator;\n-import org.apache.cassandra.db.ClusteringPrefix;\n import org.apache.cassandra.db.MultiCBuilder;\n import org.apache.cassandra.db.filter.RowFilter;\n+import org.apache.cassandra.service.QueryState;\n import org.apache.cassandra.index.IndexRegistry;\n \n /**\n@@ -42,27 +44,12 @@\n      */\n     protected final ClusteringComparator comparator;\n \n-    public PartitionKeySingleRestrictionSet(ClusteringComparator comparator)\n+    private PartitionKeySingleRestrictionSet(RestrictionSet restrictionSet, ClusteringComparator comparator)\n     {\n-        super(new RestrictionSet());\n+        super(restrictionSet);\n         this.comparator = comparator;\n     }\n \n-    private PartitionKeySingleRestrictionSet(PartitionKeySingleRestrictionSet restrictionSet,\n-                                       SingleRestriction restriction)\n-    {\n-        super(restrictionSet.restrictions.addRestriction(restriction));\n-        this.comparator = restrictionSet.comparator;\n-    }\n-\n-    private List<ByteBuffer> toByteBuffers(SortedSet<? extends ClusteringPrefix> clusterings)\n-    {\n-        List<ByteBuffer> l = new ArrayList<>(clusterings.size());\n-        for (ClusteringPrefix clustering : clusterings)\n-            l.add(clustering.serializeAsPartitionKey());\n-        return l;\n-    }\n-\n     @Override\n     public PartitionKeyRestrictions mergeWith(Restriction restriction)\n     {\n@@ -71,36 +58,49 @@ public PartitionKeyRestrictions mergeWith(Restriction restriction)\n             if (isEmpty())\n                 return (PartitionKeyRestrictions) restriction;\n \n-            return new TokenFilter(this, (TokenRestriction) restriction);\n+            return TokenFilter.create(this, (TokenRestriction) restriction);\n         }\n \n-        return new PartitionKeySingleRestrictionSet(this, (SingleRestriction) restriction);\n+        Builder builder = PartitionKeySingleRestrictionSet.builder(comparator);\n+        List<SingleRestriction> restrictions = restrictions();\n+        for (int i = 0; i < restrictions.size(); i++)\n+        {\n+            SingleRestriction r = restrictions.get(i);\n+            builder.addRestriction(r);\n+        }\n+        return builder.addRestriction(restriction)\n+                      .build();\n     }\n \n     @Override\n     public List<ByteBuffer> values(QueryOptions options)\n     {\n         MultiCBuilder builder = MultiCBuilder.create(comparator, hasIN());\n-        for (SingleRestriction r : restrictions)\n+        List<SingleRestriction> restrictions = restrictions();\n+        for (int i = 0; i < restrictions.size(); i++)\n         {\n+            SingleRestriction r = restrictions.get(i);\n             r.appendTo(builder, options);\n+\n             if (builder.hasMissingElements())\n                 break;\n         }\n-        return toByteBuffers(builder.build());\n+        return builder.buildSerializedPartitionKeys();\n     }\n \n     @Override\n     public List<ByteBuffer> bounds(Bound bound, QueryOptions options)\n     {\n         MultiCBuilder builder = MultiCBuilder.create(comparator, hasIN());\n-        for (SingleRestriction r : restrictions)\n+        List<SingleRestriction> restrictions = restrictions();\n+        for (int i = 0; i < restrictions.size(); i++)\n         {\n+            SingleRestriction r = restrictions.get(i);\n             r.appendBoundTo(builder, bound, options);\n             if (builder.hasMissingElements())\n-                return Collections.emptyList();\n+                return Collections.EMPTY_LIST;\n         }\n-        return toByteBuffers(builder.buildBound(bound.isStart(), true));\n+        return builder.buildSerializedPartitionKeys();\n     }\n \n     @Override\n@@ -120,13 +120,15 @@ public boolean isInclusive(Bound b)\n     }\n \n     @Override\n-    public void addRowFilterTo(RowFilter filter,\n+    public void addToRowFilter(RowFilter filter,\n                                IndexRegistry indexRegistry,\n                                QueryOptions options)\n     {\n-        for (SingleRestriction restriction : restrictions)\n+        List<SingleRestriction> restrictions = restrictions();\n+        for (int i = 0; i < restrictions.size(); i++)\n         {\n-             restriction.addRowFilterTo(filter, indexRegistry, options);\n+            SingleRestriction r = restrictions.get(i);\n+            r.addToRowFilter(filter, indexRegistry, options);\n         }\n     }\n \n@@ -146,9 +148,56 @@ public boolean hasUnrestrictedPartitionKeyComponents(TableMetadata table)\n         return size() < table.partitionKeyColumns().size();\n     }\n \n-    @Override\n-    public boolean hasSlice()\n+    public static Builder builder(ClusteringComparator clusteringComparator)\n+    {\n+        return new Builder(clusteringComparator);\n+    }\n+\n+    public static final class Builder\n     {\n-        return restrictions.hasSlice();\n+        private final ClusteringComparator clusteringComparator;\n+\n+        private final List<Restriction> restrictions = new ArrayList<>();\n+\n+        private Builder(ClusteringComparator clusteringComparator) {\n+            this.clusteringComparator = clusteringComparator;\n+        }\n+\n+        public Builder addRestriction(Restriction restriction) {\n+            restrictions.add(restriction);\n+            return this;\n+        }\n+\n+        public PartitionKeyRestrictions build() {\n+            RestrictionSet.Builder restrictionSet = RestrictionSet.builder();\n+\n+            for (int i = 0; i < restrictions.size(); i++) {\n+                Restriction restriction = restrictions.get(i);\n+\n+                // restrictions on tokens are handled in a special way\n+                if (restriction.isOnToken())\n+                    return buildWithTokens(restrictionSet, i);\n+\n+                restrictionSet.addRestriction((SingleRestriction) restriction);\n+            }\n+\n+            return buildPartitionKeyRestrictions(restrictionSet);\n+        }\n+\n+        private PartitionKeyRestrictions buildWithTokens(RestrictionSet.Builder restrictionSet, int i) {\n+            PartitionKeyRestrictions merged = buildPartitionKeyRestrictions(restrictionSet);\n+\n+            for (; i < restrictions.size(); i++) {\n+                Restriction restriction = restrictions.get(i);\n+\n+                merged = merged.mergeWith(restriction);\n+            }\n+\n+            return merged;\n+        }\n+\n+        private PartitionKeySingleRestrictionSet buildPartitionKeyRestrictions(RestrictionSet.Builder restrictionSet) {\n+            return new PartitionKeySingleRestrictionSet(restrictionSet.build(), clusteringComparator);\n+        }\n     }\n }"
  },
  {
    "sha": "f523d45096e97cf85e3ee6c88d42e4c9b6d17c72",
    "filename": "src/java/org/apache/cassandra/cql3/restrictions/Restriction.java",
    "status": "modified",
    "additions": 15,
    "deletions": 1,
    "changes": 16,
    "blob_url": "https://github.com/datastax/cassandra/blob/782ad0aa1ea82a157aee5cfc9def7fac3ef00dac/src/java/org/apache/cassandra/cql3/restrictions/Restriction.java",
    "raw_url": "https://github.com/datastax/cassandra/raw/782ad0aa1ea82a157aee5cfc9def7fac3ef00dac/src/java/org/apache/cassandra/cql3/restrictions/Restriction.java",
    "contents_url": "https://api.github.com/repos/datastax/cassandra/contents/src/java/org/apache/cassandra/cql3/restrictions/Restriction.java?ref=782ad0aa1ea82a157aee5cfc9def7fac3ef00dac",
    "patch": "@@ -18,7 +18,9 @@\n package org.apache.cassandra.cql3.restrictions;\n \n import java.util.List;\n+import java.util.function.Consumer;\n \n+import org.apache.cassandra.index.Index;\n import org.apache.cassandra.schema.ColumnMetadata;\n import org.apache.cassandra.cql3.QueryOptions;\n import org.apache.cassandra.cql3.functions.Function;\n@@ -30,6 +32,10 @@\n  */\n public interface Restriction\n {\n+    /**\n+     * Check if the restriction is on a partition key\n+     * @return <code>true</code> if the restriction is on a partition key, <code>false</code>\n+     */\n     public default boolean isOnToken()\n     {\n         return false;\n@@ -68,14 +74,22 @@ public default boolean isOnToken()\n      */\n     public boolean hasSupportingIndex(IndexRegistry indexRegistry);\n \n+    /**\n+     * Returns whether this restriction would need filtering if the specified index group were used.\n+     *\n+     * @param indexGroup an index group\n+     * @return {@code true} if this would need filtering if {@code indexGroup} were used, {@code false} otherwise\n+     */\n+    public boolean needsFiltering(Index.Group indexGroup);\n+\n     /**\n      * Adds to the specified row filter the expressions corresponding to this <code>Restriction</code>.\n      *\n      * @param filter the row filter to add expressions to\n      * @param indexRegistry the index registry\n      * @param options the query options\n      */\n-    public void addRowFilterTo(RowFilter filter,\n+    public void addToRowFilter(RowFilter filter,\n                                IndexRegistry indexRegistry,\n                                QueryOptions options);\n }"
  },
  {
    "sha": "8548ea2b8b9daf001f68d54e447f4dca88bdb27f",
    "filename": "src/java/org/apache/cassandra/cql3/restrictions/RestrictionSet.java",
    "status": "modified",
    "additions": 351,
    "deletions": 263,
    "changes": 614,
    "blob_url": "https://github.com/datastax/cassandra/blob/782ad0aa1ea82a157aee5cfc9def7fac3ef00dac/src/java/org/apache/cassandra/cql3/restrictions/RestrictionSet.java",
    "raw_url": "https://github.com/datastax/cassandra/raw/782ad0aa1ea82a157aee5cfc9def7fac3ef00dac/src/java/org/apache/cassandra/cql3/restrictions/RestrictionSet.java",
    "contents_url": "https://api.github.com/repos/datastax/cassandra/contents/src/java/org/apache/cassandra/cql3/restrictions/RestrictionSet.java?ref=782ad0aa1ea82a157aee5cfc9def7fac3ef00dac",
    "patch": "@@ -18,358 +18,446 @@\n package org.apache.cassandra.cql3.restrictions;\n \n import java.util.*;\n+import java.util.function.Consumer;\n \n-import com.google.common.collect.AbstractIterator;\n-\n-import org.apache.cassandra.schema.ColumnMetadata;\n import org.apache.cassandra.cql3.QueryOptions;\n import org.apache.cassandra.cql3.functions.Function;\n import org.apache.cassandra.cql3.restrictions.SingleColumnRestriction.ContainsRestriction;\n import org.apache.cassandra.db.filter.RowFilter;\n import org.apache.cassandra.exceptions.InvalidRequestException;\n+import org.apache.cassandra.index.Index;\n import org.apache.cassandra.index.IndexRegistry;\n-import org.apache.commons.lang3.builder.ToStringBuilder;\n-import org.apache.commons.lang3.builder.ToStringStyle;\n+import org.apache.cassandra.schema.ColumnMetadata;\n \n /**\n  * Sets of column restrictions.\n  *\n  * <p>This class is immutable.</p>\n  */\n-final class RestrictionSet implements Restrictions, Iterable<SingleRestriction>\n+public abstract class RestrictionSet implements Restrictions\n {\n     /**\n      * The comparator used to sort the <code>Restriction</code>s.\n      */\n-    private static final Comparator<ColumnMetadata> COLUMN_DEFINITION_COMPARATOR = new Comparator<ColumnMetadata>()\n+    private static final Comparator<ColumnMetadata> COLUMN_DEFINITION_COMPARATOR = Comparator.comparingInt(ColumnMetadata::position).thenComparing(column -> column.name.bytes);\n+\n+    private static final class EmptyRestrictionSet extends RestrictionSet\n     {\n+        private static final EmptyRestrictionSet INSTANCE = new EmptyRestrictionSet();\n+\n+        private EmptyRestrictionSet()\n+        {\n+        }\n+\n         @Override\n-        public int compare(ColumnMetadata column, ColumnMetadata otherColumn)\n+        public void addToRowFilter(RowFilter filter, IndexRegistry indexRegistry, QueryOptions options) throws InvalidRequestException\n         {\n-            int value = Integer.compare(column.position(), otherColumn.position());\n-            return value != 0 ? value : column.name.bytes.compareTo(otherColumn.name.bytes);\n         }\n-    };\n \n-    private static final TreeMap<ColumnMetadata, SingleRestriction> EMPTY = new TreeMap<>(COLUMN_DEFINITION_COMPARATOR);\n+        @Override\n+        public List<ColumnMetadata> getColumnDefs()\n+        {\n+            return Collections.EMPTY_LIST;\n+        }\n \n-    /**\n-     * The restrictions per column.\n-     */\n-    protected final TreeMap<ColumnMetadata, SingleRestriction> restrictions;\n+        @Override\n+        public void addFunctionsTo(List<Function> functions)\n+        {\n+        }\n \n-    /**\n-     * {@code true} if it contains multi-column restrictions, {@code false} otherwise.\n-     */\n-    private final boolean hasMultiColumnRestrictions;\n+        @Override\n+        public boolean isEmpty()\n+        {\n+            return true;\n+        }\n \n-    private final boolean hasIn;\n-    private final boolean hasContains;\n-    private final boolean hasSlice;\n-    private final boolean hasOnlyEqualityRestrictions;\n+        @Override\n+        public int size()\n+        {\n+            return 0;\n+        }\n \n-    public RestrictionSet()\n-    {\n-        this(EMPTY, false,\n-             false,\n-             false,\n-             false,\n-             true);\n-    }\n+        @Override\n+        public boolean hasRestrictionFor(ColumnMetadata.Kind kind)\n+        {\n+            return false;\n+        }\n \n-    private RestrictionSet(TreeMap<ColumnMetadata, SingleRestriction> restrictions,\n-                           boolean hasMultiColumnRestrictions,\n-                           boolean hasIn,\n-                           boolean hasContains,\n-                           boolean hasSlice,\n-                           boolean hasOnlyEqualityRestrictions)\n-    {\n-        this.restrictions = restrictions;\n-        this.hasMultiColumnRestrictions = hasMultiColumnRestrictions;\n-        this.hasIn = hasIn;\n-        this.hasContains = hasContains;\n-        this.hasSlice = hasSlice;\n-        this.hasOnlyEqualityRestrictions = hasOnlyEqualityRestrictions;\n-    }\n+        @Override\n+        public Set<Restriction> getRestrictions(ColumnMetadata columnDef)\n+        {\n+            return Collections.emptySet();\n+        }\n \n-    @Override\n-    public void addRowFilterTo(RowFilter filter, IndexRegistry indexRegistry, QueryOptions options) throws InvalidRequestException\n-    {\n-        for (Restriction restriction : restrictions.values())\n-            restriction.addRowFilterTo(filter, indexRegistry, options);\n-    }\n+        @Override\n+        public boolean hasSupportingIndex(IndexRegistry indexRegistry)\n+        {\n+            return false;\n+        }\n \n-    @Override\n-    public List<ColumnMetadata> getColumnDefs()\n-    {\n-        return new ArrayList<>(restrictions.keySet());\n-    }\n+        @Override\n+        public boolean needsFiltering(Index.Group indexGroup)\n+        {\n+            return false;\n+        }\n \n-    @Override\n-    public void addFunctionsTo(List<Function> functions)\n-    {\n-        for (Restriction restriction : this)\n-            restriction.addFunctionsTo(functions);\n-    }\n+        @Override\n+        public ColumnMetadata getFirstColumn()\n+        {\n+            return null;\n+        }\n \n-    @Override\n-    public boolean isEmpty()\n-    {\n-        return restrictions.isEmpty();\n-    }\n+        @Override\n+        public ColumnMetadata getLastColumn()\n+        {\n+            return null;\n+        }\n \n-    @Override\n-    public int size()\n-    {\n-        return restrictions.size();\n-    }\n+        @Override\n+        public SingleRestriction lastRestriction()\n+        {\n+            return null;\n+        }\n \n-    /**\n-     * Checks if one of the restrictions applies to a column of the specific kind.\n-     * @param kind the column kind\n-     * @return {@code true} if one of the restrictions applies to a column of the specific kind, {@code false} otherwise.\n-     */\n-    public boolean hasRestrictionFor(ColumnMetadata.Kind kind)\n-    {\n-        for (ColumnMetadata column : restrictions.keySet())\n+        @Override\n+        public boolean hasMultipleContains()\n         {\n-            if (column.kind == kind)\n-                return true;\n+            return false;\n         }\n-        return false;\n-    }\n \n-    /**\n-     * Adds the specified restriction to this set of restrictions.\n-     *\n-     * @param restriction the restriction to add\n-     * @return the new set of restrictions\n-     */\n-    public RestrictionSet addRestriction(SingleRestriction restriction)\n-    {\n-        // RestrictionSet is immutable so we need to clone the restrictions map.\n-        TreeMap<ColumnMetadata, SingleRestriction> newRestricitons = new TreeMap<>(this.restrictions);\n-\n-        boolean newHasIn = hasIn || restriction.isIN();\n-        boolean newHasContains = hasContains || restriction.isContains();\n-        boolean newHasSlice = hasSlice || restriction.isSlice();\n-        boolean newHasOnlyEqualityRestrictions = hasOnlyEqualityRestrictions && (restriction.isEQ() || restriction.isIN());\n-\n-        return new RestrictionSet(mergeRestrictions(newRestricitons, restriction),\n-                                  hasMultiColumnRestrictions || restriction.isMultiColumn(),\n-                                  newHasIn,\n-                                  newHasContains,\n-                                  newHasSlice,\n-                                  newHasOnlyEqualityRestrictions);\n+        @Override\n+        public List<SingleRestriction> restrictions()\n+        {\n+            return Collections.EMPTY_LIST;\n+        }\n+\n+        @Override\n+        public boolean hasMultiColumnSlice()\n+        {\n+            return false;\n+        }\n     }\n \n-    private TreeMap<ColumnMetadata, SingleRestriction> mergeRestrictions(TreeMap<ColumnMetadata, SingleRestriction> restrictions,\n-                                                                         SingleRestriction restriction)\n+    private static final class DefaultRestrictionSet extends RestrictionSet\n     {\n-        Collection<ColumnMetadata> columnDefs = restriction.getColumnDefs();\n-        Set<SingleRestriction> existingRestrictions = getRestrictions(columnDefs);\n \n-        if (existingRestrictions.isEmpty())\n-        {\n-            for (ColumnMetadata columnDef : columnDefs)\n-                restrictions.put(columnDef, restriction);\n-        }\n-        else\n+        /**\n+         * The keys from the 'restrictions' parameter to the\n+         */\n+        private final List<ColumnMetadata> restrictionsKeys;\n+        /**\n+         * The values as returned from {@link #restrictions()}.\n+         */\n+        private final List<SingleRestriction> restrictionsValues;\n+        private final Map<ColumnMetadata, SingleRestriction> restrictionsHashMap;\n+        private final int hasBitmap;\n+        private final int restrictionForKindBitmap;\n+        private static final int maskHasContains = 1;\n+        private static final int maskHasSlice = 2;\n+        private static final int maskHasIN = 4;\n+        private static final int maskHasOnlyEqualityRestrictions = 8;\n+        private static final int maskHasMultiColumnSlice = 16;\n+        private static final int maskHasMultipleContains = 32;\n+\n+        private DefaultRestrictionSet(Map<ColumnMetadata, SingleRestriction> restrictions,\n+                                      boolean hasMultiColumnRestrictions)\n         {\n-            for (SingleRestriction existing : existingRestrictions)\n+            this.restrictionsKeys = new ArrayList<>(restrictions.keySet());\n+            restrictionsKeys.sort(COLUMN_DEFINITION_COMPARATOR);\n+\n+            List<SingleRestriction> sortedRestrictions = new ArrayList<>();\n+\n+            int numberOfContains = 0;\n+            int restrictionForBitmap = 0;\n+            int bitmap = maskHasOnlyEqualityRestrictions;\n+\n+            SingleRestriction previous = null;\n+            for (int i = 0; i < restrictionsKeys.size(); i++)\n             {\n-                SingleRestriction newRestriction = mergeRestrictions(existing, restriction);\n+                ColumnMetadata col = restrictionsKeys.get(i);\n+                SingleRestriction singleRestriction = restrictions.get(col);\n+\n+                if (singleRestriction.isContains())\n+                {\n+                    bitmap |= maskHasContains;\n+                    ContainsRestriction contains = (ContainsRestriction) singleRestriction;\n+                    numberOfContains += (contains.numberOfValues() + contains.numberOfKeys() + contains.numberOfEntries());\n+                }\n+\n+                if (hasMultiColumnRestrictions)\n+                {\n+                    if (singleRestriction.equals(previous))\n+                        continue;\n+                    previous = singleRestriction;\n+                }\n+\n+                restrictionForBitmap |= 1 << col.kind.ordinal();\n \n-                for (ColumnMetadata columnDef : columnDefs)\n-                    restrictions.put(columnDef, newRestriction);\n+                sortedRestrictions.add(singleRestriction);\n+\n+                if (singleRestriction.isSlice())\n+                {\n+                    bitmap |= maskHasSlice;\n+                    if (singleRestriction.isMultiColumn())\n+                        bitmap |= maskHasMultiColumnSlice;\n+                }\n+\n+                if (singleRestriction.isIN())\n+                    bitmap |= maskHasIN;\n+                else if (!singleRestriction.isEQ())\n+                    bitmap &= ~maskHasOnlyEqualityRestrictions;\n             }\n+            this.hasBitmap = bitmap | (numberOfContains > 1 ? maskHasMultipleContains : 0);\n+            this.restrictionForKindBitmap = restrictionForBitmap;\n+\n+            this.restrictionsValues = Collections.unmodifiableList(sortedRestrictions);\n+            this.restrictionsHashMap = restrictions;\n         }\n \n-        return restrictions;\n-    }\n+        @Override\n+        public void addToRowFilter(RowFilter filter,\n+                                   IndexRegistry indexRegistry,\n+                                   QueryOptions options) throws InvalidRequestException\n+        {\n+            for (SingleRestriction restriction : restrictionsHashMap.values())\n+                restriction.addToRowFilter(filter, indexRegistry, options);\n+        }\n \n-    @Override\n-    public Set<Restriction> getRestrictions(ColumnMetadata columnDef)\n-    {\n-        Restriction existing = restrictions.get(columnDef);\n-        return existing == null ? Collections.emptySet() : Collections.singleton(existing);\n-    }\n+        @Override\n+        public List<ColumnMetadata> getColumnDefs()\n+        {\n+            return restrictionsKeys;\n+        }\n \n-    /**\n-     * Returns all the restrictions applied to the specified columns.\n-     *\n-     * @param columnDefs the column definitions\n-     * @return all the restrictions applied to the specified columns\n-     */\n-    private Set<SingleRestriction> getRestrictions(Collection<ColumnMetadata> columnDefs)\n-    {\n-        Set<SingleRestriction> set = new HashSet<>();\n-        for (ColumnMetadata columnDef : columnDefs)\n+        @Override\n+        public void addFunctionsTo(List<Function> functions)\n         {\n-            SingleRestriction existing = restrictions.get(columnDef);\n-            if (existing != null)\n-                set.add(existing);\n+            for (int i = 0; i < restrictionsValues.size(); i++)\n+                restrictionsValues.get(i).addFunctionsTo(functions);\n         }\n-        return set;\n-    }\n \n-    @Override\n-    public final boolean hasSupportingIndex(IndexRegistry indexRegistry)\n-    {\n-        for (Restriction restriction : restrictions.values())\n+        @Override\n+        public boolean isEmpty()\n         {\n-            if (restriction.hasSupportingIndex(indexRegistry))\n-                return true;\n+            return false;\n         }\n-        return false;\n-    }\n \n-    /**\n-     * Returns the column after the specified one.\n-     *\n-     * @param columnDef the column for which the next one need to be found\n-     * @return the column after the specified one.\n-     */\n-    ColumnMetadata nextColumn(ColumnMetadata columnDef)\n-    {\n-        return restrictions.tailMap(columnDef, false).firstKey();\n-    }\n+        @Override\n+        public int size()\n+        {\n+            return restrictionsKeys.size();\n+        }\n \n-    @Override\n-    public ColumnMetadata getFirstColumn()\n-    {\n-        return isEmpty() ? null : this.restrictions.firstKey();\n-    }\n+        @Override\n+        public boolean hasRestrictionFor(ColumnMetadata.Kind kind)\n+        {\n+            return 0 != (restrictionForKindBitmap & 1 << kind.ordinal());\n+        }\n \n-    @Override\n-    public ColumnMetadata getLastColumn()\n-    {\n-        return isEmpty() ? null : this.restrictions.lastKey();\n+        @Override\n+        public Set<Restriction> getRestrictions(ColumnMetadata columnDef)\n+        {\n+            Restriction existing = restrictionsHashMap.get(columnDef);\n+            return existing == null ? Collections.emptySet() : Collections.singleton(existing);\n+        }\n+\n+        @Override\n+        public boolean hasSupportingIndex(IndexRegistry indexRegistry)\n+        {\n+            for (SingleRestriction restriction : restrictionsHashMap.values())\n+                if (restriction.hasSupportingIndex(indexRegistry))\n+                    return true;\n+            return false;\n+        }\n+\n+        @Override\n+        public boolean needsFiltering(Index.Group indexGroup)\n+        {\n+            for (SingleRestriction restriction : restrictionsHashMap.values())\n+                if (restriction.needsFiltering(indexGroup))\n+                    return true;\n+\n+            return false;\n+        }\n+\n+        @Override\n+        public ColumnMetadata getFirstColumn()\n+        {\n+            return this.restrictionsKeys.get(0);\n+        }\n+\n+        @Override\n+        public ColumnMetadata getLastColumn()\n+        {\n+            return this.restrictionsKeys.get(this.restrictionsKeys.size() - 1);\n+        }\n+\n+        @Override\n+        public SingleRestriction lastRestriction()\n+        {\n+            return this.restrictionsValues.get(this.restrictionsValues.size() - 1);\n+        }\n+\n+        @Override\n+        public boolean hasMultipleContains()\n+        {\n+            return 0 != (hasBitmap & maskHasMultipleContains);\n+        }\n+\n+        @Override\n+        public List<SingleRestriction> restrictions()\n+        {\n+            return restrictionsValues;\n+        }\n+\n+        @Override\n+        public boolean hasIN()\n+        {\n+            return 0 != (hasBitmap & maskHasIN);\n+        }\n+\n+        @Override\n+        public boolean hasContains()\n+        {\n+            return 0 != (hasBitmap & maskHasContains);\n+        }\n+\n+        @Override\n+        public boolean hasSlice()\n+        {\n+            return 0 != (hasBitmap & maskHasSlice);\n+        }\n+\n+        @Override\n+        public boolean hasMultiColumnSlice()\n+        {\n+            return 0 != (hasBitmap & maskHasMultiColumnSlice);\n+        }\n+\n+        @Override\n+        public boolean hasOnlyEqualityRestrictions()\n+        {\n+            return 0 != (hasBitmap & maskHasOnlyEqualityRestrictions);\n+        }\n     }\n \n     /**\n-     * Returns the last restriction.\n-     *\n-     * @return the last restriction.\n+     * Checks if one of the restrictions applies to a column of the specific kind.\n+     * @param kind the column kind\n+     * @return {@code true} if one of the restrictions applies to a column of the specific kind, {@code false} otherwise.\n      */\n-    SingleRestriction lastRestriction()\n-    {\n-        return isEmpty() ? null : this.restrictions.lastEntry().getValue();\n-    }\n+    public abstract boolean hasRestrictionFor(ColumnMetadata.Kind kind);\n \n     /**\n-     * Merges the two specified restrictions.\n-     *\n-     * @param restriction the first restriction\n-     * @param otherRestriction the second restriction\n-     * @return the merged restriction\n-     * @throws InvalidRequestException if the two restrictions cannot be merged\n+     * Returns the last restriction.\n      */\n-    private static SingleRestriction mergeRestrictions(SingleRestriction restriction,\n-                                                       SingleRestriction otherRestriction)\n-    {\n-        return restriction == null ? otherRestriction\n-                                   : restriction.mergeWith(otherRestriction);\n-    }\n+    public abstract SingleRestriction lastRestriction();\n \n     /**\n      * Checks if the restrictions contains multiple contains, contains key, or map[key] = value.\n      *\n-     * @return <code>true</code> if the restrictions contains multiple contains, contains key, or ,\n+     * @return <code>true</code> if the restrictions contain multiple contains, contains key, or ,\n      * map[key] = value; <code>false</code> otherwise\n      */\n-    public final boolean hasMultipleContains()\n-    {\n-        int numberOfContains = 0;\n-        for (SingleRestriction restriction : restrictions.values())\n-        {\n-            if (restriction.isContains())\n-            {\n-                ContainsRestriction contains = (ContainsRestriction) restriction;\n-                numberOfContains += (contains.numberOfValues() + contains.numberOfKeys() + contains.numberOfEntries());\n-            }\n-        }\n-        return numberOfContains > 1;\n-    }\n+    public abstract boolean hasMultipleContains();\n \n-    @Override\n-    public Iterator<SingleRestriction> iterator()\n-    {\n-        Iterator<SingleRestriction> iterator = restrictions.values().iterator();\n-        return hasMultiColumnRestrictions ? new DistinctIterator<>(iterator) : iterator;\n-    }\n+    public abstract List<SingleRestriction> restrictions();\n \n     /**\n-     * Checks if any of the underlying restriction is an IN.\n-     * @return <code>true</code> if any of the underlying restriction is an IN, <code>false</code> otherwise\n+     * Checks if the restrictions contains multiple contains, contains key, or map[key] = value.\n+     *\n+     * @return <code>true</code> if the restrictions contains multiple contains, contains key, or ,\n+     * map[key] = value; <code>false</code> otherwise\n      */\n-    public final boolean hasIN()\n-    {\n-        return hasIn;\n-    }\n-\n-    public boolean hasContains()\n-    {\n-        return hasContains;\n-    }\n+    public abstract boolean hasMultiColumnSlice();\n \n-    public final boolean hasSlice()\n+    public static Builder builder()\n     {\n-        return hasSlice;\n+        return new Builder();\n     }\n \n-    /**\n-     * Checks if all of the underlying restrictions are EQ or IN restrictions.\n-     *\n-     * @return <code>true</code> if all of the underlying restrictions are EQ or IN restrictions,\n-     * <code>false</code> otherwise\n-     */\n-    public final boolean hasOnlyEqualityRestrictions()\n+    public static final class Builder\n     {\n-        return hasOnlyEqualityRestrictions;\n-    }\n+        private final Map<ColumnMetadata, SingleRestriction> newRestrictions = new HashMap<>();\n+        private boolean multiColumn = false;\n \n-    /**\n-     * {@code Iterator} decorator that removes duplicates in an ordered one.\n-     *\n-     * @param iterator the decorated iterator\n-     * @param <E> the iterator element type.\n-     */\n-    private static final class DistinctIterator<E> extends AbstractIterator<E>\n-    {\n-        /**\n-         * The decorated iterator.\n-         */\n-        private final Iterator<E> iterator;\n+        private ColumnMetadata lastRestrictionColumn;\n+        private SingleRestriction lastRestriction;\n \n-        /**\n-         * The previous element.\n-         */\n-        private E previous;\n+        private Builder()\n+        {\n+        }\n \n-        public DistinctIterator(Iterator<E> iterator)\n+        public void addRestriction(SingleRestriction restriction)\n         {\n-            this.iterator = iterator;\n+            List<ColumnMetadata> columnDefs = restriction.getColumnDefs();\n+            Set<SingleRestriction> existingRestrictions = getRestrictions(newRestrictions, columnDefs);\n+\n+            if (existingRestrictions.isEmpty())\n+            {\n+                addRestrictionForColumns(columnDefs, restriction);\n+            }\n+            else\n+            {\n+                for (SingleRestriction existing : existingRestrictions)\n+                {\n+                    SingleRestriction newRestriction = existing.mergeWith(restriction);\n+\n+                    addRestrictionForColumns(columnDefs, newRestriction);\n+                }\n+            }\n         }\n \n-        protected E computeNext()\n+        private void addRestrictionForColumns(List<ColumnMetadata> columnDefs, SingleRestriction restriction)\n         {\n-            while(iterator.hasNext())\n+            for (int i = 0; i < columnDefs.size(); i++)\n             {\n-                E next = iterator.next();\n-                if (!next.equals(previous))\n+                ColumnMetadata column = columnDefs.get(i);\n+                if (lastRestrictionColumn == null || COLUMN_DEFINITION_COMPARATOR.compare(lastRestrictionColumn, column) < 0)\n                 {\n-                    previous = next;\n-                    return next;\n+                    lastRestrictionColumn = column;\n+                    lastRestriction = restriction;\n                 }\n+                newRestrictions.put(column, restriction);\n             }\n-            return endOfData();\n+\n+            multiColumn |= restriction.isMultiColumn();\n+        }\n+\n+        private static Set<SingleRestriction> getRestrictions(Map<ColumnMetadata, SingleRestriction> restrictions,\n+                                                              List<ColumnMetadata> columnDefs)\n+        {\n+            Set<SingleRestriction> set = new HashSet<>();\n+            for (int i = 0; i < columnDefs.size(); i++)\n+            {\n+                SingleRestriction existing = restrictions.get(columnDefs.get(i));\n+                if (existing != null)\n+                    set.add(existing);\n+            }\n+            return set;\n+        }\n+\n+        public RestrictionSet build()\n+        {\n+            return isEmpty() ? EmptyRestrictionSet.INSTANCE : new DefaultRestrictionSet(newRestrictions, multiColumn);\n+        }\n+\n+        public boolean isEmpty()\n+        {\n+            return newRestrictions.isEmpty();\n+        }\n+\n+        public SingleRestriction lastRestriction()\n+        {\n+            return lastRestriction;\n+        }\n+\n+        public ColumnMetadata nextColumn(ColumnMetadata columnDef)\n+        {\n+            // This method is only invoked in the statement-preparation-phase to construct an error message.\n+            NavigableSet<ColumnMetadata> columns = new TreeSet<>(COLUMN_DEFINITION_COMPARATOR);\n+            columns.addAll(newRestrictions.keySet());\n+            return columns.tailSet(columnDef, false).first();\n         }\n-    }\n-    \n-    @Override\n-    public String toString()\n-    {\n-        return ToStringBuilder.reflectionToString(this, ToStringStyle.SHORT_PREFIX_STYLE);\n     }\n }"
  },
  {
    "sha": "967e1bad8f3cb0ec0fcd01631153479c6d048aff",
    "filename": "src/java/org/apache/cassandra/cql3/restrictions/RestrictionSetWrapper.java",
    "status": "modified",
    "additions": 27,
    "deletions": 12,
    "changes": 39,
    "blob_url": "https://github.com/datastax/cassandra/blob/782ad0aa1ea82a157aee5cfc9def7fac3ef00dac/src/java/org/apache/cassandra/cql3/restrictions/RestrictionSetWrapper.java",
    "raw_url": "https://github.com/datastax/cassandra/raw/782ad0aa1ea82a157aee5cfc9def7fac3ef00dac/src/java/org/apache/cassandra/cql3/restrictions/RestrictionSetWrapper.java",
    "contents_url": "https://api.github.com/repos/datastax/cassandra/contents/src/java/org/apache/cassandra/cql3/restrictions/RestrictionSetWrapper.java?ref=782ad0aa1ea82a157aee5cfc9def7fac3ef00dac",
    "patch": "@@ -19,10 +19,9 @@\n \n import java.util.List;\n import java.util.Set;\n+import java.util.function.Consumer;\n \n-import org.apache.commons.lang3.builder.ToStringBuilder;\n-import org.apache.commons.lang3.builder.ToStringStyle;\n-\n+import org.apache.cassandra.index.Index;\n import org.apache.cassandra.schema.ColumnMetadata;\n import org.apache.cassandra.cql3.QueryOptions;\n import org.apache.cassandra.cql3.functions.Function;\n@@ -40,23 +39,26 @@\n      */\n     protected final RestrictionSet restrictions;\n \n-    public RestrictionSetWrapper(RestrictionSet restrictions)\n+    RestrictionSetWrapper(RestrictionSet restrictions)\n     {\n         this.restrictions = restrictions;\n     }\n \n-    public void addRowFilterTo(RowFilter filter,\n+    @Override\n+    public void addToRowFilter(RowFilter filter,\n                                IndexRegistry indexRegistry,\n                                QueryOptions options)\n     {\n-        restrictions.addRowFilterTo(filter, indexRegistry, options);\n+        restrictions.addToRowFilter(filter, indexRegistry, options);\n     }\n \n+    @Override\n     public List<ColumnMetadata> getColumnDefs()\n     {\n         return restrictions.getColumnDefs();\n     }\n \n+    @Override\n     public void addFunctionsTo(List<Function> functions)\n     {\n         restrictions.addFunctionsTo(functions);\n@@ -67,54 +69,67 @@ public boolean isEmpty()\n         return restrictions.isEmpty();\n     }\n \n+    public List<SingleRestriction> restrictions()\n+    {\n+        return restrictions.restrictions();\n+    }\n+\n     public int size()\n     {\n         return restrictions.size();\n     }\n \n+    @Override\n     public boolean hasSupportingIndex(IndexRegistry indexRegistry)\n     {\n         return restrictions.hasSupportingIndex(indexRegistry);\n     }\n \n+    @Override\n+    public boolean needsFiltering(Index.Group indexGroup)\n+    {\n+        return restrictions.needsFiltering(indexGroup);\n+    }\n+\n+    @Override\n     public ColumnMetadata getFirstColumn()\n     {\n         return restrictions.getFirstColumn();\n     }\n \n+    @Override\n     public ColumnMetadata getLastColumn()\n     {\n         return restrictions.getLastColumn();\n     }\n \n+    @Override\n     public boolean hasIN()\n     {\n         return restrictions.hasIN();\n     }\n \n+    @Override\n     public boolean hasContains()\n     {\n         return restrictions.hasContains();\n     }\n \n+    @Override\n     public boolean hasSlice()\n     {\n         return restrictions.hasSlice();\n     }\n \n+    @Override\n     public boolean hasOnlyEqualityRestrictions()\n     {\n         return restrictions.hasOnlyEqualityRestrictions();\n     }\n \n+    @Override\n     public Set<Restriction> getRestrictions(ColumnMetadata columnDef)\n     {\n         return restrictions.getRestrictions(columnDef);\n     }\n-    \n-    @Override\n-    public String toString()\n-    {\n-        return ToStringBuilder.reflectionToString(this, ToStringStyle.SHORT_PREFIX_STYLE);\n-    }\n }"
  },
  {
    "sha": "8a016835fffbedf1cca2a8a7fc5b8fffee80fc36",
    "filename": "src/java/org/apache/cassandra/cql3/restrictions/Restrictions.java",
    "status": "modified",
    "additions": 17,
    "deletions": 4,
    "changes": 21,
    "blob_url": "https://github.com/datastax/cassandra/blob/782ad0aa1ea82a157aee5cfc9def7fac3ef00dac/src/java/org/apache/cassandra/cql3/restrictions/Restrictions.java",
    "raw_url": "https://github.com/datastax/cassandra/raw/782ad0aa1ea82a157aee5cfc9def7fac3ef00dac/src/java/org/apache/cassandra/cql3/restrictions/Restrictions.java",
    "contents_url": "https://api.github.com/repos/datastax/cassandra/contents/src/java/org/apache/cassandra/cql3/restrictions/Restrictions.java?ref=782ad0aa1ea82a157aee5cfc9def7fac3ef00dac",
    "patch": "@@ -52,24 +52,37 @@\n      * Checks if any of the underlying restriction is an IN.\n      * @return <code>true</code> if any of the underlying restriction is an IN, <code>false</code> otherwise\n      */\n-    public boolean hasIN();\n+    default public boolean hasIN()\n+    {\n+        return false;\n+    }\n \n     /**\n      * Checks if any of the underlying restrictions is a CONTAINS / CONTAINS KEY restriction.\n      * @return <code>true</code> if any of the underlying restrictions is CONTAINS, <code>false</code> otherwise\n      */\n-    public boolean hasContains();\n+    default public boolean hasContains()\n+    {\n+        return false;\n+    }\n+\n     /**\n      * Checks if any of the underlying restrictions is a slice.\n      * @return <code>true</code> if any of the underlying restrictions is a slice, <code>false</code> otherwise\n      */\n-    public boolean hasSlice();\n+    default public boolean hasSlice()\n+    {\n+        return false;\n+    }\n \n     /**\n      * Checks if all of the underlying restrictions are EQ or IN restrictions.\n      *\n      * @return <code>true</code> if all of the underlying restrictions are EQ or IN restrictions,\n      * <code>false</code> otherwise\n      */\n-    public boolean hasOnlyEqualityRestrictions();\n+    default public boolean hasOnlyEqualityRestrictions()\n+    {\n+        return true;\n+    }\n }"
  },
  {
    "sha": "0af4d2e730e1fed4d76a6589ba475e11b6e21332",
    "filename": "src/java/org/apache/cassandra/cql3/restrictions/SingleColumnRestriction.java",
    "status": "modified",
    "additions": 27,
    "deletions": 7,
    "changes": 34,
    "blob_url": "https://github.com/datastax/cassandra/blob/782ad0aa1ea82a157aee5cfc9def7fac3ef00dac/src/java/org/apache/cassandra/cql3/restrictions/SingleColumnRestriction.java",
    "raw_url": "https://github.com/datastax/cassandra/raw/782ad0aa1ea82a157aee5cfc9def7fac3ef00dac/src/java/org/apache/cassandra/cql3/restrictions/SingleColumnRestriction.java",
    "contents_url": "https://api.github.com/repos/datastax/cassandra/contents/src/java/org/apache/cassandra/cql3/restrictions/SingleColumnRestriction.java?ref=782ad0aa1ea82a157aee5cfc9def7fac3ef00dac",
    "patch": "@@ -21,6 +21,7 @@\n import java.util.ArrayList;\n import java.util.Collections;\n import java.util.List;\n+import java.util.function.Consumer;\n \n import org.apache.cassandra.schema.ColumnMetadata;\n import org.apache.cassandra.cql3.*;\n@@ -31,6 +32,8 @@\n import org.apache.cassandra.db.filter.RowFilter;\n import org.apache.cassandra.index.Index;\n import org.apache.cassandra.index.IndexRegistry;\n+import org.apache.cassandra.serializers.ListSerializer;\n+import org.apache.cassandra.transport.ProtocolVersion;\n import org.apache.cassandra.utils.ByteBufferUtil;\n import org.apache.cassandra.utils.Pair;\n \n@@ -80,6 +83,16 @@ public boolean hasSupportingIndex(IndexRegistry indexRegistry)\n         return false;\n     }\n \n+    @Override\n+    public boolean needsFiltering(Index.Group indexGroup)\n+    {\n+        for (Index index : indexGroup.getIndexes())\n+            if (isSupportedBy(index))\n+                return false;\n+\n+        return true;\n+    }\n+\n     @Override\n     public final SingleRestriction mergeWith(SingleRestriction otherRestriction)\n     {\n@@ -150,7 +163,7 @@ MultiColumnRestriction toMultiColumnRestriction()\n         }\n \n         @Override\n-        public void addRowFilterTo(RowFilter filter,\n+        public void addToRowFilter(RowFilter filter,\n                                    IndexRegistry indexRegistry,\n                                    QueryOptions options)\n         {\n@@ -214,11 +227,18 @@ public MultiCBuilder appendTo(MultiCBuilder builder, QueryOptions options)\n         }\n \n         @Override\n-        public void addRowFilterTo(RowFilter filter,\n+        public void addToRowFilter(RowFilter filter,\n                                    IndexRegistry indexRegistry,\n                                    QueryOptions options)\n         {\n-            throw invalidRequest(\"IN restrictions are not supported on indexed columns\");\n+            List<ByteBuffer> values = getValues(options);\n+            for (ByteBuffer v : values)\n+            {\n+                checkNotNull(v, \"Invalid null value for column %s\", columnDef.name);\n+                checkBindValueSet(v, \"Invalid unset value for column %s\", columnDef.name);\n+            }\n+            ByteBuffer buffer = ListSerializer.pack(values, values.size(), ProtocolVersion.V3);\n+            filter.add(columnDef, Operator.IN, buffer);\n         }\n \n         @Override\n@@ -385,7 +405,7 @@ public SingleRestriction doMergeWith(SingleRestriction otherRestriction)\n         }\n \n         @Override\n-        public void addRowFilterTo(RowFilter filter, IndexRegistry indexRegistry, QueryOptions options)\n+        public void addToRowFilter(RowFilter filter, IndexRegistry indexRegistry, QueryOptions options)\n         {\n             for (Bound b : Bound.values())\n                 if (hasBound(b))\n@@ -475,7 +495,7 @@ public SingleRestriction doMergeWith(SingleRestriction otherRestriction)\n         }\n \n         @Override\n-        public void addRowFilterTo(RowFilter filter, IndexRegistry indexRegistry, QueryOptions options)\n+        public void addToRowFilter(RowFilter filter, IndexRegistry indexRegistry, QueryOptions options)\n         {\n             for (ByteBuffer value : bindAndGet(values, options))\n                 filter.add(columnDef, Operator.CONTAINS, value);\n@@ -614,7 +634,7 @@ MultiColumnRestriction toMultiColumnRestriction()\n         }\n \n         @Override\n-        public void addRowFilterTo(RowFilter filter,\n+        public void addToRowFilter(RowFilter filter,\n                                    IndexRegistry indexRegistry,\n                                    QueryOptions options)\n         {\n@@ -690,7 +710,7 @@ MultiColumnRestriction toMultiColumnRestriction()\n         }\n \n         @Override\n-        public void addRowFilterTo(RowFilter filter,\n+        public void addToRowFilter(RowFilter filter,\n                                    IndexRegistry indexRegistry,\n                                    QueryOptions options)\n         {"
  },
  {
    "sha": "1ac9d16d05039bc77869f5084a883626fa70a526",
    "filename": "src/java/org/apache/cassandra/cql3/restrictions/StatementRestrictions.java",
    "status": "modified",
    "additions": 245,
    "deletions": 108,
    "changes": 353,
    "blob_url": "https://github.com/datastax/cassandra/blob/782ad0aa1ea82a157aee5cfc9def7fac3ef00dac/src/java/org/apache/cassandra/cql3/restrictions/StatementRestrictions.java",
    "raw_url": "https://github.com/datastax/cassandra/raw/782ad0aa1ea82a157aee5cfc9def7fac3ef00dac/src/java/org/apache/cassandra/cql3/restrictions/StatementRestrictions.java",
    "contents_url": "https://api.github.com/repos/datastax/cassandra/contents/src/java/org/apache/cassandra/cql3/restrictions/StatementRestrictions.java?ref=782ad0aa1ea82a157aee5cfc9def7fac3ef00dac",
    "patch": "@@ -19,8 +19,12 @@\n \n import java.nio.ByteBuffer;\n import java.util.*;\n+import java.util.function.Consumer;\n \n import com.google.common.base.Joiner;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableSet;\n+import com.google.common.collect.Iterables;\n \n import org.apache.cassandra.cql3.*;\n import org.apache.cassandra.cql3.functions.Function;\n@@ -35,24 +39,30 @@\n import org.apache.cassandra.index.IndexRegistry;\n import org.apache.cassandra.schema.ColumnMetadata;\n import org.apache.cassandra.schema.TableMetadata;\n+import org.apache.cassandra.service.QueryState;\n import org.apache.cassandra.utils.btree.BTreeSet;\n \n-import org.apache.commons.lang3.builder.ToStringBuilder;\n-import org.apache.commons.lang3.builder.ToStringStyle;\n-\n-import static org.apache.cassandra.cql3.statements.RequestValidations.checkFalse;\n-import static org.apache.cassandra.cql3.statements.RequestValidations.checkNotNull;\n-import static org.apache.cassandra.cql3.statements.RequestValidations.invalidRequest;\n+import static org.apache.cassandra.cql3.statements.RequestValidations.*;\n \n /**\n  * The restrictions corresponding to the relations specified on the where-clause of CQL query.\n  */\n-public final class StatementRestrictions\n+public class StatementRestrictions\n {\n     public static final String REQUIRES_ALLOW_FILTERING_MESSAGE =\n-            \"Cannot execute this query as it might involve data filtering and \" +\n-            \"thus may have unpredictable performance. If you want to execute \" +\n-            \"this query despite the performance unpredictability, use ALLOW FILTERING\";\n+    \"Cannot execute this query as it might involve data filtering and \" +\n+    \"thus may have unpredictable performance. If you want to execute \" +\n+    \"this query despite the performance unpredictability, use ALLOW FILTERING\";\n+\n+    public static final String HAS_UNSUPPORTED_INDEX_RESTRICTION_MESSAGE_SINGLE =\n+    \"Column '%s' has an index but does not support the operators specified in the query. \" +\n+    \"If you want to execute this query despite the performance unpredictability, use ALLOW FILTERING\";\n+\n+    public static final String HAS_UNSUPPORTED_INDEX_RESTRICTION_MESSAGE_MULTI =\n+    \"Columns %s have indexes but do not support the operators specified in the query. \" +\n+    \"If you want to execute this query despite the performance unpredictability, use ALLOW FILTERING\";\n+\n+    public static final String INDEX_DOES_NOT_SUPPORT_LIKE_MESSAGE = \"Index on column %s does not support LIKE restrictions.\";\n \n     /**\n      * The type of statement\n@@ -67,34 +77,34 @@\n     /**\n      * Restrictions on partitioning columns\n      */\n-    private PartitionKeyRestrictions partitionKeyRestrictions;\n+    protected final PartitionKeyRestrictions partitionKeyRestrictions;\n \n     /**\n      * Restrictions on clustering columns\n      */\n-    private ClusteringColumnRestrictions clusteringColumnsRestrictions;\n+    private final ClusteringColumnRestrictions clusteringColumnsRestrictions;\n \n     /**\n      * Restriction on non-primary key columns (i.e. secondary index restrictions)\n      */\n-    private RestrictionSet nonPrimaryKeyRestrictions;\n+    private final RestrictionSet nonPrimaryKeyRestrictions;\n \n-    private Set<ColumnMetadata> notNullColumns;\n+    private final ImmutableSet<ColumnMetadata> notNullColumns;\n \n     /**\n      * The restrictions used to build the row filter\n      */\n-    private final IndexRestrictions filterRestrictions = new IndexRestrictions();\n+    private final IndexRestrictions filterRestrictions;\n \n     /**\n      * <code>true</code> if the secondary index need to be queried, <code>false</code> otherwise\n      */\n-    private boolean usesSecondaryIndexing;\n+    protected boolean usesSecondaryIndexing;\n \n     /**\n      * Specify if the query will return a range of partition keys.\n      */\n-    private boolean isKeyRange;\n+    protected boolean isKeyRange;\n \n     /**\n      * <code>true</code> if nonPrimaryKeyRestrictions contains restriction on a regular column,\n@@ -118,10 +128,81 @@ private StatementRestrictions(StatementType type, TableMetadata table, boolean a\n     {\n         this.type = type;\n         this.table = table;\n-        this.partitionKeyRestrictions = new PartitionKeySingleRestrictionSet(table.partitionKeyAsClusteringComparator());\n-        this.clusteringColumnsRestrictions = new ClusteringColumnRestrictions(table, allowFiltering);\n-        this.nonPrimaryKeyRestrictions = new RestrictionSet();\n-        this.notNullColumns = new HashSet<>();\n+        this.partitionKeyRestrictions = PartitionKeySingleRestrictionSet.builder(table.partitionKeyAsClusteringComparator()).build();\n+        this.clusteringColumnsRestrictions = ClusteringColumnRestrictions.builder(table, allowFiltering).build();\n+        this.nonPrimaryKeyRestrictions = RestrictionSet.builder().build();\n+        this.notNullColumns = ImmutableSet.of();\n+        this.filterRestrictions = IndexRestrictions.of();\n+    }\n+\n+    private StatementRestrictions(StatementType type,\n+                                  TableMetadata table,\n+                                  PartitionKeyRestrictions partitionKeyRestrictions,\n+                                  ClusteringColumnRestrictions clusteringColumnsRestrictions,\n+                                  RestrictionSet nonPrimaryKeyRestrictions,\n+                                  ImmutableSet<ColumnMetadata> notNullColumns,\n+                                  boolean usesSecondaryIndexing,\n+                                  boolean isKeyRange,\n+                                  IndexRestrictions filterRestrictions)\n+    {\n+        this.type = type;\n+        this.table = table;\n+        this.partitionKeyRestrictions = partitionKeyRestrictions;\n+        this.clusteringColumnsRestrictions = clusteringColumnsRestrictions;\n+        this.nonPrimaryKeyRestrictions = nonPrimaryKeyRestrictions;\n+        this.notNullColumns = notNullColumns;\n+        this.usesSecondaryIndexing = usesSecondaryIndexing;\n+        this.isKeyRange = isKeyRange;\n+        this.filterRestrictions = filterRestrictions;\n+    }\n+\n+    /**\n+     * Adds the following restrictions to the index restrictions.\n+     *\n+     * @param restrictions the restrictions to add to the index restrictions\n+     * @return a new {@code StatementRestrictions} with the new index restrictions\n+     */\n+    public StatementRestrictions addIndexRestrictions(Restrictions restrictions)\n+    {\n+        IndexRestrictions newIndexRestrictions = IndexRestrictions.builder()\n+                                                                  .add(filterRestrictions)\n+                                                                  .add(restrictions)\n+                                                                  .build();\n+\n+        return new StatementRestrictions(type,\n+                                         table,\n+                                         partitionKeyRestrictions,\n+                                         clusteringColumnsRestrictions,\n+                                         nonPrimaryKeyRestrictions,\n+                                         notNullColumns,\n+                                         usesSecondaryIndexing,\n+                                         isKeyRange,\n+                                         newIndexRestrictions);\n+    }\n+\n+    /**\n+     * Adds the following external restrictions (mostly custom and user index expressions) to the index restrictions.\n+     *\n+     * @param restrictions the restrictions to add to the index restrictions\n+     * @return a new {@code StatementRestrictions} with the new index restrictions\n+     */\n+    public StatementRestrictions addExternalRestrictions(Iterable<CustomIndexExpression> restrictions)\n+    {\n+        IndexRestrictions.Builder newIndexRestrictions = IndexRestrictions.builder()\n+                                                                          .add(filterRestrictions);\n+\n+        for (CustomIndexExpression restriction : restrictions)\n+            newIndexRestrictions.add(restriction);\n+\n+        return new StatementRestrictions(type,\n+                                         table,\n+                                         partitionKeyRestrictions,\n+                                         clusteringColumnsRestrictions,\n+                                         nonPrimaryKeyRestrictions,\n+                                         notNullColumns,\n+                                         usesSecondaryIndexing,\n+                                         isKeyRange,\n+                                         newIndexRestrictions.build());\n     }\n \n     public StatementRestrictions(StatementType type,\n@@ -148,12 +229,22 @@ public StatementRestrictions(StatementType type,\n                                  boolean allowFiltering,\n                                  boolean forView)\n     {\n-        this(type, table, allowFiltering);\n+        this.type = type;\n+        this.table = table;\n \n         IndexRegistry indexRegistry = null;\n-        if (type.allowUseOfSecondaryIndices())\n+\n+        // We want to avoid opening the keyspace during view construction\n+        // since we're parsing these for restore and the base table or keyspace might not exist in the current schema.\n+        if (allowUseOfSecondaryIndices && type.allowUseOfSecondaryIndices())\n             indexRegistry = IndexRegistry.obtain(table);\n \n+        PartitionKeySingleRestrictionSet.Builder partitionKeyRestrictionSet = PartitionKeySingleRestrictionSet.builder(table.partitionKeyAsClusteringComparator());\n+        ClusteringColumnRestrictions.Builder clusteringColumnsRestrictionSet = ClusteringColumnRestrictions.builder(table, allowFiltering, indexRegistry);\n+        RestrictionSet.Builder nonPrimaryKeyRestrictionSet = RestrictionSet.builder();\n+\n+        ImmutableSet.Builder<ColumnMetadata> notNullColumnsBuilder = ImmutableSet.builder();\n+\n         /*\n          * WHERE clause. For a given entity, rules are:\n          *   - EQ relation conflicts with anything else (including a 2nd EQ)\n@@ -168,42 +259,68 @@ public StatementRestrictions(StatementType type,\n             if (relation.operator() == Operator.IS_NOT)\n             {\n                 if (!forView)\n-                    throw new InvalidRequestException(\"Unsupported restriction: \" + relation);\n+                    throw invalidRequest(\"Unsupported restriction: %s\", relation);\n \n-                this.notNullColumns.addAll(relation.toRestriction(table, boundNames).getColumnDefs());\n+                notNullColumnsBuilder.addAll(relation.toRestriction(table, boundNames).getColumnDefs());\n             }\n-            else if (relation.isLIKE())\n+            else\n             {\n                 Restriction restriction = relation.toRestriction(table, boundNames);\n \n-                if (!type.allowUseOfSecondaryIndices() || !restriction.hasSupportingIndex(indexRegistry))\n-                    throw new InvalidRequestException(String.format(\"LIKE restriction is only supported on properly \" +\n-                                                                    \"indexed columns. %s is not valid.\",\n-                                                                    relation.toString()));\n+                if (relation.isLIKE() && (!type.allowUseOfSecondaryIndices() || !restriction.hasSupportingIndex(indexRegistry)))\n+                {\n+                    if (getColumnsWithUnsupportedIndexRestrictions(table, ImmutableList.of(restriction)).isEmpty())\n+                    {\n+                        throw invalidRequest(\"LIKE restriction is only supported on properly indexed columns. %s is not valid.\", relation.toString());\n+                    }\n+                    else\n+                    {\n+                        throw invalidRequest(INDEX_DOES_NOT_SUPPORT_LIKE_MESSAGE, restriction.getFirstColumn());\n+                    }\n+                }\n \n-                addRestriction(restriction);\n-            }\n-            else\n-            {\n-                addRestriction(relation.toRestriction(table, boundNames));\n+                ColumnMetadata def = restriction.getFirstColumn();\n+                if (def.isPartitionKey())\n+                {\n+                    partitionKeyRestrictionSet.addRestriction(restriction);\n+                }\n+                else if (def.isClusteringColumn())\n+                {\n+                    clusteringColumnsRestrictionSet.addRestriction(restriction);\n+                }\n+                else\n+                {\n+                    nonPrimaryKeyRestrictionSet.addRestriction((SingleRestriction) restriction);\n+                }\n             }\n         }\n \n-        hasRegularColumnsRestrictions = nonPrimaryKeyRestrictions.hasRestrictionFor(ColumnMetadata.Kind.REGULAR);\n+        this.partitionKeyRestrictions = partitionKeyRestrictionSet.build();\n+        this.clusteringColumnsRestrictions = clusteringColumnsRestrictionSet.build();\n+        this.nonPrimaryKeyRestrictions = nonPrimaryKeyRestrictionSet.build();\n+        this.notNullColumns = notNullColumnsBuilder.build();\n+        this.hasRegularColumnsRestrictions = nonPrimaryKeyRestrictions.hasRestrictionFor(ColumnMetadata.Kind.REGULAR);\n \n         boolean hasQueriableClusteringColumnIndex = false;\n         boolean hasQueriableIndex = false;\n \n+        IndexRestrictions.Builder filterRestrictionsBuilder = IndexRestrictions.builder();\n+\n         if (allowUseOfSecondaryIndices)\n         {\n             if (whereClause.containsCustomExpressions())\n-                processCustomIndexExpressions(whereClause.expressions, boundNames, indexRegistry);\n+            {\n+                CustomIndexExpression customExpression = prepareCustomIndexExpression(whereClause.expressions,\n+                                                                                      boundNames,\n+                                                                                      indexRegistry);\n+                filterRestrictionsBuilder.add(customExpression);\n+            }\n \n             hasQueriableClusteringColumnIndex = clusteringColumnsRestrictions.hasSupportingIndex(indexRegistry);\n-            hasQueriableIndex = !filterRestrictions.getCustomIndexExpressions().isEmpty()\n-                    || hasQueriableClusteringColumnIndex\n-                    || partitionKeyRestrictions.hasSupportingIndex(indexRegistry)\n-                    || nonPrimaryKeyRestrictions.hasSupportingIndex(indexRegistry);\n+            hasQueriableIndex = whereClause.containsCustomExpressions()\n+                                || hasQueriableClusteringColumnIndex\n+                                || partitionKeyRestrictions.hasSupportingIndex(indexRegistry)\n+                                || nonPrimaryKeyRestrictions.hasSupportingIndex(indexRegistry);\n         }\n \n         // At this point, the select statement if fully constructed, but we still have a few things to validate\n@@ -212,7 +329,7 @@ else if (relation.isLIKE())\n         // Some but not all of the partition key columns have been specified;\n         // hence we need turn these restrictions into a row filter.\n         if (usesSecondaryIndexing || partitionKeyRestrictions.needFiltering(table))\n-            filterRestrictions.add(partitionKeyRestrictions);\n+            filterRestrictionsBuilder.add(partitionKeyRestrictions);\n \n         if (selectsOnlyStaticColumns && hasClusteringColumnsRestrictions())\n         {\n@@ -229,8 +346,6 @@ else if (relation.isLIKE())\n             if (type.isDelete() || type.isUpdate())\n                 throw invalidRequest(\"Invalid restrictions on clustering columns since the %s statement modifies only static columns\",\n                                      type);\n-            if (type.isSelect())\n-                throw invalidRequest(\"Cannot restrict clustering columns when selecting only static columns\");\n         }\n \n         processClusteringColumnsRestrictions(hasQueriableIndex,\n@@ -243,7 +358,7 @@ else if (relation.isLIKE())\n             usesSecondaryIndexing = true;\n \n         if (usesSecondaryIndexing || clusteringColumnsRestrictions.needFiltering())\n-            filterRestrictions.add(clusteringColumnsRestrictions);\n+            filterRestrictionsBuilder.add(clusteringColumnsRestrictions);\n \n         // Even if usesSecondaryIndexing is false at this point, we'll still have to use one if\n         // there is restrictions not covered by the PK.\n@@ -252,32 +367,40 @@ else if (relation.isLIKE())\n             if (!type.allowNonPrimaryKeyInWhereClause())\n             {\n                 Collection<ColumnIdentifier> nonPrimaryKeyColumns =\n-                        ColumnMetadata.toIdentifiers(nonPrimaryKeyRestrictions.getColumnDefs());\n+                ColumnMetadata.toIdentifiers(nonPrimaryKeyRestrictions.getColumnDefs());\n \n                 throw invalidRequest(\"Non PRIMARY KEY columns found in where clause: %s \",\n                                      Joiner.on(\", \").join(nonPrimaryKeyColumns));\n             }\n             if (hasQueriableIndex)\n                 usesSecondaryIndexing = true;\n             else if (!allowFiltering)\n-                throw invalidRequest(StatementRestrictions.REQUIRES_ALLOW_FILTERING_MESSAGE);\n+                throwRequiresAllowFilteringError(table);\n \n-            filterRestrictions.add(nonPrimaryKeyRestrictions);\n+            filterRestrictionsBuilder.add(nonPrimaryKeyRestrictions);\n         }\n \n+        filterRestrictions = filterRestrictionsBuilder.build();\n+\n         if (usesSecondaryIndexing)\n             validateSecondaryIndexSelections();\n     }\n \n-    private void addRestriction(Restriction restriction)\n+    public void throwRequiresAllowFilteringError(TableMetadata table)\n     {\n-        ColumnMetadata def = restriction.getFirstColumn();\n-        if (def.isPartitionKey())\n-            partitionKeyRestrictions = partitionKeyRestrictions.mergeWith(restriction);\n-        else if (def.isClusteringColumn())\n-            clusteringColumnsRestrictions = clusteringColumnsRestrictions.mergeWith(restriction);\n+        Set<ColumnMetadata> unsupported = getColumnsWithUnsupportedIndexRestrictions(table);\n+        if (unsupported.isEmpty())\n+        {\n+            throw invalidRequest(StatementRestrictions.REQUIRES_ALLOW_FILTERING_MESSAGE);\n+        }\n         else\n-            nonPrimaryKeyRestrictions = nonPrimaryKeyRestrictions.addRestriction((SingleRestriction) restriction);\n+        {\n+            // If there's an index on these columns but the restriction is not supported on this index, throw a more specific error message\n+            if (unsupported.size() == 1)\n+                throw invalidRequest(String.format(StatementRestrictions.HAS_UNSUPPORTED_INDEX_RESTRICTION_MESSAGE_SINGLE, unsupported.iterator().next()));\n+            else\n+                throw invalidRequest(String.format(StatementRestrictions.HAS_UNSUPPORTED_INDEX_RESTRICTION_MESSAGE_MULTI, unsupported));\n+        }\n     }\n \n     public void addFunctionsTo(List<Function> functions)\n@@ -323,7 +446,7 @@ public IndexRestrictions getIndexRestrictions()\n     /**\n      * @return the set of columns that have an IS NOT NULL restriction on them\n      */\n-    public Set<ColumnMetadata> notNullColumns()\n+    public ImmutableSet<ColumnMetadata> notNullColumns()\n     {\n         return notNullColumns;\n     }\n@@ -381,7 +504,7 @@ public boolean isColumnRestrictedByEq(ColumnMetadata columnDef)\n      * @param kind the column type\n      * @return the <code>Restrictions</code> for the specified type of columns\n      */\n-    private Restrictions getRestrictions(ColumnMetadata.Kind kind)\n+    protected Restrictions getRestrictions(ColumnMetadata.Kind kind)\n     {\n         switch (kind)\n         {\n@@ -401,7 +524,7 @@ public boolean usesSecondaryIndexing()\n         return this.usesSecondaryIndexing;\n     }\n \n-    private void processPartitionKeyRestrictions(boolean hasQueriableIndex, boolean allowFiltering, boolean forView)\n+    protected void processPartitionKeyRestrictions(boolean hasQueriableIndex, boolean allowFiltering, boolean forView)\n     {\n         if (!type.allowPartitionKeyRanges())\n         {\n@@ -414,8 +537,8 @@ private void processPartitionKeyRestrictions(boolean hasQueriableIndex, boolean\n \n             // slice query\n             checkFalse(partitionKeyRestrictions.hasSlice(),\n-                    \"Only EQ and IN relation are supported on the partition key (unless you use the token() function)\"\n-                            + \" for %s statements\", type);\n+                       \"Only EQ and IN relation are supported on the partition key (unless you use the token() function)\"\n+                       + \" for %s statements\", type);\n         }\n         else\n         {\n@@ -440,9 +563,6 @@ private void processPartitionKeyRestrictions(boolean hasQueriableIndex, boolean\n                 if (!allowFiltering && !forView && !hasQueriableIndex)\n                     throw new InvalidRequestException(REQUIRES_ALLOW_FILTERING_MESSAGE);\n \n-                if (partitionKeyRestrictions.hasIN())\n-                    throw new InvalidRequestException(\"IN restrictions are not supported when the query involves filtering\");\n-\n                 isKeyRange = true;\n                 usesSecondaryIndexing = hasQueriableIndex;\n             }\n@@ -532,7 +652,7 @@ private void processClusteringColumnsRestrictions(boolean hasQueriableIndex,\n                 else if (!allowFiltering)\n                 {\n                     List<ColumnMetadata> clusteringColumns = table.clusteringColumns();\n-                    List<ColumnMetadata> restrictedColumns = new LinkedList<>(clusteringColumnsRestrictions.getColumnDefs());\n+                    List<ColumnMetadata> restrictedColumns = clusteringColumnsRestrictions.getColumnDefs();\n \n                     for (int i = 0, m = restrictedColumns.size(); i < m; i++)\n                     {\n@@ -560,7 +680,7 @@ else if (!allowFiltering)\n     private Collection<ColumnIdentifier> getUnrestrictedClusteringColumns()\n     {\n         List<ColumnMetadata> missingClusteringColumns = new ArrayList<>(table.clusteringColumns());\n-        missingClusteringColumns.removeAll(new LinkedList<>(clusteringColumnsRestrictions.getColumnDefs()));\n+        missingClusteringColumns.removeAll(clusteringColumnsRestrictions.getColumnDefs());\n         return ColumnMetadata.toIdentifiers(missingClusteringColumns);\n     }\n \n@@ -573,9 +693,9 @@ private boolean hasUnrestrictedClusteringColumns()\n         return table.clusteringColumns().size() != clusteringColumnsRestrictions.size();\n     }\n \n-    private void processCustomIndexExpressions(List<CustomIndexExpression> expressions,\n-                                               VariableSpecifications boundNames,\n-                                               IndexRegistry indexRegistry)\n+    private CustomIndexExpression prepareCustomIndexExpression(List<CustomIndexExpression> expressions,\n+                                                               VariableSpecifications boundNames,\n+                                                               IndexRegistry indexRegistry)\n     {\n         if (expressions.size() > 1)\n             throw new InvalidRequestException(IndexRestrictions.MULTIPLE_EXPRESSIONS);\n@@ -599,20 +719,19 @@ private void processCustomIndexExpressions(List<CustomIndexExpression> expressio\n             throw IndexRestrictions.customExpressionNotSupported(expression.targetIndex);\n \n         expression.prepareValue(table, expressionType, boundNames);\n-\n-        filterRestrictions.add(expression);\n+        return expression;\n     }\n \n-    public RowFilter getRowFilter(IndexRegistry indexRegistry, QueryOptions options)\n+    public RowFilter getRowFilter(IndexRegistry indexManager, QueryOptions options)\n     {\n         if (filterRestrictions.isEmpty())\n             return RowFilter.NONE;\n \n         RowFilter filter = RowFilter.create();\n         for (Restrictions restrictions : filterRestrictions.getRestrictions())\n-            restrictions.addRowFilterTo(filter, indexRegistry, options);\n+            restrictions.addToRowFilter(filter, indexManager, options);\n \n-        for (CustomIndexExpression expression : filterRestrictions.getCustomIndexExpressions())\n+        for (CustomIndexExpression expression : filterRestrictions.getExternalExpressions())\n             expression.addToRowFilter(filter, table, options);\n \n         return filter;\n@@ -680,13 +799,13 @@ private ByteBuffer getPartitionKeyBound(Bound b, QueryOptions options)\n         if (partitionKeyRestrictions.isInclusive(Bound.START))\n         {\n             return partitionKeyRestrictions.isInclusive(Bound.END)\n-                    ? new Bounds<>(startKey, finishKey)\n-                    : new IncludingExcludingBounds<>(startKey, finishKey);\n+                   ? new Bounds<>(startKey, finishKey)\n+                   : new IncludingExcludingBounds<>(startKey, finishKey);\n         }\n \n         return partitionKeyRestrictions.isInclusive(Bound.END)\n-                ? new Range<>(startKey, finishKey)\n-                : new ExcludingBounds<>(startKey, finishKey);\n+               ? new Range<>(startKey, finishKey)\n+               : new ExcludingBounds<>(startKey, finishKey);\n     }\n \n     private AbstractBounds<PartitionPosition> getPartitionKeyBoundsForTokenRestrictions(IPartitioner p,\n@@ -710,7 +829,7 @@ private ByteBuffer getPartitionKeyBound(Bound b, QueryOptions options)\n          */\n         int cmp = startToken.compareTo(endToken);\n         if (!startToken.isMinimum() && !endToken.isMinimum()\n-                && (cmp > 0 || (cmp == 0 && (!includeStart || !includeEnd))))\n+            && (cmp > 0 || (cmp == 0 && (!includeStart || !includeEnd))))\n             return null;\n \n         PartitionPosition start = includeStart ? startToken.minKeyBound() : startToken.maxKeyBound();\n@@ -776,37 +895,61 @@ public boolean hasClusteringColumnsRestrictions()\n      */\n     public boolean isColumnRange()\n     {\n-        int numberOfClusteringColumns = table.clusteringColumns().size();\n-        if (table.isStaticCompactTable())\n-        {\n-            // For static compact tables we want to ignore the fake clustering column (note that if we weren't special casing,\n-            // this would mean a 'SELECT *' on a static compact table would query whole partitions, even though we'll only return\n-            // the static part as far as CQL is concerned. This is thus mostly an optimization to use the query-by-name path).\n-            numberOfClusteringColumns = 0;\n-        }\n-\n+        // For static compact tables we want to ignore the fake clustering column (note that if we weren't special casing,\n+        // this would mean a 'SELECT *' on a static compact table would query whole partitions, even though we'll only return\n+        // the static part as far as CQL is concerned. This is thus mostly an optimization to use the query-by-name path).\n+        int numberOfClusteringColumns = table.isStaticCompactTable() ? 0 : table.clusteringColumns().size();\n         // it is a range query if it has at least one the column alias for which no relation is defined or is not EQ or IN.\n         return clusteringColumnsRestrictions.size() < numberOfClusteringColumns\n-            || !clusteringColumnsRestrictions.hasOnlyEqualityRestrictions();\n+               || !clusteringColumnsRestrictions.hasOnlyEqualityRestrictions();\n     }\n \n     /**\n-     * Checks if the query need to use filtering.\n+     * Checks if the query needs to use filtering.\n+     *\n      * @return <code>true</code> if the query need to use filtering, <code>false</code> otherwise.\n      */\n-    public boolean needFiltering()\n+    public boolean needFiltering(TableMetadata table)\n     {\n-        int numberOfRestrictions = filterRestrictions.getCustomIndexExpressions().size();\n-        for (Restrictions restrictions : filterRestrictions.getRestrictions())\n-            numberOfRestrictions += restrictions.size();\n+        IndexRegistry indexRegistry = IndexRegistry.obtain(table);\n+        boolean hasClusteringColumnRestrictions = !clusteringColumnsRestrictions.isEmpty();\n+        boolean hasMultipleContains = nonPrimaryKeyRestrictions.hasMultipleContains();\n+        return filterRestrictions.needFiltering(indexRegistry, hasClusteringColumnRestrictions, hasMultipleContains);\n+    }\n \n-        return numberOfRestrictions > 1\n-                || (numberOfRestrictions == 0 && !clusteringColumnsRestrictions.isEmpty())\n-                || (numberOfRestrictions != 0\n-                        && nonPrimaryKeyRestrictions.hasMultipleContains());\n+    public Set<ColumnMetadata> getColumnsWithUnsupportedIndexRestrictions(TableMetadata table)\n+    {\n+        return getColumnsWithUnsupportedIndexRestrictions(table, Iterables.concat(clusteringColumnsRestrictions.restrictions(), nonPrimaryKeyRestrictions.restrictions()));\n     }\n \n-    private void validateSecondaryIndexSelections()\n+    public Set<ColumnMetadata> getColumnsWithUnsupportedIndexRestrictions(TableMetadata table, Iterable<Restriction> restrictions)\n+    {\n+        IndexRegistry indexRegistry = IndexRegistry.obtain(table);\n+        if (indexRegistry.listIndexes().isEmpty())\n+            return Collections.emptySet();\n+\n+        ImmutableSet.Builder<ColumnMetadata> builder = ImmutableSet.builder();\n+\n+        for (Restriction restriction : restrictions)\n+        {\n+            if (!restriction.hasSupportingIndex(indexRegistry))\n+            {\n+                for (Index index : indexRegistry.listIndexes())\n+                {\n+                    // If a column restriction has an index which was not picked up by hasSupportingIndex, it means it's an unsupported restriction\n+                    for (ColumnMetadata column : restriction.getColumnDefs())\n+                    {\n+                        if (index.dependsOn(column))\n+                            builder.add(column);\n+                    }\n+                }\n+            }\n+        }\n+\n+        return builder.build();\n+    }\n+\n+    protected void validateSecondaryIndexSelections()\n     {\n         checkFalse(keyIsInRelation(),\n                    \"Select on indexed columns and with IN clause for the PRIMARY KEY are not supported\");\n@@ -821,10 +964,10 @@ private void validateSecondaryIndexSelections()\n     public boolean hasAllPKColumnsRestrictedByEqualities()\n     {\n         return !isPartitionKeyRestrictionsOnToken()\n-                && !partitionKeyRestrictions.hasUnrestrictedPartitionKeyComponents(table)\n-                && (partitionKeyRestrictions.hasOnlyEqualityRestrictions())\n-                && !hasUnrestrictedClusteringColumns()\n-                && (clusteringColumnsRestrictions.hasOnlyEqualityRestrictions());\n+               && !partitionKeyRestrictions.hasUnrestrictedPartitionKeyComponents(table)\n+               && (partitionKeyRestrictions.hasOnlyEqualityRestrictions())\n+               && !hasUnrestrictedClusteringColumns()\n+               && (clusteringColumnsRestrictions.hasOnlyEqualityRestrictions());\n     }\n \n     /**\n@@ -835,10 +978,4 @@ public boolean hasRegularColumnsRestrictions()\n     {\n         return hasRegularColumnsRestrictions;\n     }\n-    \n-    @Override\n-    public String toString()\n-    {\n-        return ToStringBuilder.reflectionToString(this, ToStringStyle.SHORT_PREFIX_STYLE);\n-    }\n }"
  },
  {
    "sha": "84ec5e6b1c3b2bac942367b0c4202ccf76d7209a",
    "filename": "src/java/org/apache/cassandra/cql3/restrictions/TokenFilter.java",
    "status": "modified",
    "additions": 100,
    "deletions": 49,
    "changes": 149,
    "blob_url": "https://github.com/datastax/cassandra/blob/782ad0aa1ea82a157aee5cfc9def7fac3ef00dac/src/java/org/apache/cassandra/cql3/restrictions/TokenFilter.java",
    "raw_url": "https://github.com/datastax/cassandra/raw/782ad0aa1ea82a157aee5cfc9def7fac3ef00dac/src/java/org/apache/cassandra/cql3/restrictions/TokenFilter.java",
    "contents_url": "https://api.github.com/repos/datastax/cassandra/contents/src/java/org/apache/cassandra/cql3/restrictions/TokenFilter.java?ref=782ad0aa1ea82a157aee5cfc9def7fac3ef00dac",
    "patch": "@@ -18,23 +18,29 @@\n package org.apache.cassandra.cql3.restrictions;\n \n import java.nio.ByteBuffer;\n-import java.util.*;\n+import java.util.ArrayList;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+import java.util.function.Consumer;\n \n import com.google.common.collect.BoundType;\n import com.google.common.collect.ImmutableRangeSet;\n import com.google.common.collect.Range;\n import com.google.common.collect.RangeSet;\n \n-import org.apache.cassandra.schema.ColumnMetadata;\n-import org.apache.cassandra.schema.TableMetadata;\n import org.apache.cassandra.cql3.QueryOptions;\n import org.apache.cassandra.cql3.functions.Function;\n import org.apache.cassandra.cql3.statements.Bound;\n import org.apache.cassandra.db.filter.RowFilter;\n import org.apache.cassandra.dht.IPartitioner;\n import org.apache.cassandra.dht.Token;\n import org.apache.cassandra.exceptions.InvalidRequestException;\n+import org.apache.cassandra.index.Index;\n import org.apache.cassandra.index.IndexRegistry;\n+import org.apache.cassandra.schema.ColumnMetadata;\n+import org.apache.cassandra.schema.TableMetadata;\n+import org.apache.cassandra.service.QueryState;\n \n import static org.apache.cassandra.cql3.statements.Bound.END;\n import static org.apache.cassandra.cql3.statements.Bound.START;\n@@ -45,36 +51,108 @@\n  * <p>If all partition key columns have non-token restrictions and do not need filtering, they take precedence\n  * when calculating bounds, incusiveness etc (see CASSANDRA-12149).</p>\n  */\n-final class TokenFilter implements PartitionKeyRestrictions\n+abstract class TokenFilter implements PartitionKeyRestrictions\n {\n     /**\n      * The decorated restriction\n      */\n-    private final PartitionKeyRestrictions restrictions;\n+    final PartitionKeyRestrictions restrictions;\n \n     /**\n      * The restriction on the token\n      */\n-    private final TokenRestriction tokenRestriction;\n+    final TokenRestriction tokenRestriction;\n \n     /**\n      * Partitioner to manage tokens, extracted from tokenRestriction metadata.\n      */\n     private final IPartitioner partitioner;\n \n-    public boolean hasIN()\n+    static TokenFilter create(PartitionKeyRestrictions restrictions, TokenRestriction tokenRestriction)\n     {\n-        return isOnToken() ? false : restrictions.hasIN();\n+        boolean onToken = restrictions.needFiltering(tokenRestriction.metadata) || restrictions.size() < tokenRestriction.size();\n+        return onToken ? new TokenFilter.OnToken(restrictions, tokenRestriction)\n+                       : new TokenFilter.NotOnToken(restrictions, tokenRestriction);\n     }\n \n-    public boolean hasContains()\n+    private TokenFilter(PartitionKeyRestrictions restrictions, TokenRestriction tokenRestriction)\n     {\n-        return isOnToken() ? false : restrictions.hasContains();\n+        this.restrictions = restrictions;\n+        this.tokenRestriction = tokenRestriction;\n+        this.partitioner = tokenRestriction.metadata.partitioner;\n     }\n \n-    public boolean hasOnlyEqualityRestrictions()\n+    private static final class OnToken extends TokenFilter\n     {\n-        return isOnToken() ? false : restrictions.hasOnlyEqualityRestrictions();\n+        private OnToken(PartitionKeyRestrictions restrictions, TokenRestriction tokenRestriction)\n+        {\n+            super(restrictions, tokenRestriction);\n+        }\n+\n+        @Override\n+        public boolean isOnToken()\n+        {\n+            return true;\n+        }\n+\n+        @Override\n+        public boolean isInclusive(Bound bound)\n+        {\n+            return tokenRestriction.isInclusive(bound);\n+        }\n+\n+        @Override\n+        public boolean hasBound(Bound bound)\n+        {\n+            return tokenRestriction.hasBound(bound);\n+        }\n+\n+        @Override\n+        public List<ByteBuffer> bounds(Bound bound, QueryOptions options) throws InvalidRequestException\n+        {\n+            return tokenRestriction.bounds(bound, options);\n+        }\n+    }\n+\n+    private static final class NotOnToken extends TokenFilter\n+    {\n+        private NotOnToken(PartitionKeyRestrictions restrictions, TokenRestriction tokenRestriction)\n+        {\n+            super(restrictions, tokenRestriction);\n+        }\n+\n+        @Override\n+        public boolean isInclusive(Bound bound)\n+        {\n+            return restrictions.isInclusive(bound);\n+        }\n+\n+        @Override\n+        public boolean hasBound(Bound bound)\n+        {\n+            return restrictions.hasBound(bound);\n+        }\n+\n+        @Override\n+        public List<ByteBuffer> bounds(Bound bound, QueryOptions options) throws InvalidRequestException\n+        {\n+            return restrictions.bounds(bound, options);\n+        }\n+\n+        public boolean hasIN()\n+        {\n+            return restrictions.hasIN();\n+        }\n+\n+        public boolean hasContains()\n+        {\n+            return restrictions.hasContains();\n+        }\n+\n+        public boolean hasOnlyEqualityRestrictions()\n+        {\n+            return restrictions.hasOnlyEqualityRestrictions();\n+        }\n     }\n \n     @Override\n@@ -86,21 +164,6 @@ public boolean hasOnlyEqualityRestrictions()\n         return set;\n     }\n \n-    @Override\n-    public boolean isOnToken()\n-    {\n-        // if all partition key columns have non-token restrictions and do not need filtering,\n-        // we can simply use the token range to filter those restrictions and then ignore the token range\n-        return needFiltering(tokenRestriction.metadata) || restrictions.size() < tokenRestriction.size();\n-    }\n-\n-    public TokenFilter(PartitionKeyRestrictions restrictions, TokenRestriction tokenRestriction)\n-    {\n-        this.restrictions = restrictions;\n-        this.tokenRestriction = tokenRestriction;\n-        this.partitioner = tokenRestriction.metadata.partitioner;\n-    }\n-\n     @Override\n     public List<ByteBuffer> values(QueryOptions options) throws InvalidRequestException\n     {\n@@ -111,27 +174,9 @@ public TokenFilter(PartitionKeyRestrictions restrictions, TokenRestriction token\n     public PartitionKeyRestrictions mergeWith(Restriction restriction) throws InvalidRequestException\n     {\n         if (restriction.isOnToken())\n-            return new TokenFilter(restrictions, (TokenRestriction) tokenRestriction.mergeWith(restriction));\n-\n-        return new TokenFilter(restrictions.mergeWith(restriction), tokenRestriction);\n-    }\n+            return TokenFilter.create(restrictions, (TokenRestriction) tokenRestriction.mergeWith(restriction));\n \n-    @Override\n-    public boolean isInclusive(Bound bound)\n-    {\n-        return isOnToken() ? tokenRestriction.isInclusive(bound) : restrictions.isInclusive(bound);\n-    }\n-\n-    @Override\n-    public boolean hasBound(Bound bound)\n-    {\n-        return isOnToken() ? tokenRestriction.hasBound(bound) : restrictions.hasBound(bound);\n-    }\n-\n-    @Override\n-    public List<ByteBuffer> bounds(Bound bound, QueryOptions options) throws InvalidRequestException\n-    {\n-        return isOnToken() ? tokenRestriction.bounds(bound, options) : restrictions.bounds(bound, options);\n+        return TokenFilter.create(restrictions.mergeWith(restriction), tokenRestriction);\n     }\n \n     /**\n@@ -278,9 +323,15 @@ public boolean hasSupportingIndex(IndexRegistry indexRegistry)\n     }\n \n     @Override\n-    public void addRowFilterTo(RowFilter filter, IndexRegistry indexRegistry, QueryOptions options)\n+    public boolean needsFiltering(Index.Group indexGroup)\n+    {\n+        return restrictions.needsFiltering(indexGroup);\n+    }\n+\n+    @Override\n+    public void addToRowFilter(RowFilter filter, IndexRegistry indexRegistry, QueryOptions options)\n     {\n-        restrictions.addRowFilterTo(filter, indexRegistry, options);\n+        restrictions.addToRowFilter(filter, indexRegistry, options);\n     }\n \n     @Override"
  },
  {
    "sha": "62c93236b56709c1449ed73111c0424162b126b4",
    "filename": "src/java/org/apache/cassandra/cql3/restrictions/TokenRestriction.java",
    "status": "modified",
    "additions": 12,
    "deletions": 3,
    "changes": 15,
    "blob_url": "https://github.com/datastax/cassandra/blob/782ad0aa1ea82a157aee5cfc9def7fac3ef00dac/src/java/org/apache/cassandra/cql3/restrictions/TokenRestriction.java",
    "raw_url": "https://github.com/datastax/cassandra/raw/782ad0aa1ea82a157aee5cfc9def7fac3ef00dac/src/java/org/apache/cassandra/cql3/restrictions/TokenRestriction.java",
    "contents_url": "https://api.github.com/repos/datastax/cassandra/contents/src/java/org/apache/cassandra/cql3/restrictions/TokenRestriction.java?ref=782ad0aa1ea82a157aee5cfc9def7fac3ef00dac",
    "patch": "@@ -22,6 +22,7 @@\n \n import com.google.common.base.Joiner;\n \n+import org.apache.cassandra.index.Index;\n import org.apache.cassandra.schema.ColumnMetadata;\n import org.apache.cassandra.schema.TableMetadata;\n import org.apache.cassandra.cql3.QueryOptions;\n@@ -122,7 +123,13 @@ public boolean hasSupportingIndex(IndexRegistry indexRegistry)\n     }\n \n     @Override\n-    public void addRowFilterTo(RowFilter filter, IndexRegistry indexRegistry, QueryOptions options)\n+    public boolean needsFiltering(Index.Group indexGroup)\n+    {\n+        return false;\n+    }\n+\n+    @Override\n+    public void addToRowFilter(RowFilter filter, IndexRegistry indexRegistry, QueryOptions options)\n     {\n         throw new UnsupportedOperationException(\"Index expression cannot be created for token restriction\");\n     }\n@@ -153,7 +160,7 @@ protected final String getColumnNamesAsString()\n     public final PartitionKeyRestrictions mergeWith(Restriction otherRestriction) throws InvalidRequestException\n     {\n         if (!otherRestriction.isOnToken())\n-            return new TokenFilter(toPartitionKeyRestrictions(otherRestriction), this);\n+            return TokenFilter.create(toPartitionKeyRestrictions(otherRestriction), this);\n \n         return doMergeWith((TokenRestriction) otherRestriction);\n     }\n@@ -176,7 +183,9 @@ private PartitionKeyRestrictions toPartitionKeyRestrictions(Restriction restrict\n         if (restriction instanceof PartitionKeyRestrictions)\n             return (PartitionKeyRestrictions) restriction;\n \n-        return new PartitionKeySingleRestrictionSet(metadata.partitionKeyAsClusteringComparator()).mergeWith(restriction);\n+        return PartitionKeySingleRestrictionSet.builder(metadata.partitionKeyAsClusteringComparator())\n+                                               .addRestriction(restriction)\n+                                               .build();\n     }\n \n     public static final class EQRestriction extends TokenRestriction"
  },
  {
    "sha": "403d3bed2e2036d7c7f92957d8057fda622f6d49",
    "filename": "src/java/org/apache/cassandra/cql3/selection/FieldSelector.java",
    "status": "modified",
    "additions": 2,
    "deletions": 1,
    "changes": 3,
    "blob_url": "https://github.com/datastax/cassandra/blob/782ad0aa1ea82a157aee5cfc9def7fac3ef00dac/src/java/org/apache/cassandra/cql3/selection/FieldSelector.java",
    "raw_url": "https://github.com/datastax/cassandra/raw/782ad0aa1ea82a157aee5cfc9def7fac3ef00dac/src/java/org/apache/cassandra/cql3/selection/FieldSelector.java",
    "contents_url": "https://api.github.com/repos/datastax/cassandra/contents/src/java/org/apache/cassandra/cql3/selection/FieldSelector.java?ref=782ad0aa1ea82a157aee5cfc9def7fac3ef00dac",
    "patch": "@@ -23,6 +23,7 @@\n import org.apache.cassandra.cql3.QueryOptions;\n import org.apache.cassandra.db.filter.ColumnFilter;\n import org.apache.cassandra.db.marshal.AbstractType;\n+import org.apache.cassandra.db.marshal.ByteBufferAccessor;\n import org.apache.cassandra.db.marshal.UserType;\n import org.apache.cassandra.exceptions.InvalidRequestException;\n import org.apache.cassandra.transport.ProtocolVersion;\n@@ -89,7 +90,7 @@ public ByteBuffer getOutput(ProtocolVersion protocolVersion) throws InvalidReque\n         ByteBuffer value = selected.getOutput(protocolVersion);\n         if (value == null)\n             return null;\n-        ByteBuffer[] buffers = type.split(value);\n+        ByteBuffer[] buffers = type.split(ByteBufferAccessor.instance, value);\n         return field < buffers.length ? buffers[field] : null;\n     }\n "
  }
]
