[
  {
    "sha": "d59cb242f3052f5eeebe83dabb2747a7378ce856",
    "filename": "client/src/main/java/io/pravega/client/admin/impl/StreamCutHelper.java",
    "status": "modified",
    "additions": 19,
    "deletions": 11,
    "changes": 30,
    "blob_url": "https://github.com/pravega/pravega/blob/c3b233cf21eca821774c33ff56144bccd26b133d/client/src/main/java/io/pravega/client/admin/impl/StreamCutHelper.java",
    "raw_url": "https://github.com/pravega/pravega/raw/c3b233cf21eca821774c33ff56144bccd26b133d/client/src/main/java/io/pravega/client/admin/impl/StreamCutHelper.java",
    "contents_url": "https://api.github.com/repos/pravega/pravega/contents/client/src/main/java/io/pravega/client/admin/impl/StreamCutHelper.java?ref=c3b233cf21eca821774c33ff56144bccd26b133d",
    "patch": "@@ -10,6 +10,7 @@\n package io.pravega.client.admin.impl;\n \n import io.pravega.client.connection.impl.ConnectionPool;\n+import io.pravega.client.control.impl.Controller;\n import io.pravega.client.security.auth.DelegationTokenProvider;\n import io.pravega.client.security.auth.DelegationTokenProviderFactory;\n import io.pravega.client.segment.impl.Segment;\n@@ -19,10 +20,13 @@\n import io.pravega.client.segment.impl.SegmentMetadataClientFactoryImpl;\n import io.pravega.client.stream.Stream;\n import io.pravega.client.stream.StreamCut;\n-import io.pravega.client.control.impl.Controller;\n import io.pravega.client.stream.impl.StreamCutImpl;\n import io.pravega.client.stream.impl.StreamImpl;\n+import io.pravega.common.concurrent.Futures;\n import io.pravega.shared.security.auth.AccessOperation;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.List;\n import java.util.Map;\n import java.util.concurrent.CompletableFuture;\n import java.util.stream.Collectors;\n@@ -62,17 +66,21 @@ public StreamCutHelper(Controller controller, ConnectionPool connectionPool) {\n         final DelegationTokenProvider tokenProvider = DelegationTokenProviderFactory.create(controller,\n                 stream.getScope(), stream.getStreamName(), AccessOperation.READ);\n         return controller.getCurrentSegments(stream.getScope(), stream.getStreamName())\n-                         .thenApply(streamsegments -> {\n-                             Map<Segment, Long> pos = streamsegments.getSegments().stream()\n-                                             .map(segment -> segmentToInfo(segment, tokenProvider))\n-                                             .collect(Collectors.toMap(SegmentInfo::getSegment, SegmentInfo::getWriteOffset));\n-                             return new StreamCutImpl(stream, pos);\n-                         });\n+            .thenCompose(streamsegments -> segmentToInfos(streamsegments.getSegments(), tokenProvider))\n+            .thenApply(infos -> {\n+                Map<Segment, Long> pos = infos.stream()\n+                    .collect(Collectors.toMap(SegmentInfo::getSegment, SegmentInfo::getWriteOffset));\n+                return new StreamCutImpl(stream, pos);\n+            });\n     }\n \n-    private SegmentInfo segmentToInfo(Segment s, DelegationTokenProvider tokenProvider) {\n-        @Cleanup\n-        SegmentMetadataClient client = segmentMetadataClientFactory.createSegmentMetadataClient(s, tokenProvider);\n-        return client.getSegmentInfo();\n+    private CompletableFuture<List<SegmentInfo>> segmentToInfos(Collection<Segment> segments, DelegationTokenProvider tokenProvider) {\n+        List<CompletableFuture<SegmentInfo>> results = new ArrayList<>();\n+        for (Segment s : segments) {\n+            @Cleanup\n+            SegmentMetadataClient client = segmentMetadataClientFactory.createSegmentMetadataClient(s, tokenProvider);\n+            results.add(client.getSegmentInfo());\n+        }\n+        return Futures.allOfWithResults(results);\n     }\n }"
  },
  {
    "sha": "a64a130a292bf9dacb2cb5be1dae28881ffc6f30",
    "filename": "client/src/main/java/io/pravega/client/admin/impl/StreamManagerImpl.java",
    "status": "modified",
    "additions": 3,
    "deletions": 7,
    "changes": 10,
    "blob_url": "https://github.com/pravega/pravega/blob/c3b233cf21eca821774c33ff56144bccd26b133d/client/src/main/java/io/pravega/client/admin/impl/StreamManagerImpl.java",
    "raw_url": "https://github.com/pravega/pravega/raw/c3b233cf21eca821774c33ff56144bccd26b133d/client/src/main/java/io/pravega/client/admin/impl/StreamManagerImpl.java",
    "contents_url": "https://api.github.com/repos/pravega/pravega/contents/client/src/main/java/io/pravega/client/admin/impl/StreamManagerImpl.java?ref=c3b233cf21eca821774c33ff56144bccd26b133d",
    "patch": "@@ -28,7 +28,6 @@\n import io.pravega.client.stream.StreamCut;\n import io.pravega.client.stream.impl.StreamCutImpl;\n import io.pravega.common.Exceptions;\n-import io.pravega.common.concurrent.ExecutorServiceHelpers;\n import io.pravega.common.concurrent.Futures;\n import io.pravega.common.function.Callbacks;\n import io.pravega.common.util.AsyncIterator;\n@@ -56,17 +55,17 @@ public StreamManagerImpl(ClientConfig clientConfig) {\n \n     @VisibleForTesting\n     public StreamManagerImpl(ClientConfig clientConfig, ControllerImplConfig controllerConfig) {\n-        this.executor = ExecutorServiceHelpers.newScheduledThreadPool(1, \"StreamManager-Controller\");\n-        this.controller = new ControllerImpl(controllerConfig, executor);\n         this.connectionPool = new ConnectionPoolImpl(clientConfig, new SocketConnectionFactoryImpl(clientConfig));\n+        this.executor = connectionPool.getInternalExecutor();\n+        this.controller = new ControllerImpl(controllerConfig, executor);\n         this.streamCutHelper = new StreamCutHelper(controller, connectionPool);\n     }\n \n     @VisibleForTesting\n     public StreamManagerImpl(Controller controller, ConnectionPool connectionPool) {\n-        this.executor = null;\n         this.controller = controller;\n         this.connectionPool = connectionPool;\n+        this.executor = connectionPool.getInternalExecutor();\n         this.streamCutHelper = new StreamCutHelper(controller, connectionPool);\n     }\n \n@@ -215,9 +214,6 @@ public void close() {\n         if (this.controller != null) {\n             Callbacks.invokeSafely(this.controller::close, ex -> log.error(\"Unable to close Controller client.\", ex));\n         }\n-        if (this.executor != null) {\n-            ExecutorServiceHelpers.shutdown(this.executor);\n-        }\n         if (this.connectionPool != null) {\n             this.connectionPool.close();\n         }"
  },
  {
    "sha": "b0b14237af7e906685f24bc4c2f243c713abfaf1",
    "filename": "client/src/main/java/io/pravega/client/batch/impl/BatchClientFactoryImpl.java",
    "status": "modified",
    "additions": 21,
    "deletions": 19,
    "changes": 40,
    "blob_url": "https://github.com/pravega/pravega/blob/c3b233cf21eca821774c33ff56144bccd26b133d/client/src/main/java/io/pravega/client/batch/impl/BatchClientFactoryImpl.java",
    "raw_url": "https://github.com/pravega/pravega/raw/c3b233cf21eca821774c33ff56144bccd26b133d/client/src/main/java/io/pravega/client/batch/impl/BatchClientFactoryImpl.java",
    "contents_url": "https://api.github.com/repos/pravega/pravega/contents/client/src/main/java/io/pravega/client/batch/impl/BatchClientFactoryImpl.java?ref=c3b233cf21eca821774c33ff56144bccd26b133d",
    "patch": "@@ -11,7 +11,6 @@\n \n import com.google.common.annotations.Beta;\n import com.google.common.base.Preconditions;\n-import com.google.common.collect.Iterators;\n import io.pravega.client.BatchClientFactory;\n import io.pravega.client.ClientConfig;\n import io.pravega.client.admin.impl.StreamCutHelper;\n@@ -21,6 +20,7 @@\n import io.pravega.client.connection.impl.ConnectionFactory;\n import io.pravega.client.connection.impl.ConnectionPool;\n import io.pravega.client.connection.impl.ConnectionPoolImpl;\n+import io.pravega.client.control.impl.Controller;\n import io.pravega.client.security.auth.DelegationTokenProvider;\n import io.pravega.client.security.auth.DelegationTokenProviderFactory;\n import io.pravega.client.segment.impl.Segment;\n@@ -33,14 +33,15 @@\n import io.pravega.client.stream.Serializer;\n import io.pravega.client.stream.Stream;\n import io.pravega.client.stream.StreamCut;\n-import io.pravega.client.control.impl.Controller;\n import io.pravega.client.stream.impl.StreamSegmentSuccessors;\n+import io.pravega.common.concurrent.Futures;\n import io.pravega.shared.security.auth.AccessOperation;\n-import java.util.Iterator;\n+import java.util.List;\n import java.util.Optional;\n import java.util.SortedSet;\n import java.util.TreeSet;\n import java.util.concurrent.CompletableFuture;\n+import java.util.stream.Collectors;\n import lombok.Cleanup;\n import lombok.val;\n import lombok.extern.slf4j.Slf4j;\n@@ -94,9 +95,7 @@ private StreamSegmentsIterator listSegments(final Stream stream, final Optional<\n                 CompletableFuture.completedFuture(endCut.get()) : streamCutHelper.fetchTailStreamCut(stream);\n \n         //fetch the StreamSegmentsInfo based on start and end streamCuts.\n-        CompletableFuture<StreamSegmentsIterator> streamSegmentInfo = startSCFuture.thenCombine(endSCFuture,\n-                (startSC, endSC) -> getStreamSegmentInfo(stream, startSC, endSC));\n-        return getAndHandleExceptions(streamSegmentInfo, RuntimeException::new);\n+        return getStreamSegmentInfo(stream, startSCFuture.join(), endSCFuture.join());\n     }\n \n     private StreamSegmentsIterator getStreamSegmentInfo(final Stream stream, final StreamCut startStreamCut, final StreamCut endStreamCut) {\n@@ -110,9 +109,9 @@ private StreamSegmentsIterator getStreamSegmentInfo(final Stream stream, final S\n                 .create(controller, stream.getScope(), stream.getStreamName(), AccessOperation.READ);\n         log.debug(\"List of Segments between the start and end stream cuts : {}\", segmentSet);\n \n-        Iterator<SegmentRange> iterator = Iterators.transform(segmentSet.iterator(),\n-                s -> getSegmentRange(s, startStreamCut, endStreamCut, tokenProvider));\n-        return StreamSegmentsInfoImpl.builder().segmentRangeIterator(iterator)\n+        val futures = segmentSet.stream().map(s -> getSegmentRange(s, startStreamCut, endStreamCut, tokenProvider)).collect(Collectors.toList());\n+        List<SegmentRange> results = Futures.getThrowingException(Futures.allOfWithResults(futures));\n+        return StreamSegmentsInfoImpl.builder().segmentRangeIterator(results.iterator())\n                                      .startStreamCut(startStreamCut)\n                                      .endStreamCut(endStreamCut).build();\n     }\n@@ -122,24 +121,27 @@ private StreamSegmentsIterator getStreamSegmentInfo(final Stream stream, final S\n      * - If segment is part of startStreamCut / endStreamCut update startOffset and endOffset accordingly.\n      * - If segment is not part of the streamCuts fetch the data using SegmentMetadataClient.\n      */\n-    private SegmentRange getSegmentRange(final Segment segment, final StreamCut startStreamCut,\n+    private CompletableFuture<SegmentRange> getSegmentRange(final Segment segment, final StreamCut startStreamCut,\n                                          final StreamCut endStreamCut, final DelegationTokenProvider tokenProvider) {\n-        SegmentRangeImpl.SegmentRangeImplBuilder segmentRangeBuilder = SegmentRangeImpl.builder()\n-                                                                                       .segment(segment);\n         if (startStreamCut.asImpl().getPositions().containsKey(segment) && endStreamCut.asImpl().getPositions().containsKey(segment)) {\n-            //use the meta data present in startStreamCut and endStreamCuts.\n+            // use the meta data present in startStreamCut and endStreamCuts.\n+            SegmentRangeImpl.SegmentRangeImplBuilder segmentRangeBuilder = SegmentRangeImpl.builder().segment(segment);\n             segmentRangeBuilder.startOffset(startStreamCut.asImpl().getPositions().get(segment))\n-                               .endOffset(endStreamCut.asImpl().getPositions().get(segment));\n+                .endOffset(endStreamCut.asImpl().getPositions().get(segment));\n+            return CompletableFuture.completedFuture(segmentRangeBuilder.build());\n         } else {\n             //use segment meta data client to fetch the segment offsets.\n-            SegmentInfo r = segmentToInfo(segment, tokenProvider);\n-            segmentRangeBuilder.startOffset(startStreamCut.asImpl().getPositions().getOrDefault(segment, r.getStartingOffset()))\n-                               .endOffset(endStreamCut.asImpl().getPositions().getOrDefault(segment, r.getWriteOffset()));\n+            return segmentToInfo(segment, tokenProvider).thenApply(r -> {\n+                SegmentRangeImpl.SegmentRangeImplBuilder segmentRangeBuilder = SegmentRangeImpl.builder().segment(segment);\n+                segmentRangeBuilder.startOffset(startStreamCut.asImpl().getPositions().getOrDefault(segment, r.getStartingOffset()))\n+                                   .endOffset(endStreamCut.asImpl().getPositions().getOrDefault(segment, r.getWriteOffset()));\n+                return segmentRangeBuilder.build();\n+            });\n         }\n-        return segmentRangeBuilder.build();\n+\n     }\n \n-    private SegmentInfo segmentToInfo(Segment s, DelegationTokenProvider tokenProvider) {\n+    private CompletableFuture<SegmentInfo> segmentToInfo(Segment s, DelegationTokenProvider tokenProvider) {\n         @Cleanup\n         SegmentMetadataClient client = segmentMetadataClientFactory.createSegmentMetadataClient(s, tokenProvider);\n         return client.getSegmentInfo();"
  },
  {
    "sha": "814d1df8329dea21934856f4ea8475138bdc4aa9",
    "filename": "client/src/main/java/io/pravega/client/byteStream/impl/ByteStreamClientImpl.java",
    "status": "modified",
    "additions": 1,
    "deletions": 1,
    "changes": 2,
    "blob_url": "https://github.com/pravega/pravega/blob/c3b233cf21eca821774c33ff56144bccd26b133d/client/src/main/java/io/pravega/client/byteStream/impl/ByteStreamClientImpl.java",
    "raw_url": "https://github.com/pravega/pravega/raw/c3b233cf21eca821774c33ff56144bccd26b133d/client/src/main/java/io/pravega/client/byteStream/impl/ByteStreamClientImpl.java",
    "contents_url": "https://api.github.com/repos/pravega/pravega/contents/client/src/main/java/io/pravega/client/byteStream/impl/ByteStreamClientImpl.java?ref=c3b233cf21eca821774c33ff56144bccd26b133d",
    "patch": "@@ -65,7 +65,7 @@ private ByteStreamReader createByteStreamReaders(Segment segment) {\n \n         DelegationTokenProvider tokenProvider = DelegationTokenProviderFactory.create(delegationToken, controller, segment, AccessOperation.READ);\n         SegmentMetadataClient metaClient = metaStreamFactory.createSegmentMetadataClient(segment, tokenProvider);\n-        long startOffset = metaClient.getSegmentInfo().getStartingOffset();\n+        long startOffset = Futures.getThrowingException(metaClient.getSegmentInfo()).getStartingOffset();\n         return new ByteStreamReaderImpl(inputStreamFactory.createInputStreamForSegment(segment, tokenProvider, startOffset),\n                 metaClient);\n     }"
  },
  {
    "sha": "0dfba4d1acf51dae14f2fb8019cf2a0fb89c20bc",
    "filename": "client/src/main/java/io/pravega/client/byteStream/impl/ByteStreamReaderImpl.java",
    "status": "modified",
    "additions": 2,
    "deletions": 1,
    "changes": 3,
    "blob_url": "https://github.com/pravega/pravega/blob/c3b233cf21eca821774c33ff56144bccd26b133d/client/src/main/java/io/pravega/client/byteStream/impl/ByteStreamReaderImpl.java",
    "raw_url": "https://github.com/pravega/pravega/raw/c3b233cf21eca821774c33ff56144bccd26b133d/client/src/main/java/io/pravega/client/byteStream/impl/ByteStreamReaderImpl.java",
    "contents_url": "https://api.github.com/repos/pravega/pravega/contents/client/src/main/java/io/pravega/client/byteStream/impl/ByteStreamReaderImpl.java?ref=c3b233cf21eca821774c33ff56144bccd26b133d",
    "patch": "@@ -14,6 +14,7 @@\n import io.pravega.client.segment.impl.SegmentInputStream;\n import io.pravega.client.segment.impl.SegmentMetadataClient;\n import io.pravega.common.Exceptions;\n+import io.pravega.common.concurrent.Futures;\n import java.io.IOException;\n import java.nio.ByteBuffer;\n import java.util.concurrent.CompletableFuture;\n@@ -70,7 +71,7 @@ public void close() {\n \n     @Override\n     public long fetchTailOffset() {\n-        return meta.fetchCurrentSegmentLength();\n+        return Futures.getThrowingException(meta.fetchCurrentSegmentLength());\n     }\n \n     @Override"
  },
  {
    "sha": "0ababcba6dde50dc2437f052fca6adae26992912",
    "filename": "client/src/main/java/io/pravega/client/byteStream/impl/ByteStreamWriterImpl.java",
    "status": "modified",
    "additions": 4,
    "deletions": 3,
    "changes": 7,
    "blob_url": "https://github.com/pravega/pravega/blob/c3b233cf21eca821774c33ff56144bccd26b133d/client/src/main/java/io/pravega/client/byteStream/impl/ByteStreamWriterImpl.java",
    "raw_url": "https://github.com/pravega/pravega/raw/c3b233cf21eca821774c33ff56144bccd26b133d/client/src/main/java/io/pravega/client/byteStream/impl/ByteStreamWriterImpl.java",
    "contents_url": "https://api.github.com/repos/pravega/pravega/contents/client/src/main/java/io/pravega/client/byteStream/impl/ByteStreamWriterImpl.java?ref=c3b233cf21eca821774c33ff56144bccd26b133d",
    "patch": "@@ -13,6 +13,7 @@\n import io.pravega.client.segment.impl.SegmentMetadataClient;\n import io.pravega.client.segment.impl.SegmentOutputStream;\n import io.pravega.client.stream.impl.PendingEvent;\n+import io.pravega.common.concurrent.Futures;\n import java.io.IOException;\n import java.nio.ByteBuffer;\n import lombok.NonNull;\n@@ -56,18 +57,18 @@ public void flush() throws IOException {\n     @Override\n     public void closeAndSeal() throws IOException {\n         out.close();\n-        meta.sealSegment();\n+        Futures.getThrowingException(meta.sealSegment());\n         meta.close();\n     }\n \n     @Override\n     public long fetchTailOffset() {\n-        return meta.fetchCurrentSegmentLength();\n+        return Futures.getThrowingException(meta.fetchCurrentSegmentLength());\n     }\n \n     @Override\n     public void truncateDataBefore(long offset) {\n-        meta.truncateSegment(offset);\n+        Futures.getThrowingException(meta.truncateSegment(offset));\n     }\n \n }"
  },
  {
    "sha": "a75b0fea471a8c3b24bd2059699c33a0ddf851f6",
    "filename": "client/src/main/java/io/pravega/client/connection/impl/SocketConnectionFactoryImpl.java",
    "status": "modified",
    "additions": 1,
    "deletions": 1,
    "changes": 2,
    "blob_url": "https://github.com/pravega/pravega/blob/c3b233cf21eca821774c33ff56144bccd26b133d/client/src/main/java/io/pravega/client/connection/impl/SocketConnectionFactoryImpl.java",
    "raw_url": "https://github.com/pravega/pravega/raw/c3b233cf21eca821774c33ff56144bccd26b133d/client/src/main/java/io/pravega/client/connection/impl/SocketConnectionFactoryImpl.java",
    "contents_url": "https://api.github.com/repos/pravega/pravega/contents/client/src/main/java/io/pravega/client/connection/impl/SocketConnectionFactoryImpl.java?ref=c3b233cf21eca821774c33ff56144bccd26b133d",
    "patch": "@@ -68,7 +68,7 @@ private int getThreadPoolSize(Integer threadCount) {\n         if (configuredThreads != null) {\n             return Integer.parseInt(configuredThreads);\n         }\n-        return Runtime.getRuntime().availableProcessors();\n+        return Math.max(2, Runtime.getRuntime().availableProcessors());\n     }\n \n     @Override"
  },
  {
    "sha": "4b4ec4b1921313919767c468d2ec720e885f1513",
    "filename": "client/src/main/java/io/pravega/client/control/impl/ControllerImpl.java",
    "status": "modified",
    "additions": 96,
    "deletions": 93,
    "changes": 189,
    "blob_url": "https://github.com/pravega/pravega/blob/c3b233cf21eca821774c33ff56144bccd26b133d/client/src/main/java/io/pravega/client/control/impl/ControllerImpl.java",
    "raw_url": "https://github.com/pravega/pravega/raw/c3b233cf21eca821774c33ff56144bccd26b133d/client/src/main/java/io/pravega/client/control/impl/ControllerImpl.java",
    "contents_url": "https://api.github.com/repos/pravega/pravega/contents/client/src/main/java/io/pravega/client/control/impl/ControllerImpl.java?ref=c3b233cf21eca821774c33ff56144bccd26b133d",
    "patch": "@@ -179,6 +179,7 @@ public ControllerImpl(final ControllerImplConfig config,\n         this(NettyChannelBuilder.forTarget(config.getClientConfig().getControllerURI().toString())\n                                 .nameResolverFactory(new ControllerResolverFactory(executor))\n                                 .defaultLoadBalancingPolicy(\"round_robin\")\n+                                .directExecutor()\n                                 .keepAliveTime(DEFAULT_KEEPALIVE_TIME_MINUTES, TimeUnit.MINUTES),\n                 config, executor);\n         log.info(\"Controller client connecting to server at {}\", config.getClientConfig().getControllerURI().getAuthority());\n@@ -287,31 +288,31 @@ private RetryAndThrowConditionally createRetryConfig(final ControllerImplConfig\n                                                         .createScope(ScopeInfo.newBuilder().setScope(scopeName).build(), callback);\n             return callback.getFuture();\n         }, this.executor);\n-        return result.thenApply(x -> {\n-                switch (x.getStatus()) {\n-                case FAILURE:\n-                    log.warn(requestId, \"Failed to create scope: {}\", scopeName);\n-                    throw new ControllerFailureException(\"Failed to create scope: \" + scopeName);\n-                case INVALID_SCOPE_NAME:\n-                    log.warn(requestId, \"Illegal scope name: {}\", scopeName);\n-                    throw new IllegalArgumentException(\"Illegal scope name: \" + scopeName);\n-                case SCOPE_EXISTS:\n-                    log.warn(requestId, \"Scope already exists: {}\", scopeName);\n-                    return false;\n-                case SUCCESS:\n-                    log.info(requestId, \"Scope created successfully: {}\", scopeName);\n-                    return true;\n-                case UNRECOGNIZED:\n-                default:\n-                    throw new ControllerFailureException(\"Unknown return status creating scope \" + scopeName\n-                                                         + \" \" + x.getStatus());\n-                }\n-            }).whenComplete((x, e) -> {\n-                if (e != null) {\n-                    log.warn(requestId, \"createScope {} failed: \", scopeName, e);\n-                }\n-                LoggerHelpers.traceLeave(log, \"createScope\", traceId, scopeName, requestId);\n-            });\n+        return result.thenApplyAsync(x -> {\n+            switch (x.getStatus()) {\n+            case FAILURE:\n+                log.warn(requestId, \"Failed to create scope: {}\", scopeName);\n+                throw new ControllerFailureException(\"Failed to create scope: \" + scopeName);\n+            case INVALID_SCOPE_NAME:\n+                log.warn(requestId, \"Illegal scope name: {}\", scopeName);\n+                throw new IllegalArgumentException(\"Illegal scope name: \" + scopeName);\n+            case SCOPE_EXISTS:\n+                log.warn(requestId, \"Scope already exists: {}\", scopeName);\n+                return false;\n+            case SUCCESS:\n+                log.info(requestId, \"Scope created successfully: {}\", scopeName);\n+                return true;\n+            case UNRECOGNIZED:\n+            default:\n+                throw new ControllerFailureException(\n+                        \"Unknown return status creating scope \" + scopeName + \" \" + x.getStatus());\n+            }\n+        }, this.executor).whenComplete((x, e) -> {\n+            if (e != null) {\n+                log.warn(requestId, \"createScope {} failed: \", scopeName, e);\n+            }\n+            LoggerHelpers.traceLeave(log, \"createScope\", traceId, scopeName, requestId);\n+        });\n     }\n \n     @Override\n@@ -326,12 +327,12 @@ private RetryAndThrowConditionally createRetryConfig(final ControllerImplConfig\n                                                              .checkScopeExists(ScopeInfo.newBuilder().setScope(scopeName).build(), callback);\n             return callback.getFuture().thenApply(ExistsResponse::getExists);\n         }, this.executor);\n-        return result.whenComplete((x, e) -> {\n+        return result.whenCompleteAsync((x, e) -> {\n             if (e != null) {\n                 log.warn(requestId, \"checkScopeExists {} failed: \", scopeName, e);\n             }\n             LoggerHelpers.traceLeave(log, \"checkScopeExists\", traceId, scopeName, requestId);\n-        });\n+        }, this.executor);\n     }\n \n     @Override\n@@ -348,10 +349,10 @@ private RetryAndThrowConditionally createRetryConfig(final ControllerImplConfig\n                                                                     .listScopes(ScopesRequest\n                                                                   .newBuilder().setContinuationToken(token).build(), callback);\n                         return callback.getFuture()\n-                                       .thenApply(x -> {\n+                                       .thenApplyAsync(x -> {\n                                                List<String> result = x.getScopesList();\n                                                return new AbstractMap.SimpleEntry<>(x.getContinuationToken(), result);\n-                                       });\n+                                       }, this.executor);\n                     }, this.executor);\n             return new ContinuationTokenAsyncIterator<>(function, ContinuationToken.newBuilder().build());\n         } finally {\n@@ -373,7 +374,7 @@ private RetryAndThrowConditionally createRetryConfig(final ControllerImplConfig\n                                                                     .listStreamsInScope(StreamsInScopeRequest\n                                                                   .newBuilder().setScope(scopeInfo).setContinuationToken(token).build(), callback);\n                         return callback.getFuture()\n-                                       .thenApply(x -> {\n+                                       .thenApplyAsync(x -> {\n                                            switch (x.getStatus()) {\n                                                case SCOPE_NOT_FOUND:\n                                                    log.warn(requestId, \"Scope not found: {}\", scopeName);\n@@ -389,7 +390,7 @@ private RetryAndThrowConditionally createRetryConfig(final ControllerImplConfig\n                                                                           .map(y -> new StreamImpl(y.getScope(), y.getStream())).collect(Collectors.toList());\n                                                    return new AbstractMap.SimpleEntry<>(x.getContinuationToken(), result);\n                                            }\n-                                       });\n+                                       }, this.executor);\n                     }, this.executor);\n             return new ContinuationTokenAsyncIterator<>(function, ContinuationToken.newBuilder().build());\n         } finally {\n@@ -409,7 +410,7 @@ private RetryAndThrowConditionally createRetryConfig(final ControllerImplConfig\n                                                         .deleteScope(ScopeInfo.newBuilder().setScope(scopeName).build(), callback);\n             return callback.getFuture();\n         }, this.executor);\n-        return result.thenApply(x -> {\n+        return result.thenApplyAsync(x -> {\n             switch (x.getStatus()) {\n                 case FAILURE:\n                     log.warn(requestId, \"Failed to delete scope: {}\", scopeName);\n@@ -428,7 +429,7 @@ private RetryAndThrowConditionally createRetryConfig(final ControllerImplConfig\n                     throw new ControllerFailureException(\"Unknown return status deleting scope \" + scopeName\n                                                          + \" \" + x.getStatus());\n                 }\n-            }).whenComplete((x, e) -> {\n+            }, this.executor).whenComplete((x, e) -> {\n                 if (e != null) {\n                     log.warn(requestId, \"deleteScope {} failed: \", scopeName, e);\n                 }\n@@ -450,7 +451,7 @@ private RetryAndThrowConditionally createRetryConfig(final ControllerImplConfig\n                                                         .createStream(ModelHelper.decode(scope, streamName, streamConfig), callback);\n             return callback.getFuture();\n         }, this.executor);\n-        return result.thenApply(x -> {\n+        return result.thenApplyAsync(x -> {\n             switch (x.getStatus()) {\n             case FAILURE:\n                 log.warn(requestId, \"Failed to create stream: {}\", streamName);\n@@ -472,7 +473,7 @@ private RetryAndThrowConditionally createRetryConfig(final ControllerImplConfig\n                 throw new ControllerFailureException(\"Unknown return status creating stream \" + streamConfig\n                                                      + \" \" + x.getStatus());\n             }\n-        }).whenComplete((x, e) -> {\n+        }, this.executor).whenComplete((x, e) -> {\n             if (e != null) {\n                 log.warn(requestId, \"createStream {}/{} failed: \", scope, streamName, e);\n             }\n@@ -493,12 +494,12 @@ private RetryAndThrowConditionally createRetryConfig(final ControllerImplConfig\n                                                                                           .setStream(streamName).build(), callback);\n             return callback.getFuture().thenApply(ExistsResponse::getExists);\n         }, this.executor);\n-        return result.whenComplete((x, e) -> {\n+        return result.whenCompleteAsync((x, e) -> {\n             if (e != null) {\n                 log.warn(requestId, \"checkStreamExists {}/{} failed: \", scopeName, streamName, e);\n             }\n             LoggerHelpers.traceLeave(log, \"checkStreamExists\", traceId, scopeName, streamName, requestId);\n-        });\n+        }, this.executor);\n     }\n \n     @Override\n@@ -514,7 +515,7 @@ private RetryAndThrowConditionally createRetryConfig(final ControllerImplConfig\n                                                         .updateStream(ModelHelper.decode(scope, streamName, streamConfig), callback);\n             return callback.getFuture();\n         }, this.executor);\n-        return result.thenApply(x -> {\n+        return result.thenApplyAsync(x -> {\n             switch (x.getStatus()) {\n             case FAILURE:\n                 log.warn(requestId, \"Failed to update stream: {}\", streamName);\n@@ -533,7 +534,7 @@ private RetryAndThrowConditionally createRetryConfig(final ControllerImplConfig\n                 throw new ControllerFailureException(\"Unknown return status updating stream \" + streamConfig\n                                                      + \" \" + x.getStatus());\n             }\n-        }).whenComplete((x, e) -> {\n+        }, this.executor).whenComplete((x, e) -> {\n             if (e != null) {\n                 log.warn(requestId, \"updateStream {}/{} failed: \", scope, streamName, e);\n             }\n@@ -555,7 +556,7 @@ private RetryAndThrowConditionally createRetryConfig(final ControllerImplConfig\n                 .listSubscribers(ModelHelper.createStreamInfo(scope, streamName), callback);\n         return callback.getFuture();\n         }, this.executor);\n-        return result.thenApply(x -> {\n+        return result.thenApplyAsync(x -> {\n             switch (x.getStatus()) {\n                 case FAILURE:\n                     log.warn(requestId, \"Failed to list subscribers for stream {}/{}\", scope, streamName);\n@@ -570,7 +571,7 @@ private RetryAndThrowConditionally createRetryConfig(final ControllerImplConfig\n                 default:\n                     throw new ControllerFailureException(\"Unknown return status listing subscribers \" + x.getStatus());\n             }\n-        }).whenComplete((x, e) -> {\n+        }, this.executor).whenComplete((x, e) -> {\n             if (e != null) {\n                 log.warn(requestId, \"listSubscribers for stream {}/{} failed: \", scope, streamName, e);\n             }\n@@ -595,7 +596,7 @@ private RetryAndThrowConditionally createRetryConfig(final ControllerImplConfig\n                 .updateSubscriberStreamCut(ModelHelper.decode(scope, streamName, subscriber, readerGroupId, generation, getStreamCutMap(streamCut)), callback);\n             return callback.getFuture();\n         }, this.executor);\n-        return result.thenApply(x -> {\n+        return result.thenApplyAsync(x -> {\n             switch (x.getStatus()) {\n                 case FAILURE:\n                     log.warn(requestId, \"Failed to update stream cut for Reader Group: {}\", subscriber);\n@@ -620,7 +621,7 @@ private RetryAndThrowConditionally createRetryConfig(final ControllerImplConfig\n                     throw new ControllerFailureException(\"Unknown return status for updateTruncationStreamCut for Stream :\"\n                             + scope + \"/\" + streamName + \": subscriber:\" + subscriber + \": status=\" + x.getStatus());\n             }\n-        }).whenComplete((x, e) -> {\n+        }, this.executor).whenComplete((x, e) -> {\n             if (e != null) {\n                 log.warn(requestId, \"updateTruncationStreamCut for Subscriber {} for stream {}/{} failed: \", subscriber, scope, streamName, e);\n             }\n@@ -645,7 +646,7 @@ private RetryAndThrowConditionally createRetryConfig(final ControllerImplConfig\n                                                         .truncateStream(ModelHelper.decode(scope, stream, streamCut), callback);\n             return callback.getFuture();\n         }, this.executor);\n-        return result.thenApply(x -> {\n+        return result.thenApplyAsync(x -> {\n             switch (x.getStatus()) {\n                 case FAILURE:\n                     log.warn(requestId, \"Failed to truncate stream: {}/{}\", scope, stream);\n@@ -664,7 +665,7 @@ private RetryAndThrowConditionally createRetryConfig(final ControllerImplConfig\n                     throw new ControllerFailureException(\"Unknown return status truncating stream \" + scope + \"/\" + stream\n                             + \" \" + x.getStatus());\n             }\n-        }).whenComplete((x, e) -> {\n+        }, this.executor).whenComplete((x, e) -> {\n             if (e != null) {\n                 log.warn(requestId, \"truncateStream {}/{} failed: \", scope, stream, e);\n             }\n@@ -681,7 +682,7 @@ private RetryAndThrowConditionally createRetryConfig(final ControllerImplConfig\n         final long requestId = requestIdGenerator.get();\n         long traceId = LoggerHelpers.traceEnter(log, \"scaleStream\", stream, requestId);\n         startScaleInternal(stream, sealedSegments, newKeyRanges, \"scaleStream\", requestId)\n-                .whenComplete((startScaleResponse, e) -> {\n+                .whenCompleteAsync((startScaleResponse, e) -> {\n                     if (e != null) {\n                         log.error(requestId, \"Failed to start scale for stream {}\", stream, e);\n                         cancellableRequest.start(() -> Futures.failedFuture(e), any -> true, executor);\n@@ -701,7 +702,7 @@ private RetryAndThrowConditionally createRetryConfig(final ControllerImplConfig\n                             cancellableRequest.start(() -> Futures.failedFuture(ex), any -> true, executor);\n                         }\n                     }\n-                });\n+                }, executor);\n \n         return cancellableRequest;\n     }\n@@ -713,7 +714,7 @@ private RetryAndThrowConditionally createRetryConfig(final ControllerImplConfig\n         final long requestId = requestIdGenerator.get();\n         long traceId = LoggerHelpers.traceEnter(log, \"scaleStream\", stream, requestId);\n         return startScaleInternal(stream, sealedSegments, newKeyRanges, \"scaleStream\", requestId)\n-                .thenApply(response -> handleScaleResponse(stream, response, traceId))\n+                .thenApplyAsync(response -> handleScaleResponse(stream, response, traceId), this.executor)\n                 .whenComplete((x, e) -> {\n                     if (e != null) {\n                         log.warn(requestId, \"Failed to start scale of stream: {} \", stream.getStreamName(), e);\n@@ -755,7 +756,7 @@ private Boolean handleScaleResponse(Stream stream, ScaleResponse response, long\n                     callback);\n             return callback.getFuture();\n         }, this.executor);\n-        return result.thenApply(response -> {\n+        return result.thenApplyAsync(response -> {\n             switch (response.getStatus()) {\n                 case IN_PROGRESS:\n                     return false;\n@@ -769,7 +770,7 @@ private Boolean handleScaleResponse(Stream stream, ScaleResponse response, long\n                     throw new ControllerFailureException(\"Unknown return status checking scale of stream \"  + stream + \" \"\n                             + response.getStatus());\n             }\n-        }).whenComplete((x, e) -> {\n+        }, this.executor).whenComplete((x, e) -> {\n             if (e != null) {\n                 log.warn(\"checkScaleStatus {} failed: \", stream.getStreamName(), e);\n             }\n@@ -818,7 +819,7 @@ private Boolean handleScaleResponse(Stream stream, ScaleResponse response, long\n                                                         .sealStream(ModelHelper.createStreamInfo(scope, streamName), callback);\n             return callback.getFuture();\n         }, this.executor);\n-        return result.thenApply(x -> {\n+        return result.thenApplyAsync(x -> {\n             switch (x.getStatus()) {\n             case FAILURE:\n                 log.warn(requestId, \"Failed to seal stream: {}\", streamName);\n@@ -836,7 +837,7 @@ private Boolean handleScaleResponse(Stream stream, ScaleResponse response, long\n             default:\n                 throw new ControllerFailureException(\"Unknown return status sealing stream \" + streamName + \" \" + x.getStatus());\n             }\n-        }).whenComplete((x, e) -> {\n+        }, this.executor).whenComplete((x, e) -> {\n             if (e != null) {\n                 log.warn(requestId, \"sealStream {}/{} failed: \", scope, streamName, e);\n             }\n@@ -858,7 +859,7 @@ private Boolean handleScaleResponse(Stream stream, ScaleResponse response, long\n                                                         .deleteStream(ModelHelper.createStreamInfo(scope, streamName), callback);\n             return callback.getFuture();\n         }, this.executor);\n-        return result.thenApply(x -> {\n+        return result.thenApplyAsync(x -> {\n             switch (x.getStatus()) {\n             case FAILURE:\n                 log.warn(requestId, \"Failed to delete stream: {}\", streamName);\n@@ -876,7 +877,7 @@ private Boolean handleScaleResponse(Stream stream, ScaleResponse response, long\n             default:\n                 throw new ControllerFailureException(\"Unknown return status deleting stream \" + streamName + \" \" + x.getStatus());\n             }\n-        }).whenComplete((x, e) -> {\n+        }, this.executor).whenComplete((x, e) -> {\n             if (e != null) {\n                 log.warn(requestId, \"deleteStream {}/{} failed: \", scope, streamName, e);\n             }\n@@ -900,13 +901,13 @@ private Boolean handleScaleResponse(Stream stream, ScaleResponse response, long\n             client.withDeadlineAfter(timeoutMillis, TimeUnit.MILLISECONDS).getSegments(request, callback);\n             return callback.getFuture();\n         }, this.executor);\n-        return result.thenApply(segments -> {\n+        return result.thenApplyAsync(segments -> {\n             log.debug(\"Received the following data from the controller {}\", segments.getSegmentsList());\n             return segments.getSegmentsList()\n                            .stream()\n                            .collect(Collectors.toMap(location -> ModelHelper.encode(location.getSegmentId()),\n                                                      location -> location.getOffset()));\n-        }).whenComplete((x, e) -> {\n+        }, this.executor).whenComplete((x, e) -> {\n             if (e != null) {\n                 log.warn(\"get Segments of {} at time {} failed: \", stream.getStreamName(), timestamp,  e);\n             }\n@@ -927,14 +928,14 @@ private Boolean handleScaleResponse(Stream stream, ScaleResponse response, long\n \n             return callback.getFuture();\n         }, this.executor);\n-        return resultFuture.thenApply(successors -> {\n+        return resultFuture.thenApplyAsync(successors -> {\n             log.debug(\"Received the following data from the controller {}\", successors.getSegmentsList());\n             Map<SegmentWithRange, List<Long>> result = new HashMap<>();\n             for (SuccessorResponse.SegmentEntry entry : successors.getSegmentsList()) {\n                 result.put(ModelHelper.encode(entry.getSegment()), entry.getValueList());\n             }\n             return new StreamSegmentsWithPredecessors(result, successors.getDelegationToken());\n-        }).whenComplete((x, e) -> {\n+        }, this.executor).whenComplete((x, e) -> {\n             if (e != null) {\n                 log.warn(requestId, \"getSuccessors of segment {} failed: \", segment.getSegmentId(), e);\n             }\n@@ -987,12 +988,12 @@ private Boolean handleScaleResponse(Stream stream, ScaleResponse response, long\n                     getStreamCutMap(fromStreamCut), getStreamCutMap(toStreamCut)), callback);\n             return callback.getFuture();\n         }, this.executor);\n-        return resultFuture.thenApply(response -> {\n+        return resultFuture.thenApplyAsync(response -> {\n             log.debug(\"Received the following data from the controller {}\", response.getSegmentsList());\n \n             return new StreamSegmentSuccessors(response.getSegmentsList().stream().map(ModelHelper::encode).collect(Collectors.toSet()),\n                     response.getDelegationToken());\n-        });\n+        }, this.executor);\n     }\n \n     private Map<Long, Long> getStreamCutMap(StreamCut streamCut) {\n@@ -1017,7 +1018,7 @@ private Boolean handleScaleResponse(Stream stream, ScaleResponse response, long\n                   .getCurrentSegments(ModelHelper.createStreamInfo(scope, stream, AccessOperation.NONE), callback);\n             return callback.getFuture();\n         }, this.executor);\n-        return result.thenApply(this::getStreamSegments)\n+        return result.thenApplyAsync(this::getStreamSegments, this.executor)\n                      .whenComplete((x, e) -> {\n                          if (e != null) {\n                              log.warn(requestId, \"getCurrentSegments for {}/{} failed: \", scope, stream, e);\n@@ -1047,7 +1048,7 @@ private Boolean handleScaleResponse(Stream stream, ScaleResponse response, long\n                     .getEpochSegments(request, callback);\n             return callback.getFuture();\n         }, this.executor);\n-        return result.thenApply(this::getStreamSegments)\n+        return result.thenApplyAsync(this::getStreamSegments, this.executor)\n                 .whenComplete((x, e) -> {\n                     if (e != null) {\n                         log.warn(requestId, \"getEpochSegments for {}/{} with epoch {} failed: \", scope, stream, epoch, e);\n@@ -1086,7 +1087,7 @@ private StreamSegments getStreamSegments(final SegmentRanges ranges) {\n                             callback);\n             return callback.getFuture();\n         }, this.executor);\n-        return result.thenApply(ModelHelper::encode)\n+        return result.thenApplyAsync(ModelHelper::encode, this.executor)\n                 .whenComplete((x, e) -> {\n                     if (e != null) {\n                         log.warn(requestId, \"getEndpointForSegment {} failed: \", qualifiedSegmentName, e);\n@@ -1108,7 +1109,7 @@ private StreamSegments getStreamSegments(final SegmentRanges ranges) {\n                     callback);\n             return callback.getFuture();\n         }, this.executor);\n-        return result.thenApply(SegmentValidityResponse::getResponse)\n+        return result.thenApplyAsync(SegmentValidityResponse::getResponse, this.executor)\n                 .whenComplete((x, e) -> {\n                     if (e != null) {\n                         log.warn(\"isSegmentOpen for segment {} failed: \", segment, e);\n@@ -1134,7 +1135,7 @@ private StreamSegments getStreamSegments(final SegmentRanges ranges) {\n                             callback);\n             return callback.getFuture();\n         }, this.executor);\n-        return result.thenApply(this::convert)\n+        return result.thenApplyAsync(this::convert, this.executor)\n                 .whenComplete((x, e) -> {\n                     if (e != null) {\n                         log.warn(requestId, \"createTransaction on stream {} failed: \", stream.getStreamName(), e);\n@@ -1169,13 +1170,13 @@ private TxnSegments convert(CreateTxnResponse response) {\n                                                  .setLease(lease).build(), callback);\n             return callback.getFuture();\n         }, this.executor);\n-        return result.thenApply(status -> {\n+        return result.thenApplyAsync(status -> {\n             try {\n                 return ModelHelper.encode(status.getStatus(), stream + \" \" + txId);\n             } catch (PingFailedException ex) {\n                 throw new CompletionException(ex);\n             }\n-        }).whenComplete((s, e) -> {\n+        }, this.executor).whenComplete((s, e) -> {\n             if (e != null) {\n                 log.warn(requestId, \"PingTransaction {} failed:\", txId, e);\n             }\n@@ -1205,7 +1206,7 @@ private TxnSegments convert(CreateTxnResponse response) {\n             client.withDeadlineAfter(timeoutMillis, TimeUnit.MILLISECONDS).commitTransaction(txnRequest.build(), callback);\n             return callback.getFuture();\n         }, this.executor);\n-        return result.thenApply(txnStatus -> {\n+        return result.thenApplyAsync(txnStatus -> {\n             LoggerHelpers.traceLeave(log, \"commitTransaction\", traceId, stream, txId);\n             if (txnStatus.getStatus().equals(TxnStatus.Status.STREAM_NOT_FOUND)) {\n                 log.warn(\"Stream {} not found while trying to commit transaction {}\", stream.getStreamName(), txId);\n@@ -1220,7 +1221,7 @@ private TxnSegments convert(CreateTxnResponse response) {\n             }\n             log.warn(\"Unable to commit transaction {} on stream {}, commit status is {}\", txId, stream, txnStatus.getStatus());\n             throw Exceptions.sneakyThrow(new TxnFailedException(\"Commit transaction failed with status: \" + txnStatus.getStatus()));\n-        });\n+        }, this.executor);\n     }\n \n     @Override\n@@ -1241,7 +1242,7 @@ private TxnSegments convert(CreateTxnResponse response) {\n                     callback);\n             return callback.getFuture();\n         }, this.executor);\n-        return result.thenApply(txnStatus -> {\n+        return result.thenApplyAsync(txnStatus -> {\n             LoggerHelpers.traceLeave(log, \"abortTransaction\", traceId, stream, txId);\n             if (txnStatus.getStatus().equals(TxnStatus.Status.STREAM_NOT_FOUND)) {\n                 log.warn(\"Stream {} not found while trying to abort transaction {}\", stream, txId);\n@@ -1256,7 +1257,7 @@ private TxnSegments convert(CreateTxnResponse response) {\n             }\n             log.warn(\"Unable to abort transaction {} on stream {}, abort status is {} \", txId, stream, txnStatus.getStatus());\n             throw new RuntimeException(\"Error aborting transaction: \" + txnStatus.getStatus());\n-        });\n+        }, this.executor);\n     }\n \n     @Override\n@@ -1277,7 +1278,7 @@ private TxnSegments convert(CreateTxnResponse response) {\n                     callback);\n             return callback.getFuture();\n         }, this.executor);\n-        return result.thenApply(status -> ModelHelper.encode(status.getState(), stream + \" \" + txId))\n+        return result.thenApplyAsync(status -> ModelHelper.encode(status.getState(), stream + \" \" + txId), this.executor)\n                 .whenComplete((x, e) -> {\n                     if (e != null) {\n                         log.warn(requestId, \"checkTransactionStatus for transaction {} on  stream {} failed \", txId, stream, e);\n@@ -1306,15 +1307,15 @@ private TxnSegments convert(CreateTxnResponse response) {\n                             callback);\n             return callback.getFuture();\n         }, this.executor);\n-        return result.thenApply(response -> {\n+        return result.thenApplyAsync(response -> {\n             LoggerHelpers.traceLeave(log, \"noteTimestampFromWriter\", traceId, writer, stream, requestId);\n             if (response.getResult().equals(TimestampResponse.Status.SUCCESS)) {\n                 return null;\n             }\n             log.warn(requestId, \"Writer \" + writer + \" failed to note time because: \" + response.getResult()\n                     + \" time was: \" + timestamp + \" position=\" + lastWrittenPosition);\n             throw new RuntimeException(\"failed to note time because: \" + response.getResult());\n-        });\n+        }, this.executor);\n     }\n \n     @Override\n@@ -1333,15 +1334,15 @@ private TxnSegments convert(CreateTxnResponse response) {\n                             .build(), callback);\n             return callback.getFuture();\n         }, this.executor);\n-        return result.thenApply(response -> {\n+        return result.thenApplyAsync(response -> {\n             LoggerHelpers.traceLeave(log, \"removeWriter\", traceId, writerId, stream, requestId);\n             if (response.getResult().equals(RemoveWriterResponse.Status.SUCCESS)) {\n                 return null;\n             }\n             log.warn(requestId, \"Notifying the controller of writer shutdown failed for writer: \" + writerId + \" because of \"\n                     + response.getResult());\n             throw new RuntimeException(\"Unable to remove writer due to: \" + response.getResult());\n-        });\n+        }, this.executor);\n     }\n \n     @Override\n@@ -1373,7 +1374,7 @@ private void closeChannel() {\n             return callback.getFuture();\n         }, this.executor);\n \n-        return result.thenApply( token -> token.getDelegationToken())\n+        return result.thenApplyAsync( token -> token.getDelegationToken(), this.executor)\n         .whenComplete((x, e) -> {\n             if (e != null) {\n                 log.warn(\"getOrRefreshDelegationTokenFor {}/{} failed: \", scope, streamName, e);\n@@ -1399,7 +1400,7 @@ private void closeChannel() {\n                     .createKeyValueTable(ModelHelper.decode(scope, kvtName, kvtConfig), callback);\n             return callback.getFuture();\n         }, this.executor);\n-        return result.thenApply(x -> {\n+        return result.thenApplyAsync(x -> {\n             switch (x.getStatus()) {\n                 case FAILURE:\n                     log.warn(requestId, \"Failed to create KeyValueTable: {}\", kvtName);\n@@ -1421,7 +1422,7 @@ private void closeChannel() {\n                     throw new ControllerFailureException(\"Unknown return status creating KeyValueTable \" + kvtConfig\n                             + \" \" + x.getStatus());\n             }\n-        }).whenComplete((x, e) -> {\n+        }, this.executor).whenComplete((x, e) -> {\n             if (e != null) {\n                 log.warn(requestId, \"createKeyValueTable {}/{} failed: \", scope, kvtName, e);\n             }\n@@ -1443,7 +1444,7 @@ private void closeChannel() {\n                                 .listKeyValueTables(KVTablesInScopeRequest.newBuilder().setScope(scopeInfo)\n                                                         .setContinuationToken(token).build(), callback);\n                         return callback.getFuture()\n-                                .thenApply(x -> {\n+                                .thenApplyAsync(x -> {\n                                     switch (x.getStatus()) {\n                                         case SCOPE_NOT_FOUND:\n                                             log.warn(requestId, \"Scope not found: {}\", scopeName);\n@@ -1459,7 +1460,7 @@ private void closeChannel() {\n                                                     .map(y -> new KeyValueTableInfo(y.getScope(), y.getKvtName())).collect(Collectors.toList());\n                                             return new AbstractMap.SimpleEntry<>(x.getContinuationToken(), kvtList);\n                                     }\n-                                });\n+                                }, this.executor);\n                     }, this.executor);\n             return new ContinuationTokenAsyncIterator<>(function, ContinuationToken.newBuilder().build());\n         } finally {\n@@ -1481,7 +1482,7 @@ private void closeChannel() {\n                     .deleteKeyValueTable(ModelHelper.createKeyValueTableInfo(scope, kvtName), callback);\n             return callback.getFuture();\n         }, this.executor);\n-        return result.thenApply(x -> {\n+        return result.thenApplyAsync(x -> {\n             switch (x.getStatus()) {\n                 case FAILURE:\n                     log.warn(requestId, \"Failed to delete KeyValueTable: {}\", kvtName);\n@@ -1496,7 +1497,7 @@ private void closeChannel() {\n                 default:\n                     throw new ControllerFailureException(\"Unknown return status deleting KeyValueTable \" + kvtName + \" \" + x.getStatus());\n             }\n-        }).whenComplete((x, e) -> {\n+        }, this.executor).whenComplete((x, e) -> {\n             if (e != null) {\n                 log.warn(requestId, \"deleteKeyValueTable {}/{} failed: \", scope, kvtName, e);\n             }\n@@ -1517,7 +1518,7 @@ private void closeChannel() {\n                         .getCurrentSegmentsKeyValueTable(ModelHelper.createKeyValueTableInfo(scope, kvtName), callback);\n                 return callback.getFuture();\n             }, this.executor);\n-            return result.thenApply(ranges -> {\n+            return result.thenApplyAsync(ranges -> {\n                 log.debug(\"Received the following data from the controller {}\", ranges.getSegmentRangesList());\n                 NavigableMap<Double, SegmentWithRange> rangeMap = new TreeMap<>();\n                 for (SegmentRange r : ranges.getSegmentRangesList()) {\n@@ -1527,7 +1528,7 @@ private void closeChannel() {\n                     rangeMap.put(r.getMaxKey(), new SegmentWithRange(ModelHelper.encode(r.getSegmentId()), r.getMinKey(), r.getMaxKey()));\n                 }\n                 return new KeyValueTableSegments(rangeMap);\n-            }).whenComplete((x, e) -> {\n+            }, this.executor).whenComplete((x, e) -> {\n                 if (e != null) {\n                     log.warn(\"getCurrentSegmentsForKeyValueTable for {}/{} failed: \", scope, kvtName, e);\n                 }\n@@ -1537,6 +1538,7 @@ private void closeChannel() {\n     //endregion\n \n     // region ReaderGroups\n+    @Override\n     public CompletableFuture<ReaderGroupConfig> createReaderGroup(String scope, String rgName, final ReaderGroupConfig rgConfig) {\n         Exceptions.checkNotClosed(closed.get(), this);\n         Exceptions.checkNotNullOrEmpty(scope, \"scope\");\n@@ -1551,7 +1553,7 @@ private void closeChannel() {\n                     .createReaderGroup(ModelHelper.decode(scope, rgName, rgConfig), callback);\n             return callback.getFuture();\n         }, this.executor);\n-        return result.thenApply(x -> {\n+        return result.thenApplyAsync(x -> {\n             switch (x.getStatus()) {\n                 case FAILURE:\n                     log.warn(requestId, \"Failed to create reader group: {}\", rgName);\n@@ -1570,14 +1572,15 @@ private void closeChannel() {\n                     throw new ControllerFailureException(\"Unknown return status creating reader group \" + rgName\n                             + \" \" + x.getStatus());\n             }\n-        }).whenComplete((x, e) -> {\n+        }, this.executor).whenComplete((x, e) -> {\n             if (e != null) {\n                 log.warn(requestId, \"createReaderGroup {}/{} failed: \", scope, rgName, e);\n             }\n             LoggerHelpers.traceLeave(log, \"createReaderGroup\", traceId, rgConfig, requestId);\n         });\n     }\n \n+    @Override\n     public CompletableFuture<Long> updateReaderGroup(String scope, String rgName, final ReaderGroupConfig rgConfig) {\n         Exceptions.checkNotClosed(closed.get(), this);\n         Exceptions.checkNotNullOrEmpty(scope, \"scope\");\n@@ -1592,7 +1595,7 @@ private void closeChannel() {\n                     .updateReaderGroup(ModelHelper.decode(scope, rgName, rgConfig), callback);\n             return callback.getFuture();\n         }, this.executor);\n-        return result.thenApply(x -> {\n+        return result.thenApplyAsync(x -> {\n             final String rgScopedName = NameUtils.getScopedReaderGroupName(scope, rgName);\n             switch (x.getStatus()) {\n                 case FAILURE:\n@@ -1612,7 +1615,7 @@ private void closeChannel() {\n                     throw new ControllerFailureException(\"Unknown return status creating reader group \" + rgScopedName\n                             + \" \" + x.getStatus());\n             }\n-        }).whenComplete((x, e) -> {\n+        }, this.executor).whenComplete((x, e) -> {\n             if (e != null) {\n                 log.warn(requestId, \"createReaderGroup {}/{} failed: \", scope, rgName, e);\n             }\n@@ -1635,7 +1638,7 @@ private void closeChannel() {\n                     .getReaderGroupConfig(ModelHelper.createReaderGroupInfo(scope, rgName, emptyUUID, 0L), callback);\n             return callback.getFuture();\n         }, this.executor);\n-        return result.thenApply(x -> {\n+        return result.thenApplyAsync(x -> {\n             switch (x.getStatus()) {\n                 case FAILURE:\n                     log.warn(requestId, \"Failed to get config for reader group: {}\", scopedRGName);\n@@ -1650,7 +1653,7 @@ private void closeChannel() {\n                 default:\n                     throw new ControllerFailureException(\"Unknown return status getting config for ReaderGroup \" + scopedRGName + \" \" + x.getStatus());\n             }\n-        }).whenComplete((x, e) -> {\n+        }, this.executor).whenComplete((x, e) -> {\n             if (e != null) {\n                 log.warn(requestId, \"getReaderGroupConfig failed for Reader Group: {}\", scopedRGName, e);\n             }\n@@ -1675,7 +1678,7 @@ private void closeChannel() {\n                     .deleteReaderGroup(ModelHelper.createReaderGroupInfo(scope, rgName, readerGroupId.toString(), 0L), callback);\n             return callback.getFuture();\n         }, this.executor);\n-        return result.thenApply(x -> {\n+        return result.thenApplyAsync(x -> {\n             switch (x.getStatus()) {\n                 case FAILURE:\n                     log.warn(requestId, \"Failed to delete reader group: {}\", scopedRGName);\n@@ -1690,7 +1693,7 @@ private void closeChannel() {\n                 default:\n                     throw new ControllerFailureException(\"Unknown return status getting config for ReaderGroup \" + scopedRGName + \" \" + x.getStatus());\n             }\n-        }).whenComplete((x, e) -> {\n+        }, this.executor).whenComplete((x, e) -> {\n             if (e != null) {\n                 log.warn(requestId, \"deleteReaderGroup failed for Reader Group: {}\", scopedRGName, e);\n             }"
  },
  {
    "sha": "be0426a5c88a43ffb127303c4ae29e72d50224da",
    "filename": "client/src/main/java/io/pravega/client/segment/impl/SegmentMetadataClient.java",
    "status": "modified",
    "additions": 11,
    "deletions": 9,
    "changes": 20,
    "blob_url": "https://github.com/pravega/pravega/blob/c3b233cf21eca821774c33ff56144bccd26b133d/client/src/main/java/io/pravega/client/segment/impl/SegmentMetadataClient.java",
    "raw_url": "https://github.com/pravega/pravega/raw/c3b233cf21eca821774c33ff56144bccd26b133d/client/src/main/java/io/pravega/client/segment/impl/SegmentMetadataClient.java",
    "contents_url": "https://api.github.com/repos/pravega/pravega/contents/client/src/main/java/io/pravega/client/segment/impl/SegmentMetadataClient.java?ref=c3b233cf21eca821774c33ff56144bccd26b133d",
    "patch": "@@ -9,6 +9,8 @@\n  */\n package io.pravega.client.segment.impl;\n \n+import java.util.concurrent.CompletableFuture;\n+\n /**\n  * A client for looking at and editing the metadata related to a specific segment.\n  */\n@@ -17,23 +19,23 @@\n     /**\n      * Returns info for the current segment.\n      *\n-     * @return Metadata about the segment.\n+     * @return a future containing the Metadata about the segment.\n      */\n-    abstract SegmentInfo getSegmentInfo();\n+    abstract CompletableFuture<SegmentInfo> getSegmentInfo();\n     \n     /**\n      * Returns the length of the current segment. i.e. the total length of all data written to the segment.\n      *\n-     * @return The length of the current segment.\n+     * @return a future containing the length of the current segment.\n      */\n-    abstract long fetchCurrentSegmentLength();\n+    abstract CompletableFuture<Long> fetchCurrentSegmentLength();\n \n     /**\n      * Gets the current value of the provided attribute.\n      * @param attribute The attribute to get the value of.\n-     * @return The value of the attribute or {@link SegmentAttribute#NULL_VALUE} if it is not set.\n+     * @return a future containing the value of the attribute or {@link SegmentAttribute#NULL_VALUE} if it is not set.\n      */\n-    abstract long fetchProperty(SegmentAttribute attribute);\n+    abstract CompletableFuture<Long> fetchProperty(SegmentAttribute attribute);\n \n     /**\n      * Atomically replaces the value of attribute with newValue if it is expectedValue.\n@@ -43,20 +45,20 @@\n      * @param newValue The new value for the attribute\n      * @return If the replacement occurred. (False if the attribute was not expectedValue)\n      */\n-    abstract boolean compareAndSetAttribute(SegmentAttribute attribute, long expectedValue, long newValue);\n+    abstract CompletableFuture<Boolean> compareAndSetAttribute(SegmentAttribute attribute, long expectedValue, long newValue);\n     \n     /**\n      * Deletes all data before the offset of the provided segment.\n      * This data will no longer be readable. Existing offsets are not affected by this operations. \n      * The new startingOffset will be reflected in {@link SegmentMetadataClient#getSegmentInfo()}.{@link SegmentInfo#getStartingOffset()}.\n      * @param offset The offset the segment should be truncated at.\n      */\n-    abstract void truncateSegment(long offset);\n+    abstract CompletableFuture<Void> truncateSegment(long offset);\n     \n     /**\n      * Seals the segment so that no more writes can go to it.\n      */\n-    abstract void sealSegment();\n+    abstract CompletableFuture<Void> sealSegment();\n     \n     @Override\n     abstract void close();"
  },
  {
    "sha": "a0d56bad96c4a5bf84fc006dff569ae4430fe4f9",
    "filename": "client/src/main/java/io/pravega/client/segment/impl/SegmentMetadataClientImpl.java",
    "status": "modified",
    "additions": 39,
    "deletions": 29,
    "changes": 68,
    "blob_url": "https://github.com/pravega/pravega/blob/c3b233cf21eca821774c33ff56144bccd26b133d/client/src/main/java/io/pravega/client/segment/impl/SegmentMetadataClientImpl.java",
    "raw_url": "https://github.com/pravega/pravega/raw/c3b233cf21eca821774c33ff56144bccd26b133d/client/src/main/java/io/pravega/client/segment/impl/SegmentMetadataClientImpl.java",
    "contents_url": "https://api.github.com/repos/pravega/pravega/contents/client/src/main/java/io/pravega/client/segment/impl/SegmentMetadataClientImpl.java?ref=c3b233cf21eca821774c33ff56144bccd26b133d",
    "patch": "@@ -15,13 +15,12 @@\n import io.pravega.auth.TokenExpiredException;\n import io.pravega.client.connection.impl.ConnectionPool;\n import io.pravega.client.connection.impl.RawClient;\n+import io.pravega.client.control.impl.Controller;\n import io.pravega.client.security.auth.DelegationTokenProvider;\n import io.pravega.client.security.auth.DelegationTokenProviderFactory;\n import io.pravega.client.stream.impl.ConnectionClosedException;\n-import io.pravega.client.control.impl.Controller;\n import io.pravega.common.Exceptions;\n import io.pravega.common.concurrent.Futures;\n-import io.pravega.shared.security.auth.AccessOperation;\n import io.pravega.common.util.Retry;\n import io.pravega.common.util.Retry.RetryWithBackoff;\n import io.pravega.shared.protocol.netty.ConnectionFailedException;\n@@ -37,9 +36,11 @@\n import io.pravega.shared.protocol.netty.WireCommands.TruncateSegment;\n import io.pravega.shared.protocol.netty.WireCommands.UpdateSegmentAttribute;\n import io.pravega.shared.protocol.netty.WireCommands.WrongHost;\n+import io.pravega.shared.security.auth.AccessOperation;\n import java.util.UUID;\n import java.util.concurrent.CompletableFuture;\n import java.util.concurrent.CompletionException;\n+import java.util.concurrent.ScheduledExecutorService;\n import java.util.concurrent.atomic.AtomicBoolean;\n import javax.annotation.concurrent.GuardedBy;\n import lombok.RequiredArgsConstructor;\n@@ -68,6 +69,10 @@ public SegmentMetadataClientImpl(Segment segment, Controller controller, Connect\n         this(segment, controller, connectionPool,\n                 DelegationTokenProviderFactory.create(delegationToken, controller, segment, AccessOperation.READ));\n     }\n+    \n+    private final ScheduledExecutorService executor() {\n+        return connectionPool.getInternalExecutor();\n+    }\n \n     private void closeConnection(Reply badReply) {\n         log.info(\"Closing connection as a result of receiving: {}\", badReply);\n@@ -198,30 +203,30 @@ RawClient getConnection() {\n     }\n \n     @Override\n-    public long fetchCurrentSegmentLength() {\n+    public CompletableFuture<Long> fetchCurrentSegmentLength() {\n         Exceptions.checkNotClosed(closed.get(), this);\n         val result = RETRY_SCHEDULE.retryingOn(ConnectionFailedException.class)\n                                    .throwingOn(NoSuchSegmentException.class)\n-                                   .run(() -> Futures.getThrowingException(getStreamSegmentInfo()));\n-        return result.getWriteOffset();\n+                                   .runAsync(this::getStreamSegmentInfo, executor());\n+        return result.thenApply(info -> info.getWriteOffset());\n     }\n \n     @Override\n-    public long fetchProperty(SegmentAttribute attribute) {\n+    public CompletableFuture<Long> fetchProperty(SegmentAttribute attribute) {\n         Exceptions.checkNotClosed(closed.get(), this);\n         val result = RETRY_SCHEDULE.retryingOn(ConnectionFailedException.class)\n                                    .throwingOn(NoSuchSegmentException.class)\n-                                   .run(() -> Futures.getThrowingException(getPropertyAsync(attribute.getValue())));\n-        return result.getValue();\n+                                   .runAsync(() -> getPropertyAsync(attribute.getValue()), executor());\n+        return result.thenApply(p -> p.getValue());\n     }\n \n     @Override\n-    public boolean compareAndSetAttribute(SegmentAttribute attribute, long expectedValue, long newValue) {\n+    public CompletableFuture<Boolean> compareAndSetAttribute(SegmentAttribute attribute, long expectedValue, long newValue) {\n         Exceptions.checkNotClosed(closed.get(), this);\n         val result = RETRY_SCHEDULE.retryingOn(ConnectionFailedException.class)\n                                    .throwingOn(NoSuchSegmentException.class)\n-                                   .run(() -> Futures.getThrowingException(updatePropertyAsync(attribute.getValue(), expectedValue, newValue)));\n-        return result.isSuccess();\n+                                   .runAsync(() -> updatePropertyAsync(attribute.getValue(), expectedValue, newValue), executor());\n+        return result.thenApply(r -> r.isSuccess());\n     }\n \n     @Override\n@@ -233,35 +238,40 @@ public void close() {\n     }\n \n     @Override\n-    public SegmentInfo getSegmentInfo() {\n-        StreamSegmentInfo info = RETRY_SCHEDULE.retryingOn(ConnectionFailedException.class)\n-                .throwingOn(NoSuchSegmentException.class)\n-                .run(() -> Futures.getThrowingException(getStreamSegmentInfo()));\n-        return new SegmentInfo(segmentId, info.getStartOffset(), info.getWriteOffset(), info.isSealed(),\n-                               info.getLastModified());\n+    public CompletableFuture<SegmentInfo> getSegmentInfo() {\n+        return RETRY_SCHEDULE.retryingOn(ConnectionFailedException.class)\n+            .throwingOn(NoSuchSegmentException.class)\n+            .runAsync(() -> getStreamSegmentInfo(), executor())\n+            .thenApply(info -> {\n+                return new SegmentInfo(segmentId,\n+                        info.getStartOffset(),\n+                        info.getWriteOffset(),\n+                        info.isSealed(),\n+                        info.getLastModified());\n+            });\n     }\n \n     @Override\n-    public void truncateSegment(long offset) {\n-        RETRY_SCHEDULE.retryingOn(ConnectionFailedException.class).throwingOn(NoSuchSegmentException.class).run(() -> {\n-            truncateSegmentAsync(segmentId, offset, tokenProvider).exceptionally(t -> {\n+    public CompletableFuture<Void> truncateSegment(long offset) {\n+        return Futures.toVoid(RETRY_SCHEDULE.retryingOn(ConnectionFailedException.class)\n+            .throwingOn(NoSuchSegmentException.class)\n+            .runAsync(() -> truncateSegmentAsync(segmentId, offset, tokenProvider).exceptionally(t -> {\n                 final Throwable ex = Exceptions.unwrap(t);\n                 if (ex.getCause() instanceof SegmentTruncatedException) {\n-                    log.debug(\"Segment already truncated at offset {}. Details: {}\", offset, ex.getCause().getMessage());\n+                    log.debug(\"Segment already truncated at offset {}. Details: {}\",\n+                              offset,\n+                              ex.getCause().getMessage());\n                     return null;\n                 }\n                 throw new CompletionException(ex);\n-            }).join();\n-            return null;\n-        });\n+            }), executor()));\n     }\n \n     @Override\n-    public void sealSegment() {\n-        RETRY_SCHEDULE.retryingOn(ConnectionFailedException.class).throwingOn(NoSuchSegmentException.class).run(() -> {\n-            sealSegmentAsync(segmentId, tokenProvider).join();\n-            return null;\n-        });\n+    public CompletableFuture<Void> sealSegment() {\n+        return Futures.toVoid(RETRY_SCHEDULE.retryingOn(ConnectionFailedException.class)\n+            .throwingOn(NoSuchSegmentException.class)\n+            .runAsync(() -> sealSegmentAsync(segmentId, tokenProvider), executor()));\n     }\n \n }"
  },
  {
    "sha": "5021c861f1e6b07768bb8c47004dff06c9a402c3",
    "filename": "client/src/main/java/io/pravega/client/state/impl/RevisionedStreamClientImpl.java",
    "status": "modified",
    "additions": 14,
    "deletions": 8,
    "changes": 22,
    "blob_url": "https://github.com/pravega/pravega/blob/c3b233cf21eca821774c33ff56144bccd26b133d/client/src/main/java/io/pravega/client/state/impl/RevisionedStreamClientImpl.java",
    "raw_url": "https://github.com/pravega/pravega/raw/c3b233cf21eca821774c33ff56144bccd26b133d/client/src/main/java/io/pravega/client/state/impl/RevisionedStreamClientImpl.java",
    "contents_url": "https://api.github.com/repos/pravega/pravega/contents/client/src/main/java/io/pravega/client/state/impl/RevisionedStreamClientImpl.java?ref=c3b233cf21eca821774c33ff56144bccd26b133d",
    "patch": "@@ -131,7 +131,7 @@ public void writeUnconditionally(T value) {\n         log.trace(\"Read segment {} from revision {}\", segment, start);\n         synchronized (lock) {\n             long startOffset = start.asImpl().getOffsetInSegment();\n-            SegmentInfo segmentInfo = meta.getSegmentInfo();\n+            SegmentInfo segmentInfo = Futures.getThrowingException(meta.getSegmentInfo());\n             long endOffset = segmentInfo.getWriteOffset();\n             if (startOffset < segmentInfo.getStartingOffset()) {\n                 throw new TruncatedDataException(format(\"Data at the supplied revision {%s} has been truncated. The current segment info is {%s}\", start, segmentInfo));\n@@ -143,10 +143,12 @@ public void writeUnconditionally(T value) {\n     \n     @Override\n     public Revision fetchLatestRevision() {\n+        CompletableFuture<Long> streamLength;\n         synchronized (lock) {\n-            long streamLength = meta.fetchCurrentSegmentLength();\n-            return new RevisionImpl(segment, streamLength, 0);\n+            streamLength = meta.fetchCurrentSegmentLength();\n         }\n+        return new RevisionImpl(segment, Futures.getThrowingException(streamLength), 0);\n+        \n     }\n \n     private class StreamIterator implements Iterator<Entry<Revision, T>> {\n@@ -196,30 +198,34 @@ public boolean hasNext() {\n     @Override\n     public Revision getMark() {\n         log.trace(\"Fetching mark for segment {}\", segment);\n+        CompletableFuture<Long> valueF;\n         synchronized (lock) {\n-            long value = meta.fetchProperty(RevisionStreamClientMark);\n-            return value == NULL_VALUE ? null : new RevisionImpl(segment, value, 0);\n+            valueF = meta.fetchProperty(RevisionStreamClientMark);\n         }\n+        long value = Futures.getThrowingException(valueF);\n+        return value == NULL_VALUE ? null : new RevisionImpl(segment, value, 0);\n     }\n \n     @Override\n     public boolean compareAndSetMark(Revision expected, Revision newLocation) {\n         long expectedValue = expected == null ? NULL_VALUE : expected.asImpl().getOffsetInSegment();\n         long newValue = newLocation == null ? NULL_VALUE : newLocation.asImpl().getOffsetInSegment();\n+        CompletableFuture<Boolean> result;\n         synchronized (lock) {\n-            return meta.compareAndSetAttribute(RevisionStreamClientMark, expectedValue, newValue);\n+            result = meta.compareAndSetAttribute(RevisionStreamClientMark, expectedValue, newValue);\n         }\n+        return Futures.getThrowingException(result);\n     }\n \n     @Override\n     public Revision fetchOldestRevision() {\n-        long startingOffset = meta.getSegmentInfo().getStartingOffset();\n+        long startingOffset = Futures.getThrowingException(meta.getSegmentInfo()).getStartingOffset();\n         return new RevisionImpl(segment, startingOffset, 0);\n     }\n \n     @Override\n     public void truncateToRevision(Revision newStart) {\n-        meta.truncateSegment(newStart.asImpl().getOffsetInSegment());\n+        Futures.getThrowingException(meta.truncateSegment(newStart.asImpl().getOffsetInSegment()));\n     }\n \n     @Override"
  },
  {
    "sha": "3b3dc42f6a6afb5727e4a85431f8c5ce03ddd90c",
    "filename": "client/src/main/java/io/pravega/client/stream/impl/EventStreamReaderImpl.java",
    "status": "modified",
    "additions": 2,
    "deletions": 1,
    "changes": 3,
    "blob_url": "https://github.com/pravega/pravega/blob/c3b233cf21eca821774c33ff56144bccd26b133d/client/src/main/java/io/pravega/client/stream/impl/EventStreamReaderImpl.java",
    "raw_url": "https://github.com/pravega/pravega/raw/c3b233cf21eca821774c33ff56144bccd26b133d/client/src/main/java/io/pravega/client/stream/impl/EventStreamReaderImpl.java",
    "contents_url": "https://api.github.com/repos/pravega/pravega/contents/client/src/main/java/io/pravega/client/stream/impl/EventStreamReaderImpl.java?ref=c3b233cf21eca821774c33ff56144bccd26b133d",
    "patch": "@@ -39,6 +39,7 @@\n import io.pravega.client.stream.impl.SegmentWithRange.Range;\n import io.pravega.common.Exceptions;\n import io.pravega.common.Timer;\n+import io.pravega.common.concurrent.Futures;\n import io.pravega.shared.security.auth.AccessOperation;\n import io.pravega.common.util.CopyOnWriteHashMap;\n import io.pravega.shared.protocol.netty.WireCommands;\n@@ -385,7 +386,7 @@ private void handleSegmentTruncated(EventSegmentReader segmentReader) throws Tru\n         SegmentMetadataClient metadataClient = metadataClientFactory.createSegmentMetadataClient(segmentId,\n                 DelegationTokenProviderFactory.create(controller, segmentId, AccessOperation.READ));\n         try {\n-            long startingOffset = metadataClient.getSegmentInfo().getStartingOffset();\n+            long startingOffset = Futures.getThrowingException(metadataClient.getSegmentInfo()).getStartingOffset();\n             segmentReader.setOffset(startingOffset);\n         } catch (NoSuchSegmentException e) {\n             handleEndOfSegment(segmentReader, true);"
  },
  {
    "sha": "4b60e31d53714f11c83961629a6870bf50392b47",
    "filename": "client/src/main/java/io/pravega/client/stream/impl/ReaderGroupImpl.java",
    "status": "modified",
    "additions": 18,
    "deletions": 16,
    "changes": 34,
    "blob_url": "https://github.com/pravega/pravega/blob/c3b233cf21eca821774c33ff56144bccd26b133d/client/src/main/java/io/pravega/client/stream/impl/ReaderGroupImpl.java",
    "raw_url": "https://github.com/pravega/pravega/raw/c3b233cf21eca821774c33ff56144bccd26b133d/client/src/main/java/io/pravega/client/stream/impl/ReaderGroupImpl.java",
    "contents_url": "https://api.github.com/repos/pravega/pravega/contents/client/src/main/java/io/pravega/client/stream/impl/ReaderGroupImpl.java?ref=c3b233cf21eca821774c33ff56144bccd26b133d",
    "patch": "@@ -353,20 +353,20 @@ public long unreadBytes() {\n \n         if (checkPointedPositions.isPresent()) {\n             log.debug(\"Computing unread bytes based on the last checkPoint position\");\n-            return getUnreadBytes(checkPointedPositions.get(), synchronizer.getState().getEndSegments(), metaFactory);\n+            return getUnreadBytes(checkPointedPositions.get(), synchronizer.getState().getEndSegments());\n         } else {\n             log.info(\"No checkpoints found, using the last known offset to compute unread bytes\");\n-            return getUnreadBytesIgnoringRange(synchronizer.getState().getPositions(), synchronizer.getState().getEndSegments(), metaFactory);\n+            return getUnreadBytesIgnoringRange(synchronizer.getState().getPositions(), synchronizer.getState().getEndSegments());\n         }\n     }\n \n-    private long getUnreadBytes(Map<Stream, Map<Segment, Long>> positions, Map<Segment, Long> endSegments, SegmentMetadataClientFactory metaFactory) {\n+    private long getUnreadBytes(Map<Stream, Map<Segment, Long>> positions, Map<Segment, Long> endSegments) {\n         log.debug(\"Compute unread bytes from position {}\", positions);\n         final List<CompletableFuture<Long>> futures = new ArrayList<>(positions.size());\n         for (Entry<Stream, Map<Segment, Long>> streamPosition : positions.entrySet()) {\n             StreamCut fromStreamCut = new StreamCutImpl(streamPosition.getKey(), streamPosition.getValue());\n             StreamCut toStreamCut = computeEndStreamCut(streamPosition.getKey(), endSegments);\n-            futures.add(getRemainingBytes(metaFactory, fromStreamCut, toStreamCut));\n+            futures.add(getRemainingBytes(streamPosition.getKey(), fromStreamCut, toStreamCut));\n         }\n         return Futures.getAndHandleExceptions(allOfWithResults(futures).thenApply(listOfLong -> {\n             return listOfLong.stream()\n@@ -376,13 +376,13 @@ private long getUnreadBytes(Map<Stream, Map<Segment, Long>> positions, Map<Segme\n     }\n     \n     private long getUnreadBytesIgnoringRange(Map<Stream, Map<SegmentWithRange, Long>> positions,\n-                                             Map<Segment, Long> endSegments, SegmentMetadataClientFactory metaFactory) {\n+                                             Map<Segment, Long> endSegments) {\n         log.debug(\"Compute unread bytes from position {}\", positions);\n         long totalLength = 0;\n         for (Entry<Stream, Map<SegmentWithRange, Long>> streamPosition : positions.entrySet()) {\n             StreamCut fromStreamCut = new StreamCutImpl(streamPosition.getKey(), dropRange(streamPosition.getValue()));\n             StreamCut toStreamCut = computeEndStreamCut(streamPosition.getKey(), endSegments);\n-            totalLength += Futures.getAndHandleExceptions(getRemainingBytes(metaFactory, fromStreamCut, toStreamCut), RuntimeException::new).longValue();\n+            totalLength += Futures.getAndHandleExceptions(getRemainingBytes(streamPosition.getKey(), fromStreamCut, toStreamCut), RuntimeException::new).longValue();\n         }\n         return totalLength;\n     }\n@@ -398,7 +398,7 @@ private StreamCut computeEndStreamCut(Stream stream, Map<Segment, Long> endSegme\n         return toPositions.isEmpty() ? StreamCut.UNBOUNDED : new StreamCutImpl(stream, toPositions);\n     }\n \n-    private CompletableFuture<Long> getRemainingBytes(SegmentMetadataClientFactory metaFactory, StreamCut fromStreamCut, StreamCut toStreamCut) {\n+    private CompletableFuture<Long> getRemainingBytes(Stream stream, StreamCut fromStreamCut, StreamCut toStreamCut) {\n         //fetch StreamSegmentSuccessors\n         final CompletableFuture<StreamSegmentSuccessors> unread;\n         final Map<Segment, Long> endPositions;\n@@ -409,20 +409,22 @@ private StreamCut computeEndStreamCut(Stream stream, Map<Segment, Long> endSegme\n             unread = controller.getSegments(fromStreamCut, toStreamCut);\n             endPositions = toStreamCut.asImpl().getPositions();\n         }\n-        return unread.thenApply(unreadVal -> {\n-            long totalLength = 0;\n-            DelegationTokenProvider tokenProvider = null;\n-            for (Segment s : unreadVal.getSegments()) {\n+        return unread.thenCompose(unreadVal -> {\n+            DelegationTokenProvider tokenProvider = DelegationTokenProviderFactory\n+                .create(controller, stream.getScope(), stream.getStreamName(), AccessOperation.READ);\n+            return Futures.allOfWithResults(unreadVal.getSegments().stream().map(s -> {\n                 if (endPositions.containsKey(s)) {\n-                    totalLength += endPositions.get(s);\n+                    return CompletableFuture.completedFuture(endPositions.get(s));\n                 } else {\n-                    if (tokenProvider == null) {\n-                        tokenProvider = DelegationTokenProviderFactory.create(controller, s, AccessOperation.READ);\n-                    }\n                     @Cleanup\n                     SegmentMetadataClient metadataClient = metaFactory.createSegmentMetadataClient(s, tokenProvider);\n-                    totalLength += metadataClient.fetchCurrentSegmentLength();\n+                    return metadataClient.fetchCurrentSegmentLength();\n                 }\n+            }).collect(Collectors.toList()));\n+        }).thenApply(sizes -> {\n+            long totalLength = 0;\n+            for (long bytesRemaining : sizes) {\n+                totalLength += bytesRemaining;\n             }\n             for (long bytesRead : fromStreamCut.asImpl().getPositions().values()) {\n                 totalLength -= bytesRead;"
  },
  {
    "sha": "992d6139b7c5f646e83430bcac0c5583c9e960ce",
    "filename": "client/src/test/java/io/pravega/client/batch/impl/SegmentIteratorTest.java",
    "status": "modified",
    "additions": 4,
    "deletions": 4,
    "changes": 8,
    "blob_url": "https://github.com/pravega/pravega/blob/c3b233cf21eca821774c33ff56144bccd26b133d/client/src/test/java/io/pravega/client/batch/impl/SegmentIteratorTest.java",
    "raw_url": "https://github.com/pravega/pravega/raw/c3b233cf21eca821774c33ff56144bccd26b133d/client/src/test/java/io/pravega/client/batch/impl/SegmentIteratorTest.java",
    "contents_url": "https://api.github.com/repos/pravega/pravega/contents/client/src/test/java/io/pravega/client/batch/impl/SegmentIteratorTest.java?ref=c3b233cf21eca821774c33ff56144bccd26b133d",
    "patch": "@@ -52,7 +52,7 @@ public void testHasNext() {\n         sendData(\"2\", outputStream);\n         sendData(\"3\", outputStream);\n         SegmentMetadataClient metadataClient = factory.createSegmentMetadataClient(segment, DelegationTokenProviderFactory.createWithEmptyToken());\n-        long length = metadataClient.getSegmentInfo().getWriteOffset();\n+        long length = metadataClient.getSegmentInfo().join().getWriteOffset();\n         @Cleanup\n         SegmentIteratorImpl<String> iter = new SegmentIteratorImpl<>(factory, segment, stringSerializer, 0, length);\n         assertTrue(iter.hasNext());\n@@ -78,7 +78,7 @@ public void testOffset() {\n         sendData(\"3\", outputStream);\n         SegmentMetadataClient metadataClient = factory.createSegmentMetadataClient(segment,\n                 DelegationTokenProviderFactory.createWithEmptyToken());\n-        long length = metadataClient.getSegmentInfo().getWriteOffset();\n+        long length = metadataClient.getSegmentInfo().join().getWriteOffset();\n         @Cleanup\n         SegmentIteratorImpl<String> iter = new SegmentIteratorImpl<>(factory, segment, stringSerializer, 0, length);\n         assertEquals(0, iter.getOffset());\n@@ -107,11 +107,11 @@ public void testTruncate() {\n         sendData(\"3\", outputStream);\n         SegmentMetadataClient metadataClient = factory.createSegmentMetadataClient(segment,\n                 DelegationTokenProviderFactory.createWithEmptyToken());\n-        long length = metadataClient.getSegmentInfo().getWriteOffset();\n+        long length = metadataClient.getSegmentInfo().join().getWriteOffset();\n         @Cleanup\n         SegmentIteratorImpl<String> iter = new SegmentIteratorImpl<>(factory, segment, stringSerializer, 0, length);\n         assertEquals(\"1\", iter.next());\n-        long segmentLength = metadataClient.fetchCurrentSegmentLength();\n+        long segmentLength = metadataClient.fetchCurrentSegmentLength().join();\n         assertEquals(0, segmentLength % 3);\n         metadataClient.truncateSegment(segmentLength * 2 / 3);\n         AssertExtensions.assertThrows(TruncatedDataException.class, () -> iter.next());"
  },
  {
    "sha": "7046ef5cdc47d297eb996d7537b2e1444bbf9b78",
    "filename": "client/src/test/java/io/pravega/client/segment/impl/SegmentMetadataClientTest.java",
    "status": "modified",
    "additions": 5,
    "deletions": 5,
    "changes": 10,
    "blob_url": "https://github.com/pravega/pravega/blob/c3b233cf21eca821774c33ff56144bccd26b133d/client/src/test/java/io/pravega/client/segment/impl/SegmentMetadataClientTest.java",
    "raw_url": "https://github.com/pravega/pravega/raw/c3b233cf21eca821774c33ff56144bccd26b133d/client/src/test/java/io/pravega/client/segment/impl/SegmentMetadataClientTest.java",
    "contents_url": "https://api.github.com/repos/pravega/pravega/contents/client/src/test/java/io/pravega/client/segment/impl/SegmentMetadataClientTest.java?ref=c3b233cf21eca821774c33ff56144bccd26b133d",
    "patch": "@@ -70,7 +70,7 @@ public Void answer(InvocationOnMock invocation) throws Throwable {\n                 return null;\n             }\n         }).when(connection).send(any(WireCommands.GetStreamSegmentInfo.class));\n-        long length = client.fetchCurrentSegmentLength();\n+        long length = client.fetchCurrentSegmentLength().join();\n         assertEquals(123, length);\n     }\n     \n@@ -213,7 +213,7 @@ public Void answer(InvocationOnMock invocation) throws Throwable {\n                 return null;\n             }\n         }).when(connection).send(any(WireCommands.GetSegmentAttribute.class));\n-        long value = client.fetchProperty(SegmentAttribute.RevisionStreamClientMark);\n+        long value = client.fetchProperty(SegmentAttribute.RevisionStreamClientMark).join();\n         assertEquals(123, value);\n     }\n \n@@ -239,7 +239,7 @@ public Void answer(InvocationOnMock invocation) throws Throwable {\n                 return null;\n             }\n         }).when(connection).send(any(WireCommands.UpdateSegmentAttribute.class));\n-        assertTrue(client.compareAndSetAttribute(SegmentAttribute.RevisionStreamClientMark, -1234, 1234));\n+        assertTrue(client.compareAndSetAttribute(SegmentAttribute.RevisionStreamClientMark, -1234, 1234).join());\n     }\n \n     @Test(timeout = 10000)\n@@ -274,7 +274,7 @@ public Void answer(InvocationOnMock invocation) throws Throwable {\n             }\n         }).when(connection).send(any(WireCommands.GetStreamSegmentInfo.class));\n \n-        long length = client.fetchCurrentSegmentLength();\n+        long length = client.fetchCurrentSegmentLength().join();\n         InOrder order = Mockito.inOrder(connection, cf);\n         order.verify(cf).establishConnection(eq(endpoint), any(ReplyProcessor.class));\n         order.verify(connection).send(Mockito.eq(new WireCommands.GetStreamSegmentInfo(requestIds.get(0), segment.getScopedName(), \"\")));\n@@ -342,7 +342,7 @@ public Void answer(InvocationOnMock invocation) throws Throwable {\n         @Cleanup\n         SegmentMetadataClientImpl client = new SegmentMetadataClientImpl(segment, controller, cf, \"\");\n         InOrder order = Mockito.inOrder(connection1, connection2, cf);\n-        long length = client.fetchCurrentSegmentLength();\n+        long length = client.fetchCurrentSegmentLength().join();\n         order.verify(cf, Mockito.times(2)).getClientConnection(Mockito.any(Flow.class), Mockito.eq(endpoint), Mockito.any(), Mockito.<CompletableFuture<ClientConnection>>any());\n         order.verify(connection1).send(Mockito.eq(new WireCommands.GetStreamSegmentInfo(requestIds.get(0), segment.getScopedName(), \"\")));\n         order.verify(connection1).close();"
  },
  {
    "sha": "d2ba82faa5cd5126bc51be8a64a5ef9101d34cc5",
    "filename": "client/src/test/java/io/pravega/client/state/impl/RevisionedStreamClientTest.java",
    "status": "modified",
    "additions": 1,
    "deletions": 1,
    "changes": 2,
    "blob_url": "https://github.com/pravega/pravega/blob/c3b233cf21eca821774c33ff56144bccd26b133d/client/src/test/java/io/pravega/client/state/impl/RevisionedStreamClientTest.java",
    "raw_url": "https://github.com/pravega/pravega/raw/c3b233cf21eca821774c33ff56144bccd26b133d/client/src/test/java/io/pravega/client/state/impl/RevisionedStreamClientTest.java",
    "contents_url": "https://api.github.com/repos/pravega/pravega/contents/client/src/test/java/io/pravega/client/state/impl/RevisionedStreamClientTest.java?ref=c3b233cf21eca821774c33ff56144bccd26b133d",
    "patch": "@@ -358,7 +358,7 @@ public void testTimeoutWithStreamIterator() throws Exception {\n         SegmentMetadataClientFactory metaFactory = mock(SegmentMetadataClientFactory.class);\n         SegmentMetadataClient metaClient = mock(SegmentMetadataClient.class);\n         when(metaFactory.createSegmentMetadataClient(any(Segment.class), any(DelegationTokenProvider.class))).thenReturn(metaClient);\n-        when(metaClient.getSegmentInfo()).thenReturn(new SegmentInfo(segment, 0, 30, false, System.currentTimeMillis()));\n+        when(metaClient.getSegmentInfo()).thenReturn(CompletableFuture.completedFuture(new SegmentInfo(segment, 0, 30, false, System.currentTimeMillis())));\n \n         @Cleanup\n         SynchronizerClientFactory clientFactory = new ClientFactoryImpl(scope, controller, connectionFactory,"
  },
  {
    "sha": "16e33147d059f828ba756b331056143b4a950a09",
    "filename": "client/src/test/java/io/pravega/client/stream/impl/EventStreamReaderTest.java",
    "status": "modified",
    "additions": 1,
    "deletions": 1,
    "changes": 2,
    "blob_url": "https://github.com/pravega/pravega/blob/c3b233cf21eca821774c33ff56144bccd26b133d/client/src/test/java/io/pravega/client/stream/impl/EventStreamReaderTest.java",
    "raw_url": "https://github.com/pravega/pravega/raw/c3b233cf21eca821774c33ff56144bccd26b133d/client/src/test/java/io/pravega/client/stream/impl/EventStreamReaderTest.java",
    "contents_url": "https://api.github.com/repos/pravega/pravega/contents/client/src/test/java/io/pravega/client/stream/impl/EventStreamReaderTest.java?ref=c3b233cf21eca821774c33ff56144bccd26b133d",
    "patch": "@@ -703,7 +703,7 @@ public void testDataTruncated() throws SegmentSealedException, ReaderNotInReader\n         ByteBuffer buffer1 = writeInt(stream, 1);\n         ByteBuffer buffer2 = writeInt(stream, 2);\n         writeInt(stream, 3);\n-        long length = metadataClient.fetchCurrentSegmentLength();\n+        long length = metadataClient.fetchCurrentSegmentLength().join();\n         assertEquals(0, length % 3);\n         EventRead<byte[]> event1 = reader.readNextEvent(0);\n         assertEquals(buffer1, ByteBuffer.wrap(event1.getEvent()));"
  },
  {
    "sha": "51606d40a37ec2328afb9b1ad92087afce7aa7d9",
    "filename": "client/src/test/java/io/pravega/client/stream/impl/EventStreamWriterTest.java",
    "status": "modified",
    "additions": 5,
    "deletions": 5,
    "changes": 10,
    "blob_url": "https://github.com/pravega/pravega/blob/c3b233cf21eca821774c33ff56144bccd26b133d/client/src/test/java/io/pravega/client/stream/impl/EventStreamWriterTest.java",
    "raw_url": "https://github.com/pravega/pravega/raw/c3b233cf21eca821774c33ff56144bccd26b133d/client/src/test/java/io/pravega/client/stream/impl/EventStreamWriterTest.java",
    "contents_url": "https://api.github.com/repos/pravega/pravega/contents/client/src/test/java/io/pravega/client/stream/impl/EventStreamWriterTest.java?ref=c3b233cf21eca821774c33ff56144bccd26b133d",
    "patch": "@@ -528,7 +528,7 @@ public void testSegmentSealedInFlush() throws EndOfSegmentException, SegmentTrun\n         writer.flush();\n \n         Mockito.verify(controller, Mockito.times(1)).getCurrentSegments(any(), any());\n-        assertTrue(outputStream2.fetchCurrentSegmentLength() > 0);\n+        assertTrue(outputStream2.fetchCurrentSegmentLength().join() > 0);\n         assertEquals(serializer.serialize(\"Foo\"), outputStream2.read());\n     }\n \n@@ -571,7 +571,7 @@ public void testRetryFlushSegmentSealed() throws EndOfSegmentException, SegmentT\n         });\n \n         Mockito.verify(controller, Mockito.times(1)).getCurrentSegments(any(), any());\n-        assertTrue(outputStream2.fetchCurrentSegmentLength() > 0);\n+        assertTrue(outputStream2.fetchCurrentSegmentLength().join() > 0);\n         assertEquals(serializer.serialize(\"Foo\"), outputStream2.read());\n     }\n \n@@ -620,7 +620,7 @@ public void testWriteBetweenSeals() throws EndOfSegmentException, SegmentTruncat\n         });\n \n         Mockito.verify(controller, Mockito.times(1)).getCurrentSegments(any(), any());\n-        assertTrue(outputStream2.fetchCurrentSegmentLength() > 0);\n+        assertTrue(outputStream2.fetchCurrentSegmentLength().join() > 0);\n         assertEquals(serializer.serialize(\"Foo\"), outputStream2.read());\n     }\n     \n@@ -663,7 +663,7 @@ public void testRetryCloseSegmentSealed() throws EndOfSegmentException, SegmentT\n         });\n \n         Mockito.verify(controller, Mockito.times(1)).getCurrentSegments(any(), any());\n-        assertTrue(outputStream2.fetchCurrentSegmentLength() > 0);\n+        assertTrue(outputStream2.fetchCurrentSegmentLength().join() > 0);\n         assertTrue(outputStream2.isClosed());\n         //the connection to outputStream is closed with the failConnection during SegmentSealed Callback.\n         assertEquals(serializer.serialize(\"Foo\"), outputStream2.read());\n@@ -704,7 +704,7 @@ public void testSegmentSealedInClose() throws EndOfSegmentException, SegmentTrun\n         writer.close();\n \n         Mockito.verify(controller, Mockito.times(1)).getCurrentSegments(any(), any());\n-        assertTrue(outputStream2.fetchCurrentSegmentLength() > 0);\n+        assertTrue(outputStream2.fetchCurrentSegmentLength().join() > 0);\n         assertEquals(serializer.serialize(\"Foo\"), outputStream2.read());\n     }\n "
  },
  {
    "sha": "07adc3c3ce488e4f6b56c8d4eb93df51b994a79f",
    "filename": "client/src/test/java/io/pravega/client/stream/mock/MockSegmentIoStreams.java",
    "status": "modified",
    "additions": 13,
    "deletions": 11,
    "changes": 24,
    "blob_url": "https://github.com/pravega/pravega/blob/c3b233cf21eca821774c33ff56144bccd26b133d/client/src/test/java/io/pravega/client/stream/mock/MockSegmentIoStreams.java",
    "raw_url": "https://github.com/pravega/pravega/raw/c3b233cf21eca821774c33ff56144bccd26b133d/client/src/test/java/io/pravega/client/stream/mock/MockSegmentIoStreams.java",
    "contents_url": "https://api.github.com/repos/pravega/pravega/contents/client/src/test/java/io/pravega/client/stream/mock/MockSegmentIoStreams.java?ref=c3b233cf21eca821774c33ff56144bccd26b133d",
    "patch": "@@ -80,8 +80,8 @@ public long getOffset() {\n \n     @Override\n     @Synchronized\n-    public long fetchCurrentSegmentLength() {\n-        return writeOffset;\n+    public CompletableFuture<Long> fetchCurrentSegmentLength() {\n+        return CompletableFuture.completedFuture(writeOffset);\n     }\n \n     \n@@ -204,15 +204,15 @@ public String getSegmentName() {\n     }\n \n     @Override\n-    public long fetchProperty(SegmentAttribute attribute) {\n+    public CompletableFuture<Long> fetchProperty(SegmentAttribute attribute) {\n         Long result = attributes.get(attribute);\n-        return result == null ? SegmentAttribute.NULL_VALUE : result;\n+        return CompletableFuture.completedFuture(result == null ? Long.valueOf(SegmentAttribute.NULL_VALUE) : result);\n     }\n \n     @Override\n-    public boolean compareAndSetAttribute(SegmentAttribute attribute, long expectedValue, long newValue) {\n+    public CompletableFuture<Boolean> compareAndSetAttribute(SegmentAttribute attribute, long expectedValue, long newValue) {\n         attributes.putIfAbsent(attribute, SegmentAttribute.NULL_VALUE);\n-        return attributes.replace(attribute, expectedValue, newValue);\n+        return CompletableFuture.completedFuture(attributes.replace(attribute, expectedValue, newValue));\n     }\n \n     public boolean isClosed() {\n@@ -221,17 +221,18 @@ public boolean isClosed() {\n \n     @Override\n     @Synchronized\n-    public SegmentInfo getSegmentInfo() {\n-        return new SegmentInfo(segment, startingOffset, writeOffset, false, System.currentTimeMillis());\n+    public CompletableFuture<SegmentInfo> getSegmentInfo() {\n+        return CompletableFuture.completedFuture(new SegmentInfo(segment, startingOffset, writeOffset, false, System.currentTimeMillis()));\n     }\n \n     @Override\n     @Synchronized\n-    public void truncateSegment(long offset) {\n+    public CompletableFuture<Void> truncateSegment(long offset) {\n         Preconditions.checkArgument(offset <= writeOffset);\n         if (offset >= startingOffset) {\n             startingOffset = offset;\n         }\n+        return CompletableFuture.completedFuture(null);\n     }\n \n     @Override\n@@ -246,12 +247,13 @@ public int bytesInBuffer() {\n     }\n \n     @Override\n-    public void sealSegment() {\n+    public CompletableFuture<Void> sealSegment() {\n         //Nothing to do\n+        return CompletableFuture.completedFuture(null);\n     }\n \n     @Override\n     public long getLastObservedWriteOffset() {\n-        return fetchCurrentSegmentLength();\n+        return fetchCurrentSegmentLength().join();\n     }\n }"
  },
  {
    "sha": "4582524c59d9026a249e989ec7d01614517ebb00",
    "filename": "test/integration/src/test/java/io/pravega/test/integration/AppendReconnectTest.java",
    "status": "modified",
    "additions": 2,
    "deletions": 2,
    "changes": 4,
    "blob_url": "https://github.com/pravega/pravega/blob/c3b233cf21eca821774c33ff56144bccd26b133d/test/integration/src/test/java/io/pravega/test/integration/AppendReconnectTest.java",
    "raw_url": "https://github.com/pravega/pravega/raw/c3b233cf21eca821774c33ff56144bccd26b133d/test/integration/src/test/java/io/pravega/test/integration/AppendReconnectTest.java",
    "contents_url": "https://api.github.com/repos/pravega/pravega/contents/test/integration/src/test/java/io/pravega/test/integration/AppendReconnectTest.java?ref=c3b233cf21eca821774c33ff56144bccd26b133d",
    "patch": "@@ -104,7 +104,7 @@ public void reconnectOnSegmentClient() throws Exception {\n         @Cleanup\n         SegmentMetadataClient metadataClient = new SegmentMetadataClientFactoryImpl(controller, connectionPool).createSegmentMetadataClient(segment,\n                 DelegationTokenProviderFactory.createWithEmptyToken());\n-        assertEquals(payload.length * 2, metadataClient.fetchCurrentSegmentLength());\n+        assertEquals(payload.length * 2, metadataClient.fetchCurrentSegmentLength().join().longValue());\n     }\n     \n     @Test(timeout = 30000)\n@@ -142,6 +142,6 @@ public void reconnectThroughConditionalClient() throws Exception {\n         SegmentMetadataClient metadataClient = new SegmentMetadataClientFactoryImpl(controller, connectionPool).createSegmentMetadataClient(segment,\n                 DelegationTokenProviderFactory.createWithEmptyToken());\n         assertEquals((payload.length + WireCommands.TYPE_PLUS_LENGTH_SIZE) * 2,\n-                     metadataClient.fetchCurrentSegmentLength());\n+                     metadataClient.fetchCurrentSegmentLength().join().longValue());\n     }\n }"
  },
  {
    "sha": "186c68ac166a13d215305d20220f99589c776dc4",
    "filename": "test/integration/src/test/java/io/pravega/test/integration/endtoendtest/EndToEndTruncationTest.java",
    "status": "modified",
    "additions": 7,
    "deletions": 7,
    "changes": 14,
    "blob_url": "https://github.com/pravega/pravega/blob/c3b233cf21eca821774c33ff56144bccd26b133d/test/integration/src/test/java/io/pravega/test/integration/endtoendtest/EndToEndTruncationTest.java",
    "raw_url": "https://github.com/pravega/pravega/raw/c3b233cf21eca821774c33ff56144bccd26b133d/test/integration/src/test/java/io/pravega/test/integration/endtoendtest/EndToEndTruncationTest.java",
    "contents_url": "https://api.github.com/repos/pravega/pravega/contents/test/integration/src/test/java/io/pravega/test/integration/endtoendtest/EndToEndTruncationTest.java?ref=c3b233cf21eca821774c33ff56144bccd26b133d",
    "patch": "@@ -170,14 +170,14 @@ public void testTruncationOffsets() throws InterruptedException, ExecutionExcept\n         Segment segment = new Segment(scope, streamName, 0);\n         SegmentMetadataClient metadataClient = metadataClientFactory.createSegmentMetadataClient(segment,\n                 DelegationTokenProviderFactory.createWithEmptyToken());\n-        assertEquals(0, metadataClient.getSegmentInfo().getStartingOffset());\n-        long writeOffset = metadataClient.getSegmentInfo().getWriteOffset();\n-        assertEquals(writeOffset, metadataClient.fetchCurrentSegmentLength());\n-        assertTrue(metadataClient.getSegmentInfo().getWriteOffset() > testString.length());\n+        assertEquals(0, metadataClient.getSegmentInfo().join().getStartingOffset());\n+        long writeOffset = metadataClient.getSegmentInfo().join().getWriteOffset();\n+        assertEquals(writeOffset, metadataClient.fetchCurrentSegmentLength().join().longValue());\n+        assertTrue(metadataClient.getSegmentInfo().join().getWriteOffset() > testString.length());\n         metadataClient.truncateSegment(writeOffset);\n-        assertEquals(writeOffset, metadataClient.getSegmentInfo().getStartingOffset());\n-        assertEquals(writeOffset, metadataClient.getSegmentInfo().getWriteOffset());\n-        assertEquals(writeOffset, metadataClient.fetchCurrentSegmentLength());\n+        assertEquals(writeOffset, metadataClient.getSegmentInfo().join().getStartingOffset());\n+        assertEquals(writeOffset, metadataClient.getSegmentInfo().join().getWriteOffset());\n+        assertEquals(writeOffset, metadataClient.fetchCurrentSegmentLength().join().longValue());\n \n         ack = producer.writeEvent(testString);\n         ack.get(5, TimeUnit.SECONDS);"
  }
]
