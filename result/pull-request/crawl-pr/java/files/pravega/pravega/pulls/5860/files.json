[
  {
    "sha": "9058f9e0a22fe5e83ddb2f5f537696715c6c9ef3",
    "filename": "common/src/main/java/io/pravega/common/util/AbstractBufferView.java",
    "status": "modified",
    "additions": 5,
    "deletions": 0,
    "changes": 5,
    "blob_url": "https://github.com/pravega/pravega/blob/3bf83956144fe73175fc85a183c1b26cc7732520/common/src/main/java/io/pravega/common/util/AbstractBufferView.java",
    "raw_url": "https://github.com/pravega/pravega/raw/3bf83956144fe73175fc85a183c1b26cc7732520/common/src/main/java/io/pravega/common/util/AbstractBufferView.java",
    "contents_url": "https://api.github.com/repos/pravega/pravega/contents/common/src/main/java/io/pravega/common/util/AbstractBufferView.java?ref=3bf83956144fe73175fc85a183c1b26cc7732520",
    "patch": "@@ -166,6 +166,11 @@ public int getLength() {\n             return 0;\n         }\n \n+        @Override\n+        public int getAllocatedLength() {\n+            return 0;\n+        }\n+\n         @Override\n         public InputStream getReader(int offset, int length) {\n             return slice(offset, length).getReader();"
  },
  {
    "sha": "fb54b4d8b0ad8ec122492725311c91b15c06d433",
    "filename": "common/src/main/java/io/pravega/common/util/BufferView.java",
    "status": "modified",
    "additions": 8,
    "deletions": 1,
    "changes": 9,
    "blob_url": "https://github.com/pravega/pravega/blob/3bf83956144fe73175fc85a183c1b26cc7732520/common/src/main/java/io/pravega/common/util/BufferView.java",
    "raw_url": "https://github.com/pravega/pravega/raw/3bf83956144fe73175fc85a183c1b26cc7732520/common/src/main/java/io/pravega/common/util/BufferView.java",
    "contents_url": "https://api.github.com/repos/pravega/pravega/contents/common/src/main/java/io/pravega/common/util/BufferView.java?ref=3bf83956144fe73175fc85a183c1b26cc7732520",
    "patch": "@@ -37,6 +37,13 @@\n      */\n     int getLength();\n \n+    /**\n+     * Gets a value indicating the amount of memory (in bytes) allocated for this {@link BufferView}.\n+     *\n+     * @return The allocated memory size.\n+     */\n+    int getAllocatedLength();\n+\n     /**\n      * Creates a new {@link BufferView.Reader} that can be used to read this {@link BufferView}. This reader is\n      * preferable to {@link #getReader()} that returns an {@link InputStream} as it contains optimized methods for copying\n@@ -87,7 +94,7 @@ default BufferView slice() {\n     /**\n      * Returns a copy of the contents of this {@link BufferView}.\n      *\n-     * @return A byte array with the same length as this ArrayView, containing a copy of the data within it.\n+     * @return A byte array with the same length as this {@link BufferView}, containing a copy of the data within it.\n      */\n     byte[] getCopy();\n "
  },
  {
    "sha": "744b06944ee6e2358ac9d13f2dc6f48c21942c2d",
    "filename": "common/src/main/java/io/pravega/common/util/ByteArraySegment.java",
    "status": "modified",
    "additions": 5,
    "deletions": 0,
    "changes": 5,
    "blob_url": "https://github.com/pravega/pravega/blob/3bf83956144fe73175fc85a183c1b26cc7732520/common/src/main/java/io/pravega/common/util/ByteArraySegment.java",
    "raw_url": "https://github.com/pravega/pravega/raw/3bf83956144fe73175fc85a183c1b26cc7732520/common/src/main/java/io/pravega/common/util/ByteArraySegment.java",
    "contents_url": "https://api.github.com/repos/pravega/pravega/contents/common/src/main/java/io/pravega/common/util/ByteArraySegment.java?ref=3bf83956144fe73175fc85a183c1b26cc7732520",
    "patch": "@@ -76,6 +76,11 @@ public ByteArraySegment(byte[] array, int startOffset, int length) {\n \n     //region ArrayView Implementation\n \n+    @Override\n+    public int getAllocatedLength() {\n+        return this.array().length;\n+    }\n+\n     @Override\n     public byte get(int index) {\n         return this.buffer.get(this.buffer.position() + index);"
  },
  {
    "sha": "35de1335ff6d3d76b93048941dacdc9cd86b514f",
    "filename": "common/src/main/java/io/pravega/common/util/CompositeBufferView.java",
    "status": "modified",
    "additions": 10,
    "deletions": 0,
    "changes": 10,
    "blob_url": "https://github.com/pravega/pravega/blob/3bf83956144fe73175fc85a183c1b26cc7732520/common/src/main/java/io/pravega/common/util/CompositeBufferView.java",
    "raw_url": "https://github.com/pravega/pravega/raw/3bf83956144fe73175fc85a183c1b26cc7732520/common/src/main/java/io/pravega/common/util/CompositeBufferView.java",
    "contents_url": "https://api.github.com/repos/pravega/pravega/contents/common/src/main/java/io/pravega/common/util/CompositeBufferView.java?ref=3bf83956144fe73175fc85a183c1b26cc7732520",
    "patch": "@@ -35,6 +35,7 @@\n     private final List<BufferView> components;\n     @Getter\n     private final int length;\n+    private volatile int allocatedLength = -1;\n \n     //endregion\n \n@@ -66,6 +67,15 @@\n \n     //region BufferView implementation\n \n+    @Override\n+    public int getAllocatedLength() {\n+        if (this.allocatedLength < 0) {\n+            this.allocatedLength = this.components.stream().mapToInt(BufferView::getAllocatedLength).sum();\n+        }\n+\n+        return this.allocatedLength;\n+    }\n+\n     @Override\n     public Reader getBufferViewReader() {\n         return new Reader(this.components.stream().map(BufferView::getBufferViewReader).iterator(), getLength());"
  },
  {
    "sha": "f90d93ef7840520134b201409716d49cf0ee2a16",
    "filename": "common/src/main/java/io/pravega/common/util/CompositeByteArraySegment.java",
    "status": "modified",
    "additions": 5,
    "deletions": 0,
    "changes": 5,
    "blob_url": "https://github.com/pravega/pravega/blob/3bf83956144fe73175fc85a183c1b26cc7732520/common/src/main/java/io/pravega/common/util/CompositeByteArraySegment.java",
    "raw_url": "https://github.com/pravega/pravega/raw/3bf83956144fe73175fc85a183c1b26cc7732520/common/src/main/java/io/pravega/common/util/CompositeByteArraySegment.java",
    "contents_url": "https://api.github.com/repos/pravega/pravega/contents/common/src/main/java/io/pravega/common/util/CompositeByteArraySegment.java?ref=3bf83956144fe73175fc85a183c1b26cc7732520",
    "patch": "@@ -182,6 +182,11 @@ private void setValue(long value, int bits, byte[] array, int bufferId, int buff\n         }\n     }\n \n+    @Override\n+    public int getAllocatedLength() {\n+        return getAllocatedArrayCount() * this.bufferLayout.bufferSize;\n+    }\n+\n     @Override\n     public CompositeReader getBufferViewReader() {\n         return new CompositeReader();"
  },
  {
    "sha": "f02113f3b1cf765b711dde1958c9ca6dade33828",
    "filename": "common/src/test/java/io/pravega/common/util/AbstractBufferViewTests.java",
    "status": "modified",
    "additions": 1,
    "deletions": 0,
    "changes": 1,
    "blob_url": "https://github.com/pravega/pravega/blob/3bf83956144fe73175fc85a183c1b26cc7732520/common/src/test/java/io/pravega/common/util/AbstractBufferViewTests.java",
    "raw_url": "https://github.com/pravega/pravega/raw/3bf83956144fe73175fc85a183c1b26cc7732520/common/src/test/java/io/pravega/common/util/AbstractBufferViewTests.java",
    "contents_url": "https://api.github.com/repos/pravega/pravega/contents/common/src/test/java/io/pravega/common/util/AbstractBufferViewTests.java?ref=3bf83956144fe73175fc85a183c1b26cc7732520",
    "patch": "@@ -81,6 +81,7 @@ public void testEmptyBufferView() throws Exception {\n         val e = BufferView.empty();\n         Assert.assertSame(\"Expecting same instance.\", e, BufferView.empty());\n         Assert.assertEquals(0, e.getLength());\n+        Assert.assertEquals(0, e.getAllocatedLength());\n         Assert.assertEquals(0, e.getCopy().length);\n         Assert.assertSame(e, e.slice(0, 0));\n         AssertExtensions.assertThrows(\"\", () -> e.slice(0, 1), ex -> ex instanceof IndexOutOfBoundsException);"
  },
  {
    "sha": "b104e5ca6772ee24fcd05c1da7711ea908104223",
    "filename": "common/src/test/java/io/pravega/common/util/BufferViewTestBase.java",
    "status": "modified",
    "additions": 10,
    "deletions": 1,
    "changes": 11,
    "blob_url": "https://github.com/pravega/pravega/blob/3bf83956144fe73175fc85a183c1b26cc7732520/common/src/test/java/io/pravega/common/util/BufferViewTestBase.java",
    "raw_url": "https://github.com/pravega/pravega/raw/3bf83956144fe73175fc85a183c1b26cc7732520/common/src/test/java/io/pravega/common/util/BufferViewTestBase.java",
    "contents_url": "https://api.github.com/repos/pravega/pravega/contents/common/src/test/java/io/pravega/common/util/BufferViewTestBase.java?ref=3bf83956144fe73175fc85a183c1b26cc7732520",
    "patch": "@@ -304,7 +304,10 @@ public void testSlice() throws IOException {\n             for (int length = 0; length < data.getLength() - offset; length += 11) {\n                 val expected = new byte[length];\n                 System.arraycopy(data.array(), data.arrayOffset() + offset, expected, 0, length);\n-                val slice = bufferView.slice(offset, length).getCopy();\n+                val sliceBuffer = bufferView.slice(offset, length);\n+                checkAllocatedSize(sliceBuffer, bufferView);\n+\n+                val slice = sliceBuffer.getCopy();\n                 Assert.assertArrayEquals(\"Unexpected slice() result for offset \" + offset + \", length \" + length, expected, slice);\n                 if (length == 0) {\n                     Assert.assertEquals(\"Unexpected getReader() result for offset \" + offset + \", length \" + length,\n@@ -340,5 +343,11 @@ private ArrayView getData(List<ByteBuffer> buffers) {\n         return Lists.newArrayList(bufferView.iterateBuffers());\n     }\n \n+    protected void checkAllocatedSize(BufferView slice, BufferView base) {\n+        Assert.assertEquals(\"Unexpected allocated length for slice.\", slice.getAllocatedLength(), base.getLength());\n+        AssertExtensions.assertGreaterThanOrEqual(\"Expected slice length to be at most the allocated length.\",\n+                slice.getLength(), slice.getAllocatedLength());\n+    }\n+\n     protected abstract BufferView toBufferView(ArrayView data);\n }"
  },
  {
    "sha": "b53d9e55590f7ca2c622e88490fa0b94ab09dea8",
    "filename": "common/src/test/java/io/pravega/common/util/CompositeBufferViewTests.java",
    "status": "modified",
    "additions": 25,
    "deletions": 1,
    "changes": 26,
    "blob_url": "https://github.com/pravega/pravega/blob/3bf83956144fe73175fc85a183c1b26cc7732520/common/src/test/java/io/pravega/common/util/CompositeBufferViewTests.java",
    "raw_url": "https://github.com/pravega/pravega/raw/3bf83956144fe73175fc85a183c1b26cc7732520/common/src/test/java/io/pravega/common/util/CompositeBufferViewTests.java",
    "contents_url": "https://api.github.com/repos/pravega/pravega/contents/common/src/test/java/io/pravega/common/util/CompositeBufferViewTests.java?ref=3bf83956144fe73175fc85a183c1b26cc7732520",
    "patch": "@@ -22,7 +22,9 @@\n import java.util.Collections;\n import java.util.List;\n import java.util.Random;\n+import java.util.TreeMap;\n import java.util.stream.Collectors;\n+import java.util.stream.IntStream;\n import java.util.stream.Stream;\n import lombok.val;\n import org.junit.Assert;\n@@ -125,22 +127,44 @@ public void testCopyToOutputStream() throws IOException {\n      * Tests {@link CompositeBufferView#slice(int, int)} and {@link CompositeBufferView#getReader(int, int)}.\n      */\n     @Test\n+    @Override\n     public void testSlice() throws IOException {\n         val components = createComponents();\n         val cb = BufferView.wrap(components);\n         val expectedSize = components.stream().mapToInt(BufferView::getLength).sum();\n         val expected = StreamHelpers.readAll(\n                 new SequenceInputStream(Iterators.asEnumeration(components.stream().map(BufferView::getReader).iterator())),\n                 expectedSize);\n+\n+        val expectedInitialAllocatedSize = components.stream().mapToInt(BufferView::getAllocatedLength).sum();\n+        Assert.assertEquals(\"Unexpected initial allocated size.\", expectedInitialAllocatedSize, cb.getAllocatedLength());\n+\n+        val componentIndexByOffset = new TreeMap<Integer, Integer>();\n+        int offset = 0;\n+        for (int i = 0; i < components.size(); i++) {\n+            val c = components.get(i);\n+            componentIndexByOffset.put(offset, i);\n+            offset += c.getLength();\n+        }\n+\n         for (int i = 0; i < expectedSize / 2; i++) {\n-            int sliceLength = expectedSize - i;\n+            int sliceLength = expectedSize - 2 * i;\n             val slice = cb.slice(i, sliceLength);\n             val sliceData = slice.getCopy();\n             AssertExtensions.assertArrayEquals(\"slice(offset, length)\", expected, i, sliceData, 0, sliceLength);\n \n             val sliceReader = cb.getReader(i, sliceLength);\n             val sliceReaderData = StreamHelpers.readAll(sliceReader, sliceLength);\n             AssertExtensions.assertArrayEquals(\"getReader(offset, length)\", expected, i, sliceReaderData, 0, sliceLength);\n+\n+            val startComponentIndex = componentIndexByOffset.floorEntry(i).getValue();\n+            val endComponentIndex = componentIndexByOffset.floorEntry(i + sliceLength - 1).getValue();\n+            val expectedAllocatedSize = IntStream.rangeClosed(startComponentIndex, endComponentIndex)\n+                    .mapToObj(components::get)\n+                    .mapToInt(BufferView::getAllocatedLength)\n+                    .sum();\n+            Assert.assertEquals(\"Unexpected allocated size for slice \" + i + \"-\" + (i + sliceLength),\n+                    expectedAllocatedSize, slice.getAllocatedLength());\n         }\n     }\n "
  },
  {
    "sha": "7dcb11286457be8a7186b89f7c2b342ba31acecf",
    "filename": "segmentstore/contracts/src/main/java/io/pravega/segmentstore/contracts/ReadResult.java",
    "status": "modified",
    "additions": 16,
    "deletions": 1,
    "changes": 17,
    "blob_url": "https://github.com/pravega/pravega/blob/3bf83956144fe73175fc85a183c1b26cc7732520/segmentstore/contracts/src/main/java/io/pravega/segmentstore/contracts/ReadResult.java",
    "raw_url": "https://github.com/pravega/pravega/raw/3bf83956144fe73175fc85a183c1b26cc7732520/segmentstore/contracts/src/main/java/io/pravega/segmentstore/contracts/ReadResult.java",
    "contents_url": "https://api.github.com/repos/pravega/pravega/contents/segmentstore/contracts/src/main/java/io/pravega/segmentstore/contracts/ReadResult.java?ref=3bf83956144fe73175fc85a183c1b26cc7732520",
    "patch": "@@ -85,11 +85,26 @@\n      */\n     void setCopyOnRead(boolean value);\n \n+    /**\n+     * Gets a value indicating the maximum number of bytes to read at once with every invocation of {@link #next()}.\n+     *\n+     * @return The maximum number of bytes to read at once.\n+     */\n+    int getMaxReadAtOnce();\n+\n+    /**\n+     * Sets the maximum number of bytes to read at once with every invocation of {@link #next()}.\n+     *\n+     * @param value The value to set. If not positive or exceeds {@link #getMaxResultLength()}, this will be set to\n+     *              {@link #getMaxResultLength()}.\n+     */\n+    void setMaxReadAtOnce(int value);\n+\n     /**\n      * Gets a value indicating whether this ReadResult is fully consumed (either because it was read in its entirety\n      * or because it was closed externally).\n      *\n-     * @return true if ReadResult is fully consumed or closed externally, otherwise false\n+     * @return true if ReadResult is fully consumed or closed externally, otherwise false.\n      */\n     boolean isClosed();\n "
  },
  {
    "sha": "d9806a37be46d37d6cc848a863aea6f4f29a81e0",
    "filename": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/CacheManager.java",
    "status": "modified",
    "additions": 36,
    "deletions": 5,
    "changes": 41,
    "blob_url": "https://github.com/pravega/pravega/blob/3bf83956144fe73175fc85a183c1b26cc7732520/segmentstore/server/src/main/java/io/pravega/segmentstore/server/CacheManager.java",
    "raw_url": "https://github.com/pravega/pravega/raw/3bf83956144fe73175fc85a183c1b26cc7732520/segmentstore/server/src/main/java/io/pravega/segmentstore/server/CacheManager.java",
    "contents_url": "https://api.github.com/repos/pravega/pravega/contents/segmentstore/server/src/main/java/io/pravega/segmentstore/server/CacheManager.java?ref=3bf83956144fe73175fc85a183c1b26cc7732520",
    "patch": "@@ -57,6 +57,7 @@\n     private final ScheduledExecutorService executorService;\n     private final AtomicInteger currentGeneration;\n     private final AtomicInteger oldestGeneration;\n+    private final AtomicBoolean essentialEntriesOnly;\n     private final AtomicReference<CacheState> lastCacheState;\n     private final AtomicBoolean running;\n     private final CachePolicy policy;\n@@ -98,6 +99,7 @@ public CacheManager(CachePolicy policy, CacheStorage cacheStorage, ScheduledExec\n         this.clients = new HashSet<>();\n         this.oldestGeneration = new AtomicInteger(0);\n         this.currentGeneration = new AtomicInteger(0);\n+        this.essentialEntriesOnly = new AtomicBoolean(false);\n         this.running = new AtomicBoolean();\n         this.closed = new AtomicBoolean();\n         this.lastCacheState = new AtomicReference<>();\n@@ -176,7 +178,7 @@ public void register(Client client) {\n             }\n         }\n \n-        client.updateGenerations(this.currentGeneration.get(), this.oldestGeneration.get());\n+        client.updateGenerations(this.currentGeneration.get(), this.oldestGeneration.get(), this.essentialEntriesOnly.get());\n         log.info(\"{} Registered {}.\", TRACE_OBJECT_ID, client);\n     }\n \n@@ -203,6 +205,21 @@ public void unregister(Client client) {\n \n     //region Helpers\n \n+    /**\n+     * Gets a value indicating whether the CacheManager has entered \"Essential-only\" mode.\n+     *\n+     * @return True if essential-only, false otherwise.\n+     */\n+    @VisibleForTesting\n+    public boolean isEssentialEntriesOnly() {\n+        return this.essentialEntriesOnly.get();\n+    }\n+\n+    @VisibleForTesting\n+    public int getCurrentGeneration() {\n+        return this.currentGeneration.get();\n+    }\n+\n     private boolean cacheFullCallback() {\n         log.info(\"{}: Cache full. Forcing cache policy.\", TRACE_OBJECT_ID);\n         return applyCachePolicy();\n@@ -352,16 +369,19 @@ private CacheStatus collectStatus() {\n \n     private void fetchCacheState() {\n         this.lastCacheState.set(this.cacheStorage.getState());\n+        adjustNonEssentialEnabled();\n     }\n \n     private boolean updateClients() {\n         final int cg = this.currentGeneration.get();\n         final int og = this.oldestGeneration.get();\n+        final boolean essentialEntriesOnly = this.essentialEntriesOnly.get();\n         ArrayList<Client> toUnregister = new ArrayList<>();\n         boolean reduced = false;\n+        log.debug(\"{}: UpdateClients. Gen={}-{}, EssentialOnly={}.\", TRACE_OBJECT_ID, cg, og, essentialEntriesOnly);\n         for (Client c : getClients()) {\n             try {\n-                reduced = c.updateGenerations(cg, og) | reduced;\n+                reduced = c.updateGenerations(cg, og, essentialEntriesOnly) | reduced;\n             } catch (ObjectClosedException ex) {\n                 // This object was closed but it was not unregistered. Do it now.\n                 log.warn(\"{} Detected closed client {}.\", TRACE_OBJECT_ID, c);\n@@ -415,6 +435,10 @@ private boolean adjustOldestGeneration(CacheStatus currentStatus) {\n         return isAdjusted;\n     }\n \n+    private void adjustNonEssentialEnabled() {\n+        this.essentialEntriesOnly.set(this.lastCacheState.get().getUsedBytes() >= this.policy.getCriticalThreshold());\n+    }\n+\n     private boolean exceedsPolicy(CacheStatus currentStatus) {\n         // We need to increment the OldestGeneration only if any of the following conditions occurred:\n         // 1. We currently exceed the maximum usable size as defined by the cache policy.\n@@ -432,8 +456,9 @@ private int getOldestPermissibleGeneration() {\n     }\n \n     private void logCurrentStatus(CacheStatus status) {\n-        log.info(\"{}: Gen: {}-{}; Clients: {} ({}-{}); Cache: {}.\", TRACE_OBJECT_ID, this.currentGeneration, this.oldestGeneration,\n-                this.clients.size(), status.getNewestGeneration(), status.getOldestGeneration(), this.lastCacheState);\n+        log.info(\"{}: Gen: {}-{}; EssentialOnly: {}; Clients: {} ({}-{}); Cache: {}.\", TRACE_OBJECT_ID, this.currentGeneration,\n+                this.oldestGeneration, this.essentialEntriesOnly, this.clients.size(), status.getNewestGeneration(),\n+                status.getOldestGeneration(), this.lastCacheState);\n     }\n \n     private long getStoredBytes() {\n@@ -462,9 +487,15 @@ private long getStoredBytes() {\n          * @param currentGeneration The value of the current generation.\n          * @param oldestGeneration  The value of the oldest generation. This is the cutoff for which entries can still\n          *                          exist in the cache.\n+         * @param essentialOnly     If true, essential-only indicates that only cache entries that must be added to the\n+         *                          cache should be inserted (i.e., those that cannot yet be recovered from persistent storage).\n+         *                          This usually indicates an extremely high cache utilization level so non-essential cache\n+         *                          entries should not be inserted in order to improve system stability (such as avoiding\n+         *                          {@link io.pravega.segmentstore.storage.cache.CacheFullException}).\n+         *                          If false, any cache entries may be inserted.\n          * @return If any cache data was trimmed with this update.\n          */\n-        boolean updateGenerations(int currentGeneration, int oldestGeneration);\n+        boolean updateGenerations(int currentGeneration, int oldestGeneration, boolean essentialOnly);\n     }\n \n     //endregion"
  },
  {
    "sha": "36e5459d041df0c60c260ef22bc04f44580f4d8e",
    "filename": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/CachePolicy.java",
    "status": "modified",
    "additions": 13,
    "deletions": 4,
    "changes": 17,
    "blob_url": "https://github.com/pravega/pravega/blob/3bf83956144fe73175fc85a183c1b26cc7732520/segmentstore/server/src/main/java/io/pravega/segmentstore/server/CachePolicy.java",
    "raw_url": "https://github.com/pravega/pravega/raw/3bf83956144fe73175fc85a183c1b26cc7732520/segmentstore/server/src/main/java/io/pravega/segmentstore/server/CachePolicy.java",
    "contents_url": "https://api.github.com/repos/pravega/pravega/contents/segmentstore/server/src/main/java/io/pravega/segmentstore/server/CachePolicy.java?ref=3bf83956144fe73175fc85a183c1b26cc7732520",
    "patch": "@@ -46,11 +46,19 @@\n     @Getter\n     private final double maxUtilization;\n     /**\n-     * The maximum usable size of the cache. When the cache reaches or exceeds this threshold, cache eviction will kick in.\n-     * This is a pre-calculated value of {@link #getMaxSize()} * {@link #getTargetUtilization()} ()}.\n+     * The target size of the cache (ideally, the cache would contain at most this amount of data). When the cache reaches\n+     * or exceeds this threshold, cache eviction will kick in.\n+     * This is a pre-calculated value of {@link #getMaxSize()} * {@link #getTargetUtilization()}.\n      */\n     @Getter\n     private final long evictionThreshold;\n+    /**\n+     * The maximum usable size of the cache. If the cache reaches or exceeds this threshold, the cache is considered to\n+     * be under critical stress, and there is no guarantee that a subsequent cache insertion would succeed.\n+     * This is a pre-calculated value of {@link  #getMaxSize()} * {@link #getMaxUtilization()}.\n+     */\n+    @Getter\n+    private final long criticalThreshold;\n     /**\n      * The maximum number of generations a cache entry can be inactive in the cache for, before being eligible for eviction.\n      */\n@@ -97,6 +105,7 @@ public CachePolicy(long maxSize, double targetUtilization, double maxUtilization\n         this.targetUtilization = targetUtilization;\n         this.maxUtilization = maxUtilization;\n         this.evictionThreshold = (long) Math.floor(this.maxSize * this.targetUtilization);\n+        this.criticalThreshold = (long) Math.floor(this.maxSize * this.maxUtilization);\n         this.generationDuration = generationDuration;\n         this.maxGenerations = Math.max(1, (int) ((double) maxTime.toMillis() / generationDuration.toMillis()));\n     }\n@@ -105,7 +114,7 @@ public CachePolicy(long maxSize, double targetUtilization, double maxUtilization\n \n     @Override\n     public String toString() {\n-        return String.format(\"MaxSize = %d, UsableSize = %d, MaxGen = %d, Generation = %s\",\n-                this.maxSize, this.evictionThreshold, this.maxGenerations, this.generationDuration);\n+        return String.format(\"MaxSize = %d, UsableSize = %d, CriticalSize = %d, MaxGen = %d, Generation = %s\",\n+                this.maxSize, this.evictionThreshold, this.criticalThreshold, this.maxGenerations, this.generationDuration);\n     }\n }"
  },
  {
    "sha": "f56ae27fbc7e9abd7bf03ad1788a22ccd4d5c963",
    "filename": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/CacheUtilizationProvider.java",
    "status": "modified",
    "additions": 5,
    "deletions": 40,
    "changes": 45,
    "blob_url": "https://github.com/pravega/pravega/blob/3bf83956144fe73175fc85a183c1b26cc7732520/segmentstore/server/src/main/java/io/pravega/segmentstore/server/CacheUtilizationProvider.java",
    "raw_url": "https://github.com/pravega/pravega/raw/3bf83956144fe73175fc85a183c1b26cc7732520/segmentstore/server/src/main/java/io/pravega/segmentstore/server/CacheUtilizationProvider.java",
    "contents_url": "https://api.github.com/repos/pravega/pravega/contents/segmentstore/server/src/main/java/io/pravega/segmentstore/server/CacheUtilizationProvider.java?ref=3bf83956144fe73175fc85a183c1b26cc7732520",
    "patch": "@@ -9,13 +9,10 @@\n  */\n package io.pravega.segmentstore.server;\n \n-import io.pravega.common.Exceptions;\n import io.pravega.segmentstore.storage.ThrottleSourceListener;\n-import java.util.ArrayList;\n-import java.util.HashSet;\n+import io.pravega.segmentstore.storage.ThrottlerSourceListenerCollection;\n import java.util.concurrent.atomic.AtomicLong;\n import java.util.function.Supplier;\n-import javax.annotation.concurrent.GuardedBy;\n import javax.annotation.concurrent.ThreadSafe;\n import lombok.NonNull;\n import lombok.extern.slf4j.Slf4j;\n@@ -30,8 +27,7 @@\n \n     private final CachePolicy policy;\n     private final Supplier<Long> getCacheStoredBytes;\n-    @GuardedBy(\"cleanupListeners\")\n-    private final HashSet<ThrottleSourceListener> cleanupListeners;\n+    private final ThrottlerSourceListenerCollection cleanupListeners;\n     private final AtomicLong pendingBytes;\n     private final double utilizationSpread;\n     private final double maxInsertCapacityThreshold;\n@@ -49,7 +45,7 @@\n     CacheUtilizationProvider(@NonNull CachePolicy policy, @NonNull Supplier<Long> getCacheStoredBytes) {\n         this.policy = policy;\n         this.getCacheStoredBytes = getCacheStoredBytes;\n-        this.cleanupListeners = new HashSet<>();\n+        this.cleanupListeners = new ThrottlerSourceListenerCollection();\n         this.pendingBytes = new AtomicLong();\n         this.utilizationSpread = 2 * (policy.getMaxUtilization() - policy.getTargetUtilization());\n         this.maxInsertCapacityThreshold = policy.getMaxUtilization() - this.utilizationSpread;\n@@ -160,46 +156,15 @@ public double getCacheInsertionCapacity() {\n      *                 run that detects {@link ThrottleSourceListener#isClosed()} to be true.\n      */\n     public void registerCleanupListener(@NonNull ThrottleSourceListener listener) {\n-        if (listener.isClosed()) {\n-            log.warn(\"Attempted to register a closed ThrottleSourceListener ({}).\", listener);\n-            return;\n-        }\n-\n-        synchronized (this.cleanupListeners) {\n-            this.cleanupListeners.add(listener); // This is a Set, so we won't be adding the same listener twice.\n-        }\n+        this.cleanupListeners.register(listener);\n     }\n \n     /**\n      * Notifies any registered {@link ThrottleSourceListener} (via {@link #registerCleanupListener}) that a Cache Cleanup\n      * event has just completed.\n      */\n     void notifyCleanupListeners() {\n-        ArrayList<ThrottleSourceListener> toNotify = new ArrayList<>();\n-        ArrayList<ThrottleSourceListener> toRemove = new ArrayList<>();\n-        synchronized (this.cleanupListeners) {\n-            for (ThrottleSourceListener l : this.cleanupListeners) {\n-                if (l.isClosed()) {\n-                    toRemove.add(l);\n-                } else {\n-                    toNotify.add(l);\n-                }\n-            }\n-\n-            this.cleanupListeners.removeAll(toRemove);\n-        }\n-\n-        for (ThrottleSourceListener l : toNotify) {\n-            try {\n-                l.notifyThrottleSourceChanged();\n-            } catch (Throwable ex) {\n-                if (Exceptions.mustRethrow(ex)) {\n-                    throw ex;\n-                }\n-\n-                log.error(\"Error while notifying cleanup listener {}.\", l, ex);\n-            }\n-        }\n+        this.cleanupListeners.notifySourceChanged();\n     }\n \n     //endregion"
  },
  {
    "sha": "f10bae04c86616a5c8cb48ca54ccb061da7676f2",
    "filename": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/ReadIndex.java",
    "status": "modified",
    "additions": 6,
    "deletions": 0,
    "changes": 6,
    "blob_url": "https://github.com/pravega/pravega/blob/3bf83956144fe73175fc85a183c1b26cc7732520/segmentstore/server/src/main/java/io/pravega/segmentstore/server/ReadIndex.java",
    "raw_url": "https://github.com/pravega/pravega/raw/3bf83956144fe73175fc85a183c1b26cc7732520/segmentstore/server/src/main/java/io/pravega/segmentstore/server/ReadIndex.java",
    "contents_url": "https://api.github.com/repos/pravega/pravega/contents/segmentstore/server/src/main/java/io/pravega/segmentstore/server/ReadIndex.java?ref=3bf83956144fe73175fc85a183c1b26cc7732520",
    "patch": "@@ -125,6 +125,12 @@\n      */\n     void cleanup(Collection<Long> segmentIds);\n \n+    /**\n+     * Evicts all cache entries that are eligible for eviction. Only applicable in recovery mode.\n+     * @throws IllegalStateException If the ReadIndex is not in recovery mode.\n+     */\n+    long trimCache();\n+\n     /**\n      * Puts the ReadIndex in Recovery Mode. Some operations may not be available in Recovery Mode.\n      *"
  },
  {
    "sha": "9a7b6531b7fcdffbc1544e9f64b8c91a162ba4a0",
    "filename": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/WriterFlushResult.java",
    "status": "modified",
    "additions": 3,
    "deletions": 3,
    "changes": 6,
    "blob_url": "https://github.com/pravega/pravega/blob/3bf83956144fe73175fc85a183c1b26cc7732520/segmentstore/server/src/main/java/io/pravega/segmentstore/server/WriterFlushResult.java",
    "raw_url": "https://github.com/pravega/pravega/raw/3bf83956144fe73175fc85a183c1b26cc7732520/segmentstore/server/src/main/java/io/pravega/segmentstore/server/WriterFlushResult.java",
    "contents_url": "https://api.github.com/repos/pravega/pravega/contents/segmentstore/server/src/main/java/io/pravega/segmentstore/server/WriterFlushResult.java?ref=3bf83956144fe73175fc85a183c1b26cc7732520",
    "patch": "@@ -17,9 +17,9 @@\n  * Represents the result of a Storage Flush Operation.\n  */\n public class WriterFlushResult {\n-    private AtomicLong flushedBytes;\n-    private AtomicLong mergedBytes;\n-    private AtomicInteger flushedAttributes;\n+    private final AtomicLong flushedBytes;\n+    private final AtomicLong mergedBytes;\n+    private final AtomicInteger flushedAttributes;\n \n     /**\n      * Creates a new instance of the WriterFlushResult class."
  },
  {
    "sha": "3b0d72137008c469a2b0dcf0957312fb3dca74aa",
    "filename": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/attributes/SegmentAttributeBTreeIndex.java",
    "status": "modified",
    "additions": 21,
    "deletions": 1,
    "changes": 22,
    "blob_url": "https://github.com/pravega/pravega/blob/3bf83956144fe73175fc85a183c1b26cc7732520/segmentstore/server/src/main/java/io/pravega/segmentstore/server/attributes/SegmentAttributeBTreeIndex.java",
    "raw_url": "https://github.com/pravega/pravega/raw/3bf83956144fe73175fc85a183c1b26cc7732520/segmentstore/server/src/main/java/io/pravega/segmentstore/server/attributes/SegmentAttributeBTreeIndex.java",
    "contents_url": "https://api.github.com/repos/pravega/pravega/contents/segmentstore/server/src/main/java/io/pravega/segmentstore/server/attributes/SegmentAttributeBTreeIndex.java?ref=3bf83956144fe73175fc85a183c1b26cc7732520",
    "patch": "@@ -105,6 +105,8 @@\n     private int currentCacheGeneration;\n     @GuardedBy(\"cacheEntries\")\n     private final Map<Long, CacheEntry> cacheEntries;\n+    @GuardedBy(\"cacheEntries\")\n+    private boolean cacheDisabled;\n     @GuardedBy(\"pendingReads\")\n     private final Map<Long, PendingRead> pendingReads;\n     private final BTreeIndex index;\n@@ -148,6 +150,7 @@\n         this.cacheEntries = new HashMap<>();\n         this.pendingReads = new HashMap<>();\n         this.closed = new AtomicBoolean();\n+        this.cacheDisabled = false;\n     }\n \n     /**\n@@ -247,12 +250,14 @@ void removeAllCacheEntries() {\n     }\n \n     @Override\n-    public boolean updateGenerations(int currentGeneration, int oldestGeneration) {\n+    public boolean updateGenerations(int currentGeneration, int oldestGeneration, boolean essentialOnly) {\n         Exceptions.checkNotClosed(this.closed.get(), this);\n \n         // Remove those entries that have a generation below the oldest permissible one.\n         boolean anyRemoved;\n         synchronized (this.cacheEntries) {\n+            // All of our data are non-essential as we only cache BTreeIndex pages that are already durable persisted.\n+            this.cacheDisabled = essentialOnly;\n             this.currentCacheGeneration = currentGeneration;\n             ArrayList<CacheEntry> toRemove = new ArrayList<>();\n             for (val entry : this.cacheEntries.values()) {\n@@ -358,6 +363,13 @@ SegmentHandle getAttributeSegmentHandle() {\n         return this.handle.get();\n     }\n \n+    @VisibleForTesting\n+    int getPendingReadCount() {\n+        synchronized (this.pendingReads) {\n+            return this.pendingReads.size();\n+        }\n+    }\n+\n     @Override\n     public String toString() {\n         return this.traceObjectId;\n@@ -717,6 +729,14 @@ private void storeInCache(long entryOffset, ByteArraySegment data) {\n             return;\n         }\n \n+        // All our cache entries are considered \"non-essential\" since they can always be reloaded from Storage. Do not\n+        // try to insert/update them into the cache if such traffic is discouraged.\n+        if (this.cacheDisabled) {\n+            log.debug(\"{}: Cache update skipped for offset {}, length {}. Non-essential cache disabled.\",\n+                    this.traceObjectId, entryOffset, data.getLength());\n+            return;\n+        }\n+\n         // Insert/Update the cache. There is a chance this won't go through, so be able to handle that. It's not the end\n         // of the world if we can't update the cache (as we always have the data in the attribute segment). If we are\n         // having trouble, log the error and move on."
  },
  {
    "sha": "4a3dee486638c9936191c1fca3cc6f282635c679",
    "filename": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/logs/ContainerMetadataUpdateTransaction.java",
    "status": "modified",
    "additions": 228,
    "deletions": 15,
    "changes": 243,
    "blob_url": "https://github.com/pravega/pravega/blob/3bf83956144fe73175fc85a183c1b26cc7732520/segmentstore/server/src/main/java/io/pravega/segmentstore/server/logs/ContainerMetadataUpdateTransaction.java",
    "raw_url": "https://github.com/pravega/pravega/raw/3bf83956144fe73175fc85a183c1b26cc7732520/segmentstore/server/src/main/java/io/pravega/segmentstore/server/logs/ContainerMetadataUpdateTransaction.java",
    "contents_url": "https://api.github.com/repos/pravega/pravega/contents/segmentstore/server/src/main/java/io/pravega/segmentstore/server/logs/ContainerMetadataUpdateTransaction.java?ref=3bf83956144fe73175fc85a183c1b26cc7732520",
    "patch": "@@ -18,6 +18,8 @@\n import io.pravega.common.util.ImmutableDate;\n import io.pravega.segmentstore.contracts.Attributes;\n import io.pravega.segmentstore.contracts.ContainerException;\n+import io.pravega.segmentstore.contracts.SegmentProperties;\n+import io.pravega.segmentstore.contracts.SegmentType;\n import io.pravega.segmentstore.contracts.StreamSegmentException;\n import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n import io.pravega.segmentstore.contracts.TooManyActiveSegmentsException;\n@@ -41,10 +43,15 @@\n import java.io.IOException;\n import java.util.ArrayList;\n import java.util.Collection;\n+import java.util.Collections;\n import java.util.HashMap;\n import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.function.BiPredicate;\n import java.util.stream.Collectors;\n import javax.annotation.concurrent.NotThreadSafe;\n+import lombok.Data;\n import lombok.Getter;\n import lombok.SneakyThrows;\n import lombok.extern.slf4j.Slf4j;\n@@ -59,13 +66,14 @@\n     // region Members\n \n     private static final MetadataCheckpointSerializer METADATA_CHECKPOINT_SERIALIZER = new MetadataCheckpointSerializer();\n+    private static final MetadataCheckpointIncrementalDeserializer METADATA_CHECKPOINT_INCREMENTAL_DESERIALIZER = new MetadataCheckpointIncrementalDeserializer();\n     private static final StorageCheckpointSerializer STORAGE_CHECKPOINT_SERIALIZER = new StorageCheckpointSerializer();\n     /**\n      * Pointer to the real (live) ContainerMetadata. Used when needing access to live information (such as Storage Info).\n      */\n     private final ContainerMetadata realMetadata;\n     private final HashMap<Long, SegmentMetadataUpdateTransaction> segmentUpdates;\n-    private final HashMap<Long, UpdateableSegmentMetadata> newSegments;\n+    private final HashMap<Long, StreamSegmentMetadata> newSegments;\n     private final HashMap<String, Long> newSegmentNames;\n     private final List<Long> newTruncationPoints;\n     @Getter\n@@ -267,6 +275,23 @@ void clear() {\n         resetNewSequenceNumber();\n     }\n \n+    private boolean isNewSegment(long segmentId) {\n+        return this.newSegments.containsKey(segmentId);\n+    }\n+\n+    private void removeNewSegment(long segmentId) {\n+        assert isRecoveryMode();\n+        val sm = this.newSegments.remove(segmentId);\n+        if (sm != null) {\n+            sm.markInactive();\n+            this.newSegmentNames.remove(sm.getName());\n+            val ut = this.segmentUpdates.remove(segmentId);\n+            if (ut != null) {\n+                ut.setActive(false);\n+            }\n+        }\n+    }\n+\n     private void resetNewSequenceNumber() {\n         if (this.baseMetadata.isRecoveryMode()) {\n             this.newSequenceNumber = ContainerMetadata.INITIAL_OPERATION_SEQUENCE_NUMBER;\n@@ -396,22 +421,25 @@ private void processMetadataOperation(MetadataCheckpointOperation operation) thr\n                 // metadata is serialized in this operation. We need to discard whatever we have accumulated so far\n                 // and rebuild the metadata from the information we have so far.\n                 if (this.processedCheckpoint) {\n+                    // A MetadataCheckpoint should be processed fully only if is the first checkpoint encountered.\n+                    // Any subsequent MetadataCheckpoints should be partially processed and applied.\n                     // But we can (should) only process at most one MetadataCheckpoint per recovery. Any additional\n                     // ones are redundant (used just for Truncation purposes) and contain the same information as\n                     // if we processed every operation in order, up to them.\n-                    log.debug(\"MetadataUpdate[{}-{}}]: Skipping MetadataCheckpointOperation with SequenceNumber {} because we already have metadata changes.\",\n-                            this.containerId, this.transactionId, operation.getSequenceNumber());\n-                    return;\n+                    log.info(\"MetadataUpdate[{}]: Recovering MetadataCheckpointOperation({}) and applying incrementally.\",\n+                            this.containerId, operation.getSequenceNumber());\n+                    METADATA_CHECKPOINT_INCREMENTAL_DESERIALIZER.deserialize(operation.getContents(), this);\n+                } else {\n+                    log.info(\"MetadataUpdate[{}]: Recovering MetadataCheckpointOperation({}).\",\n+                            this.containerId, operation.getSequenceNumber());\n+                    clear();\n+\n+                    METADATA_CHECKPOINT_SERIALIZER.deserialize(operation.getContents(), this);\n+                    this.processedCheckpoint = true;\n                 }\n \n-                log.info(\"MetadataUpdate[{}-{}}]: Recovering MetadataCheckpointOperation with SequenceNumber {}.\",\n-                        this.containerId, this.transactionId, operation.getSequenceNumber());\n-                clear();\n-\n                 // This is not retrieved from serialization, but rather from the operation itself.\n                 setOperationSequenceNumber(operation.getSequenceNumber());\n-                METADATA_CHECKPOINT_SERIALIZER.deserialize(operation.getContents(), this);\n-                this.processedCheckpoint = true;\n             } else {\n                 // In non-Recovery Mode, a MetadataCheckpointOperation means we need to serialize the current state of\n                 // the Metadata, both the base Container Metadata and the current Transaction.\n@@ -567,13 +595,13 @@ private SegmentMetadataUpdateTransaction tryGetSegmentUpdateTransaction(long seg\n      * Creates a new UpdateableSegmentMetadata for the given Segment and registers it.\n      */\n     private UpdateableSegmentMetadata createSegmentMetadata(String segmentName, long segmentId) {\n-        UpdateableSegmentMetadata metadata = new StreamSegmentMetadata(segmentName, segmentId, this.containerId);\n+        StreamSegmentMetadata metadata = new StreamSegmentMetadata(segmentName, segmentId, this.containerId);\n         this.newSegments.put(metadata.getId(), metadata);\n         this.newSegmentNames.put(metadata.getName(), metadata.getId());\n         return metadata;\n     }\n \n-    private void copySegmentMetadata(Collection<UpdateableSegmentMetadata> newSegments, UpdateableContainerMetadata target) {\n+    private void copySegmentMetadata(Collection<StreamSegmentMetadata> newSegments, UpdateableContainerMetadata target) {\n         for (SegmentMetadata newMetadata : newSegments) {\n             // Update real metadata with all the information from the new metadata.\n             UpdateableSegmentMetadata existingMetadata = target.mapStreamSegmentId(newMetadata.getName(), newMetadata.getId());\n@@ -647,7 +675,7 @@ protected void declareVersions() {\n             version(0).revision(0, this::write00, this::read00);\n         }\n \n-        private void write00(ContainerMetadataUpdateTransaction t, RevisionDataOutput output) throws IOException {\n+        protected void write00(ContainerMetadataUpdateTransaction t, RevisionDataOutput output) throws IOException {\n             // Intentionally skipping over the Sequence Number. There is no need for that here; it will be set on the\n             // operation anyway when it gets serialized.\n             output.writeCompactInt(t.containerId);\n@@ -675,7 +703,8 @@ private void read00(RevisionDataInput input, ContainerMetadataUpdateTransaction\n                 throw new SerializationException(String.format(\"Invalid ContainerId. Expected '%d', actual '%d'.\", t.containerId, containerId));\n             }\n \n-            input.readCollection(s -> readSegmentMetadata00(s, t));\n+            Collection<UpdateableSegmentMetadata> checkpointMetadata = input.readCollection(s -> readSegmentMetadata00(s, t));\n+            postRead(checkpointMetadata, t);\n         }\n \n         private void writeSegmentMetadata00(RevisionDataOutput output, SegmentMetadata sm) throws IOException {\n@@ -699,7 +728,7 @@ private UpdateableSegmentMetadata readSegmentMetadata00(RevisionDataInput input,\n             long segmentId = input.readLong();\n             String name = input.readUTF();\n \n-            UpdateableSegmentMetadata metadata = t.getOrCreateSegmentUpdateTransaction(name, segmentId);\n+            UpdateableSegmentMetadata metadata = getSegmentMetadata(name, segmentId, t);\n \n             metadata.setLength(input.readLong());\n             metadata.setStorageLength(input.readLong());\n@@ -736,6 +765,190 @@ private UpdateableSegmentMetadata readSegmentMetadata00(RevisionDataInput input,\n             metadata.updateAttributes(attributes);\n             return metadata;\n         }\n+\n+        protected UpdateableSegmentMetadata getSegmentMetadata(String name, long segmentId, ContainerMetadataUpdateTransaction t) {\n+            return t.getOrCreateSegmentUpdateTransaction(name, segmentId);\n+        }\n+\n+        protected void postRead(Collection<UpdateableSegmentMetadata> checkpointMetadata, ContainerMetadataUpdateTransaction t) {\n+            // This method intentionally left blank. Will be overridden in derived classes.\n+        }\n+    }\n+\n+    //endregion\n+\n+    //region MetadataCheckpointPartialDeserializer\n+\n+    private static class MetadataCheckpointIncrementalDeserializer extends MetadataCheckpointSerializer {\n+        @Override\n+        protected void write00(ContainerMetadataUpdateTransaction t, RevisionDataOutput output) {\n+            throw new UnsupportedOperationException(\"MetadataCheckpointPartialDeserializer may not be used for serialization.\");\n+        }\n+\n+        @Override\n+        protected UpdateableSegmentMetadata getSegmentMetadata(String name, long segmentId, ContainerMetadataUpdateTransaction t) {\n+            return new PartialSegmentMetadata(name, segmentId);\n+        }\n+\n+        @Override\n+        protected void postRead(Collection<UpdateableSegmentMetadata> checkpointMetadata, ContainerMetadataUpdateTransaction t) {\n+            Preconditions.checkState(t.isRecoveryMode(), \"MetadataCheckpointPartialDeserializer can only be used in recovery mode.\");\n+\n+            // Index checkpointed metadata by segment id.\n+            val byId = checkpointMetadata.stream().collect(Collectors.toMap(SegmentMetadata::getId, m -> m));\n+\n+            // Update any segment that we encountered. This includes unregistering a missing segment (eviction) or updating\n+            // its storage state as necessary.\n+            for (val segmentId : t.getAllStreamSegmentIds()) {\n+                val m = byId.getOrDefault(segmentId, null);\n+                if (m == null) {\n+                    val existingMetadata = t.getStreamSegmentMetadata(segmentId);\n+                    if (t.isNewSegment(segmentId) && existingMetadata != null && canUnregister(existingMetadata)) {\n+                        // This segment existed in our Update Transaction/Base Metadata, however this checkpoint no longer has it.\n+                        // This means that the segment has been evicted at one point between the last checkpoint and this one,\n+                        // so it should be safe to remove it from our list (if possible).\n+                        log.debug(\"MetadataUpdate[{}]: Un-mapping Segment Id '%s' because it is no longer present in a MetadataCheckpoint.\", t.containerId);\n+                        t.removeNewSegment(segmentId);\n+                    }\n+                } else {\n+                    // Update segment's state with latest info.\n+                    val segmentUpdate = t.getOrCreateSegmentUpdateTransaction(m.getName(), m.getId());\n+                    if (m.isSealedInStorage()) {\n+                        segmentUpdate.markSealed();\n+                    }\n+\n+                    if (m.isDeletedInStorage()) {\n+                        segmentUpdate.markDeleted();\n+                    }\n+\n+                    segmentUpdate.updateStorageState(m.getStorageLength(), m.isSealedInStorage(), m.isDeleted(), m.isDeletedInStorage());\n+                }\n+            }\n+        }\n+\n+        private boolean canUnregister(SegmentMetadata existingMetadata) {\n+            return existingMetadata.isDeleted()\n+                    || existingMetadata.getStorageLength() >= existingMetadata.getLength();\n+        }\n+\n+        @Data\n+        private static class PartialSegmentMetadata implements UpdateableSegmentMetadata {\n+            private final String name;\n+            private final long id;\n+            private long storageLength;\n+            private long startOffset;\n+            private long length;\n+            private boolean sealed;\n+            private boolean sealedInStorage;\n+            private boolean deleted;\n+            private boolean deletedInStorage;\n+            private boolean merged;\n+\n+            @Override\n+            public void markSealed() {\n+                this.sealed = true;\n+            }\n+\n+            @Override\n+            public void markSealedInStorage() {\n+                this.sealedInStorage = true;\n+            }\n+\n+            @Override\n+            public void markDeleted() {\n+                this.deleted = true;\n+            }\n+\n+            @Override\n+            public void markDeletedInStorage() {\n+                this.deletedInStorage = true;\n+            }\n+\n+            @Override\n+            public void markMerged() {\n+                this.merged = true;\n+            }\n+\n+            // region Unimplemented methods\n+\n+            @Override\n+            public boolean isActive() {\n+                return true;\n+            }\n+\n+            @Override\n+            public void updateAttributes(Map<UUID, Long> attributeValues) {\n+                // Not relevant here.\n+            }\n+\n+            @Override\n+            public void setLastModified(ImmutableDate date) {\n+                // Not relevant here.\n+            }\n+\n+            @Override\n+            public void copyFrom(SegmentMetadata other) {\n+                throw new UnsupportedOperationException(\"copyFrom not supported on \" + PartialSegmentMetadata.class.getSimpleName());\n+            }\n+\n+            @Override\n+            public void refreshType() {\n+                // Not relevant here.\n+            }\n+\n+            @Override\n+            public int getContainerId() {\n+                return -1;\n+            }\n+\n+\n+            @Override\n+            public long getLastUsed() {\n+                return 0;\n+            }\n+\n+            @Override\n+            public void setLastUsed(long value) {\n+                // Not relevant here.\n+            }\n+\n+            @Override\n+            public SegmentProperties getSnapshot() {\n+                return this;\n+            }\n+\n+            @Override\n+            public void markPinned() {\n+                // Not relevant here.\n+            }\n+\n+            @Override\n+            public boolean isPinned() {\n+                return false;\n+            }\n+\n+            @Override\n+            public ImmutableDate getLastModified() {\n+                return null;\n+            }\n+\n+            @Override\n+            public Map<UUID, Long> getAttributes() {\n+                return Collections.emptyMap();\n+            }\n+\n+            @Override\n+            public Map<UUID, Long> getAttributes(BiPredicate<UUID, Long> filter) {\n+                return Collections.emptyMap();\n+            }\n+\n+            @Override\n+            public SegmentType getType() {\n+                return null;\n+            }\n+\n+            //endregion\n+        }\n     }\n \n     //endregion"
  },
  {
    "sha": "2ea24425d8664b03ab02c780b2780d6e87684385",
    "filename": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/logs/DurableLog.java",
    "status": "modified",
    "additions": 8,
    "deletions": 5,
    "changes": 13,
    "blob_url": "https://github.com/pravega/pravega/blob/3bf83956144fe73175fc85a183c1b26cc7732520/segmentstore/server/src/main/java/io/pravega/segmentstore/server/logs/DurableLog.java",
    "raw_url": "https://github.com/pravega/pravega/raw/3bf83956144fe73175fc85a183c1b26cc7732520/segmentstore/server/src/main/java/io/pravega/segmentstore/server/logs/DurableLog.java",
    "contents_url": "https://api.github.com/repos/pravega/pravega/contents/segmentstore/server/src/main/java/io/pravega/segmentstore/server/logs/DurableLog.java?ref=3bf83956144fe73175fc85a183c1b26cc7732520",
    "patch": "@@ -319,7 +319,7 @@ public boolean isOffline() {\n         // Before we do any real truncation, we need to mini-snapshot the metadata with only those fields that are updated\n         // asynchronously for us (i.e., not via normal Log Operations) such as the Storage State. That ensures that this\n         // info will be readily available upon recovery without delay.\n-        return add(new StorageMetadataCheckpointOperation(), OperationPriority.High, timer.getRemaining())\n+        return add(new StorageMetadataCheckpointOperation(), OperationPriority.SystemCritical, timer.getRemaining())\n                 .thenComposeAsync(v -> this.durableDataLog.truncate(truncationFrameAddress, timer.getRemaining()), this.executor)\n                 .thenRunAsync(() -> this.metadata.removeTruncationMarkers(actualTruncationSequenceNumber), this.executor);\n     }\n@@ -329,9 +329,9 @@ public boolean isOffline() {\n         log.debug(\"{}: Queuing MetadataCheckpointOperation.\", this.traceObjectId);\n         MetadataCheckpointOperation op = new MetadataCheckpointOperation();\n         return this.operationProcessor\n-                .process(op, OperationPriority.Normal)\n+                .process(op, OperationPriority.SystemCritical)\n                 .thenApply(v -> {\n-                    log.info(\"{}: MetadataCheckpointOperation durably stored.\", this.traceObjectId);\n+                    log.info(\"{}: MetadataCheckpointOperation({}) stored.\", this.traceObjectId, op.getSequenceNumber());\n                     return op.getSequenceNumber();\n                 });\n     }\n@@ -342,9 +342,12 @@ public boolean isOffline() {\n         log.debug(\"{}: Read (MaxCount = {}, Timeout = {}).\", this.traceObjectId, maxCount, timeout);\n         CompletableFuture<Queue<Operation>> result = this.inMemoryOperationLog.take(maxCount, timeout, this.executor);\n         result.thenAccept(r -> {\n-            int size = r.size();\n+            final int size = r.size();\n             this.operationProcessor.getMetrics().operationLogRead(size);\n-            log.debug(\"{}: ReadResult (Count = {}).\", this.traceObjectId, size);\n+            log.debug(\"{}: ReadResult (Count = {}, Remaining = {}).\", this.traceObjectId, size, this.inMemoryOperationLog.size());\n+            if (size > 0) {\n+                this.memoryStateUpdater.notifyLogRead();\n+            }\n         });\n         return result;\n     }"
  },
  {
    "sha": "f4c273497b01eac0cff722e4e1ce1f18ccb45799",
    "filename": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/logs/MemoryStateUpdater.java",
    "status": "modified",
    "additions": 35,
    "deletions": 0,
    "changes": 35,
    "blob_url": "https://github.com/pravega/pravega/blob/3bf83956144fe73175fc85a183c1b26cc7732520/segmentstore/server/src/main/java/io/pravega/segmentstore/server/logs/MemoryStateUpdater.java",
    "raw_url": "https://github.com/pravega/pravega/raw/3bf83956144fe73175fc85a183c1b26cc7732520/segmentstore/server/src/main/java/io/pravega/segmentstore/server/logs/MemoryStateUpdater.java",
    "contents_url": "https://api.github.com/repos/pravega/pravega/contents/segmentstore/server/src/main/java/io/pravega/segmentstore/server/logs/MemoryStateUpdater.java?ref=3bf83956144fe73175fc85a183c1b26cc7732520",
    "patch": "@@ -24,12 +24,15 @@\n import io.pravega.segmentstore.server.logs.operations.Operation;\n import io.pravega.segmentstore.server.logs.operations.StorageOperation;\n import io.pravega.segmentstore.server.logs.operations.StreamSegmentAppendOperation;\n+import io.pravega.segmentstore.storage.ThrottleSourceListener;\n+import io.pravega.segmentstore.storage.ThrottlerSourceListenerCollection;\n import io.pravega.segmentstore.storage.cache.CacheFullException;\n import java.util.HashSet;\n import java.util.Iterator;\n import java.util.concurrent.atomic.AtomicBoolean;\n import java.util.function.Consumer;\n import javax.annotation.concurrent.ThreadSafe;\n+import lombok.NonNull;\n import lombok.extern.slf4j.Slf4j;\n \n /**\n@@ -43,6 +46,7 @@\n     private final ReadIndex readIndex;\n     private final AbstractDrainingQueue<Operation> inMemoryOperationLog;\n     private final AtomicBoolean recoveryMode;\n+    private final ThrottlerSourceListenerCollection readListeners;\n \n     //endregion\n \n@@ -58,12 +62,33 @@\n         this.inMemoryOperationLog = Preconditions.checkNotNull(inMemoryOperationLog, \"inMemoryOperationLog\");\n         this.readIndex = Preconditions.checkNotNull(readIndex, \"readIndex\");\n         this.recoveryMode = new AtomicBoolean();\n+        this.readListeners = new ThrottlerSourceListenerCollection();\n     }\n \n     //endregion\n \n     //region Operations\n \n+    /**\n+     * Registers a {@link ThrottleSourceListener} that will be notified on every Operation Log read.\n+     *\n+     * @param listener The {@link ThrottleSourceListener} to register.\n+     */\n+    void registerReadListener(@NonNull ThrottleSourceListener listener) {\n+        this.readListeners.register(listener);\n+    }\n+\n+    /**\n+     * Notifies all registered {@link ThrottleSourceListener} that an Operation Log read has been truncated.\n+     */\n+    void notifyLogRead() {\n+        this.readListeners.notifySourceChanged();\n+    }\n+\n+    public int getInMemoryOperationLogSize() {\n+        return this.inMemoryOperationLog.size();\n+    }\n+\n     /**\n      * Gets the {@link CacheUtilizationProvider} shared across all Segment Containers hosted in this process that can\n      * be used to query the Cache State.\n@@ -95,6 +120,16 @@ void exitRecoveryMode(boolean successfulRecovery) throws DataCorruptionException\n         this.recoveryMode.set(false);\n     }\n \n+    /**\n+     * Performs a cleanup of the {@link ReadIndex} by releasing resources allocated for segments that are no longer active\n+     * and trimming to cache to the minimum essential.\n+     */\n+    void cleanupReadIndex() {\n+        Preconditions.checkState(this.recoveryMode.get(), \"cleanupReadIndex can only be performed in recovery mode.\");\n+        this.readIndex.cleanup(null);\n+        this.readIndex.trimCache();\n+    }\n+\n     /**\n      * Processes the given operations and applies them to the ReadIndex and InMemory OperationLog.\n      *"
  },
  {
    "sha": "2aa0bf41327e3f656bcc1b9aef349af5c24b17fc",
    "filename": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/logs/OperationProcessor.java",
    "status": "modified",
    "additions": 2,
    "deletions": 0,
    "changes": 2,
    "blob_url": "https://github.com/pravega/pravega/blob/3bf83956144fe73175fc85a183c1b26cc7732520/segmentstore/server/src/main/java/io/pravega/segmentstore/server/logs/OperationProcessor.java",
    "raw_url": "https://github.com/pravega/pravega/raw/3bf83956144fe73175fc85a183c1b26cc7732520/segmentstore/server/src/main/java/io/pravega/segmentstore/server/logs/OperationProcessor.java",
    "contents_url": "https://api.github.com/repos/pravega/pravega/contents/segmentstore/server/src/main/java/io/pravega/segmentstore/server/logs/OperationProcessor.java?ref=3bf83956144fe73175fc85a183c1b26cc7732520",
    "patch": "@@ -108,10 +108,12 @@\n                 .cacheThrottler(this.cacheUtilizationProvider::getCacheUtilization, this.cacheUtilizationProvider.getCacheTargetUtilization(), this.cacheUtilizationProvider.getCacheMaxUtilization())\n                 .batchingThrottler(durableDataLog::getQueueStatistics)\n                 .durableDataLogThrottler(durableDataLog.getWriteSettings(), durableDataLog::getQueueStatistics)\n+                .operationLogThrottler(this.stateUpdater::getInMemoryOperationLogSize)\n                 .build();\n         this.throttler = new Throttler(this.metadata.getContainerId(), throttlerCalculator, this::hasThrottleExemptOperations, executor, this.metrics);\n         this.cacheUtilizationProvider.registerCleanupListener(this.throttler);\n         durableDataLog.registerQueueStateChangeListener(this.throttler);\n+        this.stateUpdater.registerReadListener(this.throttler);\n     }\n \n     //endregion"
  },
  {
    "sha": "78ba0aba1b574615e0cdffa343c0f35b76723934",
    "filename": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/logs/RecoveryProcessor.java",
    "status": "modified",
    "additions": 6,
    "deletions": 0,
    "changes": 6,
    "blob_url": "https://github.com/pravega/pravega/blob/3bf83956144fe73175fc85a183c1b26cc7732520/segmentstore/server/src/main/java/io/pravega/segmentstore/server/logs/RecoveryProcessor.java",
    "raw_url": "https://github.com/pravega/pravega/raw/3bf83956144fe73175fc85a183c1b26cc7732520/segmentstore/server/src/main/java/io/pravega/segmentstore/server/logs/RecoveryProcessor.java",
    "contents_url": "https://api.github.com/repos/pravega/pravega/contents/segmentstore/server/src/main/java/io/pravega/segmentstore/server/logs/RecoveryProcessor.java?ref=3bf83956144fe73175fc85a183c1b26cc7732520",
    "patch": "@@ -17,6 +17,7 @@\n import io.pravega.segmentstore.server.DataCorruptionException;\n import io.pravega.segmentstore.server.SegmentStoreMetrics;\n import io.pravega.segmentstore.server.UpdateableContainerMetadata;\n+import io.pravega.segmentstore.server.logs.operations.CheckpointOperationBase;\n import io.pravega.segmentstore.server.logs.operations.MetadataCheckpointOperation;\n import io.pravega.segmentstore.server.logs.operations.Operation;\n import io.pravega.segmentstore.server.logs.operations.OperationSerializer;\n@@ -187,6 +188,11 @@ protected void recoverOperation(DataFrameRecord<Operation> dataFrameRecord, Oper\n \n         // Update in-memory structures.\n         this.stateUpdater.process(operation);\n+\n+        // Perform necessary read index cleanups if possible.\n+        if (operation instanceof CheckpointOperationBase) {\n+            this.stateUpdater.cleanupReadIndex();\n+        }\n     }\n \n     private void recordTruncationMarker(DataFrameRecord<Operation> dataFrameRecord) {"
  },
  {
    "sha": "192826f3ea98eeb614d096fe0eb24afde0799aec",
    "filename": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/logs/SegmentMetadataUpdateTransaction.java",
    "status": "modified",
    "additions": 6,
    "deletions": 5,
    "changes": 11,
    "blob_url": "https://github.com/pravega/pravega/blob/3bf83956144fe73175fc85a183c1b26cc7732520/segmentstore/server/src/main/java/io/pravega/segmentstore/server/logs/SegmentMetadataUpdateTransaction.java",
    "raw_url": "https://github.com/pravega/pravega/raw/3bf83956144fe73175fc85a183c1b26cc7732520/segmentstore/server/src/main/java/io/pravega/segmentstore/server/logs/SegmentMetadataUpdateTransaction.java",
    "contents_url": "https://api.github.com/repos/pravega/pravega/contents/segmentstore/server/src/main/java/io/pravega/segmentstore/server/logs/SegmentMetadataUpdateTransaction.java?ref=3bf83956144fe73175fc85a183c1b26cc7732520",
    "patch": "@@ -39,6 +39,7 @@\n import java.util.function.BiPredicate;\n import javax.annotation.concurrent.NotThreadSafe;\n import lombok.Getter;\n+import lombok.Setter;\n \n /**\n  * An update transaction that can apply changes to a SegmentMetadata.\n@@ -79,6 +80,9 @@\n     @Getter\n     private long lastUsed;\n     private boolean isChanged;\n+    @Getter\n+    @Setter\n+    private boolean active;\n \n     //endregion\n \n@@ -108,6 +112,7 @@\n         this.baseAttributeValues = baseMetadata.getAttributes();\n         this.attributeUpdates = new HashMap<>();\n         this.lastUsed = baseMetadata.getLastUsed();\n+        this.active = true;\n     }\n \n     //endregion\n@@ -128,11 +133,6 @@ public long getStorageLength() {\n         return this.storageLength < 0 ? this.baseStorageLength : this.storageLength;\n     }\n \n-    @Override\n-    public boolean isActive() {\n-        return true;\n-    }\n-\n     @Override\n     public SegmentProperties getSnapshot() {\n         throw new UnsupportedOperationException(\"getSnapshot() is not supported on \" + getClass().getName());\n@@ -685,6 +685,7 @@ void apply(UpdateableSegmentMetadata target) {\n                 \"Target Segment Id mismatch. Expected %s, given %s.\", this.id, target.getId());\n         Preconditions.checkArgument(target.getName().equals(this.name),\n                 \"Target Segment Name mismatch. Expected %s, given %s.\", name, target.getName());\n+        Preconditions.checkState(isActive(), \"Cannot apply changes for an inactive segment. Segment Id = %s, Segment Name = '%s'.\", this.id, this.name);\n \n         // Apply to base metadata.\n         target.setLastUsed(this.lastUsed);"
  },
  {
    "sha": "21c654f154d5c6f49d0d30b22671aa7efd7420c6",
    "filename": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/logs/Throttler.java",
    "status": "modified",
    "additions": 1,
    "deletions": 2,
    "changes": 3,
    "blob_url": "https://github.com/pravega/pravega/blob/3bf83956144fe73175fc85a183c1b26cc7732520/segmentstore/server/src/main/java/io/pravega/segmentstore/server/logs/Throttler.java",
    "raw_url": "https://github.com/pravega/pravega/raw/3bf83956144fe73175fc85a183c1b26cc7732520/segmentstore/server/src/main/java/io/pravega/segmentstore/server/logs/Throttler.java",
    "contents_url": "https://api.github.com/repos/pravega/pravega/contents/segmentstore/server/src/main/java/io/pravega/segmentstore/server/logs/Throttler.java?ref=3bf83956144fe73175fc85a183c1b26cc7732520",
    "patch": "@@ -186,8 +186,7 @@ boolean isThrottlingRequired() {\n     }\n \n     private boolean isInterruptible(ThrottlerCalculator.ThrottlerName name) {\n-        return name == ThrottlerCalculator.ThrottlerName.Cache\n-                || name == ThrottlerCalculator.ThrottlerName.DurableDataLog;\n+        return name != null && name.isInterruptible();\n     }\n \n     @VisibleForTesting"
  },
  {
    "sha": "b1a45038e7ff6845fff892eeac9a99b58dadb31e",
    "filename": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/logs/ThrottlerCalculator.java",
    "status": "modified",
    "additions": 60,
    "deletions": 3,
    "changes": 63,
    "blob_url": "https://github.com/pravega/pravega/blob/3bf83956144fe73175fc85a183c1b26cc7732520/segmentstore/server/src/main/java/io/pravega/segmentstore/server/logs/ThrottlerCalculator.java",
    "raw_url": "https://github.com/pravega/pravega/raw/3bf83956144fe73175fc85a183c1b26cc7732520/segmentstore/server/src/main/java/io/pravega/segmentstore/server/logs/ThrottlerCalculator.java",
    "contents_url": "https://api.github.com/repos/pravega/pravega/contents/segmentstore/server/src/main/java/io/pravega/segmentstore/server/logs/ThrottlerCalculator.java?ref=3bf83956144fe73175fc85a183c1b26cc7732520",
    "patch": "@@ -65,6 +65,16 @@\n      */\n     @VisibleForTesting\n     static final double DURABLE_DATALOG_THROTTLE_THRESHOLD_FRACTION = 0.1;\n+    /**\n+     * Maximum size (in number of operations) of the OperationLog, above which maximum throttling will be applied.\n+     */\n+    @VisibleForTesting\n+    static final int OPERATION_LOG_MAX_SIZE = 1_000_000;\n+    /**\n+     * Desired size (in number of operations) of the OperationLog, above which a gradual throttling will begin.\n+     */\n+    @VisibleForTesting\n+    static final int OPERATION_LOG_TARGET_SIZE = (int) (OPERATION_LOG_MAX_SIZE * 0.95);\n     @Singular\n     private final List<Throttler> throttlers;\n \n@@ -287,6 +297,40 @@ ThrottlerName getName() {\n         }\n     }\n \n+    /**\n+     * Calculates the amount of time to wait before processing more operations from the queue in order to relieve pressure\n+     * from the OperationLog. This is based solely on the number of operations accumulated in the OperationLog.\n+     */\n+    @RequiredArgsConstructor\n+    private static class OperationLogThrottler extends Throttler {\n+        private static final double SIZE_SPAN = OPERATION_LOG_MAX_SIZE - OPERATION_LOG_TARGET_SIZE;\n+        @NonNull\n+        private final Supplier<Integer> getOperationLogSize;\n+\n+        @Override\n+        boolean isThrottlingRequired() {\n+            return this.getOperationLogSize.get() > OPERATION_LOG_TARGET_SIZE;\n+        }\n+\n+        @Override\n+        int getDelayMillis() {\n+            // We only throttle if we exceed the target log size. We increase the throttling amount in a linear fashion.\n+            int size = this.getOperationLogSize.get();\n+            if (size <= OPERATION_LOG_TARGET_SIZE) {\n+                return 0;\n+            } else if (size >= OPERATION_LOG_MAX_SIZE) {\n+                return MAX_DELAY_MILLIS;\n+            } else {\n+                return (int) (MAX_DELAY_MILLIS * (this.getOperationLogSize.get() - OPERATION_LOG_TARGET_SIZE) / SIZE_SPAN);\n+            }\n+        }\n+\n+        @Override\n+        ThrottlerName getName() {\n+            return ThrottlerName.OperationLog;\n+        }\n+    }\n+\n     //endregion\n \n     //region Builder\n@@ -322,6 +366,10 @@ ThrottlerCalculatorBuilder batchingThrottler(Supplier<QueueStats> getQueueStats)\n         ThrottlerCalculatorBuilder durableDataLogThrottler(WriteSettings writeSettings, Supplier<QueueStats> getQueueStats) {\n             return throttler(new DurableDataLogThrottler(writeSettings, getQueueStats));\n         }\n+\n+        ThrottlerCalculatorBuilder operationLogThrottler(Supplier<Integer> getDurableLogSize) {\n+            return throttler(new OperationLogThrottler(getDurableLogSize));\n+        }\n     }\n \n     //endregion\n@@ -371,19 +419,28 @@ public String toString() {\n     /**\n      * Defines Throttler Names.\n      */\n+    @Getter\n+    @RequiredArgsConstructor(access = AccessLevel.PRIVATE)\n     enum ThrottlerName {\n         /**\n          * Throttling is required in order to aggregate multiple operations together in a single write.\n          */\n-        Batching,\n+        Batching(false),\n         /**\n          * Throttling is required due to excessive Cache utilization.\n          */\n-        Cache,\n+        Cache(true),\n         /**\n          * Throttling is required due to excessive size of DurableDataLog's in-flight queue.\n          */\n-        DurableDataLog,\n+        DurableDataLog(true),\n+        /**\n+         * Throttling is required due to excessive accumulated Operations in OperationLog (not yet truncated).\n+         */\n+        OperationLog(true);\n+\n+        @Getter\n+        private final boolean interruptible;\n     }\n \n     //endregion"
  },
  {
    "sha": "2d5e403ab236bfe86bc209c84c7cd0d8b5b5276a",
    "filename": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/reading/AsyncReadResultHandler.java",
    "status": "modified",
    "additions": 11,
    "deletions": 1,
    "changes": 12,
    "blob_url": "https://github.com/pravega/pravega/blob/3bf83956144fe73175fc85a183c1b26cc7732520/segmentstore/server/src/main/java/io/pravega/segmentstore/server/reading/AsyncReadResultHandler.java",
    "raw_url": "https://github.com/pravega/pravega/raw/3bf83956144fe73175fc85a183c1b26cc7732520/segmentstore/server/src/main/java/io/pravega/segmentstore/server/reading/AsyncReadResultHandler.java",
    "contents_url": "https://api.github.com/repos/pravega/pravega/contents/segmentstore/server/src/main/java/io/pravega/segmentstore/server/reading/AsyncReadResultHandler.java?ref=3bf83956144fe73175fc85a183c1b26cc7732520",
    "patch": "@@ -9,9 +9,9 @@\n  */\n package io.pravega.segmentstore.server.reading;\n \n+import io.pravega.segmentstore.contracts.ReadResult;\n import io.pravega.segmentstore.contracts.ReadResultEntry;\n import io.pravega.segmentstore.contracts.ReadResultEntryType;\n-\n import java.time.Duration;\n \n /**\n@@ -61,4 +61,14 @@\n      * @return The timeout.\n      */\n     Duration getRequestContentTimeout();\n+\n+    /**\n+     * Gets a value indicating the maximum number of bytes to process at any time. See {@link ReadResult#getMaxReadAtOnce()}.\n+     *\n+     * @return The maximum number of bytes to process at any time. Default value is {@link Integer#MAX_VALUE}, which\n+     * means the underlying read result has absolute freedom in choosing the read size.\n+     */\n+    default int getMaxReadAtOnce() {\n+        return Integer.MAX_VALUE;\n+    }\n }"
  },
  {
    "sha": "055bc6a14179d6f668659aae2ac22a37d5294ebc",
    "filename": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/reading/AsyncReadResultProcessor.java",
    "status": "modified",
    "additions": 2,
    "deletions": 0,
    "changes": 2,
    "blob_url": "https://github.com/pravega/pravega/blob/3bf83956144fe73175fc85a183c1b26cc7732520/segmentstore/server/src/main/java/io/pravega/segmentstore/server/reading/AsyncReadResultProcessor.java",
    "raw_url": "https://github.com/pravega/pravega/raw/3bf83956144fe73175fc85a183c1b26cc7732520/segmentstore/server/src/main/java/io/pravega/segmentstore/server/reading/AsyncReadResultProcessor.java",
    "contents_url": "https://api.github.com/repos/pravega/pravega/contents/segmentstore/server/src/main/java/io/pravega/segmentstore/server/reading/AsyncReadResultProcessor.java?ref=3bf83956144fe73175fc85a183c1b26cc7732520",
    "patch": "@@ -66,6 +66,7 @@ private AsyncReadResultProcessor(ReadResult readResult, AsyncReadResultHandler e\n         this.readResult = readResult;\n         this.entryHandler = entryHandler;\n         this.closed = new AtomicBoolean();\n+        this.readResult.setMaxReadAtOnce(this.entryHandler.getMaxReadAtOnce());\n     }\n \n     /**\n@@ -141,6 +142,7 @@ private void processResult(Executor executor) {\n                         resultEntry -> {\n                             if (resultEntry != null) {\n                                 shouldContinue.set(this.entryHandler.processEntry(resultEntry));\n+                                this.readResult.setMaxReadAtOnce(this.entryHandler.getMaxReadAtOnce());\n                             }\n                         },\n                         executor)"
  },
  {
    "sha": "e805659ff9c0126c015398564649ecd836803907",
    "filename": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/reading/ContainerReadIndex.java",
    "status": "modified",
    "additions": 24,
    "deletions": 2,
    "changes": 26,
    "blob_url": "https://github.com/pravega/pravega/blob/3bf83956144fe73175fc85a183c1b26cc7732520/segmentstore/server/src/main/java/io/pravega/segmentstore/server/reading/ContainerReadIndex.java",
    "raw_url": "https://github.com/pravega/pravega/raw/3bf83956144fe73175fc85a183c1b26cc7732520/segmentstore/server/src/main/java/io/pravega/segmentstore/server/reading/ContainerReadIndex.java",
    "contents_url": "https://api.github.com/repos/pravega/pravega/contents/segmentstore/server/src/main/java/io/pravega/segmentstore/server/reading/ContainerReadIndex.java?ref=3bf83956144fe73175fc85a183c1b26cc7732520",
    "patch": "@@ -263,14 +263,36 @@ public void cleanup(Collection<Long> segmentIds) {\n         log.info(\"{}: Cleaned up ReadIndices for {} inactive or deleted Segments.\", this.traceObjectId, removed);\n     }\n \n+    @Override\n+    public long trimCache() {\n+        Exceptions.checkNotClosed(this.closed.get(), this);\n+        Preconditions.checkState(isRecoveryMode(), \"trimCache can only be invoked in recovery mode.\");\n+\n+        List<StreamSegmentReadIndex> indices;\n+        synchronized (this.lock) {\n+            indices = new ArrayList<>(this.readIndices.values());\n+        }\n+\n+        long totalTrimmedBytes = 0;\n+        for (StreamSegmentReadIndex index : indices) {\n+            totalTrimmedBytes += index.trimCache();\n+        }\n+\n+        if (totalTrimmedBytes > 0) {\n+            log.info(\"{}: Trimmed {} bytes.\", this.traceObjectId, totalTrimmedBytes);\n+        }\n+\n+        return totalTrimmedBytes;\n+    }\n+\n     @Override\n     public void enterRecoveryMode(ContainerMetadata recoveryMetadataSource) {\n         Exceptions.checkNotClosed(this.closed.get(), this);\n         Preconditions.checkState(!isRecoveryMode(), \"Read Index is already in recovery mode.\");\n         Preconditions.checkNotNull(recoveryMetadataSource, \"recoveryMetadataSource\");\n         Preconditions.checkArgument(recoveryMetadataSource.isRecoveryMode(), \"Given ContainerMetadata is not in recovery mode.\");\n \n-        // Swap metadata with recovery metadata (but still keep track of recovery metadata.\n+        // Swap metadata with recovery metadata (but still keep track of recovery metadata).\n         synchronized (this.lock) {\n             Preconditions.checkArgument(this.metadata.getContainerId() == recoveryMetadataSource.getContainerId(),\n                     \"Given ContainerMetadata refers to a different container than this ReadIndex.\");\n@@ -339,7 +361,7 @@ private boolean isRecoveryMode() {\n      * @param streamSegmentId The Id of the StreamSegment whose ReadIndex to get.\n      */\n     @VisibleForTesting\n-    StreamSegmentReadIndex getIndex(long streamSegmentId) {\n+    public StreamSegmentReadIndex getIndex(long streamSegmentId) {\n         synchronized (this.lock) {\n             return this.readIndices.getOrDefault(streamSegmentId, null);\n         }"
  },
  {
    "sha": "6a8f876d78b80e989909731b9637868600304ac8",
    "filename": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/reading/ReadIndexSummary.java",
    "status": "modified",
    "additions": 6,
    "deletions": 0,
    "changes": 6,
    "blob_url": "https://github.com/pravega/pravega/blob/3bf83956144fe73175fc85a183c1b26cc7732520/segmentstore/server/src/main/java/io/pravega/segmentstore/server/reading/ReadIndexSummary.java",
    "raw_url": "https://github.com/pravega/pravega/raw/3bf83956144fe73175fc85a183c1b26cc7732520/segmentstore/server/src/main/java/io/pravega/segmentstore/server/reading/ReadIndexSummary.java",
    "contents_url": "https://api.github.com/repos/pravega/pravega/contents/segmentstore/server/src/main/java/io/pravega/segmentstore/server/reading/ReadIndexSummary.java?ref=3bf83956144fe73175fc85a183c1b26cc7732520",
    "patch": "@@ -9,6 +9,7 @@\n  */\n package io.pravega.segmentstore.server.reading;\n \n+import com.google.common.annotations.VisibleForTesting;\n import com.google.common.base.Preconditions;\n import io.pravega.segmentstore.server.CacheManager;\n import java.util.HashMap;\n@@ -106,4 +107,9 @@ synchronized int touchOne(int generation) {\n     synchronized CacheManager.CacheStatus toCacheStatus() {\n         return CacheManager.CacheStatus.fromGenerations(this.generations.keySet().iterator());\n     }\n+\n+    @VisibleForTesting\n+    synchronized int size() {\n+        return this.generations.values().stream().mapToInt(i -> i).sum();\n+    }\n }"
  },
  {
    "sha": "408cf6e074b09e8115f6a0e1109fa540b6c0bed2",
    "filename": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/reading/StreamSegmentReadIndex.java",
    "status": "modified",
    "additions": 50,
    "deletions": 13,
    "changes": 63,
    "blob_url": "https://github.com/pravega/pravega/blob/3bf83956144fe73175fc85a183c1b26cc7732520/segmentstore/server/src/main/java/io/pravega/segmentstore/server/reading/StreamSegmentReadIndex.java",
    "raw_url": "https://github.com/pravega/pravega/raw/3bf83956144fe73175fc85a183c1b26cc7732520/segmentstore/server/src/main/java/io/pravega/segmentstore/server/reading/StreamSegmentReadIndex.java",
    "contents_url": "https://api.github.com/repos/pravega/pravega/contents/segmentstore/server/src/main/java/io/pravega/segmentstore/server/reading/StreamSegmentReadIndex.java?ref=3bf83956144fe73175fc85a183c1b26cc7732520",
    "patch": "@@ -41,8 +41,11 @@\n import java.util.concurrent.atomic.AtomicLong;\n import java.util.function.BiFunction;\n import java.util.function.Consumer;\n+import java.util.function.Predicate;\n import javax.annotation.concurrent.GuardedBy;\n import javax.annotation.concurrent.ThreadSafe;\n+import lombok.AccessLevel;\n+import lombok.Getter;\n import lombok.extern.slf4j.Slf4j;\n import lombok.val;\n \n@@ -70,10 +73,13 @@\n     @GuardedBy(\"lock\")\n     private final HashMap<Long, PendingMerge> pendingMergers; //Key = Source Segment Id, Value = Pending Merge Info.\n     private final StorageReadManager storageReadManager;\n+    @VisibleForTesting\n+    @Getter(AccessLevel.PACKAGE)\n     private final ReadIndexSummary summary;\n     private final ScheduledExecutorService executor;\n     private SegmentMetadata metadata;\n     private final AtomicLong lastAppendedOffset;\n+    private volatile boolean storageCacheDisabled; // True (Disabled): No Storage inserts; False (Enabled): all cache inserts.\n     private boolean recoveryMode;\n     private boolean closed;\n     private boolean merged;\n@@ -116,6 +122,7 @@\n         this.executor = executor;\n         this.summary = new ReadIndexSummary();\n         this.storageReadAlignment = alignToCacheBlockSize(this.config.getStorageReadAlignment());\n+        this.storageCacheDisabled = false;\n     }\n \n     private int alignToCacheBlockSize(int value) {\n@@ -210,26 +217,36 @@ private void removeAllEntries() {\n     }\n \n     @Override\n-    public boolean updateGenerations(int currentGeneration, int oldestGeneration) {\n+    public boolean updateGenerations(int currentGeneration, int oldestGeneration, boolean essentialOnly) {\n         Exceptions.checkNotClosed(this.closed, this);\n \n+        // If we are told that only essential cache entries must be inserted, then we need to disable Storage read\n+        // cache inserts (as we can always re-read that data from Storage).\n+        this.storageCacheDisabled = essentialOnly;\n+\n         // Update the current generation with the provided info.\n         this.summary.setCurrentGeneration(currentGeneration);\n+        return evictCacheEntries(entry -> isEvictable(entry, oldestGeneration)) > 0;\n+    }\n+\n+    private boolean isEvictable(ReadIndexEntry entry, int oldestGeneration) {\n+        // We can only evict if both these conditions are met:\n+        // 1. The entry is a Cache Entry (Redirect entries cannot be removed).\n+        // 2. Every single byte in the entry has to exist in Storage.\n+        // In addition, we are free to evict (regardless of Generation, but still subject to the above rules) if\n+        // every single byte in the entry has been truncated out.\n+        long lastOffset = entry.getLastStreamSegmentOffset();\n+        return entry.isDataEntry()\n+                && lastOffset < this.metadata.getStorageLength()\n+                && (entry.getGeneration() < oldestGeneration || lastOffset < this.metadata.getStartOffset());\n+    }\n \n+    private long evictCacheEntries(Predicate<ReadIndexEntry> isEvictable) {\n         // Identify & collect those entries that can be removed, then remove them from the index.\n         ArrayList<ReadIndexEntry> toRemove = new ArrayList<>();\n         synchronized (this.lock) {\n             this.indexEntries.forEach(entry -> {\n-                // We can only evict if both these conditions are met:\n-                // 1. The entry is a Cache Entry (Redirect entries cannot be removed).\n-                // 2. Every single byte in the entry has to exist in Storage.\n-                // In addition, we are free to evict (regardless of Generation, but still subject to the above rules) if\n-                // every single byte in the entry has been truncated out.\n-                long lastOffset = entry.getLastStreamSegmentOffset();\n-                boolean canRemove = entry.isDataEntry()\n-                        && lastOffset < this.metadata.getStorageLength()\n-                        && (entry.getGeneration() < oldestGeneration || lastOffset < this.metadata.getStartOffset());\n-                if (canRemove) {\n+                if (isEvictable.test(entry)) {\n                     toRemove.add(entry);\n                 }\n             });\n@@ -239,12 +256,18 @@ public boolean updateGenerations(int currentGeneration, int oldestGeneration) {\n         }\n \n         // Update the summary (no need for holding the lock here; we are not modifying the index).\n+        val totalSize = new AtomicLong();\n         toRemove.forEach(e -> {\n             deleteData(e);\n             this.summary.removeOne(e.getGeneration());\n+            totalSize.addAndGet(e.getLength());\n         });\n \n-        return !toRemove.isEmpty();\n+        if (!toRemove.isEmpty()) {\n+            log.debug(\"{}: Evicted {} entries totalling {} bytes.\", this.traceObjectId, toRemove.size(), totalSize);\n+        }\n+\n+        return totalSize.get();\n     }\n \n     //endregion\n@@ -314,7 +337,7 @@ int getFutureReadCount() {\n      */\n     public void exitRecoveryMode(SegmentMetadata newMetadata) {\n         Exceptions.checkNotClosed(this.closed, this);\n-        Preconditions.checkState(this.recoveryMode, \"Read Index is not in recovery mode.\");\n+        Preconditions.checkState(this.recoveryMode, \"ReadIndex[%s] is not in recovery mode.\", this.traceObjectId);\n         Preconditions.checkNotNull(newMetadata, \"newMetadata\");\n         Exceptions.checkArgument(newMetadata.getId() == this.metadata.getId(), \"newMetadata\", \"New Metadata StreamSegmentId is different from existing one.\");\n         Exceptions.checkArgument(newMetadata.getLength() == this.metadata.getLength(), \"newMetadata\", \"New Metadata Length is different from existing one.\");\n@@ -328,6 +351,15 @@ public void exitRecoveryMode(SegmentMetadata newMetadata) {\n         log.debug(\"{}: Exit RecoveryMode.\", this.traceObjectId);\n     }\n \n+    /**\n+     * Evicts every eligible entry from the Cache that does not need to be there. See {@link #isEvictable} for conditions.\n+     */\n+    long trimCache() {\n+        Exceptions.checkNotClosed(this.closed, this);\n+        Preconditions.checkState(this.recoveryMode, \"ReadIndex[%s] is not in recovery mode.\", this.traceObjectId);\n+        return evictCacheEntries(entry -> isEvictable(entry, Integer.MAX_VALUE)); // Evict anything we don't absolutely need.\n+    }\n+\n     //endregion\n \n     //region Index Updates\n@@ -501,6 +533,11 @@ void completeMerge(SegmentMetadata sourceMetadata) {\n     }\n \n     private void insert(long offset, ByteArraySegment data) {\n+        if (this.storageCacheDisabled) {\n+            log.debug(\"{}: Not inserting (Offset = {}, Length = {}) due to Storage Cache disabled.\", this.traceObjectId, offset, data.getLength());\n+            return;\n+        }\n+\n         log.debug(\"{}: Insert (Offset = {}, Length = {}).\", this.traceObjectId, offset, data.getLength());\n \n         // There is a very small chance we might be adding data twice, if we get two concurrent requests that slipped past"
  },
  {
    "sha": "32bed2760962fcf9404b04a4b7664b1510c46ec9",
    "filename": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/reading/StreamSegmentReadResult.java",
    "status": "modified",
    "additions": 14,
    "deletions": 1,
    "changes": 15,
    "blob_url": "https://github.com/pravega/pravega/blob/3bf83956144fe73175fc85a183c1b26cc7732520/segmentstore/server/src/main/java/io/pravega/segmentstore/server/reading/StreamSegmentReadResult.java",
    "raw_url": "https://github.com/pravega/pravega/raw/3bf83956144fe73175fc85a183c1b26cc7732520/segmentstore/server/src/main/java/io/pravega/segmentstore/server/reading/StreamSegmentReadResult.java",
    "contents_url": "https://api.github.com/repos/pravega/pravega/contents/segmentstore/server/src/main/java/io/pravega/segmentstore/server/reading/StreamSegmentReadResult.java?ref=3bf83956144fe73175fc85a183c1b26cc7732520",
    "patch": "@@ -43,6 +43,8 @@\n     private boolean closed;\n     @GuardedBy(\"this\")\n     private boolean copyOnRead;\n+    @GuardedBy(\"this\")\n+    private int maxReadAtOnce;\n \n     //endregion\n \n@@ -65,6 +67,7 @@ public StreamSegmentReadResult(long streamSegmentStartOffset, int maxResultLengt\n         this.traceObjectId = traceObjectId;\n         this.streamSegmentStartOffset = streamSegmentStartOffset;\n         this.maxResultLength = maxResultLength;\n+        this.maxReadAtOnce = this.maxResultLength;\n         this.getNextItem = getNextItem;\n         this.consumedLength = 0;\n         this.canRead = true;\n@@ -104,6 +107,16 @@ public synchronized void setCopyOnRead(boolean value) {\n         this.copyOnRead = value;\n     }\n \n+    @Override\n+    public synchronized int getMaxReadAtOnce() {\n+        return this.maxReadAtOnce;\n+    }\n+\n+    @Override\n+    public synchronized void setMaxReadAtOnce(int value) {\n+        this.maxReadAtOnce = value <= 0 || value > this.maxResultLength ? this.maxResultLength : value;\n+    }\n+\n     @Override\n     public synchronized boolean isClosed() {\n         return this.closed || !hasNext();\n@@ -185,7 +198,7 @@ public synchronized ReadResultEntry next() {\n \n         // Retrieve the next item.\n         long startOffset = this.streamSegmentStartOffset + this.consumedLength;\n-        int remainingLength = this.maxResultLength - this.consumedLength;\n+        int remainingLength = Math.min(this.maxReadAtOnce, this.maxResultLength - this.consumedLength);\n         CompletableReadResultEntry entry = this.getNextItem.apply(startOffset, remainingLength, this.copyOnRead);\n \n         if (entry == null) {"
  },
  {
    "sha": "67dd05345e50267d30531f20150850417d54962e",
    "filename": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/tables/AsyncTableEntryReader.java",
    "status": "modified",
    "additions": 25,
    "deletions": 4,
    "changes": 29,
    "blob_url": "https://github.com/pravega/pravega/blob/3bf83956144fe73175fc85a183c1b26cc7732520/segmentstore/server/src/main/java/io/pravega/segmentstore/server/tables/AsyncTableEntryReader.java",
    "raw_url": "https://github.com/pravega/pravega/raw/3bf83956144fe73175fc85a183c1b26cc7732520/segmentstore/server/src/main/java/io/pravega/segmentstore/server/tables/AsyncTableEntryReader.java",
    "contents_url": "https://api.github.com/repos/pravega/pravega/contents/segmentstore/server/src/main/java/io/pravega/segmentstore/server/tables/AsyncTableEntryReader.java?ref=3bf83956144fe73175fc85a183c1b26cc7732520",
    "patch": "@@ -14,6 +14,7 @@\n import io.pravega.common.io.SerializationException;\n import io.pravega.common.util.BufferView;\n import io.pravega.common.util.BufferViewBuilder;\n+import io.pravega.common.util.ByteArraySegment;\n import io.pravega.segmentstore.contracts.ReadResult;\n import io.pravega.segmentstore.contracts.ReadResultEntry;\n import io.pravega.segmentstore.contracts.ReadResultEntryType;\n@@ -41,6 +42,7 @@\n  */\n abstract class AsyncTableEntryReader<ResultT> implements AsyncReadResultHandler {\n     //region Members\n+    static final int INITIAL_READ_LENGTH = EntrySerializer.HEADER_LENGTH + EntrySerializer.MAX_KEY_LENGTH;\n \n     private final TimeoutTimer timer;\n     private final BufferViewBuilder readData;\n@@ -149,6 +151,17 @@ protected long getKeyVersion() {\n         return getKeyVersion(this.header, this.keyVersion);\n     }\n \n+    protected BufferView compactIfNeeded(BufferView source) {\n+        val l = source.getLength();\n+        if (l != 0 && l < source.getAllocatedLength() >> 1) {\n+            // We compact if we use less than half of the underlying buffer.\n+            source = new ByteArraySegment(source.getCopy());\n+        }\n+\n+        return source;\n+    }\n+\n+\n     //endregion\n \n     //region AsyncReadResultHandler implementation\n@@ -205,6 +218,14 @@ public Duration getRequestContentTimeout() {\n         return this.timer.getRemaining();\n     }\n \n+    @Override\n+    public int getMaxReadAtOnce() {\n+        if (this.result.isDone()) {\n+            return 0;\n+        }\n+        return this.header == null ? INITIAL_READ_LENGTH : this.header.getTotalLength() - this.readData.getLength();\n+    }\n+\n     //endregion\n \n     //region KeyReader\n@@ -224,7 +245,7 @@ protected boolean processReadData(BufferView readData) {\n \n             if (readData.getLength() >= EntrySerializer.HEADER_LENGTH + header.getKeyLength()) {\n                 // We read enough information.\n-                BufferView keyData = readData.slice(header.getKeyOffset(), header.getKeyLength());\n+                BufferView keyData = compactIfNeeded(readData.slice(header.getKeyOffset(), header.getKeyLength()));\n                 if (header.isDeletion()) {\n                     complete(TableKey.notExists(keyData));\n                 } else {\n@@ -301,19 +322,19 @@ protected boolean processReadData(BufferView readData) {\n             if (header.getValueLength() == 0) {\n                 valueData = BufferView.empty();\n             } else {\n-                valueData = readData.slice(header.getValueOffset(), header.getValueLength());\n+                valueData = compactIfNeeded(readData.slice(header.getValueOffset(), header.getValueLength()));\n             }\n \n             complete(TableEntry.versioned(readKey(readData, header), valueData, getKeyVersion()));\n             return true; // Now we are truly done.\n         }\n \n         private BufferView readKey(BufferView readData, EntrySerializer.Header header) {\n-            return readData.slice(header.getKeyOffset(), header.getKeyLength());\n+            return compactIfNeeded(readData.slice(header.getKeyOffset(), header.getKeyLength()));\n         }\n \n         private BufferView getOrReadKey(BufferView readData, EntrySerializer.Header header) {\n-            return this.soughtKey != null ? this.soughtKey : readData.slice(header.getKeyOffset(), header.getKeyLength());\n+            return this.soughtKey != null ? this.soughtKey : readKey(readData, header);\n         }\n     }\n "
  }
]
