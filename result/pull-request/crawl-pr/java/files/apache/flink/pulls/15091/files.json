[
  {
    "sha": "f0f4529257b35a65c7ccaa159c5bb0c6a42db948",
    "filename": "docs/layouts/shortcodes/generated/rocksdb_configuration.html",
    "status": "modified",
    "additions": 18,
    "deletions": 0,
    "changes": 18,
    "blob_url": "https://github.com/apache/flink/blob/c3d268b3dfcb4037f99d148b70e005832dd00c44/docs/layouts/shortcodes/generated/rocksdb_configuration.html",
    "raw_url": "https://github.com/apache/flink/raw/c3d268b3dfcb4037f99d148b70e005832dd00c44/docs/layouts/shortcodes/generated/rocksdb_configuration.html",
    "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/layouts/shortcodes/generated/rocksdb_configuration.html?ref=c3d268b3dfcb4037f99d148b70e005832dd00c44",
    "patch": "@@ -14,6 +14,24 @@\n             <td>Integer</td>\n             <td>The number of threads (per stateful operator) used to transfer (download and upload) files in RocksDBStateBackend.</td>\n         </tr>\n+        <tr>\n+            <td><h5>state.backend.rocksdb.latency-track-enabled</h5></td>\n+            <td style=\"word-wrap: break-word;\">false</td>\n+            <td>Boolean</td>\n+            <td>Whether to track latency of RocksDB actions, e.g put/get/delete/seek/next.</td>\n+        </tr>\n+        <tr>\n+            <td><h5>state.backend.rocksdb.latency-track-sample-interval</h5></td>\n+            <td style=\"word-wrap: break-word;\">100</td>\n+            <td>Integer</td>\n+            <td>The sample interval of latency track once 'state.backend.rocksdb.latency-track-enabled' is enabled. The default value is 100, which means we would track the latency every 100 access requests.</td>\n+        </tr>\n+        <tr>\n+            <td><h5>state.backend.rocksdb.latency-track-sliding-window</h5></td>\n+            <td style=\"word-wrap: break-word;\">10000</td>\n+            <td>Long</td>\n+            <td>The sliding window of histogram to record the latency once 'state.backend.rocksdb.latency-track-enabled' is enabled. The default value is 10 seconds, which means we stores only the measurements made in the last 10 seconds.</td>\n+        </tr>\n         <tr>\n             <td><h5>state.backend.rocksdb.localdir</h5></td>\n             <td style=\"word-wrap: break-word;\">(none)</td>"
  },
  {
    "sha": "05c7d9e9c69ae81046d3b7c1ac9614056e658185",
    "filename": "docs/layouts/shortcodes/generated/state_backend_rocksdb_section.html",
    "status": "modified",
    "additions": 18,
    "deletions": 0,
    "changes": 18,
    "blob_url": "https://github.com/apache/flink/blob/c3d268b3dfcb4037f99d148b70e005832dd00c44/docs/layouts/shortcodes/generated/state_backend_rocksdb_section.html",
    "raw_url": "https://github.com/apache/flink/raw/c3d268b3dfcb4037f99d148b70e005832dd00c44/docs/layouts/shortcodes/generated/state_backend_rocksdb_section.html",
    "contents_url": "https://api.github.com/repos/apache/flink/contents/docs/layouts/shortcodes/generated/state_backend_rocksdb_section.html?ref=c3d268b3dfcb4037f99d148b70e005832dd00c44",
    "patch": "@@ -8,6 +8,24 @@\n         </tr>\n     </thead>\n     <tbody>\n+        <tr>\n+            <td><h5>state.backend.rocksdb.latency-track-enabled</h5></td>\n+            <td style=\"word-wrap: break-word;\">false</td>\n+            <td>Boolean</td>\n+            <td>Whether to track latency of RocksDB actions, e.g put/get/delete/seek/next.</td>\n+        </tr>\n+        <tr>\n+            <td><h5>state.backend.rocksdb.latency-track-sample-interval</h5></td>\n+            <td style=\"word-wrap: break-word;\">100</td>\n+            <td>Integer</td>\n+            <td>The sample interval of latency track once 'state.backend.rocksdb.latency-track-enabled' is enabled. The default value is 100, which means we would track the latency every 100 access requests.</td>\n+        </tr>\n+        <tr>\n+            <td><h5>state.backend.rocksdb.latency-track-sliding-window</h5></td>\n+            <td style=\"word-wrap: break-word;\">10000</td>\n+            <td>Long</td>\n+            <td>The sliding window of histogram to record the latency once 'state.backend.rocksdb.latency-track-enabled' is enabled. The default value is 10 seconds, which means we stores only the measurements made in the last 10 seconds.</td>\n+        </tr>\n         <tr>\n             <td><h5>state.backend.rocksdb.memory.fixed-per-slot</h5></td>\n             <td style=\"word-wrap: break-word;\">(none)</td>"
  },
  {
    "sha": "c97276046c9526f1f529226cdeccdc9e2e016e07",
    "filename": "flink-dist/src/main/resources/META-INF/NOTICE",
    "status": "modified",
    "additions": 1,
    "deletions": 0,
    "changes": 1,
    "blob_url": "https://github.com/apache/flink/blob/c3d268b3dfcb4037f99d148b70e005832dd00c44/flink-dist/src/main/resources/META-INF/NOTICE",
    "raw_url": "https://github.com/apache/flink/raw/c3d268b3dfcb4037f99d148b70e005832dd00c44/flink-dist/src/main/resources/META-INF/NOTICE",
    "contents_url": "https://api.github.com/repos/apache/flink/contents/flink-dist/src/main/resources/META-INF/NOTICE?ref=c3d268b3dfcb4037f99d148b70e005832dd00c44",
    "patch": "@@ -19,6 +19,7 @@ This project bundles the following dependencies under the Apache Software Licens\n - commons-cli:commons-cli:1.3.1\n - commons-collections:commons-collections:3.2.2\n - commons-io:commons-io:2.7\n+- io.dropwizard.metrics:metrics-core:3.2.6\n - org.apache.commons:commons-compress:1.20\n - org.apache.commons:commons-lang3:3.3.2\n - org.apache.commons:commons-math3:3.5"
  },
  {
    "sha": "5fd69c89bff2fbf512d8f0ac05b73dba9faccd75",
    "filename": "flink-metrics/pom.xml",
    "status": "modified",
    "additions": 0,
    "deletions": 4,
    "changes": 4,
    "blob_url": "https://github.com/apache/flink/blob/c3d268b3dfcb4037f99d148b70e005832dd00c44/flink-metrics/pom.xml",
    "raw_url": "https://github.com/apache/flink/raw/c3d268b3dfcb4037f99d148b70e005832dd00c44/flink-metrics/pom.xml",
    "contents_url": "https://api.github.com/repos/apache/flink/contents/flink-metrics/pom.xml?ref=c3d268b3dfcb4037f99d148b70e005832dd00c44",
    "patch": "@@ -33,10 +33,6 @@ under the License.\n \t<name>Flink : Metrics : </name>\n \t<packaging>pom</packaging>\n \n-\t<properties>\n-\t\t<dropwizard.version>3.2.6</dropwizard.version>\n-\t</properties>\n-\n \t<modules>\n \t\t<module>flink-metrics-core</module>\n \t\t<module>flink-metrics-dropwizard</module>"
  },
  {
    "sha": "8ec664856d00ddbb66411ab53c481054c12e48b2",
    "filename": "flink-state-backends/flink-statebackend-rocksdb/pom.xml",
    "status": "modified",
    "additions": 6,
    "deletions": 0,
    "changes": 6,
    "blob_url": "https://github.com/apache/flink/blob/c3d268b3dfcb4037f99d148b70e005832dd00c44/flink-state-backends/flink-statebackend-rocksdb/pom.xml",
    "raw_url": "https://github.com/apache/flink/raw/c3d268b3dfcb4037f99d148b70e005832dd00c44/flink-state-backends/flink-statebackend-rocksdb/pom.xml",
    "contents_url": "https://api.github.com/repos/apache/flink/contents/flink-state-backends/flink-statebackend-rocksdb/pom.xml?ref=c3d268b3dfcb4037f99d148b70e005832dd00c44",
    "patch": "@@ -60,6 +60,12 @@ under the License.\n \t\t\t<version>5.17.2-artisans-2.0</version>\n \t\t</dependency>\n \n+\t\t<dependency>\n+\t\t\t<groupId>io.dropwizard.metrics</groupId>\n+\t\t\t<artifactId>metrics-core</artifactId>\n+\t\t\t<version>${dropwizard.version}</version>\n+\t\t</dependency>\n+\n \t\t<!-- test dependencies -->\n \n \t\t<dependency>"
  },
  {
    "sha": "a690cb8f81faebb3eb7d2a76ceba26989267cf4a",
    "filename": "flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/AbstractRocksDBAppendingState.java",
    "status": "modified",
    "additions": 1,
    "deletions": 2,
    "changes": 3,
    "blob_url": "https://github.com/apache/flink/blob/c3d268b3dfcb4037f99d148b70e005832dd00c44/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/AbstractRocksDBAppendingState.java",
    "raw_url": "https://github.com/apache/flink/raw/c3d268b3dfcb4037f99d148b70e005832dd00c44/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/AbstractRocksDBAppendingState.java",
    "contents_url": "https://api.github.com/repos/apache/flink/contents/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/AbstractRocksDBAppendingState.java?ref=c3d268b3dfcb4037f99d148b70e005832dd00c44",
    "patch": "@@ -22,7 +22,6 @@\n import org.apache.flink.runtime.state.internal.InternalAppendingState;\n import org.apache.flink.util.FlinkRuntimeException;\n \n-import org.rocksdb.ColumnFamilyHandle;\n import org.rocksdb.RocksDBException;\n \n import java.io.IOException;\n@@ -41,7 +40,7 @@\n      * @param backend The backend for which this state is bind to.\n      */\n     protected AbstractRocksDBAppendingState(\n-            ColumnFamilyHandle columnFamily,\n+            ColumnFamilyHandleWrapper columnFamily,\n             TypeSerializer<N> namespaceSerializer,\n             TypeSerializer<SV> valueSerializer,\n             SV defaultValue,"
  },
  {
    "sha": "aa92a6045f47ee1c5c9fdfef048c2e262506fbc4",
    "filename": "flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/AbstractRocksDBState.java",
    "status": "modified",
    "additions": 2,
    "deletions": 3,
    "changes": 5,
    "blob_url": "https://github.com/apache/flink/blob/c3d268b3dfcb4037f99d148b70e005832dd00c44/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/AbstractRocksDBState.java",
    "raw_url": "https://github.com/apache/flink/raw/c3d268b3dfcb4037f99d148b70e005832dd00c44/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/AbstractRocksDBState.java",
    "contents_url": "https://api.github.com/repos/apache/flink/contents/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/AbstractRocksDBState.java?ref=c3d268b3dfcb4037f99d148b70e005832dd00c44",
    "patch": "@@ -30,7 +30,6 @@\n import org.apache.flink.util.Preconditions;\n import org.apache.flink.util.StateMigrationException;\n \n-import org.rocksdb.ColumnFamilyHandle;\n import org.rocksdb.RocksDBException;\n import org.rocksdb.WriteOptions;\n \n@@ -61,7 +60,7 @@\n     protected RocksDBKeyedStateBackend<K> backend;\n \n     /** The column family of this particular instance of state. */\n-    protected ColumnFamilyHandle columnFamily;\n+    protected ColumnFamilyHandleWrapper columnFamily;\n \n     protected final V defaultValue;\n \n@@ -83,7 +82,7 @@\n      * @param backend The backend for which this state is bind to.\n      */\n     protected AbstractRocksDBState(\n-            ColumnFamilyHandle columnFamily,\n+            ColumnFamilyHandleWrapper columnFamily,\n             TypeSerializer<N> namespaceSerializer,\n             TypeSerializer<V> valueSerializer,\n             V defaultValue,"
  },
  {
    "sha": "b3872180ab201a75b167ef7ed9cbaacdfebe67d2",
    "filename": "flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/ColumnFamilyHandleWrapper.java",
    "status": "added",
    "additions": 48,
    "deletions": 0,
    "changes": 48,
    "blob_url": "https://github.com/apache/flink/blob/c3d268b3dfcb4037f99d148b70e005832dd00c44/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/ColumnFamilyHandleWrapper.java",
    "raw_url": "https://github.com/apache/flink/raw/c3d268b3dfcb4037f99d148b70e005832dd00c44/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/ColumnFamilyHandleWrapper.java",
    "contents_url": "https://api.github.com/repos/apache/flink/contents/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/ColumnFamilyHandleWrapper.java?ref=c3d268b3dfcb4037f99d148b70e005832dd00c44",
    "patch": "@@ -0,0 +1,48 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.contrib.streaming.state;\n+\n+import org.rocksdb.ColumnFamilyHandle;\n+\n+/**\n+ * Wrapper of {@link ColumnFamilyHandle}, we introduce this class is to avoid JNI call of {@link\n+ * ColumnFamilyHandle#getID()}.\n+ */\n+public class ColumnFamilyHandleWrapper implements AutoCloseable {\n+    private final ColumnFamilyHandle columnFamilyHandle;\n+    private final int columnFamilyId;\n+\n+    public ColumnFamilyHandleWrapper(ColumnFamilyHandle columnFamilyHandle) {\n+        this.columnFamilyHandle = columnFamilyHandle;\n+        this.columnFamilyId = columnFamilyHandle.getID();\n+    }\n+\n+    public int getColumnFamilyId() {\n+        return columnFamilyId;\n+    }\n+\n+    public ColumnFamilyHandle getColumnFamilyHandle() {\n+        return columnFamilyHandle;\n+    }\n+\n+    @Override\n+    public void close() throws Exception {\n+        columnFamilyHandle.close();\n+    }\n+}"
  },
  {
    "sha": "3f7137ae77edc8f88dbac25d26a8c0f457b3763a",
    "filename": "flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/EmbeddedRocksDBStateBackend.java",
    "status": "modified",
    "additions": 6,
    "deletions": 0,
    "changes": 6,
    "blob_url": "https://github.com/apache/flink/blob/c3d268b3dfcb4037f99d148b70e005832dd00c44/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/EmbeddedRocksDBStateBackend.java",
    "raw_url": "https://github.com/apache/flink/raw/c3d268b3dfcb4037f99d148b70e005832dd00c44/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/EmbeddedRocksDBStateBackend.java",
    "contents_url": "https://api.github.com/repos/apache/flink/contents/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/EmbeddedRocksDBStateBackend.java?ref=c3d268b3dfcb4037f99d148b70e005832dd00c44",
    "patch": "@@ -145,6 +145,9 @@\n     /** The default rocksdb metrics options. */\n     private final RocksDBNativeMetricOptions defaultMetricOptions;\n \n+    /** The options to track rocksdb latency. */\n+    private final RocksDBAccessMetric.Builder accessMetricBuilder;\n+\n     // -- runtime values, set on TaskManager when initializing / using the backend\n \n     /** Base paths for RocksDB directory, as initialized. */\n@@ -190,6 +193,7 @@ public EmbeddedRocksDBStateBackend(TernaryBoolean enableIncrementalCheckpointing\n         this.enableIncrementalCheckpointing = enableIncrementalCheckpointing;\n         this.numberOfTransferThreads = UNDEFINED_NUMBER_OF_TRANSFER_THREADS;\n         this.defaultMetricOptions = new RocksDBNativeMetricOptions();\n+        this.accessMetricBuilder = new RocksDBAccessMetric.Builder();\n         this.memoryConfiguration = new RocksDBMemoryConfiguration();\n         this.writeBatchSize = UNDEFINED_WRITE_BATCH_SIZE;\n     }\n@@ -253,6 +257,7 @@ private EmbeddedRocksDBStateBackend(\n \n         // configure metric options\n         this.defaultMetricOptions = RocksDBNativeMetricOptions.fromConfig(config);\n+        this.accessMetricBuilder = RocksDBAccessMetric.builderFromConfig(config);\n \n         // configure RocksDB predefined options\n         this.predefinedOptions =\n@@ -467,6 +472,7 @@ private File getNextStoragePath() {\n                         .setNumberOfTransferingThreads(getNumberOfTransferThreads())\n                         .setNativeMetricOptions(\n                                 resourceContainer.getMemoryWatcherOptions(defaultMetricOptions))\n+                        .setAccessMetricBuilder(accessMetricBuilder)\n                         .setWriteBatchSize(getWriteBatchSize());\n         return builder.build();\n     }"
  },
  {
    "sha": "d6c655f90c1e7cb48695b91304e44b3da5ed9b3d",
    "filename": "flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBAccessMetric.java",
    "status": "added",
    "additions": 361,
    "deletions": 0,
    "changes": 361,
    "blob_url": "https://github.com/apache/flink/blob/c3d268b3dfcb4037f99d148b70e005832dd00c44/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBAccessMetric.java",
    "raw_url": "https://github.com/apache/flink/raw/c3d268b3dfcb4037f99d148b70e005832dd00c44/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBAccessMetric.java",
    "contents_url": "https://api.github.com/repos/apache/flink/contents/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBAccessMetric.java?ref=c3d268b3dfcb4037f99d148b70e005832dd00c44",
    "patch": "@@ -0,0 +1,361 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.contrib.streaming.state;\n+\n+import org.apache.flink.annotation.VisibleForTesting;\n+import org.apache.flink.configuration.ReadableConfig;\n+import org.apache.flink.metrics.Histogram;\n+import org.apache.flink.metrics.HistogramStatistics;\n+import org.apache.flink.metrics.MetricGroup;\n+import org.apache.flink.util.Preconditions;\n+\n+import com.codahale.metrics.SlidingTimeWindowReservoir;\n+import com.codahale.metrics.Snapshot;\n+import org.rocksdb.ColumnFamilyHandle;\n+\n+import java.io.Serializable;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.TimeUnit;\n+import java.util.function.Supplier;\n+\n+import static org.apache.flink.contrib.streaming.state.RocksDBNativeMetricMonitor.COLUMN_FAMILY_KEY;\n+\n+/** Metrics to counting access latency. */\n+public class RocksDBAccessMetric implements AutoCloseable {\n+    private final Map<Integer, MetricGroup> columnFamilyMetricGroups;\n+\n+    private final Map<Integer, Counters> countersPerColumnFamily;\n+\n+    private final Map<Integer, Map<String, Histogram>> histogramMetrics;\n+\n+    private final MetricGroup metricGroup;\n+\n+    private final int sampleCountInterval;\n+\n+    private final boolean metricsSampleEnabled;\n+\n+    private final long histogramWindowSize;\n+\n+    private final Supplier<com.codahale.metrics.Histogram> histogramSupplier;\n+\n+    static final String GET_LATENCY = \"getLatency\";\n+    static final String PUT_LATENCY = \"putLatency\";\n+    static final String WRITE_BATCH_LATENCY = \"writeBatchLatency\";\n+    static final String DELETE_LATENCY = \"deleteLatency\";\n+    static final String MERGE_LATENCY = \"mergeLatency\";\n+    static final String SEEK_LATENCY = \"seekLatency\";\n+    static final String NEXT_LATENCY = \"nextLatency\";\n+\n+    RocksDBAccessMetric(\n+            MetricGroup metricGroup, int sampleCountInterval, long histogramWindowSize) {\n+        this.metricGroup = Preconditions.checkNotNull(metricGroup);\n+        this.sampleCountInterval = sampleCountInterval;\n+        this.metricsSampleEnabled = sampleCountInterval > 1;\n+\n+        Preconditions.checkArgument(histogramWindowSize > 0);\n+        this.histogramWindowSize = histogramWindowSize;\n+        this.histogramMetrics = new HashMap<>();\n+        this.columnFamilyMetricGroups = new HashMap<>();\n+        this.countersPerColumnFamily = new HashMap<>();\n+        this.histogramSupplier =\n+                () ->\n+                        new com.codahale.metrics.Histogram(\n+                                new SlidingTimeWindowReservoir(\n+                                        histogramWindowSize, TimeUnit.SECONDS));\n+    }\n+\n+    boolean checkAndUpdateGetCounter(final int columnFamilyHandleId) {\n+        return metricsSampleEnabled\n+                && countersPerColumnFamily.get(columnFamilyHandleId).checkAndUpdateGetCounter();\n+    }\n+\n+    boolean checkAndUpdatePutCounter(final int columnFamilyHandleId) {\n+        return metricsSampleEnabled\n+                && countersPerColumnFamily.get(columnFamilyHandleId).checkAndUpdatePutCounter();\n+    }\n+\n+    boolean checkAndUpdateWriteBatchCounter(final int columnFamilyHandleId) {\n+        return metricsSampleEnabled\n+                && countersPerColumnFamily\n+                        .get(columnFamilyHandleId)\n+                        .checkAndUpdateWriteBatchCounter();\n+    }\n+\n+    boolean checkAndUpdateDeleteCounter(final int columnFamilyHandleId) {\n+        return metricsSampleEnabled\n+                && countersPerColumnFamily.get(columnFamilyHandleId).checkAndUpdateDeleteCounter();\n+    }\n+\n+    boolean checkAndUpdateMergeCounter(final int columnFamilyHandleId) {\n+        return metricsSampleEnabled\n+                && countersPerColumnFamily.get(columnFamilyHandleId).checkAndUpdateMergeCounter();\n+    }\n+\n+    boolean checkAndUpdateSeekCounter(final int columnFamilyHandleId) {\n+        return metricsSampleEnabled\n+                && countersPerColumnFamily.get(columnFamilyHandleId).checkAndUpdateSeekCounter();\n+    }\n+\n+    boolean checkAndUpdateNextCounter(final int columnFamilyHandleId) {\n+        return metricsSampleEnabled\n+                && countersPerColumnFamily.get(columnFamilyHandleId).checkAndUpdateNextCounter();\n+    }\n+\n+    public void updateHistogram(\n+            final int columnFamilyHandleId, final String metricName, final long durationNanoTime) {\n+        this.histogramMetrics\n+                .get(columnFamilyHandleId)\n+                .computeIfAbsent(\n+                        metricName,\n+                        (k) -> {\n+                            HistogramWrapper histogram =\n+                                    new HistogramWrapper(histogramSupplier.get());\n+                            columnFamilyMetricGroups\n+                                    .get(columnFamilyHandleId)\n+                                    .histogram(metricName, histogram);\n+                            return histogram;\n+                        })\n+                .update(durationNanoTime);\n+    }\n+\n+    boolean isMetricsSampleEnabled() {\n+        return metricsSampleEnabled;\n+    }\n+\n+    int getSampleCountInterval() {\n+        return sampleCountInterval;\n+    }\n+\n+    long getHistogramWindowSize() {\n+        return histogramWindowSize;\n+    }\n+\n+    @VisibleForTesting\n+    Map<Integer, Map<String, Histogram>> getHistogramMetrics() {\n+        return histogramMetrics;\n+    }\n+\n+    /**\n+     * Register histogram to track latency metrics for the column family.\n+     *\n+     * @param columnFamilyName group name for the new gauges\n+     * @param handle native handle to the column family\n+     */\n+    void registerColumnFamily(String columnFamilyName, ColumnFamilyHandle handle) {\n+        int columnFamilyId = handle.getID();\n+        columnFamilyMetricGroups.putIfAbsent(\n+                columnFamilyId, metricGroup.addGroup(COLUMN_FAMILY_KEY, columnFamilyName));\n+        histogramMetrics.putIfAbsent(columnFamilyId, new HashMap<>());\n+        if (metricsSampleEnabled) {\n+            countersPerColumnFamily.putIfAbsent(columnFamilyId, new Counters(sampleCountInterval));\n+        }\n+    }\n+\n+    @Override\n+    public void close() {\n+        this.histogramMetrics.clear();\n+        this.countersPerColumnFamily.clear();\n+        this.columnFamilyMetricGroups.clear();\n+    }\n+\n+    static class HistogramWrapper implements Histogram {\n+        private final com.codahale.metrics.Histogram histogram;\n+\n+        public HistogramWrapper(com.codahale.metrics.Histogram histogram) {\n+            this.histogram = histogram;\n+        }\n+\n+        @Override\n+        public void update(long value) {\n+            histogram.update(value);\n+        }\n+\n+        @Override\n+        public long getCount() {\n+            return histogram.getCount();\n+        }\n+\n+        @Override\n+        public HistogramStatistics getStatistics() {\n+            return new SnapshotHistogramStatistics(this.histogram.getSnapshot());\n+        }\n+    }\n+\n+    private static class SnapshotHistogramStatistics extends HistogramStatistics {\n+\n+        private final Snapshot snapshot;\n+\n+        SnapshotHistogramStatistics(com.codahale.metrics.Snapshot snapshot) {\n+            this.snapshot = snapshot;\n+        }\n+\n+        @Override\n+        public double getQuantile(double quantile) {\n+            return snapshot.getValue(quantile);\n+        }\n+\n+        @Override\n+        public long[] getValues() {\n+            return snapshot.getValues();\n+        }\n+\n+        @Override\n+        public int size() {\n+            return snapshot.size();\n+        }\n+\n+        @Override\n+        public double getMean() {\n+            return snapshot.getMean();\n+        }\n+\n+        @Override\n+        public double getStdDev() {\n+            return snapshot.getStdDev();\n+        }\n+\n+        @Override\n+        public long getMax() {\n+            return snapshot.getMax();\n+        }\n+\n+        @Override\n+        public long getMin() {\n+            return snapshot.getMin();\n+        }\n+    }\n+\n+    public static Builder builderFromConfig(ReadableConfig config) {\n+        Builder builder = new Builder();\n+        return builder.setEnabled(config.get(RocksDBOptions.LATENCY_TRACK_ENABLED))\n+                .setSampleInterval(config.get(RocksDBOptions.LATENCY_TRACK_SAMPLE_INTERVAL))\n+                .setHistogramSlidingWindow(config.get(RocksDBOptions.LATENCY_TRACK_SLIDING_WINDOW));\n+    }\n+\n+    /** Builder for {@link RocksDBAccessMetric}. */\n+    public static class Builder implements Serializable {\n+        private static final long serialVersionUID = 1L;\n+\n+        private boolean isEnabled = RocksDBOptions.LATENCY_TRACK_ENABLED.defaultValue();\n+        private int sampleInterval = RocksDBOptions.LATENCY_TRACK_SAMPLE_INTERVAL.defaultValue();\n+        private long histogramSlidingWindow =\n+                RocksDBOptions.LATENCY_TRACK_SLIDING_WINDOW.defaultValue();\n+        private MetricGroup metricGroup;\n+\n+        public Builder setEnabled(boolean enabled) {\n+            this.isEnabled = enabled;\n+            return this;\n+        }\n+\n+        public Builder setSampleInterval(int sampleInterval) {\n+            this.sampleInterval = sampleInterval;\n+            return this;\n+        }\n+\n+        public Builder setHistogramSlidingWindow(long histogramSlidingWindow) {\n+            this.histogramSlidingWindow = histogramSlidingWindow;\n+            return this;\n+        }\n+\n+        public Builder setMetricGroup(MetricGroup metricGroup) {\n+            this.metricGroup = metricGroup;\n+            return this;\n+        }\n+\n+        public RocksDBAccessMetric build() {\n+            if (isEnabled) {\n+                return new RocksDBAccessMetric(\n+                        Preconditions.checkNotNull(metricGroup),\n+                        sampleInterval,\n+                        histogramSlidingWindow);\n+            } else {\n+                return null;\n+            }\n+        }\n+    }\n+\n+    private static class Counters {\n+        private final int metricSampledInterval;\n+        private int getCounter;\n+        private int putCounter;\n+        private int writeBatchCounter;\n+        private int deleteCounter;\n+        private int mergeCounter;\n+        private int seekCounter;\n+        private int nextCounter;\n+\n+        Counters(int metricSampledInterval) {\n+            this.metricSampledInterval = metricSampledInterval;\n+            this.getCounter = 0;\n+            this.putCounter = 0;\n+            this.writeBatchCounter = 0;\n+            this.deleteCounter = 0;\n+            this.mergeCounter = 0;\n+            this.seekCounter = 0;\n+            this.nextCounter = 0;\n+        }\n+\n+        private int updateMetricsSampledCounter(int counter) {\n+            return (counter + 1 < metricSampledInterval) ? counter + 1 : 0;\n+        }\n+\n+        boolean checkAndUpdateGetCounter() {\n+            boolean result = getCounter == 0;\n+            this.getCounter = updateMetricsSampledCounter(getCounter);\n+            return result;\n+        }\n+\n+        boolean checkAndUpdatePutCounter() {\n+            boolean result = putCounter == 0;\n+            this.putCounter = updateMetricsSampledCounter(putCounter);\n+            return result;\n+        }\n+\n+        boolean checkAndUpdateWriteBatchCounter() {\n+            boolean result = writeBatchCounter == 0;\n+            this.writeBatchCounter = updateMetricsSampledCounter(writeBatchCounter);\n+            return result;\n+        }\n+\n+        boolean checkAndUpdateDeleteCounter() {\n+            boolean result = deleteCounter == 0;\n+            this.deleteCounter = updateMetricsSampledCounter(deleteCounter);\n+            return result;\n+        }\n+\n+        boolean checkAndUpdateMergeCounter() {\n+            boolean result = mergeCounter == 0;\n+            this.mergeCounter = updateMetricsSampledCounter(mergeCounter);\n+            return result;\n+        }\n+\n+        boolean checkAndUpdateSeekCounter() {\n+            boolean result = seekCounter == 0;\n+            this.seekCounter = updateMetricsSampledCounter(seekCounter);\n+            return result;\n+        }\n+\n+        boolean checkAndUpdateNextCounter() {\n+            boolean result = nextCounter == 0;\n+            this.nextCounter = updateMetricsSampledCounter(nextCounter);\n+            return result;\n+        }\n+    }\n+}"
  },
  {
    "sha": "02bf26f798354bb1cf823ad00163d49f6ac2ce38",
    "filename": "flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBAggregatingState.java",
    "status": "modified",
    "additions": 2,
    "deletions": 4,
    "changes": 6,
    "blob_url": "https://github.com/apache/flink/blob/c3d268b3dfcb4037f99d148b70e005832dd00c44/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBAggregatingState.java",
    "raw_url": "https://github.com/apache/flink/raw/c3d268b3dfcb4037f99d148b70e005832dd00c44/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBAggregatingState.java",
    "contents_url": "https://api.github.com/repos/apache/flink/contents/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBAggregatingState.java?ref=c3d268b3dfcb4037f99d148b70e005832dd00c44",
    "patch": "@@ -29,8 +29,6 @@\n import org.apache.flink.runtime.state.internal.InternalAggregatingState;\n import org.apache.flink.util.FlinkRuntimeException;\n \n-import org.rocksdb.ColumnFamilyHandle;\n-\n import java.util.Collection;\n \n /**\n@@ -60,7 +58,7 @@\n      * @param backend The backend for which this state is bind to.\n      */\n     private RocksDBAggregatingState(\n-            ColumnFamilyHandle columnFamily,\n+            ColumnFamilyHandleWrapper columnFamily,\n             TypeSerializer<N> namespaceSerializer,\n             TypeSerializer<ACC> valueSerializer,\n             ACC defaultValue,\n@@ -164,7 +162,7 @@ public void mergeNamespaces(N target, Collection<N> sources) {\n     @SuppressWarnings(\"unchecked\")\n     static <K, N, SV, S extends State, IS extends S> IS create(\n             StateDescriptor<S, SV> stateDesc,\n-            Tuple2<ColumnFamilyHandle, RegisteredKeyValueStateBackendMetaInfo<N, SV>>\n+            Tuple2<ColumnFamilyHandleWrapper, RegisteredKeyValueStateBackendMetaInfo<N, SV>>\n                     registerResult,\n             RocksDBKeyedStateBackend<K> backend) {\n         return (IS)"
  },
  {
    "sha": "aeaf01cc7aad3581ab9e1a194e1acca18a6821e7",
    "filename": "flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBCachingPriorityQueueSet.java",
    "status": "modified",
    "additions": 11,
    "deletions": 9,
    "changes": 20,
    "blob_url": "https://github.com/apache/flink/blob/c3d268b3dfcb4037f99d148b70e005832dd00c44/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBCachingPriorityQueueSet.java",
    "raw_url": "https://github.com/apache/flink/raw/c3d268b3dfcb4037f99d148b70e005832dd00c44/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBCachingPriorityQueueSet.java",
    "contents_url": "https://api.github.com/repos/apache/flink/contents/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBCachingPriorityQueueSet.java?ref=c3d268b3dfcb4037f99d148b70e005832dd00c44",
    "patch": "@@ -29,9 +29,7 @@\n \n import org.apache.flink.shaded.guava18.com.google.common.primitives.UnsignedBytes;\n \n-import org.rocksdb.ColumnFamilyHandle;\n import org.rocksdb.ReadOptions;\n-import org.rocksdb.RocksDB;\n import org.rocksdb.RocksDBException;\n \n import javax.annotation.Nonnegative;\n@@ -62,12 +60,14 @@\n     private static final byte[] DUMMY_BYTES = new byte[] {};\n \n     /** The RocksDB instance that serves as store. */\n-    @Nonnull private final RocksDB db;\n+    @Nonnull private final RocksDBWrapper db;\n \n     @Nonnull private final ReadOptions readOptions;\n \n+    @Nullable private final RocksDBAccessMetric accessMetric;\n+\n     /** Handle to the column family of the RocksDB instance in which the elements are stored. */\n-    @Nonnull private final ColumnFamilyHandle columnFamilyHandle;\n+    @Nonnull private final ColumnFamilyHandleWrapper columnFamilyHandle;\n \n     /**\n      * Serializer for the contained elements. The lexicographical order of the bytes of serialized\n@@ -108,16 +108,18 @@\n     RocksDBCachingPriorityQueueSet(\n             @Nonnegative int keyGroupId,\n             @Nonnegative int keyGroupPrefixBytes,\n-            @Nonnull RocksDB db,\n+            @Nonnull RocksDBWrapper db,\n             @Nonnull ReadOptions readOptions,\n-            @Nonnull ColumnFamilyHandle columnFamilyHandle,\n+            @Nullable RocksDBAccessMetric accessMetric,\n+            @Nonnull ColumnFamilyHandleWrapper columnFamilyHandle,\n             @Nonnull TypeSerializer<E> byteOrderProducingSerializer,\n             @Nonnull DataOutputSerializer outputStream,\n             @Nonnull DataInputDeserializer inputStream,\n             @Nonnull RocksDBWriteBatchWrapper batchWrapper,\n             @Nonnull OrderedByteArraySetCache orderedByteArraySetCache) {\n         this.db = db;\n         this.readOptions = readOptions;\n+        this.accessMetric = accessMetric;\n         this.columnFamilyHandle = columnFamilyHandle;\n         this.byteOrderProducingSerializer = byteOrderProducingSerializer;\n         this.batchWrapper = batchWrapper;\n@@ -303,7 +305,7 @@ public void setInternalIndex(int newIndex) {\n     private RocksBytesIterator orderedBytesIterator() {\n         flushWriteBatch();\n         return new RocksBytesIterator(\n-                new RocksIteratorWrapper(db.newIterator(columnFamilyHandle, readOptions)));\n+                RocksDBOperationUtils.getRocksIterator(db, columnFamilyHandle, readOptions));\n     }\n \n     /** Ensures that recent writes are flushed and reflect in the RocksDB instance. */\n@@ -317,15 +319,15 @@ private void flushWriteBatch() {\n \n     private void addToRocksDB(@Nonnull byte[] toAddBytes) {\n         try {\n-            batchWrapper.put(columnFamilyHandle, toAddBytes, DUMMY_BYTES);\n+            batchWrapper.put(columnFamilyHandle.getColumnFamilyHandle(), toAddBytes, DUMMY_BYTES);\n         } catch (RocksDBException e) {\n             throw new FlinkRuntimeException(e);\n         }\n     }\n \n     private void removeFromRocksDB(@Nonnull byte[] toRemoveBytes) {\n         try {\n-            batchWrapper.remove(columnFamilyHandle, toRemoveBytes);\n+            batchWrapper.remove(columnFamilyHandle.getColumnFamilyHandle(), toRemoveBytes);\n         } catch (RocksDBException e) {\n             throw new FlinkRuntimeException(e);\n         }"
  },
  {
    "sha": "68b1de85496559f953de1483faa12c7356bb316c",
    "filename": "flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBIncrementalCheckpointUtils.java",
    "status": "modified",
    "additions": 2,
    "deletions": 2,
    "changes": 4,
    "blob_url": "https://github.com/apache/flink/blob/c3d268b3dfcb4037f99d148b70e005832dd00c44/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBIncrementalCheckpointUtils.java",
    "raw_url": "https://github.com/apache/flink/raw/c3d268b3dfcb4037f99d148b70e005832dd00c44/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBIncrementalCheckpointUtils.java",
    "contents_url": "https://api.github.com/repos/apache/flink/contents/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBIncrementalCheckpointUtils.java?ref=c3d268b3dfcb4037f99d148b70e005832dd00c44",
    "patch": "@@ -129,10 +129,10 @@ private static void deleteRange(\n         for (ColumnFamilyHandle columnFamilyHandle : columnFamilyHandles) {\n             try (ReadOptions readOptions = RocksDBOperationUtils.createTotalOrderSeekReadOptions();\n                     RocksIteratorWrapper iteratorWrapper =\n-                            RocksDBOperationUtils.getRocksIterator(\n+                            RocksDBOperationUtils.getRocksIteratorWithoutAccessMetric(\n                                     db, columnFamilyHandle, readOptions);\n                     RocksDBWriteBatchWrapper writeBatchWrapper =\n-                            new RocksDBWriteBatchWrapper(db, writeBatchSize)) {\n+                            new RocksDBWriteBatchWrapper(new RocksDBWrapper(db), writeBatchSize)) {\n \n                 iteratorWrapper.seek(beginKeyBytes);\n "
  },
  {
    "sha": "950e441c4fb32482b670db2600291e4a8d2f73c1",
    "filename": "flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBKeyedStateBackend.java",
    "status": "modified",
    "additions": 47,
    "deletions": 35,
    "changes": 82,
    "blob_url": "https://github.com/apache/flink/blob/c3d268b3dfcb4037f99d148b70e005832dd00c44/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBKeyedStateBackend.java",
    "raw_url": "https://github.com/apache/flink/raw/c3d268b3dfcb4037f99d148b70e005832dd00c44/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBKeyedStateBackend.java",
    "contents_url": "https://api.github.com/repos/apache/flink/contents/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBKeyedStateBackend.java?ref=c3d268b3dfcb4037f99d148b70e005832dd00c44",
    "patch": "@@ -147,7 +147,7 @@\n     private interface StateFactory {\n         <K, N, SV, S extends State, IS extends S> IS createState(\n                 StateDescriptor<S, SV> stateDesc,\n-                Tuple2<ColumnFamilyHandle, RegisteredKeyValueStateBackendMetaInfo<N, SV>>\n+                Tuple2<ColumnFamilyHandleWrapper, RegisteredKeyValueStateBackendMetaInfo<N, SV>>\n                         registerResult,\n                 RocksDBKeyedStateBackend<K> backend)\n                 throws Exception;\n@@ -200,8 +200,8 @@\n      */\n     private final ColumnFamilyHandle defaultColumnFamily;\n \n-    /** Shared wrapper for batch writes to the RocksDB instance. */\n-    private final RocksDBWriteBatchWrapper writeBatchWrapper;\n+    /** Shared wrapper for batch writes to the RocksDB instance for timers. */\n+    private final RocksDBWriteBatchWrapper timerWriteBatchWrapper;\n \n     /**\n      * The checkpoint snapshot strategy, e.g., if we use full or incremental checkpoints, local\n@@ -226,7 +226,7 @@\n      * to store state. The different k/v states that we have don't each have their own RocksDB\n      * instance. They all write to this instance but to their own column family.\n      */\n-    protected final RocksDB db;\n+    protected final RocksDBWrapper db;\n \n     // mark whether this backend is already disposed and prevent duplicate disposing\n     private boolean disposed = false;\n@@ -242,15 +242,15 @@ public RocksDBKeyedStateBackend(\n             TypeSerializer<K> keySerializer,\n             ExecutionConfig executionConfig,\n             TtlTimeProvider ttlTimeProvider,\n-            RocksDB db,\n+            RocksDBWrapper db,\n             LinkedHashMap<String, RocksDbKvStateInfo> kvStateInformation,\n             Map<String, HeapPriorityQueueSnapshotRestoreWrapper<?>> registeredPQStates,\n             int keyGroupPrefixBytes,\n             CloseableRegistry cancelStreamRegistry,\n             StreamCompressionDecorator keyGroupCompressionDecorator,\n             ResourceGuard rocksDBResourceGuard,\n             RocksDBSnapshotStrategyBase<K, ?> checkpointSnapshotStrategy,\n-            RocksDBWriteBatchWrapper writeBatchWrapper,\n+            RocksDBWriteBatchWrapper timerWriteBatchWrapper,\n             ColumnFamilyHandle defaultColumnFamilyHandle,\n             RocksDBNativeMetricMonitor nativeMetricMonitor,\n             SerializedCompositeKeyBuilder<K> sharedRocksKeyBuilder,\n@@ -287,7 +287,7 @@ public RocksDBKeyedStateBackend(\n         this.db = db;\n         this.rocksDBResourceGuard = rocksDBResourceGuard;\n         this.checkpointSnapshotStrategy = checkpointSnapshotStrategy;\n-        this.writeBatchWrapper = writeBatchWrapper;\n+        this.timerWriteBatchWrapper = timerWriteBatchWrapper;\n         this.defaultColumnFamily = defaultColumnFamilyHandle;\n         this.nativeMetricMonitor = nativeMetricMonitor;\n         this.sharedRocksKeyBuilder = sharedRocksKeyBuilder;\n@@ -333,7 +333,7 @@ public RocksDBKeyedStateBackend(\n \n         RocksIteratorWrapper iterator =\n                 RocksDBOperationUtils.getRocksIterator(\n-                        db, columnInfo.columnFamilyHandle, readOptions);\n+                        db, columnInfo.columnFamilyHandleWrapper, readOptions);\n         iterator.seekToFirst();\n \n         final RocksStateKeysIterator<K> iteratorWrapper =\n@@ -371,7 +371,7 @@ public RocksDBKeyedStateBackend(\n \n         RocksIteratorWrapper iterator =\n                 RocksDBOperationUtils.getRocksIterator(\n-                        db, columnInfo.columnFamilyHandle, readOptions);\n+                        db, columnInfo.columnFamilyHandleWrapper, readOptions);\n         iterator.seekToFirst();\n \n         final RocksStateKeysAndNamespaceIterator<K, N> iteratorWrapper =\n@@ -393,7 +393,9 @@ public RocksDBKeyedStateBackend(\n     @VisibleForTesting\n     ColumnFamilyHandle getColumnFamilyHandle(String state) {\n         RocksDbKvStateInfo columnInfo = kvStateInformation.get(state);\n-        return columnInfo != null ? columnInfo.columnFamilyHandle : null;\n+        return columnInfo != null\n+                ? columnInfo.columnFamilyHandleWrapper.getColumnFamilyHandle()\n+                : null;\n     }\n \n     @Override\n@@ -421,7 +423,7 @@ public void dispose() {\n         // working on the disposed object results in SEGFAULTS.\n         if (db != null) {\n \n-            IOUtils.closeQuietly(writeBatchWrapper);\n+            IOUtils.closeQuietly(timerWriteBatchWrapper);\n \n             // Metric collection occurs on a background thread. When this method returns\n             // it is guaranteed that thr RocksDB reference has been invalidated\n@@ -445,8 +447,9 @@ public void dispose() {\n             // ... continue with the ones created by Flink...\n             for (RocksDbKvStateInfo kvStateInfo : kvStateInformation.values()) {\n                 RocksDBOperationUtils.addColumnFamilyOptionsToCloseLater(\n-                        columnFamilyOptions, kvStateInfo.columnFamilyHandle);\n-                IOUtils.closeQuietly(kvStateInfo.columnFamilyHandle);\n+                        columnFamilyOptions,\n+                        kvStateInfo.columnFamilyHandleWrapper.getColumnFamilyHandle());\n+                IOUtils.closeQuietly(kvStateInfo.columnFamilyHandleWrapper);\n             }\n \n             // ... and finally close the DB instance ...\n@@ -543,7 +546,7 @@ boolean isDisposed() {\n             throws Exception {\n \n         // flush everything into db before taking a snapshot\n-        writeBatchWrapper.flush();\n+        timerWriteBatchWrapper.flush();\n \n         return new SnapshotStrategyRunner<>(\n                         checkpointSnapshotStrategy.getDescription(),\n@@ -558,7 +561,7 @@ boolean isDisposed() {\n     public SavepointResources<K> savepoint() throws Exception {\n \n         // flush everything into db before taking a snapshot\n-        writeBatchWrapper.flush();\n+        timerWriteBatchWrapper.flush();\n \n         Map<String, HeapPriorityQueueSnapshotRestoreWrapper<?>> registeredPQStates;\n         if (heapPriorityQueuesManager != null) {\n@@ -604,7 +607,7 @@ public void notifyCheckpointAborted(long checkpointId) throws Exception {\n      * (after some necessary state compatibility checks) or create a new one if it does not exist.\n      */\n     private <N, S extends State, SV, SEV>\n-            Tuple2<ColumnFamilyHandle, RegisteredKeyValueStateBackendMetaInfo<N, SV>>\n+            Tuple2<ColumnFamilyHandleWrapper, RegisteredKeyValueStateBackendMetaInfo<N, SV>>\n                     tryRegisterKvStateInformation(\n                             StateDescriptor<S, SV> stateDesc,\n                             TypeSerializer<N> namespaceSerializer,\n@@ -624,13 +627,13 @@ public void notifyCheckpointAborted(long checkpointId) throws Exception {\n \n             newMetaInfo =\n                     updateRestoredStateMetaInfo(\n-                            Tuple2.of(oldStateInfo.columnFamilyHandle, castedMetaInfo),\n+                            Tuple2.of(oldStateInfo.columnFamilyHandleWrapper, castedMetaInfo),\n                             stateDesc,\n                             namespaceSerializer,\n                             stateSerializer);\n \n             newRocksStateInfo =\n-                    new RocksDbKvStateInfo(oldStateInfo.columnFamilyHandle, newMetaInfo);\n+                    new RocksDbKvStateInfo(oldStateInfo.columnFamilyHandleWrapper, newMetaInfo);\n             kvStateInformation.put(stateDesc.getName(), newRocksStateInfo);\n         } else {\n             newMetaInfo =\n@@ -644,13 +647,14 @@ public void notifyCheckpointAborted(long checkpointId) throws Exception {\n             newRocksStateInfo =\n                     RocksDBOperationUtils.createStateInfo(\n                             newMetaInfo,\n-                            db,\n+                            db.getDb(),\n                             columnFamilyOptionsFactory,\n                             ttlCompactFiltersManager,\n                             optionsContainer.getWriteBufferManagerCapacity());\n             RocksDBOperationUtils.registerKvStateInformation(\n                     this.kvStateInformation,\n                     this.nativeMetricMonitor,\n+                    this.db.getAccessMetric(),\n                     stateDesc.getName(),\n                     newRocksStateInfo);\n         }\n@@ -662,12 +666,12 @@ public void notifyCheckpointAborted(long checkpointId) throws Exception {\n \n         ttlCompactFiltersManager.configCompactFilter(stateDesc, newMetaInfo.getStateSerializer());\n \n-        return Tuple2.of(newRocksStateInfo.columnFamilyHandle, newMetaInfo);\n+        return Tuple2.of(newRocksStateInfo.columnFamilyHandleWrapper, newMetaInfo);\n     }\n \n     private <N, S extends State, SV>\n             RegisteredKeyValueStateBackendMetaInfo<N, SV> updateRestoredStateMetaInfo(\n-                    Tuple2<ColumnFamilyHandle, RegisteredKeyValueStateBackendMetaInfo<N, SV>>\n+                    Tuple2<ColumnFamilyHandleWrapper, RegisteredKeyValueStateBackendMetaInfo<N, SV>>\n                             oldStateInfo,\n                     StateDescriptor<S, SV> stateDesc,\n                     TypeSerializer<N> namespaceSerializer,\n@@ -722,7 +726,8 @@ public void notifyCheckpointAborted(long checkpointId) throws Exception {\n     @SuppressWarnings(\"unchecked\")\n     private <N, S extends State, SV> void migrateStateValues(\n             StateDescriptor<S, SV> stateDesc,\n-            Tuple2<ColumnFamilyHandle, RegisteredKeyValueStateBackendMetaInfo<N, SV>> stateMetaInfo)\n+            Tuple2<ColumnFamilyHandleWrapper, RegisteredKeyValueStateBackendMetaInfo<N, SV>>\n+                    stateMetaInfo)\n             throws Exception {\n \n         if (stateDesc.getType() == StateDescriptor.Type.MAP) {\n@@ -774,11 +779,16 @@ public void notifyCheckpointAborted(long checkpointId) throws Exception {\n         @SuppressWarnings(\"unchecked\")\n         AbstractRocksDBState<?, ?, SV> rocksDBState = (AbstractRocksDBState<?, ?, SV>) state;\n \n-        Snapshot rocksDBSnapshot = db.getSnapshot();\n+        Snapshot rocksDBSnapshot = db.getDb().getSnapshot();\n         try (RocksIteratorWrapper iterator =\n                         RocksDBOperationUtils.getRocksIterator(db, stateMetaInfo.f0, readOptions);\n                 RocksDBWriteBatchWrapper batchWriter =\n-                        new RocksDBWriteBatchWrapper(db, getWriteOptions(), getWriteBatchSize())) {\n+                        new RocksDBWriteBatchWrapper(\n+                                db,\n+                                stateMetaInfo.f0,\n+                                getWriteOptions(),\n+                                500,\n+                                getWriteBatchSize())) {\n             iterator.seekToFirst();\n \n             DataInputDeserializer serializedValueInput = new DataInputDeserializer();\n@@ -793,15 +803,15 @@ public void notifyCheckpointAborted(long checkpointId) throws Exception {\n                         stateMetaInfo.f1.getStateSerializer());\n \n                 batchWriter.put(\n-                        stateMetaInfo.f0,\n+                        stateMetaInfo.f0.getColumnFamilyHandle(),\n                         iterator.key(),\n                         migratedSerializedValueOutput.getCopyOfBuffer());\n \n                 migratedSerializedValueOutput.clear();\n                 iterator.next();\n             }\n         } finally {\n-            db.releaseSnapshot(rocksDBSnapshot);\n+            db.getDb().releaseSnapshot(rocksDBSnapshot);\n             rocksDBSnapshot.close();\n         }\n     }\n@@ -835,9 +845,10 @@ public void notifyCheckpointAborted(long checkpointId) throws Exception {\n                             stateDesc.getClass(), this.getClass());\n             throw new FlinkRuntimeException(message);\n         }\n-        Tuple2<ColumnFamilyHandle, RegisteredKeyValueStateBackendMetaInfo<N, SV>> registerResult =\n-                tryRegisterKvStateInformation(\n-                        stateDesc, namespaceSerializer, snapshotTransformFactory);\n+        Tuple2<ColumnFamilyHandleWrapper, RegisteredKeyValueStateBackendMetaInfo<N, SV>>\n+                registerResult =\n+                        tryRegisterKvStateInformation(\n+                                stateDesc, namespaceSerializer, snapshotTransformFactory);\n         return stateFactory.createState(stateDesc, registerResult, RocksDBKeyedStateBackend.this);\n     }\n \n@@ -855,7 +866,7 @@ public int numKeyValueStateEntries() {\n             // TODO maybe filterOrTransform only for k/v states\n             try (RocksIteratorWrapper rocksIterator =\n                     RocksDBOperationUtils.getRocksIterator(\n-                            db, metaInfo.columnFamilyHandle, readOptions)) {\n+                            db, metaInfo.columnFamilyHandleWrapper, readOptions)) {\n                 rocksIterator.seekToFirst();\n \n                 while (rocksIterator.isValid()) {\n@@ -881,25 +892,26 @@ public boolean isStateImmutableInStateBackend(CheckpointType checkpointType) {\n \n     /** Rocks DB specific information about the k/v states. */\n     public static class RocksDbKvStateInfo implements AutoCloseable {\n-        public final ColumnFamilyHandle columnFamilyHandle;\n+        public final ColumnFamilyHandleWrapper columnFamilyHandleWrapper;\n         public final RegisteredStateMetaInfoBase metaInfo;\n \n         public RocksDbKvStateInfo(\n-                ColumnFamilyHandle columnFamilyHandle, RegisteredStateMetaInfoBase metaInfo) {\n-            this.columnFamilyHandle = columnFamilyHandle;\n+                ColumnFamilyHandleWrapper columnFamilyHandleWrapper,\n+                RegisteredStateMetaInfoBase metaInfo) {\n+            this.columnFamilyHandleWrapper = columnFamilyHandleWrapper;\n             this.metaInfo = metaInfo;\n         }\n \n         @Override\n         public void close() throws Exception {\n-            this.columnFamilyHandle.close();\n+            this.columnFamilyHandleWrapper.close();\n         }\n     }\n \n     @VisibleForTesting\n     public void compactState(StateDescriptor<?, ?> stateDesc) throws RocksDBException {\n         RocksDbKvStateInfo kvStateInfo = kvStateInformation.get(stateDesc.getName());\n-        db.compactRange(kvStateInfo.columnFamilyHandle);\n+        db.getDb().compactRange(kvStateInfo.columnFamilyHandleWrapper.getColumnFamilyHandle());\n     }\n \n     @Nonnegative"
  },
  {
    "sha": "9d7435678f66bf1d311b43b3b4755801f7d8d431",
    "filename": "flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBKeyedStateBackendBuilder.java",
    "status": "modified",
    "additions": 37,
    "deletions": 16,
    "changes": 53,
    "blob_url": "https://github.com/apache/flink/blob/c3d268b3dfcb4037f99d148b70e005832dd00c44/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBKeyedStateBackendBuilder.java",
    "raw_url": "https://github.com/apache/flink/raw/c3d268b3dfcb4037f99d148b70e005832dd00c44/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBKeyedStateBackendBuilder.java",
    "contents_url": "https://api.github.com/repos/apache/flink/contents/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBKeyedStateBackendBuilder.java?ref=c3d268b3dfcb4037f99d148b70e005832dd00c44",
    "patch": "@@ -113,6 +113,7 @@\n     private boolean enableIncrementalCheckpointing;\n \n     private RocksDBNativeMetricOptions nativeMetricOptions;\n+    private RocksDBAccessMetric.Builder accessMetricBuilder;\n     private int numberOfTransferingThreads;\n     private long writeBatchSize =\n             RocksDBConfigurableOptions.WRITE_BATCH_SIZE.defaultValue().getBytes();\n@@ -162,6 +163,7 @@ public RocksDBKeyedStateBackendBuilder(\n         this.metricGroup = metricGroup;\n         this.enableIncrementalCheckpointing = false;\n         this.nativeMetricOptions = new RocksDBNativeMetricOptions();\n+        this.accessMetricBuilder = new RocksDBAccessMetric.Builder();\n         this.numberOfTransferingThreads =\n                 RocksDBOptions.CHECKPOINT_TRANSFER_THREAD_NUM.defaultValue();\n     }\n@@ -221,6 +223,12 @@ public RocksDBKeyedStateBackendBuilder(\n         return this;\n     }\n \n+    RocksDBKeyedStateBackendBuilder<K> setAccessMetricBuilder(\n+            RocksDBAccessMetric.Builder accessMetricBuilder) {\n+        this.accessMetricBuilder = accessMetricBuilder;\n+        return this;\n+    }\n+\n     RocksDBKeyedStateBackendBuilder<K> setNumberOfTransferingThreads(\n             int numberOfTransferingThreads) {\n         this.numberOfTransferingThreads = numberOfTransferingThreads;\n@@ -246,15 +254,15 @@ private static void checkAndCreateDirectory(File directory) throws IOException {\n \n     @Override\n     public RocksDBKeyedStateBackend<K> build() throws BackendBuildingException {\n-        RocksDBWriteBatchWrapper writeBatchWrapper = null;\n+        RocksDBWriteBatchWrapper timerWriteBatchWrapper = null;\n         ColumnFamilyHandle defaultColumnFamilyHandle = null;\n         RocksDBNativeMetricMonitor nativeMetricMonitor = null;\n         CloseableRegistry cancelStreamRegistryForBackend = new CloseableRegistry();\n         LinkedHashMap<String, RocksDBKeyedStateBackend.RocksDbKvStateInfo> kvStateInformation =\n                 new LinkedHashMap<>();\n         LinkedHashMap<String, HeapPriorityQueueSnapshotRestoreWrapper<?>> registeredPQStates =\n                 new LinkedHashMap<>();\n-        RocksDB db = null;\n+        RocksDBWrapper db = null;\n         RocksDBRestoreOperation restoreOperation = null;\n         RocksDbTtlCompactFiltersManager ttlCompactFiltersManager =\n                 new RocksDbTtlCompactFiltersManager(ttlTimeProvider);\n@@ -274,12 +282,13 @@ private static void checkAndCreateDirectory(File directory) throws IOException {\n             SortedMap<Long, Set<StateHandleID>> materializedSstFiles = new TreeMap<>();\n             long lastCompletedCheckpointId = -1L;\n             if (injectedTestDB != null) {\n-                db = injectedTestDB;\n+                accessMetricBuilder.setMetricGroup(metricGroup);\n+                db = new RocksDBWrapper(injectedTestDB, accessMetricBuilder);\n                 defaultColumnFamilyHandle = injectedDefaultColumnFamilyHandle;\n                 nativeMetricMonitor =\n                         nativeMetricOptions.isEnabled()\n                                 ? new RocksDBNativeMetricMonitor(\n-                                        nativeMetricOptions, metricGroup, db)\n+                                        nativeMetricOptions, metricGroup, db.getDb())\n                                 : null;\n             } else {\n                 prepareDirectories();\n@@ -291,7 +300,7 @@ private static void checkAndCreateDirectory(File directory) throws IOException {\n                                 registeredPQStates,\n                                 ttlCompactFiltersManager);\n                 RocksDBRestoreResult restoreResult = restoreOperation.restore();\n-                db = restoreResult.getDb();\n+                db = restoreResult.getDBWrapper();\n                 defaultColumnFamilyHandle = restoreResult.getDefaultColumnFamilyHandle();\n                 nativeMetricMonitor = restoreResult.getNativeMetricMonitor();\n                 if (restoreOperation instanceof RocksDBIncrementalRestoreOperation) {\n@@ -301,9 +310,13 @@ private static void checkAndCreateDirectory(File directory) throws IOException {\n                 }\n             }\n \n-            writeBatchWrapper =\n+            timerWriteBatchWrapper =\n                     new RocksDBWriteBatchWrapper(\n-                            db, optionsContainer.getWriteOptions(), writeBatchSize);\n+                            db,\n+                            null,\n+                            optionsContainer.getWriteOptions(),\n+                            RocksDBWriteBatchWrapper.DEFAULT_CAPACITY,\n+                            writeBatchSize);\n \n             // it is important that we only create the key builder after the restore, and not\n             // before;\n@@ -333,23 +346,25 @@ private static void checkAndCreateDirectory(File directory) throws IOException {\n                             keyGroupPrefixBytes,\n                             kvStateInformation,\n                             db,\n-                            writeBatchWrapper,\n-                            nativeMetricMonitor);\n+                            timerWriteBatchWrapper,\n+                            nativeMetricMonitor,\n+                            db.getAccessMetric());\n         } catch (Throwable e) {\n             // Do clean up\n             List<ColumnFamilyOptions> columnFamilyOptions =\n                     new ArrayList<>(kvStateInformation.values().size());\n             IOUtils.closeQuietly(cancelStreamRegistryForBackend);\n-            IOUtils.closeQuietly(writeBatchWrapper);\n+            IOUtils.closeQuietly(timerWriteBatchWrapper);\n             RocksDBOperationUtils.addColumnFamilyOptionsToCloseLater(\n                     columnFamilyOptions, defaultColumnFamilyHandle);\n             IOUtils.closeQuietly(defaultColumnFamilyHandle);\n             IOUtils.closeQuietly(nativeMetricMonitor);\n             for (RocksDBKeyedStateBackend.RocksDbKvStateInfo kvStateInfo :\n                     kvStateInformation.values()) {\n                 RocksDBOperationUtils.addColumnFamilyOptionsToCloseLater(\n-                        columnFamilyOptions, kvStateInfo.columnFamilyHandle);\n-                IOUtils.closeQuietly(kvStateInfo.columnFamilyHandle);\n+                        columnFamilyOptions,\n+                        kvStateInfo.columnFamilyHandleWrapper.getColumnFamilyHandle());\n+                IOUtils.closeQuietly(kvStateInfo.columnFamilyHandleWrapper);\n             }\n             IOUtils.closeQuietly(db);\n             // it's possible that db has been initialized but later restore steps failed\n@@ -392,7 +407,7 @@ private static void checkAndCreateDirectory(File directory) throws IOException {\n                 this.keyGroupCompressionDecorator,\n                 rocksDBResourceGuard,\n                 checkpointStrategy,\n-                writeBatchWrapper,\n+                timerWriteBatchWrapper,\n                 defaultColumnFamilyHandle,\n                 nativeMetricMonitor,\n                 sharedRocksKeyBuilder,\n@@ -417,6 +432,7 @@ private RocksDBRestoreOperation getRocksDBRestoreOperation(\n                     columnFamilyOptionsFactory,\n                     nativeMetricOptions,\n                     metricGroup,\n+                    accessMetricBuilder,\n                     ttlCompactFiltersManager,\n                     optionsContainer.getWriteBufferManagerCapacity());\n         }\n@@ -437,6 +453,7 @@ private RocksDBRestoreOperation getRocksDBRestoreOperation(\n                     columnFamilyOptionsFactory,\n                     nativeMetricOptions,\n                     metricGroup,\n+                    accessMetricBuilder,\n                     restoreStateHandles,\n                     ttlCompactFiltersManager,\n                     writeBatchSize,\n@@ -456,6 +473,7 @@ private RocksDBRestoreOperation getRocksDBRestoreOperation(\n                     columnFamilyOptionsFactory,\n                     nativeMetricOptions,\n                     metricGroup,\n+                    accessMetricBuilder,\n                     restoreStateHandles,\n                     ttlCompactFiltersManager,\n                     writeBatchSize,\n@@ -471,6 +489,7 @@ private RocksDBRestoreOperation getRocksDBRestoreOperation(\n                     columnFamilyOptionsFactory,\n                     nativeMetricOptions,\n                     metricGroup,\n+                    accessMetricBuilder,\n                     restoreStateHandles,\n                     ttlCompactFiltersManager,\n                     writeBatchSize,\n@@ -484,7 +503,7 @@ private RocksDBRestoreOperation getRocksDBRestoreOperation(\n             LinkedHashMap<String, RocksDBKeyedStateBackend.RocksDbKvStateInfo> kvStateInformation,\n             LinkedHashMap<String, HeapPriorityQueueSnapshotRestoreWrapper<?>> registeredPQStates,\n             int keyGroupPrefixBytes,\n-            RocksDB db,\n+            RocksDBWrapper db,\n             UUID backendUID,\n             SortedMap<Long, Set<StateHandleID>> materializedSstFiles,\n             long lastCompletedCheckpointId) {\n@@ -524,9 +543,10 @@ private RocksDBRestoreOperation getRocksDBRestoreOperation(\n     private PriorityQueueSetFactory initPriorityQueueFactory(\n             int keyGroupPrefixBytes,\n             Map<String, RocksDBKeyedStateBackend.RocksDbKvStateInfo> kvStateInformation,\n-            RocksDB db,\n+            RocksDBWrapper db,\n             RocksDBWriteBatchWrapper writeBatchWrapper,\n-            RocksDBNativeMetricMonitor nativeMetricMonitor) {\n+            RocksDBNativeMetricMonitor nativeMetricMonitor,\n+            RocksDBAccessMetric accessMetric) {\n         PriorityQueueSetFactory priorityQueueFactory;\n         switch (priorityQueueStateType) {\n             case HEAP:\n@@ -543,6 +563,7 @@ private PriorityQueueSetFactory initPriorityQueueFactory(\n                                 optionsContainer.getReadOptions(),\n                                 writeBatchWrapper,\n                                 nativeMetricMonitor,\n+                                accessMetric,\n                                 columnFamilyOptionsFactory,\n                                 optionsContainer.getWriteBufferManagerCapacity());\n                 break;"
  },
  {
    "sha": "d7a3d0286b83bd3d29ccd0670291dae173cffdf1",
    "filename": "flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBListState.java",
    "status": "modified",
    "additions": 2,
    "deletions": 3,
    "changes": 5,
    "blob_url": "https://github.com/apache/flink/blob/c3d268b3dfcb4037f99d148b70e005832dd00c44/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBListState.java",
    "raw_url": "https://github.com/apache/flink/raw/c3d268b3dfcb4037f99d148b70e005832dd00c44/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBListState.java",
    "contents_url": "https://api.github.com/repos/apache/flink/contents/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBListState.java?ref=c3d268b3dfcb4037f99d148b70e005832dd00c44",
    "patch": "@@ -34,7 +34,6 @@\n import org.apache.flink.util.Preconditions;\n import org.apache.flink.util.StateMigrationException;\n \n-import org.rocksdb.ColumnFamilyHandle;\n import org.rocksdb.RocksDBException;\n \n import javax.annotation.Nullable;\n@@ -79,7 +78,7 @@\n      * @param backend The backend for which this state is bind to.\n      */\n     private RocksDBListState(\n-            ColumnFamilyHandle columnFamily,\n+            ColumnFamilyHandleWrapper columnFamily,\n             TypeSerializer<N> namespaceSerializer,\n             TypeSerializer<List<V>> valueSerializer,\n             List<V> defaultValue,\n@@ -245,7 +244,7 @@ public void migrateSerializedValue(\n     @SuppressWarnings(\"unchecked\")\n     static <E, K, N, SV, S extends State, IS extends S> IS create(\n             StateDescriptor<S, SV> stateDesc,\n-            Tuple2<ColumnFamilyHandle, RegisteredKeyValueStateBackendMetaInfo<N, SV>>\n+            Tuple2<ColumnFamilyHandleWrapper, RegisteredKeyValueStateBackendMetaInfo<N, SV>>\n                     registerResult,\n             RocksDBKeyedStateBackend<K> backend) {\n         return (IS)"
  },
  {
    "sha": "fe7d225f075365d6b2f285cc93edcc49fc267ef7",
    "filename": "flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBMapState.java",
    "status": "modified",
    "additions": 15,
    "deletions": 11,
    "changes": 26,
    "blob_url": "https://github.com/apache/flink/blob/c3d268b3dfcb4037f99d148b70e005832dd00c44/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBMapState.java",
    "raw_url": "https://github.com/apache/flink/raw/c3d268b3dfcb4037f99d148b70e005832dd00c44/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBMapState.java",
    "contents_url": "https://api.github.com/repos/apache/flink/contents/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBMapState.java?ref=c3d268b3dfcb4037f99d148b70e005832dd00c44",
    "patch": "@@ -36,8 +36,6 @@\n import org.apache.flink.util.Preconditions;\n import org.apache.flink.util.StateMigrationException;\n \n-import org.rocksdb.ColumnFamilyHandle;\n-import org.rocksdb.RocksDB;\n import org.rocksdb.RocksDBException;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n@@ -82,7 +80,7 @@\n      * @param backend The backend for which this state is bind to.\n      */\n     private RocksDBMapState(\n-            ColumnFamilyHandle columnFamily,\n+            ColumnFamilyHandleWrapper columnFamily,\n             TypeSerializer<N> namespaceSerializer,\n             TypeSerializer<Map<UK, UV>> valueSerializer,\n             Map<UK, UV> defaultValue,\n@@ -146,14 +144,18 @@ public void putAll(Map<UK, UV> map) throws IOException, RocksDBException {\n \n         try (RocksDBWriteBatchWrapper writeBatchWrapper =\n                 new RocksDBWriteBatchWrapper(\n-                        backend.db, writeOptions, backend.getWriteBatchSize())) {\n+                        backend.db,\n+                        columnFamily,\n+                        writeOptions,\n+                        RocksDBWriteBatchWrapper.DEFAULT_CAPACITY,\n+                        backend.getWriteBatchSize())) {\n             for (Map.Entry<UK, UV> entry : map.entrySet()) {\n                 byte[] rawKeyBytes =\n                         serializeCurrentKeyWithGroupAndNamespacePlusUserKey(\n                                 entry.getKey(), userKeySerializer);\n                 byte[] rawValueBytes =\n                         serializeValueNullSensitive(entry.getValue(), userValueSerializer);\n-                writeBatchWrapper.put(columnFamily, rawKeyBytes, rawValueBytes);\n+                writeBatchWrapper.put(rawKeyBytes, rawValueBytes);\n             }\n         }\n     }\n@@ -285,7 +287,9 @@ public void clear() {\n                     RocksDBWriteBatchWrapper rocksDBWriteBatchWrapper =\n                             new RocksDBWriteBatchWrapper(\n                                     backend.db,\n+                                    columnFamily,\n                                     backend.getWriteOptions(),\n+                                    RocksDBWriteBatchWrapper.DEFAULT_CAPACITY,\n                                     backend.getWriteBatchSize())) {\n \n                 final byte[] keyPrefixBytes = serializeCurrentKeyWithGroupAndNamespace();\n@@ -294,7 +298,7 @@ public void clear() {\n                 while (iterator.isValid()) {\n                     byte[] keyBytes = iterator.key();\n                     if (startWithKeyPrefix(keyPrefixBytes, keyBytes)) {\n-                        rocksDBWriteBatchWrapper.remove(columnFamily, keyBytes);\n+                        rocksDBWriteBatchWrapper.remove(keyBytes);\n                     } else {\n                         break;\n                     }\n@@ -414,7 +418,7 @@ private boolean startWithKeyPrefix(byte[] keyPrefixBytes, byte[] rawKeyBytes) {\n \n     /** A map entry in RocksDBMapState. */\n     private class RocksDBMapEntry implements Map.Entry<UK, UV> {\n-        private final RocksDB db;\n+        private final RocksDBWrapper db;\n \n         /**\n          * The raw bytes of the key stored in RocksDB. Each user key is stored in RocksDB with the\n@@ -446,7 +450,7 @@ private boolean startWithKeyPrefix(byte[] keyPrefixBytes, byte[] rawKeyBytes) {\n         private final DataInputDeserializer dataInputView;\n \n         RocksDBMapEntry(\n-                @Nonnull final RocksDB db,\n+                @Nonnull final RocksDBWrapper db,\n                 @Nonnegative final int userKeyOffset,\n                 @Nonnull final byte[] rawKeyBytes,\n                 @Nonnull final byte[] rawValueBytes,\n@@ -537,7 +541,7 @@ public UV setValue(UV value) {\n         private static final int CACHE_SIZE_LIMIT = 128;\n \n         /** The db where data resides. */\n-        private final RocksDB db;\n+        private final RocksDBWrapper db;\n \n         /**\n          * The prefix bytes of the key being accessed. All entries under the same key have the same\n@@ -567,7 +571,7 @@ public UV setValue(UV value) {\n         private final DataInputDeserializer dataInputView;\n \n         RocksDBMapIterator(\n-                final RocksDB db,\n+                final RocksDBWrapper db,\n                 final byte[] keyPrefixBytes,\n                 final TypeSerializer<UK> keySerializer,\n                 final TypeSerializer<UV> valueSerializer,\n@@ -684,7 +688,7 @@ private void loadCache() {\n     @SuppressWarnings(\"unchecked\")\n     static <UK, UV, K, N, SV, S extends State, IS extends S> IS create(\n             StateDescriptor<S, SV> stateDesc,\n-            Tuple2<ColumnFamilyHandle, RegisteredKeyValueStateBackendMetaInfo<N, SV>>\n+            Tuple2<ColumnFamilyHandleWrapper, RegisteredKeyValueStateBackendMetaInfo<N, SV>>\n                     registerResult,\n             RocksDBKeyedStateBackend<K> backend) {\n         return (IS)"
  },
  {
    "sha": "ae2ae993497d29ebe1ac6d92235d9d00926061ec",
    "filename": "flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBOperationUtils.java",
    "status": "modified",
    "additions": 26,
    "deletions": 5,
    "changes": 31,
    "blob_url": "https://github.com/apache/flink/blob/c3d268b3dfcb4037f99d148b70e005832dd00c44/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBOperationUtils.java",
    "raw_url": "https://github.com/apache/flink/raw/c3d268b3dfcb4037f99d148b70e005832dd00c44/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBOperationUtils.java",
    "contents_url": "https://api.github.com/repos/apache/flink/contents/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBOperationUtils.java?ref=c3d268b3dfcb4037f99d148b70e005832dd00c44",
    "patch": "@@ -99,9 +99,22 @@ public static RocksDB openDB(\n         return dbRef;\n     }\n \n-    public static RocksIteratorWrapper getRocksIterator(\n+    public static RocksIteratorWrapper getRocksIteratorWithoutAccessMetric(\n             RocksDB db, ColumnFamilyHandle columnFamilyHandle, ReadOptions readOptions) {\n-        return new RocksIteratorWrapper(db.newIterator(columnFamilyHandle, readOptions));\n+        return new RocksIteratorWrapper(\n+                db.newIterator(columnFamilyHandle, readOptions), null, null);\n+    }\n+\n+    public static RocksIteratorWrapper getRocksIterator(\n+            RocksDBWrapper db,\n+            ColumnFamilyHandleWrapper columnFamilyHandleWrapper,\n+            ReadOptions readOptions) {\n+        return new RocksIteratorWrapper(\n+                db.getDb()\n+                        .newIterator(\n+                                columnFamilyHandleWrapper.getColumnFamilyHandle(), readOptions),\n+                db.getAccessMetric(),\n+                columnFamilyHandleWrapper);\n     }\n \n     /**\n@@ -117,13 +130,21 @@ public static ReadOptions createTotalOrderSeekReadOptions() {\n     public static void registerKvStateInformation(\n             Map<String, RocksDBKeyedStateBackend.RocksDbKvStateInfo> kvStateInformation,\n             RocksDBNativeMetricMonitor nativeMetricMonitor,\n+            RocksDBAccessMetric accessMetric,\n             String columnFamilyName,\n             RocksDBKeyedStateBackend.RocksDbKvStateInfo registeredColumn) {\n \n         kvStateInformation.put(columnFamilyName, registeredColumn);\n         if (nativeMetricMonitor != null) {\n             nativeMetricMonitor.registerColumnFamily(\n-                    columnFamilyName, registeredColumn.columnFamilyHandle);\n+                    columnFamilyName,\n+                    registeredColumn.columnFamilyHandleWrapper.getColumnFamilyHandle());\n+        }\n+\n+        if (accessMetric != null) {\n+            accessMetric.registerColumnFamily(\n+                    columnFamilyName,\n+                    registeredColumn.columnFamilyHandleWrapper.getColumnFamilyHandle());\n         }\n     }\n \n@@ -235,10 +256,10 @@ public static ColumnFamilyOptions createColumnFamilyOptions(\n                 .setMergeOperatorName(MERGE_OPERATOR_NAME);\n     }\n \n-    private static ColumnFamilyHandle createColumnFamily(\n+    private static ColumnFamilyHandleWrapper createColumnFamily(\n             ColumnFamilyDescriptor columnDescriptor, RocksDB db) {\n         try {\n-            return db.createColumnFamily(columnDescriptor);\n+            return new ColumnFamilyHandleWrapper(db.createColumnFamily(columnDescriptor));\n         } catch (RocksDBException e) {\n             IOUtils.closeQuietly(columnDescriptor.getOptions());\n             throw new FlinkRuntimeException(\"Error creating ColumnFamilyHandle.\", e);"
  },
  {
    "sha": "4896b5e2585f4e928dccd2fa41e05860a6ffbed1",
    "filename": "flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBOptions.java",
    "status": "modified",
    "additions": 31,
    "deletions": 0,
    "changes": 31,
    "blob_url": "https://github.com/apache/flink/blob/c3d268b3dfcb4037f99d148b70e005832dd00c44/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBOptions.java",
    "raw_url": "https://github.com/apache/flink/raw/c3d268b3dfcb4037f99d148b70e005832dd00c44/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBOptions.java",
    "contents_url": "https://api.github.com/repos/apache/flink/contents/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBOptions.java?ref=c3d268b3dfcb4037f99d148b70e005832dd00c44",
    "patch": "@@ -19,6 +19,7 @@\n package org.apache.flink.contrib.streaming.state;\n \n import org.apache.flink.annotation.docs.Documentation;\n+import org.apache.flink.api.common.time.Time;\n import org.apache.flink.configuration.ConfigOption;\n import org.apache.flink.configuration.ConfigOptions;\n import org.apache.flink.configuration.MemorySize;\n@@ -149,4 +150,34 @@\n                                             + \"the partitions that are required to perform the index/filter query. \"\n                                             + \"This option only has an effect when '%s' or '%s' are configured.\",\n                                     USE_MANAGED_MEMORY.key(), FIX_PER_SLOT_MEMORY_SIZE.key()));\n+\n+    @Documentation.Section(Documentation.Sections.STATE_BACKEND_ROCKSDB)\n+    public static final ConfigOption<Boolean> LATENCY_TRACK_ENABLED =\n+            ConfigOptions.key(\"state.backend.rocksdb.latency-track-enabled\")\n+                    .booleanType()\n+                    .defaultValue(false)\n+                    .withDescription(\n+                            \"Whether to track latency of RocksDB actions, e.g put/get/delete/seek/next.\");\n+\n+    @Documentation.Section(Documentation.Sections.STATE_BACKEND_ROCKSDB)\n+    public static final ConfigOption<Integer> LATENCY_TRACK_SAMPLE_INTERVAL =\n+            ConfigOptions.key(\"state.backend.rocksdb.latency-track-sample-interval\")\n+                    .intType()\n+                    .defaultValue(100)\n+                    .withDescription(\n+                            String.format(\n+                                    \"The sample interval of latency track once '%s' is enabled. \"\n+                                            + \"The default value is 100, which means we would track the latency every 100 access requests.\",\n+                                    LATENCY_TRACK_ENABLED.key()));\n+\n+    @Documentation.Section(Documentation.Sections.STATE_BACKEND_ROCKSDB)\n+    public static final ConfigOption<Long> LATENCY_TRACK_SLIDING_WINDOW =\n+            ConfigOptions.key(\"state.backend.rocksdb.latency-track-sliding-window\")\n+                    .longType()\n+                    .defaultValue(Time.seconds(10).toMilliseconds())\n+                    .withDescription(\n+                            String.format(\n+                                    \"The sliding window of histogram to record the latency once '%s' is enabled. \"\n+                                            + \"The default value is 10 seconds, which means we stores only the measurements made in the last 10 seconds.\",\n+                                    LATENCY_TRACK_ENABLED.key()));\n }"
  },
  {
    "sha": "0058d22a99a7d7891d8d86da63378bb5a2b7f810",
    "filename": "flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBPriorityQueueSetFactory.java",
    "status": "modified",
    "additions": 11,
    "deletions": 8,
    "changes": 19,
    "blob_url": "https://github.com/apache/flink/blob/c3d268b3dfcb4037f99d148b70e005832dd00c44/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBPriorityQueueSetFactory.java",
    "raw_url": "https://github.com/apache/flink/raw/c3d268b3dfcb4037f99d148b70e005832dd00c44/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBPriorityQueueSetFactory.java",
    "contents_url": "https://api.github.com/repos/apache/flink/contents/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBPriorityQueueSetFactory.java?ref=c3d268b3dfcb4037f99d148b70e005832dd00c44",
    "patch": "@@ -35,10 +35,8 @@\n import org.apache.flink.util.FlinkRuntimeException;\n import org.apache.flink.util.StateMigrationException;\n \n-import org.rocksdb.ColumnFamilyHandle;\n import org.rocksdb.ColumnFamilyOptions;\n import org.rocksdb.ReadOptions;\n-import org.rocksdb.RocksDB;\n \n import javax.annotation.Nonnull;\n \n@@ -64,10 +62,11 @@\n     private final int keyGroupPrefixBytes;\n     private final int numberOfKeyGroups;\n     private final Map<String, RocksDBKeyedStateBackend.RocksDbKvStateInfo> kvStateInformation;\n-    private final RocksDB db;\n+    private final RocksDBWrapper db;\n     private final ReadOptions readOptions;\n     private final RocksDBWriteBatchWrapper writeBatchWrapper;\n     private final RocksDBNativeMetricMonitor nativeMetricMonitor;\n+    private final RocksDBAccessMetric accessMetric;\n     private final Function<String, ColumnFamilyOptions> columnFamilyOptionsFactory;\n     private final Long writeBufferManagerCapacity;\n \n@@ -76,10 +75,11 @@\n             int keyGroupPrefixBytes,\n             int numberOfKeyGroups,\n             Map<String, RocksDBKeyedStateBackend.RocksDbKvStateInfo> kvStateInformation,\n-            RocksDB db,\n+            RocksDBWrapper db,\n             ReadOptions readOptions,\n             RocksDBWriteBatchWrapper writeBatchWrapper,\n             RocksDBNativeMetricMonitor nativeMetricMonitor,\n+            RocksDBAccessMetric accessMetric,\n             Function<String, ColumnFamilyOptions> columnFamilyOptionsFactory,\n             Long writeBufferManagerCapacity) {\n         this.keyGroupRange = keyGroupRange;\n@@ -90,6 +90,7 @@\n         this.readOptions = readOptions;\n         this.writeBatchWrapper = writeBatchWrapper;\n         this.nativeMetricMonitor = nativeMetricMonitor;\n+        this.accessMetric = accessMetric;\n         this.columnFamilyOptionsFactory = columnFamilyOptionsFactory;\n         this.sharedElementOutView = new DataOutputSerializer(128);\n         this.sharedElementInView = new DataInputDeserializer();\n@@ -106,7 +107,8 @@\n         final RocksDBKeyedStateBackend.RocksDbKvStateInfo stateCFHandle =\n                 tryRegisterPriorityQueueMetaInfo(stateName, byteOrderedElementSerializer);\n \n-        final ColumnFamilyHandle columnFamilyHandle = stateCFHandle.columnFamilyHandle;\n+        final ColumnFamilyHandleWrapper columnFamilyHandle =\n+                stateCFHandle.columnFamilyHandleWrapper;\n \n         return new KeyGroupPartitionedPriorityQueue<>(\n                 KeyExtractorFunction.forKeyedObjects(),\n@@ -127,6 +129,7 @@\n                                 keyGroupPrefixBytes,\n                                 db,\n                                 readOptions,\n+                                accessMetric,\n                                 columnFamilyHandle,\n                                 byteOrderedElementSerializer,\n                                 sharedElementOutView,\n@@ -154,12 +157,12 @@\n             stateInfo =\n                     RocksDBOperationUtils.createStateInfo(\n                             metaInfo,\n-                            db,\n+                            db.getDb(),\n                             columnFamilyOptionsFactory,\n                             null,\n                             writeBufferManagerCapacity);\n             RocksDBOperationUtils.registerKvStateInformation(\n-                    kvStateInformation, nativeMetricMonitor, stateName, stateInfo);\n+                    kvStateInformation, nativeMetricMonitor, accessMetric, stateName, stateInfo);\n         } else {\n             // TODO we implement the simple way of supporting the current functionality, mimicking\n             // keyed state\n@@ -190,7 +193,7 @@\n                 // update meta info with new serializer\n                 stateInfo =\n                         new RocksDBKeyedStateBackend.RocksDbKvStateInfo(\n-                                stateInfo.columnFamilyHandle,\n+                                stateInfo.columnFamilyHandleWrapper,\n                                 new RegisteredPriorityQueueStateBackendMetaInfo<>(\n                                         stateName, byteOrderedElementSerializer));\n                 kvStateInformation.put(stateName, stateInfo);"
  },
  {
    "sha": "ba8dcf6928ea5735bfd0114816e64c2787b49431",
    "filename": "flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBReducingState.java",
    "status": "modified",
    "additions": 2,
    "deletions": 4,
    "changes": 6,
    "blob_url": "https://github.com/apache/flink/blob/c3d268b3dfcb4037f99d148b70e005832dd00c44/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBReducingState.java",
    "raw_url": "https://github.com/apache/flink/raw/c3d268b3dfcb4037f99d148b70e005832dd00c44/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBReducingState.java",
    "contents_url": "https://api.github.com/repos/apache/flink/contents/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBReducingState.java?ref=c3d268b3dfcb4037f99d148b70e005832dd00c44",
    "patch": "@@ -29,8 +29,6 @@\n import org.apache.flink.runtime.state.internal.InternalReducingState;\n import org.apache.flink.util.FlinkRuntimeException;\n \n-import org.rocksdb.ColumnFamilyHandle;\n-\n import java.util.Collection;\n \n /**\n@@ -57,7 +55,7 @@\n      * @param backend The backend for which this state is bind to.\n      */\n     private RocksDBReducingState(\n-            ColumnFamilyHandle columnFamily,\n+            ColumnFamilyHandleWrapper columnFamily,\n             TypeSerializer<N> namespaceSerializer,\n             TypeSerializer<V> valueSerializer,\n             V defaultValue,\n@@ -157,7 +155,7 @@ public void mergeNamespaces(N target, Collection<N> sources) {\n     @SuppressWarnings(\"unchecked\")\n     static <K, N, SV, S extends State, IS extends S> IS create(\n             StateDescriptor<S, SV> stateDesc,\n-            Tuple2<ColumnFamilyHandle, RegisteredKeyValueStateBackendMetaInfo<N, SV>>\n+            Tuple2<ColumnFamilyHandleWrapper, RegisteredKeyValueStateBackendMetaInfo<N, SV>>\n                     registerResult,\n             RocksDBKeyedStateBackend<K> backend) {\n         return (IS)"
  },
  {
    "sha": "21234d17346ac5f3ab51bdd2fd3ecb3c6c51ec9d",
    "filename": "flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBValueState.java",
    "status": "modified",
    "additions": 2,
    "deletions": 3,
    "changes": 5,
    "blob_url": "https://github.com/apache/flink/blob/c3d268b3dfcb4037f99d148b70e005832dd00c44/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBValueState.java",
    "raw_url": "https://github.com/apache/flink/raw/c3d268b3dfcb4037f99d148b70e005832dd00c44/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBValueState.java",
    "contents_url": "https://api.github.com/repos/apache/flink/contents/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBValueState.java?ref=c3d268b3dfcb4037f99d148b70e005832dd00c44",
    "patch": "@@ -27,7 +27,6 @@\n import org.apache.flink.runtime.state.internal.InternalValueState;\n import org.apache.flink.util.FlinkRuntimeException;\n \n-import org.rocksdb.ColumnFamilyHandle;\n import org.rocksdb.RocksDBException;\n \n import java.io.IOException;\n@@ -52,7 +51,7 @@\n      * @param backend The backend for which this state is bind to.\n      */\n     private RocksDBValueState(\n-            ColumnFamilyHandle columnFamily,\n+            ColumnFamilyHandleWrapper columnFamily,\n             TypeSerializer<N> namespaceSerializer,\n             TypeSerializer<V> valueSerializer,\n             V defaultValue,\n@@ -113,7 +112,7 @@ public void update(V value) {\n     @SuppressWarnings(\"unchecked\")\n     static <K, N, SV, S extends State, IS extends S> IS create(\n             StateDescriptor<S, SV> stateDesc,\n-            Tuple2<ColumnFamilyHandle, RegisteredKeyValueStateBackendMetaInfo<N, SV>>\n+            Tuple2<ColumnFamilyHandleWrapper, RegisteredKeyValueStateBackendMetaInfo<N, SV>>\n                     registerResult,\n             RocksDBKeyedStateBackend<K> backend) {\n         return (IS)"
  },
  {
    "sha": "b872fd33a3a996efdbbcb1dc566d71c0d25b9185",
    "filename": "flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBWrapper.java",
    "status": "added",
    "additions": 265,
    "deletions": 0,
    "changes": 265,
    "blob_url": "https://github.com/apache/flink/blob/c3d268b3dfcb4037f99d148b70e005832dd00c44/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBWrapper.java",
    "raw_url": "https://github.com/apache/flink/raw/c3d268b3dfcb4037f99d148b70e005832dd00c44/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBWrapper.java",
    "contents_url": "https://api.github.com/repos/apache/flink/contents/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBWrapper.java?ref=c3d268b3dfcb4037f99d148b70e005832dd00c44",
    "patch": "@@ -0,0 +1,265 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.contrib.streaming.state;\n+\n+import org.rocksdb.ColumnFamilyDescriptor;\n+import org.rocksdb.ColumnFamilyHandle;\n+import org.rocksdb.RocksDB;\n+import org.rocksdb.RocksDBException;\n+import org.rocksdb.WriteBatch;\n+import org.rocksdb.WriteOptions;\n+\n+import javax.annotation.Nullable;\n+\n+/** Wrapper of {@link RocksDB} and {@link RocksDBAccessMetric}. */\n+public class RocksDBWrapper implements AutoCloseable {\n+    /**\n+     * Our RocksDB database, this is used to store state. The different k/v states that we have will\n+     * have their own RocksDB instance and columnFamilyHandle.\n+     */\n+    private final RocksDB db;\n+\n+    @Nullable private final RocksDBAccessMetric accessMetric;\n+\n+    private final boolean trackLatencyEnabled;\n+\n+    public RocksDBWrapper(RocksDB db) {\n+        this(db, null);\n+    }\n+\n+    public RocksDBWrapper(RocksDB db, @Nullable RocksDBAccessMetric.Builder accessMetricBuilder) {\n+        this.db = db;\n+        this.accessMetric = accessMetricBuilder != null ? accessMetricBuilder.build() : null;\n+        this.trackLatencyEnabled = accessMetric != null;\n+    }\n+\n+    public RocksDB getDb() {\n+        return db;\n+    }\n+\n+    public RocksDBAccessMetric getAccessMetric() {\n+        return accessMetric;\n+    }\n+\n+    public ColumnFamilyHandle createColumnFamily(ColumnFamilyDescriptor columnFamilyDescriptor)\n+            throws RocksDBException {\n+        return db.createColumnFamily(columnFamilyDescriptor);\n+    }\n+\n+    public void put(\n+            final ColumnFamilyHandleWrapper columnFamilyHandle,\n+            final WriteOptions writeOpt,\n+            final byte[] key,\n+            final byte[] value)\n+            throws RocksDBException {\n+        if (trackLatencyEnabled) {\n+            putAndUpdateMetric(columnFamilyHandle, writeOpt, key, value);\n+        } else {\n+            originalPut(columnFamilyHandle.getColumnFamilyHandle(), writeOpt, key, value);\n+        }\n+    }\n+\n+    /**\n+     * Since {@code WriteBatch} might contain several column families only during restore. We\n+     * currently does not track latency metrics for that part operations if no column family handle\n+     * provided.\n+     */\n+    public void write(\n+            @Nullable final ColumnFamilyHandleWrapper columnFamilyHandle,\n+            final WriteOptions writeOpt,\n+            final WriteBatch writeBatch)\n+            throws RocksDBException {\n+        if (columnFamilyHandle == null) {\n+            originalWrite(writeOpt, writeBatch);\n+        } else if (trackLatencyEnabled) {\n+            writeAndUpdateMetric(columnFamilyHandle, writeOpt, writeBatch);\n+        } else {\n+            originalWrite(writeOpt, writeBatch);\n+        }\n+    }\n+\n+    public byte[] get(final ColumnFamilyHandleWrapper columnFamilyHandle, final byte[] key)\n+            throws RocksDBException {\n+        if (trackLatencyEnabled) {\n+            return getAndUpdateMetric(columnFamilyHandle, key);\n+        } else {\n+            return originalGet(columnFamilyHandle.getColumnFamilyHandle(), key);\n+        }\n+    }\n+\n+    public void delete(\n+            final ColumnFamilyHandleWrapper columnFamilyHandle,\n+            final WriteOptions writeOpt,\n+            final byte[] key)\n+            throws RocksDBException {\n+        if (trackLatencyEnabled) {\n+            deleteAndUpdateMetric(columnFamilyHandle, writeOpt, key);\n+        } else {\n+            originalDelete(columnFamilyHandle.getColumnFamilyHandle(), writeOpt, key);\n+        }\n+    }\n+\n+    public void merge(\n+            final ColumnFamilyHandleWrapper columnFamilyHandle,\n+            final WriteOptions writeOpt,\n+            final byte[] key,\n+            final byte[] value)\n+            throws RocksDBException {\n+        if (trackLatencyEnabled) {\n+            mergeAndUpdateMetric(columnFamilyHandle, writeOpt, key, value);\n+        } else {\n+            originalMerge(columnFamilyHandle.getColumnFamilyHandle(), writeOpt, key, value);\n+        }\n+    }\n+\n+    private byte[] getAndUpdateMetric(\n+            final ColumnFamilyHandleWrapper columnFamilyHandle, final byte[] key)\n+            throws RocksDBException {\n+        if (accessMetric.checkAndUpdateGetCounter(columnFamilyHandle.getColumnFamilyId())) {\n+            long start = System.nanoTime();\n+            byte[] result = originalGet(columnFamilyHandle.getColumnFamilyHandle(), key);\n+            long end = System.nanoTime();\n+            accessMetric.updateHistogram(\n+                    columnFamilyHandle.getColumnFamilyId(),\n+                    RocksDBAccessMetric.GET_LATENCY,\n+                    end - start);\n+            return result;\n+        } else {\n+            return originalGet(columnFamilyHandle.getColumnFamilyHandle(), key);\n+        }\n+    }\n+\n+    private void deleteAndUpdateMetric(\n+            final ColumnFamilyHandleWrapper columnFamilyHandle,\n+            final WriteOptions writeOpt,\n+            final byte[] key)\n+            throws RocksDBException {\n+        if (accessMetric.checkAndUpdateDeleteCounter(columnFamilyHandle.getColumnFamilyId())) {\n+            long start = System.nanoTime();\n+            originalDelete(columnFamilyHandle.getColumnFamilyHandle(), writeOpt, key);\n+            long end = System.nanoTime();\n+            accessMetric.updateHistogram(\n+                    columnFamilyHandle.getColumnFamilyId(),\n+                    RocksDBAccessMetric.DELETE_LATENCY,\n+                    end - start);\n+        } else {\n+            originalDelete(columnFamilyHandle.getColumnFamilyHandle(), writeOpt, key);\n+        }\n+    }\n+\n+    private void putAndUpdateMetric(\n+            final ColumnFamilyHandleWrapper columnFamilyHandle,\n+            final WriteOptions writeOpt,\n+            final byte[] key,\n+            final byte[] value)\n+            throws RocksDBException {\n+        if (accessMetric.checkAndUpdatePutCounter(columnFamilyHandle.getColumnFamilyId())) {\n+            long start = System.nanoTime();\n+            originalPut(columnFamilyHandle.getColumnFamilyHandle(), writeOpt, key, value);\n+            long end = System.nanoTime();\n+            accessMetric.updateHistogram(\n+                    columnFamilyHandle.getColumnFamilyId(),\n+                    RocksDBAccessMetric.PUT_LATENCY,\n+                    end - start);\n+        } else {\n+            originalPut(columnFamilyHandle.getColumnFamilyHandle(), writeOpt, key, value);\n+        }\n+    }\n+\n+    private void writeAndUpdateMetric(\n+            final ColumnFamilyHandleWrapper columnFamilyHandle,\n+            final WriteOptions writeOpt,\n+            final WriteBatch writeBatch)\n+            throws RocksDBException {\n+        if (accessMetric.checkAndUpdateWriteBatchCounter(columnFamilyHandle.getColumnFamilyId())) {\n+            long start = System.nanoTime();\n+            originalWrite(writeOpt, writeBatch);\n+            long end = System.nanoTime();\n+            accessMetric.updateHistogram(\n+                    columnFamilyHandle.getColumnFamilyId(),\n+                    RocksDBAccessMetric.WRITE_BATCH_LATENCY,\n+                    end - start);\n+        } else {\n+            originalWrite(writeOpt, writeBatch);\n+        }\n+    }\n+\n+    private void mergeAndUpdateMetric(\n+            final ColumnFamilyHandleWrapper columnFamilyHandle,\n+            final WriteOptions writeOpt,\n+            final byte[] key,\n+            final byte[] value)\n+            throws RocksDBException {\n+        if (accessMetric.checkAndUpdateMergeCounter(columnFamilyHandle.getColumnFamilyId())) {\n+            long start = System.nanoTime();\n+            originalMerge(columnFamilyHandle.getColumnFamilyHandle(), writeOpt, key, value);\n+            long end = System.nanoTime();\n+            accessMetric.updateHistogram(\n+                    columnFamilyHandle.getColumnFamilyId(),\n+                    RocksDBAccessMetric.MERGE_LATENCY,\n+                    end - start);\n+        } else {\n+            originalMerge(columnFamilyHandle.getColumnFamilyHandle(), writeOpt, key, value);\n+        }\n+    }\n+\n+    private byte[] originalGet(final ColumnFamilyHandle columnFamilyHandle, final byte[] key)\n+            throws RocksDBException {\n+        return db.get(columnFamilyHandle, key);\n+    }\n+\n+    private void originalDelete(\n+            final ColumnFamilyHandle columnFamilyHandle,\n+            final WriteOptions writeOpt,\n+            final byte[] key)\n+            throws RocksDBException {\n+        db.delete(columnFamilyHandle, writeOpt, key);\n+    }\n+\n+    private void originalPut(\n+            final ColumnFamilyHandle columnFamilyHandle,\n+            final WriteOptions writeOpts,\n+            final byte[] key,\n+            final byte[] value)\n+            throws RocksDBException {\n+        db.put(columnFamilyHandle, writeOpts, key, value);\n+    }\n+\n+    private void originalWrite(final WriteOptions writeOpts, final WriteBatch writeBatch)\n+            throws RocksDBException {\n+        db.write(writeOpts, writeBatch);\n+    }\n+\n+    private void originalMerge(\n+            final ColumnFamilyHandle columnFamilyHandle,\n+            final WriteOptions writeOpts,\n+            final byte[] key,\n+            final byte[] value)\n+            throws RocksDBException {\n+        db.merge(columnFamilyHandle, writeOpts, key, value);\n+    }\n+\n+    @Override\n+    public void close() {\n+        if (accessMetric != null) {\n+            accessMetric.close();\n+        }\n+        db.close();\n+    }\n+}"
  },
  {
    "sha": "58b7621e6aa384bcc5a42556ddd360568fdb323d",
    "filename": "flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBWriteBatchWrapper.java",
    "status": "modified",
    "additions": 29,
    "deletions": 17,
    "changes": 46,
    "blob_url": "https://github.com/apache/flink/blob/c3d268b3dfcb4037f99d148b70e005832dd00c44/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBWriteBatchWrapper.java",
    "raw_url": "https://github.com/apache/flink/raw/c3d268b3dfcb4037f99d148b70e005832dd00c44/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBWriteBatchWrapper.java",
    "contents_url": "https://api.github.com/repos/apache/flink/contents/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBWriteBatchWrapper.java?ref=c3d268b3dfcb4037f99d148b70e005832dd00c44",
    "patch": "@@ -23,7 +23,6 @@\n import org.apache.flink.util.Preconditions;\n \n import org.rocksdb.ColumnFamilyHandle;\n-import org.rocksdb.RocksDB;\n import org.rocksdb.RocksDBException;\n import org.rocksdb.WriteBatch;\n import org.rocksdb.WriteOptions;\n@@ -39,13 +38,13 @@\n  */\n public class RocksDBWriteBatchWrapper implements AutoCloseable {\n \n+    public static final int DEFAULT_CAPACITY = 500;\n+\n     private static final int MIN_CAPACITY = 100;\n     private static final int MAX_CAPACITY = 1000;\n     private static final int PER_RECORD_BYTES = 100;\n-    // default 0 for disable memory size based flush\n-    private static final long DEFAULT_BATCH_SIZE = 0;\n \n-    private final RocksDB db;\n+    private final RocksDBWrapper db;\n \n     private final WriteBatch batch;\n \n@@ -55,21 +54,19 @@\n \n     @Nonnegative private final long batchSize;\n \n-    public RocksDBWriteBatchWrapper(@Nonnull RocksDB rocksDB, long writeBatchSize) {\n-        this(rocksDB, null, 500, writeBatchSize);\n-    }\n+    /**\n+     * WriteBatch could be used for multi column family handles, which could happen during restoring\n+     * or rocksDB timer access, we set the column family handler wrapper as null in these cases.\n+     */\n+    @Nullable private final ColumnFamilyHandleWrapper columnFamilyHandleWrapper;\n \n-    public RocksDBWriteBatchWrapper(@Nonnull RocksDB rocksDB, @Nullable WriteOptions options) {\n-        this(rocksDB, options, 500, DEFAULT_BATCH_SIZE);\n+    public RocksDBWriteBatchWrapper(@Nonnull RocksDBWrapper rocksDB, long writeBatchSize) {\n+        this(rocksDB, null, null, DEFAULT_CAPACITY, writeBatchSize);\n     }\n \n     public RocksDBWriteBatchWrapper(\n-            @Nonnull RocksDB rocksDB, @Nullable WriteOptions options, long batchSize) {\n-        this(rocksDB, options, 500, batchSize);\n-    }\n-\n-    public RocksDBWriteBatchWrapper(\n-            @Nonnull RocksDB rocksDB,\n+            @Nonnull RocksDBWrapper rocksDB,\n+            @Nullable ColumnFamilyHandleWrapper columnFamilyHandle,\n             @Nullable WriteOptions options,\n             int capacity,\n             long batchSize) {\n@@ -79,6 +76,7 @@ public RocksDBWriteBatchWrapper(\n         Preconditions.checkArgument(batchSize >= 0, \"Max batch size have to be no negative.\");\n \n         this.db = rocksDB;\n+        this.columnFamilyHandleWrapper = columnFamilyHandle;\n         this.options = options;\n         this.capacity = capacity;\n         this.batchSize = batchSize;\n@@ -91,6 +89,13 @@ public RocksDBWriteBatchWrapper(\n         }\n     }\n \n+    public void put(@Nonnull byte[] key, @Nonnull byte[] value) throws RocksDBException {\n+        Preconditions.checkNotNull(columnFamilyHandleWrapper);\n+        batch.put(columnFamilyHandleWrapper.getColumnFamilyHandle(), key, value);\n+\n+        flushIfNeeded();\n+    }\n+\n     public void put(@Nonnull ColumnFamilyHandle handle, @Nonnull byte[] key, @Nonnull byte[] value)\n             throws RocksDBException {\n \n@@ -99,6 +104,13 @@ public void put(@Nonnull ColumnFamilyHandle handle, @Nonnull byte[] key, @Nonnul\n         flushIfNeeded();\n     }\n \n+    public void remove(@Nonnull byte[] key) throws RocksDBException {\n+        Preconditions.checkNotNull(columnFamilyHandleWrapper);\n+        batch.remove(columnFamilyHandleWrapper.getColumnFamilyHandle(), key);\n+\n+        flushIfNeeded();\n+    }\n+\n     public void remove(@Nonnull ColumnFamilyHandle handle, @Nonnull byte[] key)\n             throws RocksDBException {\n \n@@ -109,11 +121,11 @@ public void remove(@Nonnull ColumnFamilyHandle handle, @Nonnull byte[] key)\n \n     public void flush() throws RocksDBException {\n         if (options != null) {\n-            db.write(options, batch);\n+            db.write(columnFamilyHandleWrapper, options, batch);\n         } else {\n             // use the default WriteOptions, if wasn't provided.\n             try (WriteOptions writeOptions = new WriteOptions()) {\n-                db.write(writeOptions, batch);\n+                db.write(columnFamilyHandleWrapper, writeOptions, batch);\n             }\n         }\n         batch.clear();"
  },
  {
    "sha": "569fc8a13a292b62a12967ece8873d6c74ba0a74",
    "filename": "flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksIteratorWrapper.java",
    "status": "modified",
    "additions": 63,
    "deletions": 2,
    "changes": 65,
    "blob_url": "https://github.com/apache/flink/blob/c3d268b3dfcb4037f99d148b70e005832dd00c44/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksIteratorWrapper.java",
    "raw_url": "https://github.com/apache/flink/raw/c3d268b3dfcb4037f99d148b70e005832dd00c44/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksIteratorWrapper.java",
    "contents_url": "https://api.github.com/repos/apache/flink/contents/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksIteratorWrapper.java?ref=c3d268b3dfcb4037f99d148b70e005832dd00c44",
    "patch": "@@ -19,12 +19,14 @@\n package org.apache.flink.contrib.streaming.state;\n \n import org.apache.flink.util.FlinkRuntimeException;\n+import org.apache.flink.util.Preconditions;\n \n import org.rocksdb.RocksDBException;\n import org.rocksdb.RocksIterator;\n import org.rocksdb.RocksIteratorInterface;\n \n import javax.annotation.Nonnull;\n+import javax.annotation.Nullable;\n \n import java.io.Closeable;\n \n@@ -39,10 +41,25 @@\n  */\n public class RocksIteratorWrapper implements RocksIteratorInterface, Closeable {\n \n-    private RocksIterator iterator;\n+    private final RocksIterator iterator;\n \n-    public RocksIteratorWrapper(@Nonnull RocksIterator iterator) {\n+    private final RocksDBAccessMetric accessMetric;\n+\n+    private final ColumnFamilyHandleWrapper columnFamilyHandleWrapper;\n+\n+    private final boolean trackLatencyEnabled;\n+\n+    public RocksIteratorWrapper(\n+            @Nonnull RocksIterator iterator,\n+            @Nullable RocksDBAccessMetric accessMetric,\n+            @Nullable ColumnFamilyHandleWrapper columnFamilyHandleWrapper) {\n         this.iterator = iterator;\n+        this.accessMetric = accessMetric;\n+        this.trackLatencyEnabled = accessMetric != null;\n+        this.columnFamilyHandleWrapper = columnFamilyHandleWrapper;\n+        Preconditions.checkArgument(\n+                !trackLatencyEnabled || columnFamilyHandleWrapper != null,\n+                \"Should provide column family handle wrapper when enable latency track.\");\n     }\n \n     @Override\n@@ -64,6 +81,28 @@ public void seekToLast() {\n \n     @Override\n     public void seek(byte[] target) {\n+        if (trackLatencyEnabled) {\n+            seekAndUpdateMetric(target);\n+        } else {\n+            originalSeek(target);\n+        }\n+    }\n+\n+    private void seekAndUpdateMetric(final byte[] target) {\n+        if (accessMetric.checkAndUpdateSeekCounter(columnFamilyHandleWrapper.getColumnFamilyId())) {\n+            long start = System.nanoTime();\n+            originalSeek(target);\n+            long end = System.nanoTime();\n+            accessMetric.updateHistogram(\n+                    columnFamilyHandleWrapper.getColumnFamilyId(),\n+                    RocksDBAccessMetric.SEEK_LATENCY,\n+                    end - start);\n+        } else {\n+            originalSeek(target);\n+        }\n+    }\n+\n+    private void originalSeek(byte[] target) {\n         iterator.seek(target);\n         status();\n     }\n@@ -76,6 +115,28 @@ public void seekForPrev(byte[] target) {\n \n     @Override\n     public void next() {\n+        if (trackLatencyEnabled) {\n+            nextAndUpdateMetric();\n+        } else {\n+            originalNext();\n+        }\n+    }\n+\n+    private void nextAndUpdateMetric() {\n+        if (accessMetric.checkAndUpdateNextCounter(columnFamilyHandleWrapper.getColumnFamilyId())) {\n+            long start = System.nanoTime();\n+            originalNext();\n+            long end = System.nanoTime();\n+            accessMetric.updateHistogram(\n+                    columnFamilyHandleWrapper.getColumnFamilyId(),\n+                    RocksDBAccessMetric.NEXT_LATENCY,\n+                    end - start);\n+        } else {\n+            originalNext();\n+        }\n+    }\n+\n+    private void originalNext() {\n         iterator.next();\n         status();\n     }"
  },
  {
    "sha": "4ec598428bc09e940f1d1f2de890d0671b301fd1",
    "filename": "flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/iterator/RocksTransformingIteratorWrapper.java",
    "status": "modified",
    "additions": 1,
    "deletions": 1,
    "changes": 2,
    "blob_url": "https://github.com/apache/flink/blob/c3d268b3dfcb4037f99d148b70e005832dd00c44/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/iterator/RocksTransformingIteratorWrapper.java",
    "raw_url": "https://github.com/apache/flink/raw/c3d268b3dfcb4037f99d148b70e005832dd00c44/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/iterator/RocksTransformingIteratorWrapper.java",
    "contents_url": "https://api.github.com/repos/apache/flink/contents/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/iterator/RocksTransformingIteratorWrapper.java?ref=c3d268b3dfcb4037f99d148b70e005832dd00c44",
    "patch": "@@ -37,7 +37,7 @@\n     public RocksTransformingIteratorWrapper(\n             @Nonnull RocksIterator iterator,\n             @Nonnull StateSnapshotTransformer<byte[]> stateSnapshotTransformer) {\n-        super(iterator);\n+        super(iterator, null, null);\n         this.stateSnapshotTransformer = stateSnapshotTransformer;\n     }\n "
  },
  {
    "sha": "1b56a981f666560515419dced7802e24ae6467f4",
    "filename": "flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/restore/RocksDBFullRestoreOperation.java",
    "status": "modified",
    "additions": 7,
    "deletions": 3,
    "changes": 10,
    "blob_url": "https://github.com/apache/flink/blob/c3d268b3dfcb4037f99d148b70e005832dd00c44/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/restore/RocksDBFullRestoreOperation.java",
    "raw_url": "https://github.com/apache/flink/raw/c3d268b3dfcb4037f99d148b70e005832dd00c44/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/restore/RocksDBFullRestoreOperation.java",
    "contents_url": "https://api.github.com/repos/apache/flink/contents/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/restore/RocksDBFullRestoreOperation.java?ref=c3d268b3dfcb4037f99d148b70e005832dd00c44",
    "patch": "@@ -18,6 +18,7 @@\n \n package org.apache.flink.contrib.streaming.state.restore;\n \n+import org.apache.flink.contrib.streaming.state.RocksDBAccessMetric;\n import org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackend.RocksDbKvStateInfo;\n import org.apache.flink.contrib.streaming.state.RocksDBNativeMetricOptions;\n import org.apache.flink.contrib.streaming.state.RocksDBWriteBatchWrapper;\n@@ -68,6 +69,7 @@ public RocksDBFullRestoreOperation(\n             Function<String, ColumnFamilyOptions> columnFamilyOptionsFactory,\n             RocksDBNativeMetricOptions nativeMetricOptions,\n             MetricGroup metricGroup,\n+            RocksDBAccessMetric.Builder accessMetricBuilder,\n             @Nonnull Collection<KeyedStateHandle> restoreStateHandles,\n             @Nonnull RocksDbTtlCompactFiltersManager ttlCompactFiltersManager,\n             @Nonnegative long writeBatchSize,\n@@ -81,6 +83,7 @@ public RocksDBFullRestoreOperation(\n                         columnFamilyOptionsFactory,\n                         nativeMetricOptions,\n                         metricGroup,\n+                        accessMetricBuilder,\n                         ttlCompactFiltersManager,\n                         writeBufferManagerCapacity);\n         this.savepointRestoreOperation =\n@@ -103,7 +106,7 @@ public RocksDBRestoreResult restore()\n             }\n         }\n         return new RocksDBRestoreResult(\n-                this.rocksHandle.getDb(),\n+                this.rocksHandle.getDBWrapper(),\n                 this.rocksHandle.getDefaultColumnFamilyHandle(),\n                 this.rocksHandle.getNativeMetricMonitor(),\n                 -1,\n@@ -120,7 +123,8 @@ private void applyRestoreResult(SavepointRestoreResult savepointRestoreResult)\n             StateMetaInfoSnapshot restoredMetaInfo = restoredMetaInfos.get(i);\n             RocksDbKvStateInfo registeredStateCFHandle =\n                     this.rocksHandle.getOrRegisterStateColumnFamilyHandle(null, restoredMetaInfo);\n-            columnFamilyHandles.put(i, registeredStateCFHandle.columnFamilyHandle);\n+            columnFamilyHandles.put(\n+                    i, registeredStateCFHandle.columnFamilyHandleWrapper.getColumnFamilyHandle());\n         }\n \n         try (ThrowingIterator<KeyGroup> keyGroups = savepointRestoreResult.getRestoredKeyGroups()) {\n@@ -137,7 +141,7 @@ private void restoreKVStateData(\n             throws IOException, RocksDBException, StateMigrationException {\n         // for all key-groups in the current state handle...\n         try (RocksDBWriteBatchWrapper writeBatchWrapper =\n-                new RocksDBWriteBatchWrapper(this.rocksHandle.getDb(), writeBatchSize)) {\n+                new RocksDBWriteBatchWrapper(this.rocksHandle.getDBWrapper(), writeBatchSize)) {\n             ColumnFamilyHandle handle = null;\n             while (keyGroups.hasNext()) {\n                 KeyGroup keyGroup = keyGroups.next();"
  },
  {
    "sha": "b427d8362760c655c712a317f03157c5569df567",
    "filename": "flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/restore/RocksDBHandle.java",
    "status": "modified",
    "additions": 27,
    "deletions": 13,
    "changes": 40,
    "blob_url": "https://github.com/apache/flink/blob/c3d268b3dfcb4037f99d148b70e005832dd00c44/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/restore/RocksDBHandle.java",
    "raw_url": "https://github.com/apache/flink/raw/c3d268b3dfcb4037f99d148b70e005832dd00c44/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/restore/RocksDBHandle.java",
    "contents_url": "https://api.github.com/repos/apache/flink/contents/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/restore/RocksDBHandle.java?ref=c3d268b3dfcb4037f99d148b70e005832dd00c44",
    "patch": "@@ -18,10 +18,13 @@\n \n package org.apache.flink.contrib.streaming.state.restore;\n \n+import org.apache.flink.contrib.streaming.state.ColumnFamilyHandleWrapper;\n+import org.apache.flink.contrib.streaming.state.RocksDBAccessMetric;\n import org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackend.RocksDbKvStateInfo;\n import org.apache.flink.contrib.streaming.state.RocksDBNativeMetricMonitor;\n import org.apache.flink.contrib.streaming.state.RocksDBNativeMetricOptions;\n import org.apache.flink.contrib.streaming.state.RocksDBOperationUtils;\n+import org.apache.flink.contrib.streaming.state.RocksDBWrapper;\n import org.apache.flink.contrib.streaming.state.ttl.RocksDbTtlCompactFiltersManager;\n import org.apache.flink.metrics.MetricGroup;\n import org.apache.flink.runtime.state.RegisteredStateMetaInfoBase;\n@@ -33,7 +36,6 @@\n import org.rocksdb.ColumnFamilyHandle;\n import org.rocksdb.ColumnFamilyOptions;\n import org.rocksdb.DBOptions;\n-import org.rocksdb.RocksDB;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n@@ -68,6 +70,7 @@\n     private List<ColumnFamilyHandle> columnFamilyHandles;\n     private List<ColumnFamilyDescriptor> columnFamilyDescriptors;\n     private final RocksDBNativeMetricOptions nativeMetricOptions;\n+    private final RocksDBAccessMetric.Builder accessMetricBuilder;\n     private final MetricGroup metricGroup;\n     // Current places to set compact filter into column family options:\n     // - Incremental restore\n@@ -83,7 +86,7 @@\n     // column family\n     private final RocksDbTtlCompactFiltersManager ttlCompactFiltersManager;\n \n-    private RocksDB db;\n+    private RocksDBWrapper db;\n     private ColumnFamilyHandle defaultColumnFamilyHandle;\n     private RocksDBNativeMetricMonitor nativeMetricMonitor;\n     private final Long writeBufferManagerCapacity;\n@@ -95,6 +98,7 @@ protected RocksDBHandle(\n             Function<String, ColumnFamilyOptions> columnFamilyOptionsFactory,\n             RocksDBNativeMetricOptions nativeMetricOptions,\n             MetricGroup metricGroup,\n+            RocksDBAccessMetric.Builder accessMetricBuilder,\n             @Nonnull RocksDbTtlCompactFiltersManager ttlCompactFiltersManager,\n             Long writeBufferManagerCapacity) {\n         this.kvStateInformation = kvStateInformation;\n@@ -103,6 +107,7 @@ protected RocksDBHandle(\n         this.columnFamilyOptionsFactory = columnFamilyOptionsFactory;\n         this.nativeMetricOptions = nativeMetricOptions;\n         this.metricGroup = metricGroup;\n+        this.accessMetricBuilder = accessMetricBuilder;\n         this.ttlCompactFiltersManager = ttlCompactFiltersManager;\n         this.columnFamilyHandles = new ArrayList<>(1);\n         this.columnFamilyDescriptors = Collections.emptyList();\n@@ -131,19 +136,22 @@ void openDB(\n \n     private void loadDb() throws IOException {\n         db =\n-                RocksDBOperationUtils.openDB(\n-                        dbPath,\n-                        columnFamilyDescriptors,\n-                        columnFamilyHandles,\n-                        RocksDBOperationUtils.createColumnFamilyOptions(\n-                                columnFamilyOptionsFactory, \"default\"),\n-                        dbOptions);\n+                new RocksDBWrapper(\n+                        RocksDBOperationUtils.openDB(\n+                                dbPath,\n+                                columnFamilyDescriptors,\n+                                columnFamilyHandles,\n+                                RocksDBOperationUtils.createColumnFamilyOptions(\n+                                        columnFamilyOptionsFactory, \"default\"),\n+                                dbOptions),\n+                        accessMetricBuilder.setMetricGroup(metricGroup));\n         // remove the default column family which is located at the first index\n         defaultColumnFamilyHandle = columnFamilyHandles.remove(0);\n         // init native metrics monitor if configured\n         nativeMetricMonitor =\n                 nativeMetricOptions.isEnabled()\n-                        ? new RocksDBNativeMetricMonitor(nativeMetricOptions, metricGroup, db)\n+                        ? new RocksDBNativeMetricMonitor(\n+                                nativeMetricOptions, metricGroup, db.getDb())\n                         : null;\n     }\n \n@@ -162,18 +170,20 @@ RocksDbKvStateInfo getOrRegisterStateColumnFamilyHandle(\n                 registeredStateMetaInfoEntry =\n                         RocksDBOperationUtils.createStateInfo(\n                                 stateMetaInfo,\n-                                db,\n+                                db.getDb(),\n                                 columnFamilyOptionsFactory,\n                                 ttlCompactFiltersManager,\n                                 writeBufferManagerCapacity);\n             } else {\n                 registeredStateMetaInfoEntry =\n-                        new RocksDbKvStateInfo(columnFamilyHandle, stateMetaInfo);\n+                        new RocksDbKvStateInfo(\n+                                new ColumnFamilyHandleWrapper(columnFamilyHandle), stateMetaInfo);\n             }\n \n             RocksDBOperationUtils.registerKvStateInformation(\n                     kvStateInformation,\n                     nativeMetricMonitor,\n+                    db.getAccessMetric(),\n                     stateMetaInfoSnapshot.getName(),\n                     registeredStateMetaInfoEntry);\n         } else {\n@@ -211,14 +221,18 @@ private void restoreInstanceDirectoryFromPath(Path source) throws IOException {\n         }\n     }\n \n-    public RocksDB getDb() {\n+    public RocksDBWrapper getDBWrapper() {\n         return db;\n     }\n \n     public RocksDBNativeMetricMonitor getNativeMetricMonitor() {\n         return nativeMetricMonitor;\n     }\n \n+    public RocksDBAccessMetric.Builder getAccessMetricBuilder() {\n+        return accessMetricBuilder;\n+    }\n+\n     public ColumnFamilyHandle getDefaultColumnFamilyHandle() {\n         return defaultColumnFamilyHandle;\n     }"
  },
  {
    "sha": "eaaa1dada8fc5ac054561aa27df4acbc15c51f1a",
    "filename": "flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/restore/RocksDBHeapTimersFullRestoreOperation.java",
    "status": "modified",
    "additions": 8,
    "deletions": 3,
    "changes": 11,
    "blob_url": "https://github.com/apache/flink/blob/c3d268b3dfcb4037f99d148b70e005832dd00c44/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/restore/RocksDBHeapTimersFullRestoreOperation.java",
    "raw_url": "https://github.com/apache/flink/raw/c3d268b3dfcb4037f99d148b70e005832dd00c44/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/restore/RocksDBHeapTimersFullRestoreOperation.java",
    "contents_url": "https://api.github.com/repos/apache/flink/contents/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/restore/RocksDBHeapTimersFullRestoreOperation.java?ref=c3d268b3dfcb4037f99d148b70e005832dd00c44",
    "patch": "@@ -18,6 +18,7 @@\n \n package org.apache.flink.contrib.streaming.state.restore;\n \n+import org.apache.flink.contrib.streaming.state.RocksDBAccessMetric;\n import org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackend.RocksDbKvStateInfo;\n import org.apache.flink.contrib.streaming.state.RocksDBNativeMetricOptions;\n import org.apache.flink.contrib.streaming.state.RocksDBWriteBatchWrapper;\n@@ -91,6 +92,7 @@ public RocksDBHeapTimersFullRestoreOperation(\n             Function<String, ColumnFamilyOptions> columnFamilyOptionsFactory,\n             RocksDBNativeMetricOptions nativeMetricOptions,\n             MetricGroup metricGroup,\n+            RocksDBAccessMetric.Builder accessMetricBuilder,\n             @Nonnull Collection<KeyedStateHandle> restoreStateHandles,\n             @Nonnull RocksDbTtlCompactFiltersManager ttlCompactFiltersManager,\n             @Nonnegative long writeBatchSize,\n@@ -104,6 +106,7 @@ public RocksDBHeapTimersFullRestoreOperation(\n                         columnFamilyOptionsFactory,\n                         nativeMetricOptions,\n                         metricGroup,\n+                        accessMetricBuilder,\n                         ttlCompactFiltersManager,\n                         writeBufferManagerCapacity);\n         this.savepointRestoreOperation =\n@@ -133,7 +136,7 @@ public RocksDBRestoreResult restore()\n             }\n         }\n         return new RocksDBRestoreResult(\n-                this.rocksHandle.getDb(),\n+                this.rocksHandle.getDBWrapper(),\n                 this.rocksHandle.getDefaultColumnFamilyHandle(),\n                 this.rocksHandle.getNativeMetricMonitor(),\n                 -1,\n@@ -163,7 +166,9 @@ private void applyRestoreResult(SavepointRestoreResult savepointRestoreResult)\n                 RocksDbKvStateInfo registeredStateCFHandle =\n                         this.rocksHandle.getOrRegisterStateColumnFamilyHandle(\n                                 null, restoredMetaInfo);\n-                columnFamilyHandles.put(i, registeredStateCFHandle.columnFamilyHandle);\n+                columnFamilyHandles.put(\n+                        i,\n+                        registeredStateCFHandle.columnFamilyHandleWrapper.getColumnFamilyHandle());\n             }\n         }\n \n@@ -183,7 +188,7 @@ private void restoreKVStateData(\n             throws IOException, RocksDBException, StateMigrationException {\n         // for all key-groups in the current state handle...\n         try (RocksDBWriteBatchWrapper writeBatchWrapper =\n-                new RocksDBWriteBatchWrapper(this.rocksHandle.getDb(), writeBatchSize)) {\n+                new RocksDBWriteBatchWrapper(this.rocksHandle.getDBWrapper(), writeBatchSize)) {\n             HeapPriorityQueueSnapshotRestoreWrapper<HeapPriorityQueueElement> restoredPQ = null;\n             ColumnFamilyHandle handle = null;\n             while (keyGroups.hasNext()) {"
  },
  {
    "sha": "19c7c2989e72d0219b4b1a6b564b5fafc0ad2e9b",
    "filename": "flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/restore/RocksDBIncrementalRestoreOperation.java",
    "status": "modified",
    "additions": 26,
    "deletions": 17,
    "changes": 43,
    "blob_url": "https://github.com/apache/flink/blob/c3d268b3dfcb4037f99d148b70e005832dd00c44/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/restore/RocksDBIncrementalRestoreOperation.java",
    "raw_url": "https://github.com/apache/flink/raw/c3d268b3dfcb4037f99d148b70e005832dd00c44/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/restore/RocksDBIncrementalRestoreOperation.java",
    "contents_url": "https://api.github.com/repos/apache/flink/contents/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/restore/RocksDBIncrementalRestoreOperation.java?ref=c3d268b3dfcb4037f99d148b70e005832dd00c44",
    "patch": "@@ -20,11 +20,14 @@\n \n import org.apache.flink.api.common.typeutils.TypeSerializer;\n import org.apache.flink.api.common.typeutils.TypeSerializerSchemaCompatibility;\n+import org.apache.flink.contrib.streaming.state.ColumnFamilyHandleWrapper;\n+import org.apache.flink.contrib.streaming.state.RocksDBAccessMetric;\n import org.apache.flink.contrib.streaming.state.RocksDBIncrementalCheckpointUtils;\n import org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackend.RocksDbKvStateInfo;\n import org.apache.flink.contrib.streaming.state.RocksDBNativeMetricOptions;\n import org.apache.flink.contrib.streaming.state.RocksDBOperationUtils;\n import org.apache.flink.contrib.streaming.state.RocksDBStateDownloader;\n+import org.apache.flink.contrib.streaming.state.RocksDBWrapper;\n import org.apache.flink.contrib.streaming.state.RocksDBWriteBatchWrapper;\n import org.apache.flink.contrib.streaming.state.RocksIteratorWrapper;\n import org.apache.flink.contrib.streaming.state.ttl.RocksDbTtlCompactFiltersManager;\n@@ -55,7 +58,6 @@\n import org.rocksdb.ColumnFamilyOptions;\n import org.rocksdb.DBOptions;\n import org.rocksdb.ReadOptions;\n-import org.rocksdb.RocksDB;\n import org.rocksdb.RocksDBException;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n@@ -118,6 +120,7 @@ public RocksDBIncrementalRestoreOperation(\n             Function<String, ColumnFamilyOptions> columnFamilyOptionsFactory,\n             RocksDBNativeMetricOptions nativeMetricOptions,\n             MetricGroup metricGroup,\n+            RocksDBAccessMetric.Builder accessMetricBuilder,\n             @Nonnull Collection<KeyedStateHandle> restoreStateHandles,\n             @Nonnull RocksDbTtlCompactFiltersManager ttlCompactFiltersManager,\n             @Nonnegative long writeBatchSize,\n@@ -130,6 +133,7 @@ public RocksDBIncrementalRestoreOperation(\n                         columnFamilyOptionsFactory,\n                         nativeMetricOptions,\n                         metricGroup,\n+                        accessMetricBuilder,\n                         ttlCompactFiltersManager,\n                         writeBufferManagerCapacity);\n         this.operatorIdentifier = operatorIdentifier;\n@@ -167,7 +171,7 @@ public RocksDBRestoreResult restore() throws Exception {\n             restoreWithoutRescaling(theFirstStateHandle);\n         }\n         return new RocksDBRestoreResult(\n-                this.rocksHandle.getDb(),\n+                this.rocksHandle.getDBWrapper(),\n                 this.rocksHandle.getDefaultColumnFamilyHandle(),\n                 this.rocksHandle.getNativeMetricMonitor(),\n                 lastCompletedCheckpointId,\n@@ -324,7 +328,7 @@ private void restoreWithRescaling(Collection<KeyedStateHandle> restoreStateHandl\n                                     temporaryRestoreInstancePath);\n                     RocksDBWriteBatchWrapper writeBatchWrapper =\n                             new RocksDBWriteBatchWrapper(\n-                                    this.rocksHandle.getDb(), writeBatchSize)) {\n+                                    this.rocksHandle.getDBWrapper(), writeBatchSize)) {\n \n                 List<ColumnFamilyDescriptor> tmpColumnFamilyDescriptors =\n                         tmpRestoreDBInfo.columnFamilyDescriptors;\n@@ -337,14 +341,16 @@ private void restoreWithRescaling(Collection<KeyedStateHandle> restoreStateHandl\n                     ColumnFamilyHandle tmpColumnFamilyHandle = tmpColumnFamilyHandles.get(i);\n \n                     ColumnFamilyHandle targetColumnFamilyHandle =\n-                            this.rocksHandle.getOrRegisterStateColumnFamilyHandle(\n+                            this.rocksHandle\n+                                    .getOrRegisterStateColumnFamilyHandle(\n                                             null, tmpRestoreDBInfo.stateMetaInfoSnapshots.get(i))\n-                                    .columnFamilyHandle;\n+                                    .columnFamilyHandleWrapper\n+                                    .getColumnFamilyHandle();\n \n                     try (RocksIteratorWrapper iterator =\n                             RocksDBOperationUtils.getRocksIterator(\n                                     tmpRestoreDBInfo.db,\n-                                    tmpColumnFamilyHandle,\n+                                    new ColumnFamilyHandleWrapper(tmpColumnFamilyHandle),\n                                     tmpRestoreDBInfo.readOptions)) {\n \n                         iterator.seek(startKeyGroupPrefixBytes);\n@@ -384,7 +390,7 @@ private void initDBWithRescaling(KeyedStateHandle initialHandle) throws Exceptio\n         // 2. Clip the base DB instance\n         try {\n             RocksDBIncrementalCheckpointUtils.clipDBWithKeyGroupRange(\n-                    this.rocksHandle.getDb(),\n+                    this.rocksHandle.getDBWrapper().getDb(),\n                     this.rocksHandle.getColumnFamilyHandles(),\n                     keyGroupRange,\n                     initialHandle.getKeyGroupRange(),\n@@ -400,7 +406,7 @@ private void initDBWithRescaling(KeyedStateHandle initialHandle) throws Exceptio\n     /** Entity to hold the temporary RocksDB instance created for restore. */\n     private static class RestoredDBInstance implements AutoCloseable {\n \n-        @Nonnull private final RocksDB db;\n+        @Nonnull private final RocksDBWrapper db;\n \n         @Nonnull private final ColumnFamilyHandle defaultColumnFamilyHandle;\n \n@@ -413,7 +419,7 @@ private void initDBWithRescaling(KeyedStateHandle initialHandle) throws Exceptio\n         private final ReadOptions readOptions;\n \n         private RestoredDBInstance(\n-                @Nonnull RocksDB db,\n+                @Nonnull RocksDBWrapper db,\n                 @Nonnull List<ColumnFamilyHandle> columnFamilyHandles,\n                 @Nonnull List<ColumnFamilyDescriptor> columnFamilyDescriptors,\n                 @Nonnull List<StateMetaInfoSnapshot> stateMetaInfoSnapshots) {\n@@ -462,14 +468,17 @@ private RestoredDBInstance restoreDBInstanceFromStateHandle(\n         List<ColumnFamilyHandle> columnFamilyHandles =\n                 new ArrayList<>(stateMetaInfoSnapshots.size() + 1);\n \n-        RocksDB restoreDb =\n-                RocksDBOperationUtils.openDB(\n-                        temporaryRestoreInstancePath.toString(),\n-                        columnFamilyDescriptors,\n-                        columnFamilyHandles,\n-                        RocksDBOperationUtils.createColumnFamilyOptions(\n-                                this.rocksHandle.getColumnFamilyOptionsFactory(), \"default\"),\n-                        this.rocksHandle.getDbOptions());\n+        RocksDBWrapper restoreDb =\n+                new RocksDBWrapper(\n+                        RocksDBOperationUtils.openDB(\n+                                temporaryRestoreInstancePath.toString(),\n+                                columnFamilyDescriptors,\n+                                columnFamilyHandles,\n+                                RocksDBOperationUtils.createColumnFamilyOptions(\n+                                        this.rocksHandle.getColumnFamilyOptionsFactory(),\n+                                        \"default\"),\n+                                this.rocksHandle.getDbOptions()),\n+                        this.rocksHandle.getAccessMetricBuilder());\n \n         return new RestoredDBInstance(\n                 restoreDb, columnFamilyHandles, columnFamilyDescriptors, stateMetaInfoSnapshots);"
  }
]
