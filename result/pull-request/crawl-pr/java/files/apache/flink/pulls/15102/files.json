[
  {
    "sha": "716fb23c645a95ba6601c38a82d9db68fc29a1fb",
    "filename": "flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/JdbcKeyCreator.java",
    "status": "added",
    "additions": 23,
    "deletions": 0,
    "changes": 23,
    "blob_url": "https://github.com/apache/flink/blob/0b8157ff773760f9c4eb473cc3574d3d0152123c/flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/JdbcKeyCreator.java",
    "raw_url": "https://github.com/apache/flink/raw/0b8157ff773760f9c4eb473cc3574d3d0152123c/flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/JdbcKeyCreator.java",
    "contents_url": "https://api.github.com/repos/apache/flink/contents/flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/JdbcKeyCreator.java?ref=0b8157ff773760f9c4eb473cc3574d3d0152123c",
    "patch": "@@ -0,0 +1,23 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.connector.jdbc;\n+\n+import java.io.Serializable;\n+import java.util.function.Function;\n+\n+public interface JdbcKeyCreator<T> extends Function<T, String>, Serializable {}"
  },
  {
    "sha": "ef86cb0b2c8665e44b41214ee98e1308ecbf89fe",
    "filename": "flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/JdbcSink.java",
    "status": "modified",
    "additions": 38,
    "deletions": 0,
    "changes": 38,
    "blob_url": "https://github.com/apache/flink/blob/0b8157ff773760f9c4eb473cc3574d3d0152123c/flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/JdbcSink.java",
    "raw_url": "https://github.com/apache/flink/raw/0b8157ff773760f9c4eb473cc3574d3d0152123c/flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/JdbcSink.java",
    "contents_url": "https://api.github.com/repos/apache/flink/contents/flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/JdbcSink.java?ref=0b8157ff773760f9c4eb473cc3574d3d0152123c",
    "patch": "@@ -83,6 +83,26 @@\n                         JdbcBatchingOutputFormat.RecordExtractor.identity()));\n     }\n \n+    public static <T> SinkFunction<T> sinkWithDynamicOutput(\n+            JdbcStatementFactory<T> sqlFactory,\n+            JdbcStatementBuilder<T> statementBuilder,\n+            JdbcKeyCreator<T> keyCreator,\n+            JdbcExecutionOptions executionOptions,\n+            JdbcConnectionOptions connectionOptions) {\n+        return new GenericJdbcSinkFunction<>(\n+                new JdbcBatchingOutputFormat<>(\n+                        new SimpleJdbcConnectionProvider(connectionOptions),\n+                        executionOptions,\n+                        context -> {\n+                            Preconditions.checkState(\n+                                    !context.getExecutionConfig().isObjectReuseEnabled(),\n+                                    \"objects can not be reused with JDBC sink function\");\n+                            return JdbcBatchStatementExecutor.dynamic(\n+                                    sqlFactory, statementBuilder, keyCreator);\n+                        },\n+                        JdbcBatchingOutputFormat.RecordExtractor.identity()));\n+    }\n+\n     /**\n      * Create JDBC sink which provides exactly-once guarantee.\n      *\n@@ -117,5 +137,23 @@\n                 exactlyOnceOptions);\n     }\n \n+    public static <T> SinkFunction<T> exactlyOnceSinkWithDynamicOutput(\n+            JdbcStatementFactory<T> sqlFactory,\n+            JdbcStatementBuilder<T> statementBuilder,\n+            JdbcKeyCreator<T> keyCreator,\n+            JdbcExecutionOptions executionOptions,\n+            JdbcExactlyOnceOptions exactlyOnceOptions,\n+            SerializableSupplier<XADataSource> dataSourceSupplier) {\n+        return new JdbcXaSinkFunction<>(\n+                sqlFactory,\n+                statementBuilder,\n+                keyCreator,\n+                XaFacade.fromXaDataSourceSupplier(\n+                        dataSourceSupplier,\n+                        Optional.ofNullable(exactlyOnceOptions.getTimeoutSec())),\n+                executionOptions,\n+                exactlyOnceOptions);\n+    }\n+\n     private JdbcSink() {}\n }"
  },
  {
    "sha": "784081a85456ba31026f7932f3d806040e25882e",
    "filename": "flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/JdbcStatementFactory.java",
    "status": "added",
    "additions": 33,
    "deletions": 0,
    "changes": 33,
    "blob_url": "https://github.com/apache/flink/blob/0b8157ff773760f9c4eb473cc3574d3d0152123c/flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/JdbcStatementFactory.java",
    "raw_url": "https://github.com/apache/flink/raw/0b8157ff773760f9c4eb473cc3574d3d0152123c/flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/JdbcStatementFactory.java",
    "contents_url": "https://api.github.com/repos/apache/flink/contents/flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/JdbcStatementFactory.java?ref=0b8157ff773760f9c4eb473cc3574d3d0152123c",
    "patch": "@@ -0,0 +1,33 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.connector.jdbc;\n+\n+import org.apache.flink.annotation.PublicEvolving;\n+import org.apache.flink.connector.jdbc.internal.executor.JdbcBatchStatementExecutor;\n+\n+import java.io.Serializable;\n+import java.sql.PreparedStatement;\n+import java.util.function.Function;\n+\n+/**\n+ * Sets {@link PreparedStatement} table name to use in JDBC Sink.\n+ *\n+ * @see JdbcBatchStatementExecutor\n+ */\n+@PublicEvolving\n+public interface JdbcStatementFactory<T> extends Function<T, String>, Serializable {}"
  },
  {
    "sha": "39f2cda53343bc7d21eba0999779478a6b7252f4",
    "filename": "flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/internal/executor/DynamicBatchStatementExecutor.java",
    "status": "added",
    "additions": 109,
    "deletions": 0,
    "changes": 109,
    "blob_url": "https://github.com/apache/flink/blob/0b8157ff773760f9c4eb473cc3574d3d0152123c/flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/internal/executor/DynamicBatchStatementExecutor.java",
    "raw_url": "https://github.com/apache/flink/raw/0b8157ff773760f9c4eb473cc3574d3d0152123c/flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/internal/executor/DynamicBatchStatementExecutor.java",
    "contents_url": "https://api.github.com/repos/apache/flink/contents/flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/internal/executor/DynamicBatchStatementExecutor.java?ref=0b8157ff773760f9c4eb473cc3574d3d0152123c",
    "patch": "@@ -0,0 +1,109 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.connector.jdbc.internal.executor;\n+\n+import org.apache.flink.connector.jdbc.JdbcKeyCreator;\n+import org.apache.flink.connector.jdbc.JdbcStatementBuilder;\n+import org.apache.flink.connector.jdbc.JdbcStatementFactory;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.Serializable;\n+import java.sql.Connection;\n+import java.sql.PreparedStatement;\n+import java.sql.SQLException;\n+import java.util.*;\n+import java.util.function.Function;\n+\n+/**\n+ * A {@link JdbcBatchStatementExecutor} that creates and executes supplied statement for given the\n+ * records\n+ */\n+class DynamicBatchStatementExecutor<T> implements JdbcBatchStatementExecutor<T>, Serializable {\n+\n+    private static final Logger LOG = LoggerFactory.getLogger(DynamicBatchStatementExecutor.class);\n+\n+    private final JdbcStatementBuilder<T> parameterSetter;\n+    private final transient JdbcStatementFactory<T> sqlFactory;\n+    private final transient Function<T, String> keyExtractor;\n+\n+    private final List<T> batch;\n+    private transient Map<String, PreparedStatement> statementPool; // LRU cache?\n+    private transient Connection connection;\n+\n+    DynamicBatchStatementExecutor(\n+            JdbcStatementFactory<T> sqlFactory,\n+            JdbcStatementBuilder<T> parameterSetter,\n+            JdbcKeyCreator<T> keyExtractor) {\n+        this.sqlFactory = sqlFactory;\n+        this.parameterSetter = parameterSetter;\n+        this.keyExtractor = keyExtractor;\n+        this.batch = new ArrayList<>();\n+    }\n+\n+    @Override\n+    public void prepareStatements(Connection connection) throws SQLException {\n+        this.connection = connection;\n+        this.statementPool = new HashMap<>();\n+    }\n+\n+    @Override\n+    public void addToBatch(T record) {\n+        batch.add(record);\n+    }\n+\n+    @Override\n+    public void executeBatch() throws SQLException {\n+        Set<PreparedStatement> usedStatements = new HashSet<>();\n+        if (!batch.isEmpty()) {\n+            LOG.debug(\"Executing statements for {} rows\", batch.size());\n+            for (T r : batch) {\n+                String key = keyExtractor.apply(r);\n+                if (!statementPool.containsKey(key)) {\n+                    prepareStatement(r, key);\n+                }\n+\n+                PreparedStatement stmt = statementPool.get(key);\n+                parameterSetter.accept(stmt, r);\n+                stmt.addBatch();\n+                usedStatements.add(stmt);\n+            }\n+\n+            for (PreparedStatement stmt : usedStatements) {\n+                stmt.executeBatch();\n+            }\n+            batch.clear();\n+        }\n+    }\n+\n+    @Override\n+    public void closeStatements() throws SQLException {\n+        if (statementPool != null) {\n+            for (PreparedStatement stmt : statementPool.values()) {\n+                stmt.close();\n+            }\n+            statementPool = null;\n+        }\n+    }\n+\n+    private void prepareStatement(T value, String key) throws SQLException {\n+        PreparedStatement stmt = connection.prepareStatement(sqlFactory.apply(value));\n+        statementPool.put(key, stmt);\n+    }\n+}"
  },
  {
    "sha": "6488a95f8247e37dea225cb599c41c4f47d40b84",
    "filename": "flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/internal/executor/JdbcBatchStatementExecutor.java",
    "status": "modified",
    "additions": 9,
    "deletions": 0,
    "changes": 9,
    "blob_url": "https://github.com/apache/flink/blob/0b8157ff773760f9c4eb473cc3574d3d0152123c/flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/internal/executor/JdbcBatchStatementExecutor.java",
    "raw_url": "https://github.com/apache/flink/raw/0b8157ff773760f9c4eb473cc3574d3d0152123c/flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/internal/executor/JdbcBatchStatementExecutor.java",
    "contents_url": "https://api.github.com/repos/apache/flink/contents/flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/internal/executor/JdbcBatchStatementExecutor.java?ref=0b8157ff773760f9c4eb473cc3574d3d0152123c",
    "patch": "@@ -19,7 +19,9 @@\n package org.apache.flink.connector.jdbc.internal.executor;\n \n import org.apache.flink.annotation.Internal;\n+import org.apache.flink.connector.jdbc.JdbcKeyCreator;\n import org.apache.flink.connector.jdbc.JdbcStatementBuilder;\n+import org.apache.flink.connector.jdbc.JdbcStatementFactory;\n \n import java.sql.Connection;\n import java.sql.SQLException;\n@@ -49,4 +51,11 @@\n             String sql, JdbcStatementBuilder<V> paramSetter, Function<T, V> valueTransformer) {\n         return new SimpleBatchStatementExecutor<>(sql, paramSetter, valueTransformer);\n     }\n+\n+    static <T> JdbcBatchStatementExecutor<T> dynamic(\n+            JdbcStatementFactory<T> sqlFactory,\n+            JdbcStatementBuilder<T> paramSetter,\n+            JdbcKeyCreator<T> keyCreator) {\n+        return new DynamicBatchStatementExecutor<>(sqlFactory, paramSetter, keyCreator);\n+    }\n }"
  },
  {
    "sha": "d6f4c61b88f0c90bd62f2a50838ae3e791ee6ebb",
    "filename": "flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/xa/JdbcXaSinkFunction.java",
    "status": "modified",
    "additions": 34,
    "deletions": 3,
    "changes": 37,
    "blob_url": "https://github.com/apache/flink/blob/0b8157ff773760f9c4eb473cc3574d3d0152123c/flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/xa/JdbcXaSinkFunction.java",
    "raw_url": "https://github.com/apache/flink/raw/0b8157ff773760f9c4eb473cc3574d3d0152123c/flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/xa/JdbcXaSinkFunction.java",
    "contents_url": "https://api.github.com/repos/apache/flink/contents/flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/xa/JdbcXaSinkFunction.java?ref=0b8157ff773760f9c4eb473cc3574d3d0152123c",
    "patch": "@@ -22,9 +22,7 @@\n import org.apache.flink.api.common.state.CheckpointListener;\n import org.apache.flink.api.java.tuple.Tuple2;\n import org.apache.flink.configuration.Configuration;\n-import org.apache.flink.connector.jdbc.JdbcExactlyOnceOptions;\n-import org.apache.flink.connector.jdbc.JdbcExecutionOptions;\n-import org.apache.flink.connector.jdbc.JdbcStatementBuilder;\n+import org.apache.flink.connector.jdbc.*;\n import org.apache.flink.connector.jdbc.internal.JdbcBatchingOutputFormat;\n import org.apache.flink.connector.jdbc.internal.executor.JdbcBatchStatementExecutor;\n import org.apache.flink.connector.jdbc.xa.XaFacade.EmptyXaTransactionException;\n@@ -177,6 +175,39 @@ public JdbcXaSinkFunction(\n                 new XaGroupOpsImpl(xaFacade));\n     }\n \n+    /**\n+     * Creates a {@link JdbcXaSinkFunction}.\n+     *\n+     * <p>All parameters must be {@link java.io.Serializable serializable}.\n+     *\n+     * @param xaFacade {@link XaFacade} to manage XA transactions\n+     */\n+    public JdbcXaSinkFunction(\n+            JdbcStatementFactory<T> sqlFactory,\n+            JdbcStatementBuilder<T> statementBuilder,\n+            JdbcKeyCreator<T> keyCreator,\n+            XaFacade xaFacade,\n+            JdbcExecutionOptions executionOptions,\n+            JdbcExactlyOnceOptions options) {\n+        this(\n+                new JdbcBatchingOutputFormat<>(\n+                        xaFacade,\n+                        executionOptions,\n+                        context -> {\n+                            Preconditions.checkState(\n+                                    !context.getExecutionConfig().isObjectReuseEnabled(),\n+                                    \"objects can not be reused with JDBC sink function\");\n+                            return JdbcBatchStatementExecutor.dynamic(\n+                                    sqlFactory, statementBuilder, keyCreator);\n+                        },\n+                        JdbcBatchingOutputFormat.RecordExtractor.identity()),\n+                xaFacade,\n+                XidGenerator.semanticXidGenerator(),\n+                new XaSinkStateHandlerImpl(),\n+                options,\n+                new XaGroupOpsImpl(xaFacade));\n+    }\n+\n     /**\n      * Creates a {@link JdbcXaSinkFunction}.\n      *"
  },
  {
    "sha": "35f6338ec5e31044b5835a3dd397e54da5a9dcb8",
    "filename": "flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/xa/XaGroupOpsImpl.java",
    "status": "modified",
    "additions": 1,
    "deletions": 0,
    "changes": 1,
    "blob_url": "https://github.com/apache/flink/blob/0b8157ff773760f9c4eb473cc3574d3d0152123c/flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/xa/XaGroupOpsImpl.java",
    "raw_url": "https://github.com/apache/flink/raw/0b8157ff773760f9c4eb473cc3574d3d0152123c/flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/xa/XaGroupOpsImpl.java",
    "contents_url": "https://api.github.com/repos/apache/flink/contents/flink-connectors/flink-connector-jdbc/src/main/java/org/apache/flink/connector/jdbc/xa/XaGroupOpsImpl.java?ref=0b8157ff773760f9c4eb473cc3574d3d0152123c",
    "patch": "@@ -113,6 +113,7 @@ public void recoverAndRollback() {\n         for (Xid xid : recovered) {\n             try {\n                 xaFacade.rollback(xid);\n+                LOG.info(\"rollbacked transaction {}\", xid);\n             } catch (Exception e) {\n                 LOG.info(\"unable to rollback recovered transaction, xid={}\", xid, e);\n             }"
  },
  {
    "sha": "9ed1c4ca3d907ad24d11e6b7efa359703537ff54",
    "filename": "flink-connectors/flink-connector-jdbc/src/test/java/org/apache/flink/connector/jdbc/JdbcLookupFunctionTest.java",
    "status": "modified",
    "additions": 3,
    "deletions": 0,
    "changes": 3,
    "blob_url": "https://github.com/apache/flink/blob/0b8157ff773760f9c4eb473cc3574d3d0152123c/flink-connectors/flink-connector-jdbc/src/test/java/org/apache/flink/connector/jdbc/JdbcLookupFunctionTest.java",
    "raw_url": "https://github.com/apache/flink/raw/0b8157ff773760f9c4eb473cc3574d3d0152123c/flink-connectors/flink-connector-jdbc/src/test/java/org/apache/flink/connector/jdbc/JdbcLookupFunctionTest.java",
    "contents_url": "https://api.github.com/repos/apache/flink/contents/flink-connectors/flink-connector-jdbc/src/test/java/org/apache/flink/connector/jdbc/JdbcLookupFunctionTest.java?ref=0b8157ff773760f9c4eb473cc3574d3d0152123c",
    "patch": "@@ -75,6 +75,9 @@ public void testEval() throws Exception {\n                         .stream().map(Row::toString).sorted().collect(Collectors.toList());\n \n         List<String> expected = new ArrayList<>();\n+        //        expected.add(\"1,1,11-c1-v1,11-c2-v1\");\n+        //        expected.add(\"1,1,11-c1-v2,11-c2-v2\");\n+        //        expected.add(\"2,3,null,23-c2\");\n         expected.add(\"+I[1, 1, 11-c1-v1, 11-c2-v1]\");\n         expected.add(\"+I[1, 1, 11-c1-v2, 11-c2-v2]\");\n         expected.add(\"+I[2, 3, null, 23-c2]\");"
  },
  {
    "sha": "8893cbfc0d8630183c6071f57095af6fef6e2a9a",
    "filename": "flink-connectors/flink-connector-jdbc/src/test/java/org/apache/flink/connector/jdbc/JdbcTestFixture.java",
    "status": "modified",
    "additions": 3,
    "deletions": 0,
    "changes": 3,
    "blob_url": "https://github.com/apache/flink/blob/0b8157ff773760f9c4eb473cc3574d3d0152123c/flink-connectors/flink-connector-jdbc/src/test/java/org/apache/flink/connector/jdbc/JdbcTestFixture.java",
    "raw_url": "https://github.com/apache/flink/raw/0b8157ff773760f9c4eb473cc3574d3d0152123c/flink-connectors/flink-connector-jdbc/src/test/java/org/apache/flink/connector/jdbc/JdbcTestFixture.java",
    "contents_url": "https://api.github.com/repos/apache/flink/contents/flink-connectors/flink-connector-jdbc/src/test/java/org/apache/flink/connector/jdbc/JdbcTestFixture.java?ref=0b8157ff773760f9c4eb473cc3574d3d0152123c",
    "patch": "@@ -40,6 +40,7 @@\n     public static final JdbcTestCheckpoint CP1 = new JdbcTestCheckpoint(1, 4, 5, 6);\n \n     public static final String INPUT_TABLE = \"books\";\n+    public static final String INPUT_TABLE_2 = \"books2\";\n     public static final String OUTPUT_TABLE = \"newbooks\";\n     public static final String OUTPUT_TABLE_2 = \"newbooks2\";\n     public static final String OUTPUT_TABLE_3 = \"newbooks3\";\n@@ -190,6 +191,7 @@ public static void initSchema(DbMetadata dbMetadata)\n         Class.forName(dbMetadata.getDriverClass());\n         try (Connection conn = DriverManager.getConnection(dbMetadata.getInitUrl())) {\n             createTable(conn, JdbcTestFixture.INPUT_TABLE);\n+            createTable(conn, JdbcTestFixture.INPUT_TABLE_2);\n             createTable(conn, OUTPUT_TABLE);\n             createTable(conn, OUTPUT_TABLE_2);\n             createTable(conn, OUTPUT_TABLE_3);\n@@ -221,6 +223,7 @@ public static void cleanUpDatabasesStatic(DbMetadata dbMetadata)\n                 Statement stat = conn.createStatement()) {\n \n             stat.executeUpdate(\"DROP TABLE \" + INPUT_TABLE);\n+            stat.executeUpdate(\"DROP TABLE \" + INPUT_TABLE_2);\n             stat.executeUpdate(\"DROP TABLE \" + OUTPUT_TABLE);\n             stat.executeUpdate(\"DROP TABLE \" + OUTPUT_TABLE_2);\n             stat.executeUpdate(\"DROP TABLE \" + OUTPUT_TABLE_3);"
  },
  {
    "sha": "ac70b9c2440dbc22e9a1207cb85f805096b573e6",
    "filename": "flink-connectors/flink-connector-jdbc/src/test/java/org/apache/flink/connector/jdbc/xa/CheckpointAwaitingSource.java",
    "status": "added",
    "additions": 73,
    "deletions": 0,
    "changes": 73,
    "blob_url": "https://github.com/apache/flink/blob/0b8157ff773760f9c4eb473cc3574d3d0152123c/flink-connectors/flink-connector-jdbc/src/test/java/org/apache/flink/connector/jdbc/xa/CheckpointAwaitingSource.java",
    "raw_url": "https://github.com/apache/flink/raw/0b8157ff773760f9c4eb473cc3574d3d0152123c/flink-connectors/flink-connector-jdbc/src/test/java/org/apache/flink/connector/jdbc/xa/CheckpointAwaitingSource.java",
    "contents_url": "https://api.github.com/repos/apache/flink/contents/flink-connectors/flink-connector-jdbc/src/test/java/org/apache/flink/connector/jdbc/xa/CheckpointAwaitingSource.java?ref=0b8157ff773760f9c4eb473cc3574d3d0152123c",
    "patch": "@@ -0,0 +1,73 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.connector.jdbc.xa;\n+\n+import org.apache.flink.runtime.state.CheckpointListener;\n+import org.apache.flink.runtime.state.FunctionInitializationContext;\n+import org.apache.flink.runtime.state.FunctionSnapshotContext;\n+import org.apache.flink.streaming.api.checkpoint.CheckpointedFunction;\n+import org.apache.flink.streaming.api.functions.source.SourceFunction;\n+\n+import java.io.Serializable;\n+import java.util.List;\n+\n+public class CheckpointAwaitingSource<T extends Serializable>\n+        implements SourceFunction<T>, CheckpointListener, CheckpointedFunction {\n+    private volatile boolean allDataEmitted = false;\n+    private volatile boolean dataCheckpointed = false;\n+    private volatile boolean running = true;\n+    private volatile long checkpointAfterData = -1L;\n+    private final List<T> data;\n+\n+    public CheckpointAwaitingSource(List<T> data) {\n+        this.data = data;\n+    }\n+\n+    @Override\n+    public void run(SourceContext<T> ctx) {\n+        for (T datum : data) {\n+            ctx.collect(datum);\n+        }\n+        allDataEmitted = true;\n+        while (!dataCheckpointed && running) {\n+            Thread.yield();\n+        }\n+    }\n+\n+    @Override\n+    public void cancel() {\n+        running = false;\n+    }\n+\n+    @Override\n+    public void notifyCheckpointComplete(long checkpointId) {\n+        if (checkpointId == this.checkpointAfterData) {\n+            dataCheckpointed = true;\n+        }\n+    }\n+\n+    @Override\n+    public void snapshotState(FunctionSnapshotContext context) {\n+        if (allDataEmitted) {\n+            checkpointAfterData = context.getCheckpointId();\n+        }\n+    }\n+\n+    @Override\n+    public void initializeState(FunctionInitializationContext context) {}\n+}"
  },
  {
    "sha": "8239c1d0d873a7c6080aa00635c06bd781be7e85",
    "filename": "flink-connectors/flink-connector-jdbc/src/test/java/org/apache/flink/connector/jdbc/xa/JdbcDynamicExactlyOnceSinkE2eTest.java",
    "status": "added",
    "additions": 91,
    "deletions": 0,
    "changes": 91,
    "blob_url": "https://github.com/apache/flink/blob/0b8157ff773760f9c4eb473cc3574d3d0152123c/flink-connectors/flink-connector-jdbc/src/test/java/org/apache/flink/connector/jdbc/xa/JdbcDynamicExactlyOnceSinkE2eTest.java",
    "raw_url": "https://github.com/apache/flink/raw/0b8157ff773760f9c4eb473cc3574d3d0152123c/flink-connectors/flink-connector-jdbc/src/test/java/org/apache/flink/connector/jdbc/xa/JdbcDynamicExactlyOnceSinkE2eTest.java",
    "contents_url": "https://api.github.com/repos/apache/flink/contents/flink-connectors/flink-connector-jdbc/src/test/java/org/apache/flink/connector/jdbc/xa/JdbcDynamicExactlyOnceSinkE2eTest.java?ref=0b8157ff773760f9c4eb473cc3574d3d0152123c",
    "patch": "@@ -0,0 +1,91 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.flink.connector.jdbc.xa;\n+\n+import org.apache.flink.api.common.restartstrategy.RestartStrategies.NoRestartStrategyConfiguration;\n+import org.apache.flink.connector.jdbc.DbMetadata;\n+import org.apache.flink.connector.jdbc.JdbcExactlyOnceOptions;\n+import org.apache.flink.connector.jdbc.JdbcExecutionOptions;\n+import org.apache.flink.connector.jdbc.JdbcITCase;\n+import org.apache.flink.connector.jdbc.JdbcSink;\n+import org.apache.flink.connector.jdbc.JdbcTestFixture.TestEntry;\n+import org.apache.flink.streaming.api.CheckpointingMode;\n+import org.apache.flink.streaming.api.TimeCharacteristic;\n+import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;\n+\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.util.Arrays;\n+\n+import static org.apache.flink.connector.jdbc.JdbcTestFixture.*;\n+\n+/** A simple end-to-end test for {@link JdbcXaSinkFunction}. */\n+public class JdbcDynamicExactlyOnceSinkE2eTest extends JdbcXaSinkTestBase {\n+\n+    @Override\n+    @Before\n+    public void initHelpers() throws Exception {\n+        xaDataSource = getDbMetadata().buildXaDataSource();\n+        xaHelper =\n+                new JdbcXaFacadeTestHelper(\n+                        getDbMetadata().buildXaDataSource(),\n+                        getDbMetadata().getUrl(),\n+                        Arrays.asList(INPUT_TABLE, INPUT_TABLE_2));\n+        sinkHelper = buildSinkHelper(createStateHandler());\n+    }\n+\n+    @Test\n+    public void testDynamicTableInsert() throws Exception {\n+        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n+        env.setParallelism(1);\n+        env.setRestartStrategy(new NoRestartStrategyConfiguration());\n+        env.setStreamTimeCharacteristic(TimeCharacteristic.ProcessingTime);\n+        env.enableCheckpointing(50, CheckpointingMode.EXACTLY_ONCE);\n+        env.addSource(new CheckpointAwaitingSource<>(Arrays.asList(TEST_DATA)))\n+                .returns(TestEntry.class)\n+                .addSink(\n+                        JdbcSink.exactlyOnceSinkWithDynamicOutput(\n+                                (elem) -> {\n+                                    if (elem.id % 2 == 0) {\n+                                        return String.format(INSERT_TEMPLATE, INPUT_TABLE);\n+                                    } else {\n+                                        return String.format(INSERT_TEMPLATE, INPUT_TABLE_2);\n+                                    }\n+                                },\n+                                JdbcITCase.TEST_ENTRY_JDBC_STATEMENT_BUILDER,\n+                                (elem) -> {\n+                                    if (elem.id % 2 == 0) {\n+                                        return \"1\";\n+                                    } else {\n+                                        return \"2\";\n+                                    }\n+                                },\n+                                JdbcExecutionOptions.builder().build(),\n+                                JdbcExactlyOnceOptions.defaults(),\n+                                DERBY_EBOOKSHOP_DB::buildXaDataSource));\n+        env.execute();\n+        xaHelper.assertDbContentsEquals(\n+                Arrays.asList(1002, 1004, 1006, 1008, 1010, 1001, 1003, 1005, 1007, 1009));\n+    }\n+\n+    @Override\n+    protected DbMetadata getDbMetadata() {\n+        return DERBY_EBOOKSHOP_DB;\n+    }\n+}"
  },
  {
    "sha": "1a0837bbcbdfb31c0be58e5b4e023911564b99d8",
    "filename": "flink-connectors/flink-connector-jdbc/src/test/java/org/apache/flink/connector/jdbc/xa/JdbcExactlyOnceSinkE2eTest.java",
    "status": "modified",
    "additions": 2,
    "deletions": 54,
    "changes": 56,
    "blob_url": "https://github.com/apache/flink/blob/0b8157ff773760f9c4eb473cc3574d3d0152123c/flink-connectors/flink-connector-jdbc/src/test/java/org/apache/flink/connector/jdbc/xa/JdbcExactlyOnceSinkE2eTest.java",
    "raw_url": "https://github.com/apache/flink/raw/0b8157ff773760f9c4eb473cc3574d3d0152123c/flink-connectors/flink-connector-jdbc/src/test/java/org/apache/flink/connector/jdbc/xa/JdbcExactlyOnceSinkE2eTest.java",
    "contents_url": "https://api.github.com/repos/apache/flink/contents/flink-connectors/flink-connector-jdbc/src/test/java/org/apache/flink/connector/jdbc/xa/JdbcExactlyOnceSinkE2eTest.java?ref=0b8157ff773760f9c4eb473cc3574d3d0152123c",
    "patch": "@@ -24,18 +24,13 @@\n import org.apache.flink.connector.jdbc.JdbcITCase;\n import org.apache.flink.connector.jdbc.JdbcSink;\n import org.apache.flink.connector.jdbc.JdbcTestFixture.TestEntry;\n-import org.apache.flink.runtime.state.CheckpointListener;\n-import org.apache.flink.runtime.state.FunctionInitializationContext;\n-import org.apache.flink.runtime.state.FunctionSnapshotContext;\n import org.apache.flink.streaming.api.CheckpointingMode;\n import org.apache.flink.streaming.api.TimeCharacteristic;\n-import org.apache.flink.streaming.api.checkpoint.CheckpointedFunction;\n import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;\n-import org.apache.flink.streaming.api.functions.source.SourceFunction;\n \n import org.junit.Test;\n \n-import java.io.Serializable;\n+import java.util.Arrays;\n import java.util.stream.IntStream;\n \n import static org.apache.flink.connector.jdbc.JdbcTestFixture.DERBY_EBOOKSHOP_DB;\n@@ -53,7 +48,7 @@ public void testInsert() throws Exception {\n         env.setRestartStrategy(new NoRestartStrategyConfiguration());\n         env.setStreamTimeCharacteristic(TimeCharacteristic.ProcessingTime);\n         env.enableCheckpointing(50, CheckpointingMode.EXACTLY_ONCE);\n-        env.addSource(new CheckpointAwaitingSource<>(TEST_DATA))\n+        env.addSource(new CheckpointAwaitingSource<>(Arrays.asList(TEST_DATA)))\n                 .returns(TestEntry.class)\n                 .addSink(\n                         JdbcSink.exactlyOnceSink(\n@@ -71,51 +66,4 @@ public void testInsert() throws Exception {\n     protected DbMetadata getDbMetadata() {\n         return DERBY_EBOOKSHOP_DB;\n     }\n-\n-    /** {@link SourceFunction} emits all the data and waits for the checkpoint. */\n-    private static class CheckpointAwaitingSource<T extends Serializable>\n-            implements SourceFunction<T>, CheckpointListener, CheckpointedFunction {\n-        private volatile boolean allDataEmitted = false;\n-        private volatile boolean dataCheckpointed = false;\n-        private volatile boolean running = true;\n-        private volatile long checkpointAfterData = -1L;\n-        private final T[] data;\n-\n-        private CheckpointAwaitingSource(T... data) {\n-            this.data = data;\n-        }\n-\n-        @Override\n-        public void run(SourceContext<T> ctx) {\n-            for (T datum : data) {\n-                ctx.collect(datum);\n-            }\n-            allDataEmitted = true;\n-            while (!dataCheckpointed && running) {\n-                Thread.yield();\n-            }\n-        }\n-\n-        @Override\n-        public void cancel() {\n-            running = false;\n-        }\n-\n-        @Override\n-        public void notifyCheckpointComplete(long checkpointId) {\n-            if (checkpointId == this.checkpointAfterData) {\n-                dataCheckpointed = true;\n-            }\n-        }\n-\n-        @Override\n-        public void snapshotState(FunctionSnapshotContext context) {\n-            if (allDataEmitted) {\n-                checkpointAfterData = context.getCheckpointId();\n-            }\n-        }\n-\n-        @Override\n-        public void initializeState(FunctionInitializationContext context) {}\n-    }\n }"
  },
  {
    "sha": "5e8477993fc9c662a8fe0382847a122ab19cff67",
    "filename": "flink-connectors/flink-connector-jdbc/src/test/java/org/apache/flink/connector/jdbc/xa/JdbcXaFacadeTestHelper.java",
    "status": "modified",
    "additions": 22,
    "deletions": 10,
    "changes": 32,
    "blob_url": "https://github.com/apache/flink/blob/0b8157ff773760f9c4eb473cc3574d3d0152123c/flink-connectors/flink-connector-jdbc/src/test/java/org/apache/flink/connector/jdbc/xa/JdbcXaFacadeTestHelper.java",
    "raw_url": "https://github.com/apache/flink/raw/0b8157ff773760f9c4eb473cc3574d3d0152123c/flink-connectors/flink-connector-jdbc/src/test/java/org/apache/flink/connector/jdbc/xa/JdbcXaFacadeTestHelper.java",
    "contents_url": "https://api.github.com/repos/apache/flink/contents/flink-connectors/flink-connector-jdbc/src/test/java/org/apache/flink/connector/jdbc/xa/JdbcXaFacadeTestHelper.java?ref=0b8157ff773760f9c4eb473cc3574d3d0152123c",
    "patch": "@@ -28,6 +28,7 @@\n import java.sql.Statement;\n import java.util.ArrayList;\n import java.util.Arrays;\n+import java.util.Collections;\n import java.util.List;\n import java.util.stream.Collectors;\n import java.util.stream.IntStream;\n@@ -37,14 +38,19 @@\n \n class JdbcXaFacadeTestHelper implements AutoCloseable {\n     private final XADataSource xaDataSource;\n-    private final String table;\n+    private final List<String> tables;\n     private final String dbUrl;\n     private final XaFacade xaFacade;\n \n     JdbcXaFacadeTestHelper(XADataSource xaDataSource, String dbUrl, String table) throws Exception {\n+        this(xaDataSource, dbUrl, Collections.singletonList(table));\n+    }\n+\n+    JdbcXaFacadeTestHelper(XADataSource xaDataSource, String dbUrl, List<String> tables)\n+            throws Exception {\n         this.xaDataSource = xaDataSource;\n         this.dbUrl = dbUrl;\n-        this.table = table;\n+        this.tables = tables;\n         this.xaFacade = XaFacadeImpl.fromXaDataSource(this.xaDataSource);\n         this.xaFacade.open();\n     }\n@@ -80,10 +86,12 @@ void assertDbContentsEquals(List<Integer> expected) throws SQLException {\n         try (Connection connection = DriverManager.getConnection(dbUrl)) {\n             connection.setTransactionIsolation(Connection.TRANSACTION_READ_COMMITTED);\n             connection.setReadOnly(true);\n-            try (Statement st = connection.createStatement()) {\n-                try (ResultSet rs = st.executeQuery(\"select id from \" + table)) {\n-                    while (rs.next()) {\n-                        dbContents.add(rs.getInt(1));\n+            for (String table : tables) {\n+                try (Statement st = connection.createStatement()) {\n+                    try (ResultSet rs = st.executeQuery(\"select id from \" + table)) {\n+                        while (rs.next()) {\n+                            dbContents.add(rs.getInt(1));\n+                        }\n                     }\n                 }\n             }\n@@ -92,16 +100,20 @@ void assertDbContentsEquals(List<Integer> expected) throws SQLException {\n     }\n \n     int countInDb() throws SQLException {\n+        int counts = 0;\n         try (Connection connection = DriverManager.getConnection(dbUrl)) {\n             connection.setTransactionIsolation(Connection.TRANSACTION_READ_COMMITTED);\n             connection.setReadOnly(true);\n-            try (Statement st = connection.createStatement()) {\n-                try (ResultSet rs = st.executeQuery(\"select count(1) from \" + table)) {\n-                    rs.next();\n-                    return rs.getInt(1);\n+            for (String table : tables) {\n+                try (Statement st = connection.createStatement()) {\n+                    try (ResultSet rs = st.executeQuery(\"select count(1) from \" + table)) {\n+                        rs.next();\n+                        counts += rs.getInt(1);\n+                    }\n                 }\n             }\n         }\n+        return counts;\n     }\n \n     public XADataSource getXaDataSource() {"
  },
  {
    "sha": "20757779ecedb3b9e6cd1752681fa6bb462ea84c",
    "filename": "flink-connectors/flink-connector-jdbc/src/test/java/org/apache/flink/connector/jdbc/xa/JdbcXaSinkTestBase.java",
    "status": "modified",
    "additions": 19,
    "deletions": 6,
    "changes": 25,
    "blob_url": "https://github.com/apache/flink/blob/0b8157ff773760f9c4eb473cc3574d3d0152123c/flink-connectors/flink-connector-jdbc/src/test/java/org/apache/flink/connector/jdbc/xa/JdbcXaSinkTestBase.java",
    "raw_url": "https://github.com/apache/flink/raw/0b8157ff773760f9c4eb473cc3574d3d0152123c/flink-connectors/flink-connector-jdbc/src/test/java/org/apache/flink/connector/jdbc/xa/JdbcXaSinkTestBase.java",
    "contents_url": "https://api.github.com/repos/apache/flink/contents/flink-connectors/flink-connector-jdbc/src/test/java/org/apache/flink/connector/jdbc/xa/JdbcXaSinkTestBase.java?ref=0b8157ff773760f9c4eb473cc3574d3d0152123c",
    "patch": "@@ -91,7 +91,7 @@ public void initHelpers() throws Exception {\n         sinkHelper = buildSinkHelper(createStateHandler());\n     }\n \n-    private XaSinkStateHandler createStateHandler() {\n+    protected XaSinkStateHandler createStateHandler() {\n         return new TestXaSinkStateHandler();\n     }\n \n@@ -136,6 +136,7 @@ private XaFacadeImpl getXaFacade() {\n     }\n \n     static JdbcXaSinkFunction<TestEntry> buildSink(\n+            JdbcBatchStatementExecutor<TestEntry> statementExecutor,\n             XidGenerator xidGenerator,\n             XaFacade xaFacade,\n             XaSinkStateHandler state,\n@@ -147,11 +148,7 @@ private XaFacadeImpl getXaFacade() {\n                                 JdbcExecutionOptions.builder()\n                                         .withBatchIntervalMs(batchInterval)\n                                         .build(),\n-                                ctx ->\n-                                        JdbcBatchStatementExecutor.simple(\n-                                                String.format(INSERT_TEMPLATE, INPUT_TABLE),\n-                                                TEST_ENTRY_JDBC_STATEMENT_BUILDER,\n-                                                Function.identity()),\n+                                ctx -> statementExecutor,\n                                 JdbcBatchingOutputFormat.RecordExtractor.identity());\n         JdbcXaSinkFunction<TestEntry> sink =\n                 new JdbcXaSinkFunction<>(\n@@ -165,6 +162,22 @@ private XaFacadeImpl getXaFacade() {\n         return sink;\n     }\n \n+    static JdbcXaSinkFunction<TestEntry> buildSink(\n+            XidGenerator xidGenerator,\n+            XaFacade xaFacade,\n+            XaSinkStateHandler state,\n+            int batchInterval) {\n+        return buildSink(\n+                JdbcBatchStatementExecutor.simple(\n+                        String.format(INSERT_TEMPLATE, INPUT_TABLE),\n+                        TEST_ENTRY_JDBC_STATEMENT_BUILDER,\n+                        Function.identity()),\n+                xidGenerator,\n+                xaFacade,\n+                state,\n+                batchInterval);\n+    }\n+\n     static final RuntimeContext TEST_RUNTIME_CONTEXT =\n             new RuntimeContext() {\n                 @Override"
  }
]
