[
  {
    "sha": "58889d76da1283b39eee4e1f4d1b4597e51e1cd5",
    "filename": "flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/connectors/hive/HiveDynamicTableFactory.java",
    "status": "modified",
    "additions": 12,
    "deletions": 30,
    "changes": 42,
    "blob_url": "https://github.com/apache/flink/blob/07ff0742be91c9e503b91a31700bacad8fa03edd/flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/connectors/hive/HiveDynamicTableFactory.java",
    "raw_url": "https://github.com/apache/flink/raw/07ff0742be91c9e503b91a31700bacad8fa03edd/flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/connectors/hive/HiveDynamicTableFactory.java",
    "contents_url": "https://api.github.com/repos/apache/flink/contents/flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/connectors/hive/HiveDynamicTableFactory.java?ref=07ff0742be91c9e503b91a31700bacad8fa03edd",
    "patch": "@@ -20,8 +20,6 @@\n \n import org.apache.flink.configuration.ConfigOption;\n import org.apache.flink.configuration.Configuration;\n-import org.apache.flink.table.api.ValidationException;\n-import org.apache.flink.table.catalog.CatalogPropertiesUtil;\n import org.apache.flink.table.catalog.CatalogTable;\n import org.apache.flink.table.connector.sink.DynamicTableSink;\n import org.apache.flink.table.connector.source.DynamicTableSource;\n@@ -34,11 +32,10 @@\n import org.apache.hadoop.hive.conf.HiveConf;\n import org.apache.hadoop.mapred.JobConf;\n \n-import java.util.HashMap;\n-import java.util.Map;\n import java.util.Set;\n \n-import static org.apache.flink.table.catalog.CatalogPropertiesUtil.IS_GENERIC;\n+import static org.apache.flink.sql.parser.hive.ddl.SqlCreateHiveTable.IDENTIFIER;\n+import static org.apache.flink.table.factories.FactoryUtil.CONNECTOR;\n import static org.apache.flink.table.filesystem.FileSystemOptions.STREAMING_SOURCE_ENABLE;\n import static org.apache.flink.table.filesystem.FileSystemOptions.STREAMING_SOURCE_PARTITION_INCLUDE;\n \n@@ -66,26 +63,11 @@ public String factoryIdentifier() {\n         throw new UnsupportedOperationException(\"Hive factory is only work for catalog.\");\n     }\n \n-    private static CatalogTable removeIsGenericFlag(Context context) {\n-        Map<String, String> newOptions = new HashMap<>(context.getCatalogTable().getOptions());\n-        boolean isGeneric = Boolean.parseBoolean(newOptions.remove(IS_GENERIC));\n-        // temporary table doesn't have the IS_GENERIC flag but we still consider it generic\n-        if (!isGeneric && !context.isTemporary()) {\n-            throw new ValidationException(\n-                    \"Hive dynamic table factory now only work for generic table.\");\n-        }\n-        return context.getCatalogTable().copy(newOptions);\n-    }\n-\n     @Override\n     public DynamicTableSink createDynamicTableSink(Context context) {\n-        boolean isGeneric =\n-                Boolean.parseBoolean(\n-                        context.getCatalogTable()\n-                                .getOptions()\n-                                .get(CatalogPropertiesUtil.IS_GENERIC));\n+        boolean isGeneric = isGeneric(context.getCatalogTable());\n \n-        // temporary table doesn't have the IS_GENERIC flag but we still consider it generic\n+        // temporary table is considered generic\n         if (!isGeneric && !context.isTemporary()) {\n             Integer configuredParallelism =\n                     Configuration.fromMap(context.getCatalogTable().getOptions())\n@@ -100,7 +82,7 @@ public DynamicTableSink createDynamicTableSink(Context context) {\n             return FactoryUtil.createTableSink(\n                     null, // we already in the factory of catalog\n                     context.getObjectIdentifier(),\n-                    removeIsGenericFlag(context),\n+                    context.getCatalogTable(),\n                     context.getConfiguration(),\n                     context.getClassLoader(),\n                     context.isTemporary());\n@@ -109,13 +91,9 @@ public DynamicTableSink createDynamicTableSink(Context context) {\n \n     @Override\n     public DynamicTableSource createDynamicTableSource(Context context) {\n-        boolean isGeneric =\n-                Boolean.parseBoolean(\n-                        context.getCatalogTable()\n-                                .getOptions()\n-                                .get(CatalogPropertiesUtil.IS_GENERIC));\n+        boolean isGeneric = isGeneric(context.getCatalogTable());\n \n-        // temporary table doesn't have the IS_GENERIC flag but we still consider it generic\n+        // temporary table is considered generic\n         if (!isGeneric && !context.isTemporary()) {\n             CatalogTable catalogTable = Preconditions.checkNotNull(context.getCatalogTable());\n \n@@ -157,10 +135,14 @@ public DynamicTableSource createDynamicTableSource(Context context) {\n             return FactoryUtil.createTableSource(\n                     null, // we already in the factory of catalog\n                     context.getObjectIdentifier(),\n-                    removeIsGenericFlag(context),\n+                    context.getCatalogTable(),\n                     context.getConfiguration(),\n                     context.getClassLoader(),\n                     context.isTemporary());\n         }\n     }\n+\n+    public static boolean isGeneric(CatalogTable catalogTable) {\n+        return !IDENTIFIER.equalsIgnoreCase(catalogTable.getOptions().get(CONNECTOR.key()));\n+    }\n }"
  },
  {
    "sha": "1b99866351dac5366a029b978a8f1d0819328974",
    "filename": "flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/connectors/hive/HiveTableFactory.java",
    "status": "modified",
    "additions": 3,
    "deletions": 6,
    "changes": 9,
    "blob_url": "https://github.com/apache/flink/blob/07ff0742be91c9e503b91a31700bacad8fa03edd/flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/connectors/hive/HiveTableFactory.java",
    "raw_url": "https://github.com/apache/flink/raw/07ff0742be91c9e503b91a31700bacad8fa03edd/flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/connectors/hive/HiveTableFactory.java",
    "contents_url": "https://api.github.com/repos/apache/flink/contents/flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/connectors/hive/HiveTableFactory.java?ref=07ff0742be91c9e503b91a31700bacad8fa03edd",
    "patch": "@@ -18,7 +18,6 @@\n \n package org.apache.flink.connectors.hive;\n \n-import org.apache.flink.table.catalog.CatalogPropertiesUtil;\n import org.apache.flink.table.catalog.CatalogTable;\n import org.apache.flink.table.catalog.CatalogTableImpl;\n import org.apache.flink.table.factories.TableFactoryUtil;\n@@ -51,10 +50,9 @@ public TableSource createTableSource(TableSourceFactory.Context context) {\n         CatalogTable table = checkNotNull(context.getTable());\n         Preconditions.checkArgument(table instanceof CatalogTableImpl);\n \n-        boolean isGeneric =\n-                Boolean.parseBoolean(table.getOptions().get(CatalogPropertiesUtil.IS_GENERIC));\n+        boolean isGeneric = HiveDynamicTableFactory.isGeneric(table);\n \n-        // temporary table doesn't have the IS_GENERIC flag but we still consider it generic\n+        // temporary table is considered generic\n         if (!isGeneric && !context.isTemporary()) {\n             throw new UnsupportedOperationException(\n                     \"Hive table should be resolved by HiveDynamicTableFactory.\");\n@@ -68,8 +66,7 @@ public TableSink createTableSink(TableSinkFactory.Context context) {\n         CatalogTable table = checkNotNull(context.getTable());\n         Preconditions.checkArgument(table instanceof CatalogTableImpl);\n \n-        boolean isGeneric =\n-                Boolean.parseBoolean(table.getOptions().get(CatalogPropertiesUtil.IS_GENERIC));\n+        boolean isGeneric = HiveDynamicTableFactory.isGeneric(table);\n \n         // temporary table doesn't have the IS_GENERIC flag but we still consider it generic\n         if (!isGeneric && !context.isTemporary()) {"
  },
  {
    "sha": "e39a68ca9b7d9f83d755d628f62044c5f520d3ab",
    "filename": "flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/table/catalog/hive/HiveCatalog.java",
    "status": "modified",
    "additions": 37,
    "deletions": 55,
    "changes": 92,
    "blob_url": "https://github.com/apache/flink/blob/07ff0742be91c9e503b91a31700bacad8fa03edd/flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/table/catalog/hive/HiveCatalog.java",
    "raw_url": "https://github.com/apache/flink/raw/07ff0742be91c9e503b91a31700bacad8fa03edd/flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/table/catalog/hive/HiveCatalog.java",
    "contents_url": "https://api.github.com/repos/apache/flink/contents/flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/table/catalog/hive/HiveCatalog.java?ref=07ff0742be91c9e503b91a31700bacad8fa03edd",
    "patch": "@@ -118,13 +118,16 @@\n import static org.apache.flink.sql.parser.hive.ddl.SqlAlterHiveTable.ALTER_COL_CASCADE;\n import static org.apache.flink.sql.parser.hive.ddl.SqlAlterHiveTable.ALTER_TABLE_OP;\n import static org.apache.flink.sql.parser.hive.ddl.SqlCreateHiveTable.HiveTableStoredAs.STORED_AS_FILE_FORMAT;\n+import static org.apache.flink.sql.parser.hive.ddl.SqlCreateHiveTable.IDENTIFIER;\n import static org.apache.flink.sql.parser.hive.ddl.SqlCreateHiveTable.NOT_NULL_COLS;\n import static org.apache.flink.sql.parser.hive.ddl.SqlCreateHiveTable.NOT_NULL_CONSTRAINT_TRAITS;\n import static org.apache.flink.sql.parser.hive.ddl.SqlCreateHiveTable.PK_CONSTRAINT_TRAIT;\n import static org.apache.flink.table.catalog.CatalogPropertiesUtil.FLINK_PROPERTY_PREFIX;\n import static org.apache.flink.table.catalog.hive.util.HiveStatsUtil.parsePositiveIntStat;\n import static org.apache.flink.table.catalog.hive.util.HiveStatsUtil.parsePositiveLongStat;\n import static org.apache.flink.table.catalog.hive.util.HiveTableUtil.getHadoopConfiguration;\n+import static org.apache.flink.table.descriptors.ConnectorDescriptorValidator.CONNECTOR_TYPE;\n+import static org.apache.flink.table.factories.FactoryUtil.CONNECTOR;\n import static org.apache.flink.table.utils.PartitionPathUtils.unescapePathName;\n import static org.apache.flink.util.Preconditions.checkArgument;\n import static org.apache.flink.util.Preconditions.checkNotNull;\n@@ -678,9 +681,9 @@ private CatalogBaseTable instantiateCatalogTable(Table hiveTable, HiveConf hiveC\n         boolean isView = TableType.valueOf(hiveTable.getTableType()) == TableType.VIRTUAL_VIEW;\n \n         // Table properties\n-        Map<String, String> properties = hiveTable.getParameters();\n+        Map<String, String> properties = new HashMap<>(hiveTable.getParameters());\n \n-        boolean isGeneric = isGenericForGet(hiveTable.getParameters());\n+        boolean isGeneric = isGenericForGet(properties);\n \n         TableSchema tableSchema;\n         // Partition keys\n@@ -709,7 +712,7 @@ private CatalogBaseTable instantiateCatalogTable(Table hiveTable, HiveConf hiveC\n             // remove the schema from properties\n             properties = CatalogTableImpl.removeRedundant(properties, tableSchema, partitionKeys);\n         } else {\n-            properties.put(CatalogPropertiesUtil.IS_GENERIC, String.valueOf(false));\n+            properties.put(CONNECTOR.key(), IDENTIFIER);\n             // Table schema\n             List<FieldSchema> fields = getNonPartitionFields(hiveConf, hiveTable);\n             Set<String> notNullColumns =\n@@ -738,6 +741,9 @@ private CatalogBaseTable instantiateCatalogTable(Table hiveTable, HiveConf hiveC\n \n         String comment = properties.remove(HiveCatalogConfig.COMMENT);\n \n+        // remove this flag since we don't need it for tables\n+        properties.remove(CatalogPropertiesUtil.IS_GENERIC);\n+\n         if (isView) {\n             return new CatalogViewImpl(\n                     hiveTable.getViewOriginalText(),\n@@ -768,10 +774,7 @@ private CatalogBaseTable instantiateCatalogTable(Table hiveTable, HiveConf hiveC\n     private static Map<String, String> retrieveFlinkProperties(\n             Map<String, String> hiveTableParams) {\n         return hiveTableParams.entrySet().stream()\n-                .filter(\n-                        e ->\n-                                e.getKey().startsWith(FLINK_PROPERTY_PREFIX)\n-                                        || e.getKey().equals(CatalogPropertiesUtil.IS_GENERIC))\n+                .filter(e -> e.getKey().startsWith(FLINK_PROPERTY_PREFIX))\n                 .collect(\n                         Collectors.toMap(\n                                 e -> e.getKey().replace(FLINK_PROPERTY_PREFIX, \"\"),\n@@ -811,19 +814,16 @@ public void createPartition(\n         checkNotNull(partitionSpec, \"CatalogPartitionSpec cannot be null\");\n         checkNotNull(partition, \"Partition cannot be null\");\n \n-        boolean isGeneric =\n-                Boolean.valueOf(partition.getProperties().get(CatalogPropertiesUtil.IS_GENERIC));\n+        Table hiveTable = getHiveTable(tablePath);\n+        ensurePartitionedTable(tablePath, hiveTable);\n+\n+        // partition inherits 'is_generic' from table\n+        boolean isGeneric = isGenericForGet(hiveTable.getParameters());\n \n         if (isGeneric) {\n             throw new CatalogException(\"Currently only supports non-generic CatalogPartition\");\n         }\n \n-        Table hiveTable = getHiveTable(tablePath);\n-\n-        ensureTableAndPartitionMatch(hiveTable, partition);\n-\n-        ensurePartitionedTable(tablePath, hiveTable);\n-\n         try {\n             client.add_partition(instantiateHivePartition(hiveTable, partitionSpec, partition));\n         } catch (AlreadyExistsException e) {\n@@ -1010,18 +1010,16 @@ public void alterPartition(\n         checkNotNull(partitionSpec, \"CatalogPartitionSpec cannot be null\");\n         checkNotNull(newPartition, \"New partition cannot be null\");\n \n-        boolean isGeneric = isGenericForGet(newPartition.getProperties());\n-\n-        if (isGeneric) {\n-            throw new CatalogException(\"Currently only supports non-generic CatalogPartition\");\n-        }\n-\n         // Explicitly check if the partition exists or not\n         // because alter_partition() doesn't throw NoSuchObjectException like dropPartition() when\n         // the target doesn't exist\n         try {\n             Table hiveTable = getHiveTable(tablePath);\n-            ensureTableAndPartitionMatch(hiveTable, newPartition);\n+            boolean isGeneric = isGenericForGet(hiveTable.getParameters());\n+            if (isGeneric) {\n+                throw new CatalogException(\"Currently only supports non-generic CatalogPartition\");\n+            }\n+\n             Partition hivePartition = getHivePartition(hiveTable, partitionSpec);\n             if (hivePartition == null) {\n                 if (ignoreIfNotExists) {\n@@ -1061,21 +1059,6 @@ public void alterPartition(\n         }\n     }\n \n-    // make sure both table and partition are generic, or neither is\n-    private static void ensureTableAndPartitionMatch(\n-            Table hiveTable, CatalogPartition catalogPartition) {\n-        boolean tableIsGeneric = isGenericForGet(hiveTable.getParameters());\n-        boolean partitionIsGeneric = isGenericForGet(catalogPartition.getProperties());\n-\n-        if (tableIsGeneric != partitionIsGeneric) {\n-            throw new CatalogException(\n-                    String.format(\n-                            \"Cannot handle %s partition for %s table\",\n-                            catalogPartition.getClass().getName(),\n-                            tableIsGeneric ? \"generic\" : \"non-generic\"));\n-        }\n-    }\n-\n     private Partition instantiateHivePartition(\n             Table hiveTable, CatalogPartitionSpec partitionSpec, CatalogPartition catalogPartition)\n             throws PartitionSpecInvalidException {\n@@ -1664,30 +1647,29 @@ public CatalogColumnStatistics getPartitionColumnStatistics(\n     }\n \n     public static boolean isGenericForCreate(Map<String, String> properties) {\n-        // When creating an object, a hive object needs explicitly have a key is_generic = false\n-        // otherwise, this is a generic object if 1) the key is missing 2) is_generic = true\n-        // this is opposite to reading an object. See getObjectIsGeneric().\n+        // When creating an object, a hive object needs explicitly have connector = hive\n+        // otherwise, this is a generic object.\n         if (properties == null) {\n             return true;\n         }\n-        boolean isGeneric;\n-        if (!properties.containsKey(CatalogPropertiesUtil.IS_GENERIC)) {\n-            // must be a generic object\n-            isGeneric = true;\n-            properties.put(CatalogPropertiesUtil.IS_GENERIC, String.valueOf(true));\n-        } else {\n-            isGeneric = Boolean.parseBoolean(properties.get(CatalogPropertiesUtil.IS_GENERIC));\n-        }\n-        return isGeneric;\n+        String connector = properties.get(CONNECTOR.key());\n+        return !IDENTIFIER.equalsIgnoreCase(connector);\n     }\n \n     public static boolean isGenericForGet(Map<String, String> properties) {\n-        // When retrieving an object, a generic object needs explicitly have a key is_generic = true\n-        // otherwise, this is a Hive object if 1) the key is missing 2) is_generic = false\n-        // this is opposite to creating an object. See createObjectIsGeneric()\n-        return properties != null\n-                && Boolean.parseBoolean(\n-                        properties.getOrDefault(CatalogPropertiesUtil.IS_GENERIC, \"false\"));\n+        // When retrieving an object from catalog, a generic object needs explicitly have a key  of\n+        // 'connector' or 'connector.type', otherwise, this is a Hive object.\n+        if (properties != null) {\n+            // we still check is_generic to be backward compatible\n+            String isGeneric = properties.get(CatalogPropertiesUtil.IS_GENERIC);\n+            if (isGeneric == null) {\n+                return properties.containsKey(FLINK_PROPERTY_PREFIX + CONNECTOR.key())\n+                        || properties.containsKey(FLINK_PROPERTY_PREFIX + CONNECTOR_TYPE);\n+            } else {\n+                return Boolean.parseBoolean(isGeneric);\n+            }\n+        }\n+        return false;\n     }\n \n     public static void disallowChangeIsGeneric(boolean oldIsGeneric, boolean newIsGeneric) {"
  },
  {
    "sha": "93ca37b8f5adbba385bb2400701a494b6a83dd70",
    "filename": "flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/table/catalog/hive/HiveDatabaseUtil.java",
    "status": "modified",
    "additions": 8,
    "deletions": 4,
    "changes": 12,
    "blob_url": "https://github.com/apache/flink/blob/07ff0742be91c9e503b91a31700bacad8fa03edd/flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/table/catalog/hive/HiveDatabaseUtil.java",
    "raw_url": "https://github.com/apache/flink/raw/07ff0742be91c9e503b91a31700bacad8fa03edd/flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/table/catalog/hive/HiveDatabaseUtil.java",
    "contents_url": "https://api.github.com/repos/apache/flink/contents/flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/table/catalog/hive/HiveDatabaseUtil.java?ref=07ff0742be91c9e503b91a31700bacad8fa03edd",
    "patch": "@@ -22,6 +22,7 @@\n import org.apache.flink.sql.parser.hive.ddl.SqlAlterHiveDatabaseOwner;\n import org.apache.flink.sql.parser.hive.ddl.SqlCreateHiveDatabase;\n import org.apache.flink.table.catalog.CatalogDatabase;\n+import org.apache.flink.table.catalog.CatalogPropertiesUtil;\n import org.apache.flink.table.catalog.exceptions.CatalogException;\n \n import org.apache.hadoop.hive.metastore.api.Database;\n@@ -32,8 +33,6 @@\n import static org.apache.flink.sql.parser.hive.ddl.SqlAlterHiveDatabase.ALTER_DATABASE_OP;\n import static org.apache.flink.sql.parser.hive.ddl.SqlAlterHiveDatabaseOwner.DATABASE_OWNER_NAME;\n import static org.apache.flink.sql.parser.hive.ddl.SqlAlterHiveDatabaseOwner.DATABASE_OWNER_TYPE;\n-import static org.apache.flink.table.catalog.hive.HiveCatalog.isGenericForCreate;\n-import static org.apache.flink.table.catalog.hive.HiveCatalog.isGenericForGet;\n \n /** Util methods for processing databases in HiveCatalog. */\n public class HiveDatabaseUtil {\n@@ -44,7 +43,9 @@ static Database instantiateHiveDatabase(String databaseName, CatalogDatabase dat\n \n         Map<String, String> properties = database.getProperties();\n \n-        boolean isGeneric = isGenericForCreate(properties);\n+        properties.putIfAbsent(CatalogPropertiesUtil.IS_GENERIC, \"true\");\n+\n+        boolean isGeneric = Boolean.parseBoolean(properties.get(CatalogPropertiesUtil.IS_GENERIC));\n \n         String dbLocationUri =\n                 isGeneric ? null : properties.remove(SqlCreateHiveDatabase.DATABASE_LOCATION_URI);\n@@ -54,7 +55,10 @@ static Database instantiateHiveDatabase(String databaseName, CatalogDatabase dat\n \n     static Database alterDatabase(Database hiveDB, CatalogDatabase newDatabase) {\n         Map<String, String> params = hiveDB.getParameters();\n-        boolean isGeneric = isGenericForGet(params);\n+        boolean isGeneric =\n+                params != null\n+                        && Boolean.parseBoolean(\n+                                params.getOrDefault(CatalogPropertiesUtil.IS_GENERIC, \"false\"));\n         if (isGeneric) {\n             // altering generic DB doesn't merge properties, see CatalogTest::testAlterDb\n             hiveDB.setParameters(newDatabase.getProperties());"
  },
  {
    "sha": "f239355c24f73998160eed16abaddc8512ec87c5",
    "filename": "flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/table/catalog/hive/util/HiveTableUtil.java",
    "status": "modified",
    "additions": 6,
    "deletions": 11,
    "changes": 17,
    "blob_url": "https://github.com/apache/flink/blob/07ff0742be91c9e503b91a31700bacad8fa03edd/flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/table/catalog/hive/util/HiveTableUtil.java",
    "raw_url": "https://github.com/apache/flink/raw/07ff0742be91c9e503b91a31700bacad8fa03edd/flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/table/catalog/hive/util/HiveTableUtil.java",
    "contents_url": "https://api.github.com/repos/apache/flink/contents/flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/table/catalog/hive/util/HiveTableUtil.java?ref=07ff0742be91c9e503b91a31700bacad8fa03edd",
    "patch": "@@ -25,7 +25,6 @@\n import org.apache.flink.table.api.TableSchema;\n import org.apache.flink.table.api.constraints.UniqueConstraint;\n import org.apache.flink.table.catalog.CatalogBaseTable;\n-import org.apache.flink.table.catalog.CatalogPropertiesUtil;\n import org.apache.flink.table.catalog.CatalogTable;\n import org.apache.flink.table.catalog.CatalogView;\n import org.apache.flink.table.catalog.ObjectPath;\n@@ -79,6 +78,7 @@\n import static org.apache.flink.sql.parser.hive.ddl.SqlCreateHiveTable.TABLE_IS_EXTERNAL;\n import static org.apache.flink.sql.parser.hive.ddl.SqlCreateHiveTable.TABLE_LOCATION_URI;\n import static org.apache.flink.table.catalog.CatalogPropertiesUtil.FLINK_PROPERTY_PREFIX;\n+import static org.apache.flink.table.factories.FactoryUtil.CONNECTOR;\n import static org.apache.flink.util.Preconditions.checkArgument;\n \n /** Utils to for Hive-backed table. */\n@@ -226,7 +226,7 @@ public static boolean requireRelyConstraint(byte trait) {\n      * Extract DDL semantics from properties and use it to initiate the table. The related\n      * properties will be removed from the map after they're used.\n      */\n-    public static void initiateTableFromProperties(\n+    private static void initiateTableFromProperties(\n             Table hiveTable, Map<String, String> properties, HiveConf hiveConf) {\n         extractExternal(hiveTable, properties);\n         extractRowFormat(hiveTable.getSd(), properties);\n@@ -394,6 +394,8 @@ public static Table instantiateHiveTable(\n             } else {\n                 sd.setCols(allColumns);\n             }\n+            // remove the 'connector' option for hive table\n+            properties.remove(CONNECTOR.key());\n             // Table properties\n             hiveTable.getParameters().putAll(properties);\n         }\n@@ -413,18 +415,11 @@ public static Table instantiateHiveTable(\n \n     /**\n      * Add a prefix to Flink-created properties to distinguish them from Hive-created properties.\n-     * Note that 'is_generic' is a special key and this method will leave it as-is.\n      */\n-    public static Map<String, String> maskFlinkProperties(Map<String, String> properties) {\n+    private static Map<String, String> maskFlinkProperties(Map<String, String> properties) {\n         return properties.entrySet().stream()\n                 .filter(e -> e.getKey() != null && e.getValue() != null)\n-                .map(\n-                        e ->\n-                                new Tuple2<>(\n-                                        e.getKey().equals(CatalogPropertiesUtil.IS_GENERIC)\n-                                                ? e.getKey()\n-                                                : FLINK_PROPERTY_PREFIX + e.getKey(),\n-                                        e.getValue()))\n+                .map(e -> new Tuple2<>(FLINK_PROPERTY_PREFIX + e.getKey(), e.getValue()))\n                 .collect(Collectors.toMap(t -> t.f0, t -> t.f1));\n     }\n "
  },
  {
    "sha": "1fd2c3bdb3f6939395dd7d561db285ac945252d7",
    "filename": "flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/connectors/hive/HiveDialectITCase.java",
    "status": "modified",
    "additions": 1,
    "deletions": 2,
    "changes": 3,
    "blob_url": "https://github.com/apache/flink/blob/07ff0742be91c9e503b91a31700bacad8fa03edd/flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/connectors/hive/HiveDialectITCase.java",
    "raw_url": "https://github.com/apache/flink/raw/07ff0742be91c9e503b91a31700bacad8fa03edd/flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/connectors/hive/HiveDialectITCase.java",
    "contents_url": "https://api.github.com/repos/apache/flink/contents/flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/connectors/hive/HiveDialectITCase.java?ref=07ff0742be91c9e503b91a31700bacad8fa03edd",
    "patch": "@@ -26,7 +26,6 @@\n import org.apache.flink.table.api.TableSchema;\n import org.apache.flink.table.api.internal.TableEnvironmentInternal;\n import org.apache.flink.table.catalog.CatalogPartitionSpec;\n-import org.apache.flink.table.catalog.CatalogPropertiesUtil;\n import org.apache.flink.table.catalog.CatalogTable;\n import org.apache.flink.table.catalog.ObjectPath;\n import org.apache.flink.table.catalog.hive.HiveCatalog;\n@@ -124,7 +123,7 @@ public void testCreateDatabase() throws Exception {\n         tableEnv.executeSql(\"create database db1 comment 'db1 comment'\");\n         Database db = hiveCatalog.getHiveDatabase(\"db1\");\n         assertEquals(\"db1 comment\", db.getDescription());\n-        assertFalse(Boolean.parseBoolean(db.getParameters().get(CatalogPropertiesUtil.IS_GENERIC)));\n+        assertFalse(HiveCatalog.isGenericForGet(db.getParameters()));\n \n         String db2Location = warehouse + \"/db2_location\";\n         tableEnv.executeSql("
  },
  {
    "sha": "624bde8c6ca55a6b2a01d08309b3c80b06e08439",
    "filename": "flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/connectors/hive/HiveTableFactoryTest.java",
    "status": "modified",
    "additions": 3,
    "deletions": 4,
    "changes": 7,
    "blob_url": "https://github.com/apache/flink/blob/07ff0742be91c9e503b91a31700bacad8fa03edd/flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/connectors/hive/HiveTableFactoryTest.java",
    "raw_url": "https://github.com/apache/flink/raw/07ff0742be91c9e503b91a31700bacad8fa03edd/flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/connectors/hive/HiveTableFactoryTest.java",
    "contents_url": "https://api.github.com/repos/apache/flink/contents/flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/connectors/hive/HiveTableFactoryTest.java?ref=07ff0742be91c9e503b91a31700bacad8fa03edd",
    "patch": "@@ -19,10 +19,10 @@\n package org.apache.flink.connectors.hive;\n \n import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.sql.parser.hive.ddl.SqlCreateHiveTable;\n import org.apache.flink.table.api.DataTypes;\n import org.apache.flink.table.api.TableSchema;\n import org.apache.flink.table.catalog.CatalogDatabaseImpl;\n-import org.apache.flink.table.catalog.CatalogPropertiesUtil;\n import org.apache.flink.table.catalog.CatalogTable;\n import org.apache.flink.table.catalog.CatalogTableImpl;\n import org.apache.flink.table.catalog.ObjectIdentifier;\n@@ -74,8 +74,7 @@ public void testGenericTable() throws Exception {\n                         .build();\n \n         Map<String, String> properties = new HashMap<>();\n-        properties.put(CatalogPropertiesUtil.IS_GENERIC, String.valueOf(true));\n-        properties.put(\"connector\", \"COLLECTION\");\n+        properties.put(FactoryUtil.CONNECTOR.key(), \"COLLECTION\");\n \n         catalog.createDatabase(\"mydb\", new CatalogDatabaseImpl(new HashMap<>(), \"\"), true);\n         ObjectPath path = new ObjectPath(\"mydb\", \"mytable\");\n@@ -112,7 +111,7 @@ public void testHiveTable() throws Exception {\n                         .build();\n \n         Map<String, String> properties = new HashMap<>();\n-        properties.put(CatalogPropertiesUtil.IS_GENERIC, String.valueOf(false));\n+        properties.put(FactoryUtil.CONNECTOR.key(), SqlCreateHiveTable.IDENTIFIER);\n \n         catalog.createDatabase(\"mydb\", new CatalogDatabaseImpl(new HashMap<>(), \"\"), true);\n         ObjectPath path = new ObjectPath(\"mydb\", \"mytable\");"
  },
  {
    "sha": "d5ea1be94a329d5cdc5a6b5eabda9baff2c3a0ae",
    "filename": "flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/table/catalog/hive/HiveCatalogDataTypeTest.java",
    "status": "modified",
    "additions": 3,
    "deletions": 2,
    "changes": 5,
    "blob_url": "https://github.com/apache/flink/blob/07ff0742be91c9e503b91a31700bacad8fa03edd/flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/table/catalog/hive/HiveCatalogDataTypeTest.java",
    "raw_url": "https://github.com/apache/flink/raw/07ff0742be91c9e503b91a31700bacad8fa03edd/flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/table/catalog/hive/HiveCatalogDataTypeTest.java",
    "contents_url": "https://api.github.com/repos/apache/flink/contents/flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/table/catalog/hive/HiveCatalogDataTypeTest.java?ref=07ff0742be91c9e503b91a31700bacad8fa03edd",
    "patch": "@@ -18,15 +18,16 @@\n \n package org.apache.flink.table.catalog.hive;\n \n+import org.apache.flink.sql.parser.hive.ddl.SqlCreateHiveTable;\n import org.apache.flink.table.api.DataTypes;\n import org.apache.flink.table.api.TableSchema;\n import org.apache.flink.table.catalog.CatalogDatabase;\n import org.apache.flink.table.catalog.CatalogDatabaseImpl;\n-import org.apache.flink.table.catalog.CatalogPropertiesUtil;\n import org.apache.flink.table.catalog.CatalogTable;\n import org.apache.flink.table.catalog.CatalogTableImpl;\n import org.apache.flink.table.catalog.ObjectPath;\n import org.apache.flink.table.catalog.exceptions.CatalogException;\n+import org.apache.flink.table.factories.FactoryUtil;\n import org.apache.flink.table.types.DataType;\n import org.apache.flink.table.types.logical.BinaryType;\n \n@@ -199,7 +200,7 @@ private CatalogTable createCatalogTable(DataType[] types) {\n                 new HashMap<String, String>() {\n                     {\n                         put(\"is_streaming\", \"false\");\n-                        put(CatalogPropertiesUtil.IS_GENERIC, String.valueOf(false));\n+                        put(FactoryUtil.CONNECTOR.key(), SqlCreateHiveTable.IDENTIFIER);\n                     }\n                 },\n                 \"\");"
  },
  {
    "sha": "b31ecbd89610e39190f0c9a1ec09b715107cd30d",
    "filename": "flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/table/catalog/hive/HiveCatalogGenericMetadataTest.java",
    "status": "modified",
    "additions": 12,
    "deletions": 7,
    "changes": 19,
    "blob_url": "https://github.com/apache/flink/blob/07ff0742be91c9e503b91a31700bacad8fa03edd/flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/table/catalog/hive/HiveCatalogGenericMetadataTest.java",
    "raw_url": "https://github.com/apache/flink/raw/07ff0742be91c9e503b91a31700bacad8fa03edd/flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/table/catalog/hive/HiveCatalogGenericMetadataTest.java",
    "contents_url": "https://api.github.com/repos/apache/flink/contents/flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/table/catalog/hive/HiveCatalogGenericMetadataTest.java?ref=07ff0742be91c9e503b91a31700bacad8fa03edd",
    "patch": "@@ -18,13 +18,15 @@\n \n package org.apache.flink.table.catalog.hive;\n \n+import org.apache.flink.connectors.hive.HiveDynamicTableFactory;\n import org.apache.flink.table.api.DataTypes;\n import org.apache.flink.table.api.TableSchema;\n import org.apache.flink.table.catalog.CatalogBaseTable;\n import org.apache.flink.table.catalog.CatalogFunction;\n import org.apache.flink.table.catalog.CatalogFunctionImpl;\n import org.apache.flink.table.catalog.CatalogPartition;\n import org.apache.flink.table.catalog.CatalogPropertiesUtil;\n+import org.apache.flink.table.catalog.CatalogTable;\n import org.apache.flink.table.catalog.CatalogTableImpl;\n import org.apache.flink.table.catalog.FunctionLanguage;\n import org.apache.flink.table.catalog.ObjectPath;\n@@ -40,6 +42,7 @@\n import org.junit.Test;\n \n import java.util.ArrayList;\n+import java.util.Map;\n \n import static org.junit.Assert.assertEquals;\n import static org.junit.Assert.assertTrue;\n@@ -96,7 +99,7 @@ public void testTableSchemaCompatibility() throws Exception {\n                             tablePath.getDatabaseName(), tablePath.getObjectName());\n             hiveTable.setDbName(tablePath.getDatabaseName());\n             hiveTable.setTableName(tablePath.getObjectName());\n-            hiveTable.getParameters().putAll(getBatchTableProperties());\n+            setLegacyGeneric(hiveTable.getParameters());\n             hiveTable.getParameters().put(\"flink.generic.table.schema.0.name\", \"ti\");\n             hiveTable.getParameters().put(\"flink.generic.table.schema.0.data-type\", \"TINYINT\");\n             hiveTable.getParameters().put(\"flink.generic.table.schema.1.name\", \"si\");\n@@ -118,9 +121,7 @@ public void testTableSchemaCompatibility() throws Exception {\n             hiveTable.getParameters().put(\"flink.generic.table.schema.7.data-type\", \"DOUBLE\");\n             ((HiveCatalog) catalog).client.createTable(hiveTable);\n             CatalogBaseTable catalogBaseTable = catalog.getTable(tablePath);\n-            assertTrue(\n-                    Boolean.parseBoolean(\n-                            catalogBaseTable.getOptions().get(CatalogPropertiesUtil.IS_GENERIC)));\n+            assertTrue(HiveDynamicTableFactory.isGeneric((CatalogTable) catalogBaseTable));\n             TableSchema expectedSchema =\n                     TableSchema.builder()\n                             .fields(\n@@ -145,7 +146,7 @@ public void testTableSchemaCompatibility() throws Exception {\n                             tablePath.getDatabaseName(), tablePath.getObjectName());\n             hiveTable.setDbName(tablePath.getDatabaseName());\n             hiveTable.setTableName(tablePath.getObjectName());\n-            hiveTable.getParameters().putAll(getBatchTableProperties());\n+            setLegacyGeneric(hiveTable.getParameters());\n             hiveTable.setTableName(tablePath.getObjectName());\n             hiveTable.getParameters().put(\"flink.generic.table.schema.0.name\", \"c\");\n             hiveTable.getParameters().put(\"flink.generic.table.schema.0.data-type\", \"CHAR(265)\");\n@@ -195,7 +196,7 @@ public void testTableSchemaCompatibility() throws Exception {\n                             tablePath.getDatabaseName(), tablePath.getObjectName());\n             hiveTable.setDbName(tablePath.getDatabaseName());\n             hiveTable.setTableName(tablePath.getObjectName());\n-            hiveTable.getParameters().putAll(getBatchTableProperties());\n+            setLegacyGeneric(hiveTable.getParameters());\n             hiveTable.setTableName(tablePath.getObjectName());\n             hiveTable.getParameters().put(\"flink.generic.table.schema.0.name\", \"dt\");\n             hiveTable.getParameters().put(\"flink.generic.table.schema.0.data-type\", \"DATE\");\n@@ -241,7 +242,7 @@ public void testTableSchemaCompatibility() throws Exception {\n                             tablePath.getDatabaseName(), tablePath.getObjectName());\n             hiveTable.setDbName(tablePath.getDatabaseName());\n             hiveTable.setTableName(tablePath.getObjectName());\n-            hiveTable.getParameters().putAll(getBatchTableProperties());\n+            setLegacyGeneric(hiveTable.getParameters());\n             hiveTable.setTableName(tablePath.getObjectName());\n             hiveTable.getParameters().put(\"flink.generic.table.schema.0.name\", \"a\");\n             hiveTable.getParameters().put(\"flink.generic.table.schema.0.data-type\", \"ARRAY<INT>\");\n@@ -456,4 +457,8 @@ protected CatalogFunction createAnotherFunction() {\n         return new CatalogFunctionImpl(\n                 TestSimpleUDF.class.getCanonicalName(), FunctionLanguage.SCALA);\n     }\n+\n+    private static void setLegacyGeneric(Map<String, String> properties) {\n+        properties.put(CatalogPropertiesUtil.IS_GENERIC, \"true\");\n+    }\n }"
  },
  {
    "sha": "d3fc4b4c19140ead6d6dfe0890fda5d7352ed01f",
    "filename": "flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/table/catalog/hive/HiveCatalogHiveMetadataTest.java",
    "status": "modified",
    "additions": 17,
    "deletions": 1,
    "changes": 18,
    "blob_url": "https://github.com/apache/flink/blob/07ff0742be91c9e503b91a31700bacad8fa03edd/flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/table/catalog/hive/HiveCatalogHiveMetadataTest.java",
    "raw_url": "https://github.com/apache/flink/raw/07ff0742be91c9e503b91a31700bacad8fa03edd/flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/table/catalog/hive/HiveCatalogHiveMetadataTest.java",
    "contents_url": "https://api.github.com/repos/apache/flink/contents/flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/table/catalog/hive/HiveCatalogHiveMetadataTest.java?ref=07ff0742be91c9e503b91a31700bacad8fa03edd",
    "patch": "@@ -20,6 +20,7 @@\n \n import org.apache.flink.sql.parser.hive.ddl.SqlAlterHiveDatabase.AlterHiveDatabaseOp;\n import org.apache.flink.sql.parser.hive.ddl.SqlAlterHiveTable;\n+import org.apache.flink.sql.parser.hive.ddl.SqlCreateHiveTable;\n import org.apache.flink.table.HiveVersionTestUtil;\n import org.apache.flink.table.api.DataTypes;\n import org.apache.flink.table.api.TableSchema;\n@@ -44,6 +45,7 @@\n import org.apache.flink.table.catalog.stats.CatalogColumnStatisticsDataString;\n import org.apache.flink.table.catalog.stats.CatalogTableStatistics;\n import org.apache.flink.table.catalog.stats.Date;\n+import org.apache.flink.table.factories.FactoryUtil;\n import org.apache.flink.table.types.DataType;\n import org.apache.flink.util.StringUtils;\n \n@@ -266,7 +268,7 @@ private void checkStatistics(int inputStat, int expectStat) throws Exception {\n         catalog.dropTable(path1, true);\n \n         Map<String, String> properties = new HashMap<>();\n-        properties.put(CatalogPropertiesUtil.IS_GENERIC, \"false\");\n+        properties.put(FactoryUtil.CONNECTOR.key(), SqlCreateHiveTable.IDENTIFIER);\n         properties.put(StatsSetupConst.ROW_COUNT, String.valueOf(inputStat));\n         properties.put(StatsSetupConst.NUM_FILES, String.valueOf(inputStat));\n         properties.put(StatsSetupConst.TOTAL_SIZE, String.valueOf(inputStat));\n@@ -304,4 +306,18 @@ protected CatalogFunction createFunction() {\n     protected CatalogFunction createAnotherFunction() {\n         return new CatalogFunctionImpl(UDFRand.class.getName());\n     }\n+\n+    @Override\n+    public CatalogDatabase createDb() {\n+        CatalogDatabase database = super.createDb();\n+        database.getProperties().put(CatalogPropertiesUtil.IS_GENERIC, \"false\");\n+        return database;\n+    }\n+\n+    @Override\n+    public CatalogDatabase createAnotherDb() {\n+        CatalogDatabase database = super.createAnotherDb();\n+        database.getProperties().put(CatalogPropertiesUtil.IS_GENERIC, \"false\");\n+        return database;\n+    }\n }"
  },
  {
    "sha": "6cd1406b07af74fe50edb5557dc95746ebb2a408",
    "filename": "flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/table/catalog/hive/HiveCatalogITCase.java",
    "status": "modified",
    "additions": 25,
    "deletions": 0,
    "changes": 25,
    "blob_url": "https://github.com/apache/flink/blob/07ff0742be91c9e503b91a31700bacad8fa03edd/flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/table/catalog/hive/HiveCatalogITCase.java",
    "raw_url": "https://github.com/apache/flink/raw/07ff0742be91c9e503b91a31700bacad8fa03edd/flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/table/catalog/hive/HiveCatalogITCase.java",
    "contents_url": "https://api.github.com/repos/apache/flink/contents/flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/table/catalog/hive/HiveCatalogITCase.java?ref=07ff0742be91c9e503b91a31700bacad8fa03edd",
    "patch": "@@ -27,13 +27,16 @@\n import org.apache.flink.table.api.TableSchema;\n import org.apache.flink.table.api.Types;\n import org.apache.flink.table.api.constraints.UniqueConstraint;\n+import org.apache.flink.table.catalog.Catalog;\n+import org.apache.flink.table.catalog.CatalogBaseTable;\n import org.apache.flink.table.catalog.CatalogTable;\n import org.apache.flink.table.catalog.CatalogTableBuilder;\n import org.apache.flink.table.catalog.ObjectPath;\n import org.apache.flink.table.catalog.exceptions.TableNotExistException;\n import org.apache.flink.table.descriptors.FileSystem;\n import org.apache.flink.table.descriptors.FormatDescriptor;\n import org.apache.flink.table.descriptors.OldCsv;\n+import org.apache.flink.table.factories.FactoryUtil;\n import org.apache.flink.table.planner.factories.utils.TestCollectionTableFactory;\n import org.apache.flink.types.Row;\n import org.apache.flink.util.CollectionUtil;\n@@ -483,4 +486,26 @@ public void testTemporaryGenericTable() throws Exception {\n                 \"create temporary table blackhole(i int) with ('connector'='blackhole')\");\n         tableEnv.executeSql(\"insert into blackhole select * from datagen\").await();\n     }\n+\n+    @Test\n+    public void testCreateTableLike() throws Exception {\n+        TableEnvironment tableEnv = HiveTestUtils.createTableEnvWithBlinkPlannerBatchMode();\n+        tableEnv.registerCatalog(hiveCatalog.getName(), hiveCatalog);\n+        tableEnv.useCatalog(hiveCatalog.getName());\n+        tableEnv.executeSql(\"create table generic_table (x int) with ('connector'='COLLECTION')\");\n+        tableEnv.useCatalog(EnvironmentSettings.DEFAULT_BUILTIN_CATALOG);\n+        tableEnv.executeSql(\n+                String.format(\n+                        \"create table copy like `%s`.`default`.generic_table\",\n+                        hiveCatalog.getName()));\n+        Catalog builtInCat = tableEnv.getCatalog(EnvironmentSettings.DEFAULT_BUILTIN_CATALOG).get();\n+        CatalogBaseTable catalogTable =\n+                builtInCat.getTable(\n+                        new ObjectPath(EnvironmentSettings.DEFAULT_BUILTIN_DATABASE, \"copy\"));\n+        assertEquals(1, catalogTable.getOptions().size());\n+        assertEquals(\"COLLECTION\", catalogTable.getOptions().get(FactoryUtil.CONNECTOR.key()));\n+        assertEquals(1, catalogTable.getSchema().getFieldCount());\n+        assertEquals(\"x\", catalogTable.getSchema().getFieldNames()[0]);\n+        assertEquals(DataTypes.INT(), catalogTable.getSchema().getFieldDataTypes()[0]);\n+    }\n }"
  },
  {
    "sha": "341eec6aeeb8856b82f7b2d179f09a8d87e2816b",
    "filename": "flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/table/catalog/hive/HiveCatalogTest.java",
    "status": "modified",
    "additions": 6,
    "deletions": 4,
    "changes": 10,
    "blob_url": "https://github.com/apache/flink/blob/07ff0742be91c9e503b91a31700bacad8fa03edd/flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/table/catalog/hive/HiveCatalogTest.java",
    "raw_url": "https://github.com/apache/flink/raw/07ff0742be91c9e503b91a31700bacad8fa03edd/flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/table/catalog/hive/HiveCatalogTest.java",
    "contents_url": "https://api.github.com/repos/apache/flink/contents/flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/table/catalog/hive/HiveCatalogTest.java?ref=07ff0742be91c9e503b91a31700bacad8fa03edd",
    "patch": "@@ -18,21 +18,23 @@\n \n package org.apache.flink.table.catalog.hive;\n \n+import org.apache.flink.sql.parser.hive.ddl.SqlCreateHiveTable;\n import org.apache.flink.table.api.DataTypes;\n import org.apache.flink.table.api.TableSchema;\n import org.apache.flink.table.catalog.CatalogPropertiesUtil;\n import org.apache.flink.table.catalog.CatalogTableImpl;\n import org.apache.flink.table.catalog.ObjectPath;\n import org.apache.flink.table.catalog.hive.util.HiveTableUtil;\n import org.apache.flink.table.descriptors.FileSystem;\n+import org.apache.flink.table.factories.FactoryUtil;\n \n import org.apache.hadoop.hive.metastore.api.Table;\n import org.junit.Test;\n \n import java.util.HashMap;\n import java.util.Map;\n \n-import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertFalse;\n import static org.junit.Assert.assertTrue;\n \n /** Test for HiveCatalog. */\n@@ -54,7 +56,7 @@ public void testCreateGenericTable() {\n                         HiveTestUtils.createHiveConf());\n \n         Map<String, String> prop = hiveTable.getParameters();\n-        assertEquals(prop.remove(CatalogPropertiesUtil.IS_GENERIC), String.valueOf(\"true\"));\n+        assertTrue(HiveCatalog.isGenericForGet(prop));\n         assertTrue(\n                 prop.keySet().stream()\n                         .allMatch(k -> k.startsWith(CatalogPropertiesUtil.FLINK_PROPERTY_PREFIX)));\n@@ -64,7 +66,7 @@ public void testCreateGenericTable() {\n     public void testCreateHiveTable() {\n         Map<String, String> map = new HashMap<>(new FileSystem().path(\"/test_path\").toProperties());\n \n-        map.put(CatalogPropertiesUtil.IS_GENERIC, String.valueOf(false));\n+        map.put(FactoryUtil.CONNECTOR.key(), SqlCreateHiveTable.IDENTIFIER);\n \n         Table hiveTable =\n                 HiveTableUtil.instantiateHiveTable(\n@@ -73,7 +75,7 @@ public void testCreateHiveTable() {\n                         HiveTestUtils.createHiveConf());\n \n         Map<String, String> prop = hiveTable.getParameters();\n-        assertEquals(prop.remove(CatalogPropertiesUtil.IS_GENERIC), String.valueOf(false));\n+        assertFalse(HiveCatalog.isGenericForGet(prop));\n         assertTrue(\n                 prop.keySet().stream()\n                         .noneMatch(k -> k.startsWith(CatalogPropertiesUtil.FLINK_PROPERTY_PREFIX)));"
  },
  {
    "sha": "485f625a031c9c8a049e9cd007616079e5fe5a9a",
    "filename": "flink-table/flink-sql-client/src/test/java/org/apache/flink/table/client/gateway/local/DependencyTest.java",
    "status": "modified",
    "additions": 4,
    "deletions": 6,
    "changes": 10,
    "blob_url": "https://github.com/apache/flink/blob/07ff0742be91c9e503b91a31700bacad8fa03edd/flink-table/flink-sql-client/src/test/java/org/apache/flink/table/client/gateway/local/DependencyTest.java",
    "raw_url": "https://github.com/apache/flink/raw/07ff0742be91c9e503b91a31700bacad8fa03edd/flink-table/flink-sql-client/src/test/java/org/apache/flink/table/client/gateway/local/DependencyTest.java",
    "contents_url": "https://api.github.com/repos/apache/flink/contents/flink-table/flink-sql-client/src/test/java/org/apache/flink/table/client/gateway/local/DependencyTest.java?ref=07ff0742be91c9e503b91a31700bacad8fa03edd",
    "patch": "@@ -21,13 +21,13 @@\n import org.apache.flink.client.cli.DefaultCLI;\n import org.apache.flink.client.deployment.DefaultClusterClientServiceLoader;\n import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.sql.parser.hive.ddl.SqlCreateHiveTable;\n import org.apache.flink.table.api.DataTypes;\n import org.apache.flink.table.api.Schema;\n import org.apache.flink.table.api.TableResult;\n import org.apache.flink.table.api.TableSchema;\n import org.apache.flink.table.catalog.Catalog;\n import org.apache.flink.table.catalog.CatalogDatabaseImpl;\n-import org.apache.flink.table.catalog.CatalogPropertiesUtil;\n import org.apache.flink.table.catalog.CatalogTable;\n import org.apache.flink.table.catalog.Column;\n import org.apache.flink.table.catalog.GenericInMemoryCatalog;\n@@ -50,6 +50,7 @@\n import org.apache.flink.table.delegation.Parser;\n import org.apache.flink.table.descriptors.DescriptorProperties;\n import org.apache.flink.table.factories.CatalogFactory;\n+import org.apache.flink.table.factories.FactoryUtil;\n import org.apache.flink.table.factories.ModuleFactory;\n import org.apache.flink.table.module.Module;\n import org.apache.flink.table.operations.Operation;\n@@ -266,10 +267,7 @@ public TestCatalog(String name, String defaultDatabase) {\n \n         @Override\n         public List<String> supportedProperties() {\n-            List<String> list = super.supportedProperties();\n-            list.add(CatalogPropertiesUtil.IS_GENERIC);\n-\n-            return list;\n+            return super.supportedProperties();\n         }\n \n         @Override\n@@ -318,7 +316,7 @@ public Catalog createCatalog(String name, Map<String, String> properties) {\n         private ResolvedCatalogTable createResolvedTable(\n                 String[] fieldNames, DataType[] fieldDataTypes) {\n             final Map<String, String> options = new HashMap<>();\n-            options.put(CatalogPropertiesUtil.IS_GENERIC, String.valueOf(false));\n+            options.put(FactoryUtil.CONNECTOR.key(), SqlCreateHiveTable.IDENTIFIER);\n             final CatalogTable origin =\n                     CatalogTable.of(\n                             Schema.newBuilder().fromFields(fieldNames, fieldDataTypes).build(),"
  },
  {
    "sha": "e1eb6cfd6cfd0fcc1a273b8b60031362cf86e3f1",
    "filename": "flink-table/flink-sql-parser-hive/src/main/java/org/apache/flink/sql/parser/hive/ddl/SqlCreateHiveTable.java",
    "status": "modified",
    "additions": 4,
    "deletions": 4,
    "changes": 8,
    "blob_url": "https://github.com/apache/flink/blob/07ff0742be91c9e503b91a31700bacad8fa03edd/flink-table/flink-sql-parser-hive/src/main/java/org/apache/flink/sql/parser/hive/ddl/SqlCreateHiveTable.java",
    "raw_url": "https://github.com/apache/flink/raw/07ff0742be91c9e503b91a31700bacad8fa03edd/flink-table/flink-sql-parser-hive/src/main/java/org/apache/flink/sql/parser/hive/ddl/SqlCreateHiveTable.java",
    "contents_url": "https://api.github.com/repos/apache/flink/contents/flink-table/flink-sql-parser-hive/src/main/java/org/apache/flink/sql/parser/hive/ddl/SqlCreateHiveTable.java?ref=07ff0742be91c9e503b91a31700bacad8fa03edd",
    "patch": "@@ -24,7 +24,7 @@\n import org.apache.flink.sql.parser.ddl.SqlTableOption;\n import org.apache.flink.sql.parser.ddl.constraint.SqlTableConstraint;\n import org.apache.flink.sql.parser.hive.impl.ParseException;\n-import org.apache.flink.table.catalog.CatalogPropertiesUtil;\n+import org.apache.flink.table.factories.FactoryUtil;\n \n import org.apache.calcite.sql.SqlCharStringLiteral;\n import org.apache.calcite.sql.SqlIdentifier;\n@@ -43,6 +43,8 @@\n /** CREATE Table DDL for Hive dialect. */\n public class SqlCreateHiveTable extends SqlCreateTable {\n \n+    public static final String IDENTIFIER = \"hive\";\n+\n     public static final String TABLE_LOCATION_URI = \"hive.location-uri\";\n     public static final String TABLE_IS_EXTERNAL = \"hive.is-external\";\n     public static final String PK_CONSTRAINT_TRAIT = \"hive.pk.constraint.trait\";\n@@ -96,9 +98,7 @@ public SqlCreateHiveTable(\n         HiveDDLUtils.convertDataTypes(partColList);\n         originPropList = new SqlNodeList(propertyList.getList(), propertyList.getParserPosition());\n         // mark it as a hive table\n-        HiveDDLUtils.ensureNonGeneric(propertyList);\n-        propertyList.add(\n-                HiveDDLUtils.toTableOption(CatalogPropertiesUtil.IS_GENERIC, \"false\", pos));\n+        propertyList.add(HiveDDLUtils.toTableOption(FactoryUtil.CONNECTOR.key(), IDENTIFIER, pos));\n         // set external\n         this.isExternal = isExternal;\n         if (isExternal) {"
  },
  {
    "sha": "a366b4d6417921bf13d9cab848127c29429ac9eb",
    "filename": "flink-table/flink-sql-parser-hive/src/main/java/org/apache/flink/sql/parser/hive/ddl/SqlCreateHiveView.java",
    "status": "modified",
    "additions": 4,
    "deletions": 2,
    "changes": 6,
    "blob_url": "https://github.com/apache/flink/blob/07ff0742be91c9e503b91a31700bacad8fa03edd/flink-table/flink-sql-parser-hive/src/main/java/org/apache/flink/sql/parser/hive/ddl/SqlCreateHiveView.java",
    "raw_url": "https://github.com/apache/flink/raw/07ff0742be91c9e503b91a31700bacad8fa03edd/flink-table/flink-sql-parser-hive/src/main/java/org/apache/flink/sql/parser/hive/ddl/SqlCreateHiveView.java",
    "contents_url": "https://api.github.com/repos/apache/flink/contents/flink-table/flink-sql-parser-hive/src/main/java/org/apache/flink/sql/parser/hive/ddl/SqlCreateHiveView.java?ref=07ff0742be91c9e503b91a31700bacad8fa03edd",
    "patch": "@@ -19,7 +19,7 @@\n package org.apache.flink.sql.parser.hive.ddl;\n \n import org.apache.flink.sql.parser.ddl.SqlCreateView;\n-import org.apache.flink.table.catalog.CatalogPropertiesUtil;\n+import org.apache.flink.table.factories.FactoryUtil;\n \n import org.apache.calcite.sql.SqlCharStringLiteral;\n import org.apache.calcite.sql.SqlIdentifier;\n@@ -59,7 +59,9 @@ public SqlCreateHiveView(\n         HiveDDLUtils.unescapeProperties(properties);\n         originPropList = new SqlNodeList(properties.getList(), properties.getParserPosition());\n         // mark it as a hive view\n-        properties.add(HiveDDLUtils.toTableOption(CatalogPropertiesUtil.IS_GENERIC, \"false\", pos));\n+        properties.add(\n+                HiveDDLUtils.toTableOption(\n+                        FactoryUtil.CONNECTOR.key(), SqlCreateHiveTable.IDENTIFIER, pos));\n     }\n \n     @Override"
  },
  {
    "sha": "d7428b88cffc6133af0f458aa170366ba7b8d92c",
    "filename": "flink-table/flink-table-api-java/src/main/java/org/apache/flink/table/catalog/CatalogTableBuilder.java",
    "status": "modified",
    "additions": 0,
    "deletions": 7,
    "changes": 7,
    "blob_url": "https://github.com/apache/flink/blob/07ff0742be91c9e503b91a31700bacad8fa03edd/flink-table/flink-table-api-java/src/main/java/org/apache/flink/table/catalog/CatalogTableBuilder.java",
    "raw_url": "https://github.com/apache/flink/raw/07ff0742be91c9e503b91a31700bacad8fa03edd/flink-table/flink-table-api-java/src/main/java/org/apache/flink/table/catalog/CatalogTableBuilder.java",
    "contents_url": "https://api.github.com/repos/apache/flink/contents/flink-table/flink-table-api-java/src/main/java/org/apache/flink/table/catalog/CatalogTableBuilder.java?ref=07ff0742be91c9e503b91a31700bacad8fa03edd",
    "patch": "@@ -63,18 +63,13 @@\n \n     private String comment;\n \n-    private final boolean isGeneric;\n-\n     private List<String> partitionKeys = new ArrayList<>();\n \n     private Map<String, String> properties = Collections.emptyMap();\n \n     public CatalogTableBuilder(ConnectorDescriptor connectorDescriptor, TableSchema tableSchema) {\n         super(connectorDescriptor);\n         this.tableSchema = Preconditions.checkNotNull(tableSchema);\n-\n-        // We don't support non-generic table currently\n-        this.isGeneric = true;\n     }\n \n     public CatalogTableBuilder withComment(String comment) {\n@@ -102,8 +97,6 @@ public CatalogTable build() {\n     protected Map<String, String> additionalProperties() {\n         DescriptorProperties descriptorProperties = new DescriptorProperties();\n \n-        descriptorProperties.putBoolean(CatalogPropertiesUtil.IS_GENERIC, isGeneric);\n-\n         descriptorProperties.putProperties(this.properties);\n \n         return descriptorProperties.asMap();"
  },
  {
    "sha": "a217ca8d4afafdd331e450549c9925b562675947",
    "filename": "flink-table/flink-table-api-java/src/main/java/org/apache/flink/table/catalog/CatalogTableImpl.java",
    "status": "modified",
    "additions": 0,
    "deletions": 1,
    "changes": 1,
    "blob_url": "https://github.com/apache/flink/blob/07ff0742be91c9e503b91a31700bacad8fa03edd/flink-table/flink-table-api-java/src/main/java/org/apache/flink/table/catalog/CatalogTableImpl.java",
    "raw_url": "https://github.com/apache/flink/raw/07ff0742be91c9e503b91a31700bacad8fa03edd/flink-table/flink-table-api-java/src/main/java/org/apache/flink/table/catalog/CatalogTableImpl.java",
    "contents_url": "https://api.github.com/repos/apache/flink/contents/flink-table/flink-table-api-java/src/main/java/org/apache/flink/table/catalog/CatalogTableImpl.java?ref=07ff0742be91c9e503b91a31700bacad8fa03edd",
    "patch": "@@ -82,7 +82,6 @@ public CatalogBaseTable copy() {\n         descriptor.putPartitionKeys(getPartitionKeys());\n \n         Map<String, String> properties = new HashMap<>(getOptions());\n-        properties.remove(CatalogPropertiesUtil.IS_GENERIC);\n \n         descriptor.putProperties(properties);\n "
  },
  {
    "sha": "a588343749c157001990ae918ba45f62dacfe3b7",
    "filename": "flink-table/flink-table-api-java/src/test/java/org/apache/flink/table/catalog/CatalogTestBase.java",
    "status": "modified",
    "additions": 3,
    "deletions": 3,
    "changes": 6,
    "blob_url": "https://github.com/apache/flink/blob/07ff0742be91c9e503b91a31700bacad8fa03edd/flink-table/flink-table-api-java/src/test/java/org/apache/flink/table/catalog/CatalogTestBase.java",
    "raw_url": "https://github.com/apache/flink/raw/07ff0742be91c9e503b91a31700bacad8fa03edd/flink-table/flink-table-api-java/src/test/java/org/apache/flink/table/catalog/CatalogTestBase.java",
    "contents_url": "https://api.github.com/repos/apache/flink/contents/flink-table/flink-table-api-java/src/test/java/org/apache/flink/table/catalog/CatalogTestBase.java?ref=07ff0742be91c9e503b91a31700bacad8fa03edd",
    "patch": "@@ -19,6 +19,7 @@\n package org.apache.flink.table.catalog;\n \n import org.apache.flink.table.api.Schema;\n+import org.apache.flink.table.factories.FactoryUtil;\n \n import java.util.Collections;\n import java.util.HashMap;\n@@ -33,7 +34,6 @@ public CatalogDatabase createDb() {\n                 new HashMap<String, String>() {\n                     {\n                         put(\"k1\", \"v1\");\n-                        putAll(getGenericFlag(isGeneric()));\n                     }\n                 },\n                 TEST_COMMENT);\n@@ -45,7 +45,6 @@ public CatalogDatabase createAnotherDb() {\n                 new HashMap<String, String>() {\n                     {\n                         put(\"k2\", \"v2\");\n-                        putAll(getGenericFlag(isGeneric()));\n                     }\n                 },\n                 TEST_COMMENT);\n@@ -165,7 +164,8 @@ public CatalogView createAnotherView() {\n     private Map<String, String> getGenericFlag(boolean isGeneric) {\n         return new HashMap<String, String>() {\n             {\n-                put(CatalogPropertiesUtil.IS_GENERIC, String.valueOf(isGeneric));\n+                String connector = isGeneric ? \"COLLECTION\" : \"hive\";\n+                put(FactoryUtil.CONNECTOR.key(), connector);\n             }\n         };\n     }"
  },
  {
    "sha": "8ed819ab796d92d409c45d5ff68d1b395bce4d2d",
    "filename": "flink-table/flink-table-common/src/test/java/org/apache/flink/table/catalog/CatalogTestUtil.java",
    "status": "modified",
    "additions": 8,
    "deletions": 7,
    "changes": 15,
    "blob_url": "https://github.com/apache/flink/blob/07ff0742be91c9e503b91a31700bacad8fa03edd/flink-table/flink-table-common/src/test/java/org/apache/flink/table/catalog/CatalogTestUtil.java",
    "raw_url": "https://github.com/apache/flink/raw/07ff0742be91c9e503b91a31700bacad8fa03edd/flink-table/flink-table-common/src/test/java/org/apache/flink/table/catalog/CatalogTestUtil.java",
    "contents_url": "https://api.github.com/repos/apache/flink/contents/flink-table/flink-table-common/src/test/java/org/apache/flink/table/catalog/CatalogTestUtil.java?ref=07ff0742be91c9e503b91a31700bacad8fa03edd",
    "patch": "@@ -28,6 +28,7 @@\n import org.apache.flink.table.catalog.stats.CatalogColumnStatisticsDataString;\n import org.apache.flink.table.catalog.stats.CatalogTableStatistics;\n import org.apache.flink.table.catalog.stats.Date;\n+import org.apache.flink.table.factories.FactoryUtil;\n import org.apache.flink.table.plan.stats.TableStats;\n \n import java.util.Map;\n@@ -47,13 +48,9 @@ public static void checkEquals(CatalogTable t1, CatalogTable t2) {\n         assertEquals(t1.getPartitionKeys(), t2.getPartitionKeys());\n         assertEquals(t1.isPartitioned(), t2.isPartitioned());\n \n-        assertEquals(\n-                t1.getOptions().get(CatalogPropertiesUtil.IS_GENERIC),\n-                t2.getOptions().get(CatalogPropertiesUtil.IS_GENERIC));\n-\n         // Hive tables may have properties created by itself\n         // thus properties of Hive table is a super set of those in its corresponding Flink table\n-        if (Boolean.parseBoolean(t1.getOptions().get(CatalogPropertiesUtil.IS_GENERIC))) {\n+        if (isGeneric(t1.getOptions())) {\n             assertEquals(t1.getOptions(), t2.getOptions());\n         } else {\n             assertTrue(\n@@ -72,7 +69,7 @@ public static void checkEquals(CatalogView v1, CatalogView v2) {\n \n         // Hive tables may have properties created by itself\n         // thus properties of Hive table is a super set of those in its corresponding Flink table\n-        if (Boolean.parseBoolean(v1.getOptions().get(CatalogPropertiesUtil.IS_GENERIC))) {\n+        if (isGeneric(v1.getOptions())) {\n             assertEquals(v1.getOptions(), v2.getOptions());\n         } else {\n             assertTrue(\n@@ -88,7 +85,7 @@ public static void checkEquals(CatalogPartition p1, CatalogPartition p2) {\n \n         // Hive tables may have properties created by itself\n         // thus properties of Hive table is a super set of those in its corresponding Flink table\n-        if (Boolean.valueOf(p1.getProperties().get(CatalogPropertiesUtil.IS_GENERIC))) {\n+        if (isGeneric(p1.getProperties())) {\n             assertEquals(p1.getProperties(), p2.getProperties());\n         } else {\n             assertTrue(p2.getProperties().entrySet().containsAll(p1.getProperties().entrySet()));\n@@ -209,4 +206,8 @@ private static void checkEquals(\n     private static void checkEquals(Date v1, Date v2) {\n         assertEquals(v1.getDaysSinceEpoch(), v2.getDaysSinceEpoch());\n     }\n+\n+    private static boolean isGeneric(Map<String, String> properties) {\n+        return !\"hive\".equalsIgnoreCase(properties.get(FactoryUtil.CONNECTOR.key()));\n+    }\n }"
  }
]
