[
  {
    "sha": "ce3041c329f7faa5ac6716c35f164060fe77a056",
    "filename": "modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/rebalance/DataGenerationApplication.java",
    "status": "modified",
    "additions": 2,
    "deletions": 3,
    "changes": 5,
    "blob_url": "https://github.com/apache/ignite/blob/a39604500fbbbadaaea678ccd96bce58da0bacfe/modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/rebalance/DataGenerationApplication.java",
    "raw_url": "https://github.com/apache/ignite/raw/a39604500fbbbadaaea678ccd96bce58da0bacfe/modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/rebalance/DataGenerationApplication.java",
    "contents_url": "https://api.github.com/repos/apache/ignite/contents/modules/ducktests/src/main/java/org/apache/ignite/internal/ducktest/tests/rebalance/DataGenerationApplication.java?ref=a39604500fbbbadaaea678ccd96bce58da0bacfe",
    "patch": "@@ -38,8 +38,7 @@\n         int entryCnt = jsonNode.get(\"entryCount\").asInt();\n         int entrySize = jsonNode.get(\"entrySize\").asInt();\n \n-        log.info(\"Data generation started [backups=\" + backups + \", cacheCount=\" + cacheCnt\n-            + \", entryCount=\" + entryCnt + \", entrySize=\" + entrySize + \"]\");\n+        markInitialized();\n \n         for (int i = 1; i <= cacheCnt; i++) {\n             // TODO https://issues.apache.org/jira/browse/IGNITE-14319\n@@ -50,7 +49,7 @@\n             generateCacheData(cache.getName(), entryCnt, entrySize);\n         }\n \n-        markSyncExecutionComplete();\n+        markFinished();\n     }\n \n     /**"
  },
  {
    "sha": "ba1d93cce2de77a211222b700d2e32c9cbf99015",
    "filename": "modules/ducktests/tests/ignitetest/services/ignite.py",
    "status": "modified",
    "additions": 0,
    "deletions": 21,
    "changes": 21,
    "blob_url": "https://github.com/apache/ignite/blob/a39604500fbbbadaaea678ccd96bce58da0bacfe/modules/ducktests/tests/ignitetest/services/ignite.py",
    "raw_url": "https://github.com/apache/ignite/raw/a39604500fbbbadaaea678ccd96bce58da0bacfe/modules/ducktests/tests/ignitetest/services/ignite.py",
    "contents_url": "https://api.github.com/repos/apache/ignite/contents/modules/ducktests/tests/ignitetest/services/ignite.py?ref=a39604500fbbbadaaea678ccd96bce58da0bacfe",
    "patch": "@@ -17,9 +17,7 @@\n This module contains class to start ignite cluster node.\n \"\"\"\n \n-import re\n import signal\n-from datetime import datetime\n \n from ducktape.cluster.remoteaccount import RemoteCommandError\n \n@@ -66,22 +64,3 @@ def node_failed_event_pattern(failed_node_id=None):\n     \"\"\"Failed node pattern in log.\"\"\"\n     return \"Node FAILED: .\\\\{1,\\\\}Node \\\\[id=\" + (failed_node_id if failed_node_id else \"\") + \\\n            \".\\\\{1,\\\\}\\\\(isClient\\\\|client\\\\)=false\"\n-\n-\n-def get_event_time(service, log_node, log_pattern, from_the_beginning=True, timeout=15):\n-    \"\"\"\n-    Extracts event time from ignite log by pattern .\n-    :param service: ducktape service (ignite service) responsible to search log.\n-    :param log_node: ducktape node to search ignite log on.\n-    :param log_pattern: pattern to search ignite log for.\n-    :param from_the_beginning: switches searching log from its beginning.\n-    :param timeout: timeout to wait for the patters in the log.\n-    \"\"\"\n-    service.await_event_on_node(log_pattern, log_node, timeout, from_the_beginning=from_the_beginning,\n-                                backoff_sec=0.3)\n-\n-    _, stdout, _ = log_node.account.ssh_client.exec_command(\n-        \"grep '%s' %s\" % (log_pattern, log_node.log_file))\n-\n-    return datetime.strptime(re.match(\"^\\\\[[^\\\\[]+\\\\]\", stdout.read().decode(\"utf-8\")).group(),\n-                             \"[%Y-%m-%d %H:%M:%S,%f]\")"
  },
  {
    "sha": "fadd88db1369d2ff52a40028e3c040456862b369",
    "filename": "modules/ducktests/tests/ignitetest/services/ignite_app.py",
    "status": "modified",
    "additions": 3,
    "deletions": 3,
    "changes": 6,
    "blob_url": "https://github.com/apache/ignite/blob/a39604500fbbbadaaea678ccd96bce58da0bacfe/modules/ducktests/tests/ignitetest/services/ignite_app.py",
    "raw_url": "https://github.com/apache/ignite/raw/a39604500fbbbadaaea678ccd96bce58da0bacfe/modules/ducktests/tests/ignitetest/services/ignite_app.py",
    "contents_url": "https://api.github.com/repos/apache/ignite/contents/modules/ducktests/tests/ignitetest/services/ignite_app.py?ref=a39604500fbbbadaaea678ccd96bce58da0bacfe",
    "patch": "@@ -47,12 +47,12 @@ def __init__(self, context, config, java_class_name, num_nodes=1, params=\"\", sta\n     def await_started(self):\n         super().await_started()\n \n-        self.__check_status(\"IGNITE_APPLICATION_INITIALIZED\", timeout=self.startup_timeout_sec)\n+        return self.__check_status(\"IGNITE_APPLICATION_INITIALIZED\", timeout=self.startup_timeout_sec)\n \n     def await_stopped(self):\n         super().await_stopped()\n \n-        self.__check_status(\"IGNITE_APPLICATION_FINISHED\")\n+        return self.__check_status(\"IGNITE_APPLICATION_FINISHED\")\n \n     def __check_status(self, desired, timeout=1):\n         self.await_event(\"%s\\\\|IGNITE_APPLICATION_BROKEN\" % desired, timeout, from_the_beginning=True)\n@@ -64,7 +64,7 @@ def __check_status(self, desired, timeout=1):\n             pass\n \n         try:\n-            self.await_event(desired, 1, from_the_beginning=True)\n+            return self.event_time(desired, 1, from_the_beginning=True)\n         except Exception:\n             raise Exception(\"Java application execution failed.\") from None\n "
  },
  {
    "sha": "f0569cd16b518e2a7781c2eb5c618bd3c665c3d4",
    "filename": "modules/ducktests/tests/ignitetest/services/utils/ignite_aware.py",
    "status": "modified",
    "additions": 39,
    "deletions": 3,
    "changes": 42,
    "blob_url": "https://github.com/apache/ignite/blob/a39604500fbbbadaaea678ccd96bce58da0bacfe/modules/ducktests/tests/ignitetest/services/utils/ignite_aware.py",
    "raw_url": "https://github.com/apache/ignite/raw/a39604500fbbbadaaea678ccd96bce58da0bacfe/modules/ducktests/tests/ignitetest/services/utils/ignite_aware.py",
    "contents_url": "https://api.github.com/repos/apache/ignite/contents/modules/ducktests/tests/ignitetest/services/utils/ignite_aware.py?ref=a39604500fbbbadaaea678ccd96bce58da0bacfe",
    "patch": "@@ -17,6 +17,7 @@\n This module contains the base class to build services aware of Ignite.\n \"\"\"\n import os\n+import re\n import signal\n import socket\n import sys\n@@ -275,13 +276,28 @@ def await_event(self, evt_message, timeout_sec, from_the_beginning=False, backof\n             self.await_event_on_node(evt_message, node, timeout_sec, from_the_beginning=from_the_beginning,\n                                      backoff_sec=backoff_sec)\n \n+    def event_time(self, evt_message, timeout_sec, from_the_beginning=False, backoff_sec=5):\n+        \"\"\"\n+        Await for specific event messages on all nodes and returns max time of theirs.\n+        :param evt_message: Event message.\n+        :param timeout_sec: Number of seconds to check the condition for before failing.\n+        :param from_the_beginning: If True, search for message from the beggining of log file.\n+        :param backoff_sec: Number of seconds to back off between each failure to meet the condition\n+                before checking again.\n+        :return: Maximal event time.\n+        \"\"\"\n+        return max(map(lambda n: get_event_time(n, evt_message, timeout=timeout_sec,\n+                                                from_the_beginning=from_the_beginning, backoff_sec=backoff_sec),\n+                       self.nodes))\n+\n     def exec_on_nodes_async(self, nodes, task, simultaneously=True, delay_ms=0, timeout_sec=20):\n         \"\"\"\n         Executes given task on the nodes.\n-        :param task: a 'lambda: node'.\n+        :param nodes: Nodes list.\n+        :param task: A 'lambda: node'.\n         :param simultaneously: Enables or disables simultaneous start of the task on each node.\n-        :param delay_ms: delay before task run. Begins with 0, grows by delay_ms for each next node in nodes.\n-        :param timeout_sec: timeout to wait the task.\n+        :param delay_ms: Delay before task run. Begins with 0, grows by delay_ms for each next node in nodes.\n+        :param timeout_sec: Timeout to wait the task.\n         \"\"\"\n         sem = CountDownLatch(len(nodes)) if simultaneously else None\n         time_holder = AtomicValue()\n@@ -454,3 +470,23 @@ def restore_from_snapshot(self, snapshot_name: str):\n \n             node.account.ssh(f'rm -rf {self.database_dir}', allow_fail=False)\n             node.account.ssh(f'cp -r {snapshot_db} {self.work_dir}', allow_fail=False)\n+\n+\n+def get_event_time(log_node, log_pattern, from_the_beginning=True, timeout=15, backoff_sec=0.3):\n+    \"\"\"\n+    Extracts event time from ignite log by pattern .\n+    :param log_node: Ducktape node to search ignite log on.\n+    :param log_pattern: Pattern to search ignite log for.\n+    :param from_the_beginning: Switches searching log from its beginning.\n+    :param timeout: Timeout to wait for the patters in the log.\n+    :param backoff_sec: Number of seconds to back off.\n+    :return: Event time.\n+    \"\"\"\n+    IgniteAwareService.await_event_on_node(log_pattern, log_node, timeout, from_the_beginning=from_the_beginning,\n+                                           backoff_sec=backoff_sec)\n+\n+    _, stdout, _ = log_node.account.ssh_client.exec_command(\n+        \"grep '%s' %s\" % (log_pattern, log_node.log_file))\n+\n+    return datetime.strptime(re.match(\"^\\\\[[^\\\\[]+\\\\]\", stdout.read().decode(\"utf-8\")).group(),\n+                             \"[%Y-%m-%d %H:%M:%S,%f]\")"
  },
  {
    "sha": "9ca62783792a5e16dfbe441c8a78e82bee9f8130",
    "filename": "modules/ducktests/tests/ignitetest/tests/discovery_test.py",
    "status": "modified",
    "additions": 3,
    "deletions": 2,
    "changes": 5,
    "blob_url": "https://github.com/apache/ignite/blob/a39604500fbbbadaaea678ccd96bce58da0bacfe/modules/ducktests/tests/ignitetest/tests/discovery_test.py",
    "raw_url": "https://github.com/apache/ignite/raw/a39604500fbbbadaaea678ccd96bce58da0bacfe/modules/ducktests/tests/ignitetest/tests/discovery_test.py",
    "contents_url": "https://api.github.com/repos/apache/ignite/contents/modules/ducktests/tests/ignitetest/tests/discovery_test.py?ref=a39604500fbbbadaaea678ccd96bce58da0bacfe",
    "patch": "@@ -24,7 +24,8 @@\n from typing import NamedTuple\n \n from ducktape.mark import matrix\n-from ignitetest.services.ignite import IgniteAwareService, IgniteService, get_event_time, node_failed_event_pattern\n+from ignitetest.services.ignite import IgniteAwareService, IgniteService, node_failed_event_pattern\n+from ignitetest.services.utils.ignite_aware import get_event_time\n from ignitetest.services.ignite_app import IgniteApplicationService\n from ignitetest.services.utils.ignite_configuration import IgniteConfiguration\n from ignitetest.services.utils.ignite_configuration.cache import CacheConfiguration\n@@ -243,7 +244,7 @@ def _simulate_and_detect_failure(self, servers, failed_nodes, event_timeout_sec,\n \n         for survivor in [n for n in servers.nodes if n not in failed_nodes]:\n             for failed_id in ids_to_wait:\n-                logged_timestamps.append(get_event_time(servers, survivor, node_failed_event_pattern(failed_id),\n+                logged_timestamps.append(get_event_time(survivor, node_failed_event_pattern(failed_id),\n                                                         timeout=event_timeout_sec))\n \n             self._check_failed_number(failed_nodes, survivor)"
  },
  {
    "sha": "8f4f55549ae25ac03426083f997e4c073801f41e",
    "filename": "modules/ducktests/tests/ignitetest/tests/rebalance/__init__.py",
    "status": "modified",
    "additions": 81,
    "deletions": 14,
    "changes": 95,
    "blob_url": "https://github.com/apache/ignite/blob/a39604500fbbbadaaea678ccd96bce58da0bacfe/modules/ducktests/tests/ignitetest/tests/rebalance/__init__.py",
    "raw_url": "https://github.com/apache/ignite/raw/a39604500fbbbadaaea678ccd96bce58da0bacfe/modules/ducktests/tests/ignitetest/tests/rebalance/__init__.py",
    "contents_url": "https://api.github.com/repos/apache/ignite/contents/modules/ducktests/tests/ignitetest/tests/rebalance/__init__.py?ref=a39604500fbbbadaaea678ccd96bce58da0bacfe",
    "patch": "@@ -17,10 +17,13 @@\n This package contains rebalance tests.\n \"\"\"\n \n+from datetime import datetime\n+from typing import NamedTuple\n+\n # pylint: disable=W0622\n from ducktape.errors import TimeoutError\n \n-from ignitetest.services.ignite import get_event_time\n+from ignitetest.services.utils.ignite_aware import get_event_time\n from ignitetest.services.ignite_app import IgniteApplicationService\n \n \n@@ -45,9 +48,7 @@ def preload_data(context, config, backups, cache_count, entry_count, entry_size,\n         startup_timeout_sec=timeout)\n     app.run()\n \n-    return (get_event_time(\n-        app, app.nodes[0], \"Marking as initialized\") - get_event_time(\n-        app, app.nodes[0], \"Data generation started\")).total_seconds()\n+    return (app.await_stopped() - app.await_started()).total_seconds()\n \n \n def await_rebalance_start(ignite, timeout=1):\n@@ -61,14 +62,11 @@ def await_rebalance_start(ignite, timeout=1):\n     \"\"\"\n     for node in ignite.nodes:\n         try:\n-            rebalance_start_time = get_event_time(\n-                ignite, node,\n-                \"Starting rebalance routine \\\\[test-cache-\",\n-                timeout=timeout)\n-        except TimeoutError:\n-            continue\n+            rebalance_start_time = get_event_time(node, \"Starting rebalance routine \\\\[test-cache-\", timeout=timeout)\n+        except TimeoutError as e:\n+            ignite.logger.error(\"Rebalance was not started on node '%s' in %d sec.: %s\" % (node.name, timeout, str(e)))\n         else:\n-            return {\"node\": node, \"time\": rebalance_start_time}\n+            return node, rebalance_start_time\n \n     raise RuntimeError(\"Rebalance start was not detected on any node\")\n \n@@ -86,10 +84,79 @@ def await_rebalance_complete(ignite, node=None, cache_count=1, timeout=300):\n \n     for cache_idx in range(cache_count):\n         rebalance_complete_times.append(get_event_time(\n-            ignite,\n             node if node else ignite.nodes[0],\n-            \"Completed rebalance future: RebalanceFuture \\\\[%s \\\\[grp=test-cache-%d\" %\n-            (\"state=STARTED, grp=CacheGroupContext\", cache_idx + 1),\n+            \"Completed rebalance future: RebalanceFuture \\\\[state=STARTED, grp=CacheGroupContext \\\\\"\n+            \"[grp=test-cache-%d\" % (cache_idx + 1),\n             timeout=timeout))\n \n     return max(rebalance_complete_times)\n+\n+\n+def get_rebalance_metrics(node, cache_group):\n+    \"\"\"\n+    Gets rebalance metrics for specified node and cache group.\n+    :param node: Ignite node.\n+    :param cache_group: Cache group.\n+    :return: RebalanceMetrics instance.\n+    \"\"\"\n+    mbean = node.jmx_client().find_mbean('.*group=cacheGroups.*name=\"%s\"' % cache_group)\n+    start_time = to_datetime(int(next(mbean.RebalancingStartTime)))\n+    end_time = to_datetime(int(next(mbean.RebalancingEndTime)))\n+\n+    return RebalanceMetrics(\n+        received_bytes=int(next(mbean.RebalancingReceivedBytes)),\n+        start_time=start_time,\n+        end_time=end_time,\n+        duration=(end_time - start_time).total_seconds() if start_time and end_time else 0)\n+\n+\n+def to_datetime(ts):\n+    \"\"\"\n+    Converts timestamp in millicesonds to datetime.\n+    :param ts: Timestamp in milliseconds.\n+    :return: datetime constructed from timestamp or None if ts == -1.\n+    \"\"\"\n+    return None if ts == -1 else datetime.fromtimestamp(ts / 1000.0)\n+\n+\n+class RebalanceMetrics(NamedTuple):\n+    \"\"\"\n+    Rebalance metrics\n+    \"\"\"\n+    received_bytes: int = 0\n+    start_time: datetime = None\n+    end_time: datetime = None\n+    duration: float = 0\n+\n+\n+def aggregate_rebalance_stats(nodes, cache_count):\n+    \"\"\"\n+    Aggregates rebalance stats for specified nodes and cache count:\n+    received_bytes -> sum(all of received_bytes)\n+    start_time -> min(all of start_time)\n+    end_time -> max(all of end_time)\n+    duration -> sum(all of duration)\n+    :param nodes: Nodes list.\n+    :param cache_count: Cache count.\n+    :return: RebalanceMetrics instance with aggregated values.\n+    \"\"\"\n+    received_bytes = 0\n+    start_time = None\n+    end_time = None\n+    duration = 0\n+\n+    for node in nodes:\n+        for cache_idx in range(cache_count):\n+            m = get_rebalance_metrics(node, \"test-cache-%d\" % (cache_idx + 1))\n+            received_bytes += m.received_bytes\n+            if m.start_time is not None:\n+                start_time = min(t for t in [start_time, m.start_time] if t is not None)\n+            if m.end_time is not None:\n+                end_time = max(t for t in [end_time, m.end_time] if t is not None)\n+            duration += m.duration\n+\n+    return RebalanceMetrics(\n+        received_bytes=received_bytes,\n+        start_time=start_time,\n+        end_time=end_time,\n+        duration=duration)"
  },
  {
    "sha": "8b830cadac830733153c555b9ee98c9617cadf2a",
    "filename": "modules/ducktests/tests/ignitetest/tests/rebalance/in_memory_test.py",
    "status": "modified",
    "additions": 16,
    "deletions": 6,
    "changes": 22,
    "blob_url": "https://github.com/apache/ignite/blob/a39604500fbbbadaaea678ccd96bce58da0bacfe/modules/ducktests/tests/ignitetest/tests/rebalance/in_memory_test.py",
    "raw_url": "https://github.com/apache/ignite/raw/a39604500fbbbadaaea678ccd96bce58da0bacfe/modules/ducktests/tests/ignitetest/tests/rebalance/in_memory_test.py",
    "contents_url": "https://api.github.com/repos/apache/ignite/contents/modules/ducktests/tests/ignitetest/tests/rebalance/in_memory_test.py?ref=a39604500fbbbadaaea678ccd96bce58da0bacfe",
    "patch": "@@ -24,7 +24,8 @@\n from ignitetest.services.utils.ignite_configuration import IgniteConfiguration, DataStorageConfiguration\n from ignitetest.services.utils.ignite_configuration.data_storage import DataRegionConfiguration\n from ignitetest.services.utils.ignite_configuration.discovery import from_ignite_cluster\n-from ignitetest.tests.rebalance import preload_data, await_rebalance_start, await_rebalance_complete\n+from ignitetest.tests.rebalance import preload_data, await_rebalance_start, await_rebalance_complete, \\\n+    aggregate_rebalance_stats\n from ignitetest.utils import cluster, ignite_versions\n from ignitetest.utils.enum import constructible\n from ignitetest.utils.ignite_test import IgniteTest\n@@ -73,6 +74,7 @@ def test(self, ignite_version, trigger_event,\n                 default=DataRegionConfiguration(max_size=max(\n                     cache_count * entry_count * entry_size * (backups + 1),\n                     self.DEFAULT_DATA_REGION_SZ))),\n+            metric_exporter=\"org.apache.ignite.spi.metric.jmx.JmxMetricExporterSpi\",\n             rebalance_thread_pool_size=rebalance_thread_pool_size,\n             rebalance_batch_size=rebalance_batch_size,\n             rebalance_batches_prefetch_count=rebalance_batches_prefetch_count,\n@@ -95,10 +97,18 @@ def test(self, ignite_version, trigger_event,\n                                    num_nodes=1)\n             ignite.start()\n \n-        start_node_and_time = await_rebalance_start(ignite)\n+        start_node, start_time = await_rebalance_start(ignite)\n \n-        complete_time = await_rebalance_complete(ignite, start_node_and_time[\"node\"], cache_count)\n+        end_time = await_rebalance_complete(ignite, start_node, cache_count)\n \n-        return {\"Rebalanced in (sec)\": (complete_time - start_node_and_time[\"time\"]).total_seconds(),\n-                \"Preloaded in (sec)\": preload_time,\n-                \"Preload speed (MB/sec)\": int(cache_count * entry_count * entry_size / 1000 / preload_time) / 1000.0}\n+        stats = aggregate_rebalance_stats(ignite.nodes[:-1] if trigger_event else ignite.nodes, cache_count)\n+\n+        speed = lambda d: (int(stats.received_bytes / d / 1000) / 1000.0) if d else None\n+\n+        return {\n+            \"Rebalanced in (sec)\": (end_time - start_time).total_seconds(),\n+            \"Rebalance speed (Total, MB/sec)\": speed((stats.end_time - stats.start_time).total_seconds()),\n+            \"Rebalance speed (Average per node, MB/sec)\": speed(stats.duration),\n+            \"Preloaded in (sec)\": preload_time,\n+            \"Preload speed (MB/sec)\": int(cache_count * entry_count * entry_size / 1000 / preload_time) / 1000.0\n+        }"
  }
]
