[
  {
    "sha": "66e46005c8ee153fd0f0f7e65ae0a43b45ca4ae0",
    "filename": "core/src/main/java/org/apache/iceberg/CatalogProperties.java",
    "status": "modified",
    "additions": 2,
    "deletions": 0,
    "changes": 2,
    "blob_url": "https://github.com/apache/iceberg/blob/ac68163045fbe7c91e50197b8e42e677c206bf61/core/src/main/java/org/apache/iceberg/CatalogProperties.java",
    "raw_url": "https://github.com/apache/iceberg/raw/ac68163045fbe7c91e50197b8e42e677c206bf61/core/src/main/java/org/apache/iceberg/CatalogProperties.java",
    "contents_url": "https://api.github.com/repos/apache/iceberg/contents/core/src/main/java/org/apache/iceberg/CatalogProperties.java?ref=ac68163045fbe7c91e50197b8e42e677c206bf61",
    "patch": "@@ -33,6 +33,8 @@ private CatalogProperties() {\n   public static final String URI = \"uri\";\n   public static final String CLIENT_POOL_SIZE = \"clients\";\n   public static final int CLIENT_POOL_SIZE_DEFAULT = 2;\n+  public static final String CLIENT_POOL_CACHE_EVICTION_INTERVAL_MS = \"client.pool.cache.eviction-interval-ms\";\n+  public static final long CLIENT_POOL_CACHE_EVICTION_INTERVAL_MS_DEFAULT = TimeUnit.MINUTES.toMillis(5);\n \n   public static final String LOCK_IMPL = \"lock-impl\";\n "
  },
  {
    "sha": "7e663b2a61fedd7a976481265c40509fd0c106d1",
    "filename": "flink/src/test/java/org/apache/iceberg/flink/FlinkTestBase.java",
    "status": "modified",
    "additions": 0,
    "deletions": 1,
    "changes": 1,
    "blob_url": "https://github.com/apache/iceberg/blob/ac68163045fbe7c91e50197b8e42e677c206bf61/flink/src/test/java/org/apache/iceberg/flink/FlinkTestBase.java",
    "raw_url": "https://github.com/apache/iceberg/raw/ac68163045fbe7c91e50197b8e42e677c206bf61/flink/src/test/java/org/apache/iceberg/flink/FlinkTestBase.java",
    "contents_url": "https://api.github.com/repos/apache/iceberg/contents/flink/src/test/java/org/apache/iceberg/flink/FlinkTestBase.java?ref=ac68163045fbe7c91e50197b8e42e677c206bf61",
    "patch": "@@ -66,7 +66,6 @@ public static void startMetastore() {\n   @AfterClass\n   public static void stopMetastore() {\n     metastore.stop();\n-    catalog.close();\n     FlinkTestBase.catalog = null;\n   }\n "
  },
  {
    "sha": "2e8007c899897c37bfe2f9ba692cef0908f22b14",
    "filename": "flink/src/test/java/org/apache/iceberg/flink/source/TestFlinkReaderDeletesBase.java",
    "status": "modified",
    "additions": 0,
    "deletions": 1,
    "changes": 1,
    "blob_url": "https://github.com/apache/iceberg/blob/ac68163045fbe7c91e50197b8e42e677c206bf61/flink/src/test/java/org/apache/iceberg/flink/source/TestFlinkReaderDeletesBase.java",
    "raw_url": "https://github.com/apache/iceberg/raw/ac68163045fbe7c91e50197b8e42e677c206bf61/flink/src/test/java/org/apache/iceberg/flink/source/TestFlinkReaderDeletesBase.java",
    "contents_url": "https://api.github.com/repos/apache/iceberg/contents/flink/src/test/java/org/apache/iceberg/flink/source/TestFlinkReaderDeletesBase.java?ref=ac68163045fbe7c91e50197b8e42e677c206bf61",
    "patch": "@@ -82,7 +82,6 @@ public static void startMetastore() {\n   @AfterClass\n   public static void stopMetastore() {\n     metastore.stop();\n-    catalog.close();\n     catalog = null;\n   }\n "
  },
  {
    "sha": "eca505cf8a358579ec53e31d01128e792ce55873",
    "filename": "hive-metastore/src/main/java/org/apache/iceberg/hive/CachedClientPool.java",
    "status": "added",
    "additions": 78,
    "deletions": 0,
    "changes": 78,
    "blob_url": "https://github.com/apache/iceberg/blob/ac68163045fbe7c91e50197b8e42e677c206bf61/hive-metastore/src/main/java/org/apache/iceberg/hive/CachedClientPool.java",
    "raw_url": "https://github.com/apache/iceberg/raw/ac68163045fbe7c91e50197b8e42e677c206bf61/hive-metastore/src/main/java/org/apache/iceberg/hive/CachedClientPool.java",
    "contents_url": "https://api.github.com/repos/apache/iceberg/contents/hive-metastore/src/main/java/org/apache/iceberg/hive/CachedClientPool.java?ref=ac68163045fbe7c91e50197b8e42e677c206bf61",
    "patch": "@@ -0,0 +1,78 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.hive;\n+\n+import com.github.benmanes.caffeine.cache.Cache;\n+import com.github.benmanes.caffeine.cache.Caffeine;\n+import java.util.Map;\n+import java.util.concurrent.TimeUnit;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hive.conf.HiveConf;\n+import org.apache.hadoop.hive.metastore.HiveMetaStoreClient;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.relocated.com.google.common.annotations.VisibleForTesting;\n+import org.apache.iceberg.util.PropertyUtil;\n+import org.apache.thrift.TException;\n+\n+public class CachedClientPool implements ClientPool<HiveMetaStoreClient, TException> {\n+\n+  private static Cache<String, HiveClientPool> clientPoolCache;\n+\n+  private final Configuration conf;\n+  private final String metastoreUri;\n+  private final int clientPoolSize;\n+  private final long evictionInterval;\n+\n+  CachedClientPool(Configuration conf, Map<String, String> properties) {\n+    this.conf = conf;\n+    this.metastoreUri = conf.get(HiveConf.ConfVars.METASTOREURIS.varname, \"\");\n+    this.clientPoolSize = PropertyUtil.propertyAsInt(properties,\n+            CatalogProperties.CLIENT_POOL_SIZE,\n+            CatalogProperties.CLIENT_POOL_SIZE_DEFAULT);\n+    this.evictionInterval = PropertyUtil.propertyAsLong(properties,\n+            CatalogProperties.CLIENT_POOL_CACHE_EVICTION_INTERVAL_MS,\n+            CatalogProperties.CLIENT_POOL_CACHE_EVICTION_INTERVAL_MS_DEFAULT);\n+    init();\n+  }\n+\n+  @VisibleForTesting\n+  HiveClientPool clientPool() {\n+    return clientPoolCache.get(metastoreUri, k -> new HiveClientPool(clientPoolSize, conf));\n+  }\n+\n+\n+  private synchronized void init() {\n+    if (clientPoolCache == null) {\n+      clientPoolCache = Caffeine.newBuilder().expireAfterAccess(evictionInterval, TimeUnit.MILLISECONDS)\n+              .removalListener((key, value, cause) -> ((HiveClientPool) value).close())\n+              .build();\n+    }\n+  }\n+\n+  @VisibleForTesting\n+  static Cache<String, HiveClientPool> clientPoolCache() {\n+    return clientPoolCache;\n+  }\n+\n+  @Override\n+  public <R> R run(Action<R, HiveMetaStoreClient, TException> action) throws TException, InterruptedException {\n+    return clientPool().run(action);\n+  }\n+}"
  },
  {
    "sha": "7f32cf948d84d8a3961921647d39546da07b871c",
    "filename": "hive-metastore/src/main/java/org/apache/iceberg/hive/ClientPool.java",
    "status": "modified",
    "additions": 3,
    "deletions": 123,
    "changes": 126,
    "blob_url": "https://github.com/apache/iceberg/blob/ac68163045fbe7c91e50197b8e42e677c206bf61/hive-metastore/src/main/java/org/apache/iceberg/hive/ClientPool.java",
    "raw_url": "https://github.com/apache/iceberg/raw/ac68163045fbe7c91e50197b8e42e677c206bf61/hive-metastore/src/main/java/org/apache/iceberg/hive/ClientPool.java",
    "contents_url": "https://api.github.com/repos/apache/iceberg/contents/hive-metastore/src/main/java/org/apache/iceberg/hive/ClientPool.java?ref=ac68163045fbe7c91e50197b8e42e677c206bf61",
    "patch": "@@ -19,130 +19,10 @@\n \n package org.apache.iceberg.hive;\n \n-import java.io.Closeable;\n-import java.util.ArrayDeque;\n-import java.util.Deque;\n-import org.apache.iceberg.relocated.com.google.common.annotations.VisibleForTesting;\n-import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n-public abstract class ClientPool<C, E extends Exception> implements Closeable {\n-  private static final Logger LOG = LoggerFactory.getLogger(ClientPool.class);\n-\n-  private final int poolSize;\n-  private final Deque<C> clients;\n-  private final Class<? extends E> reconnectExc;\n-  private final Object signal = new Object();\n-  private volatile int currentSize;\n-  private boolean closed;\n-\n-  ClientPool(int poolSize, Class<? extends E> reconnectExc) {\n-    this.poolSize = poolSize;\n-    this.reconnectExc = reconnectExc;\n-    this.clients = new ArrayDeque<>(poolSize);\n-    this.currentSize = 0;\n-    this.closed = false;\n-  }\n-\n-  public interface Action<R, C, E extends Exception> {\n+public interface ClientPool<C, E extends Exception> {\n+  interface Action<R, C, E extends Exception> {\n     R run(C client) throws E;\n   }\n \n-  public <R> R run(Action<R, C, E> action) throws E, InterruptedException {\n-    C client = get();\n-    try {\n-      return action.run(client);\n-\n-    } catch (Exception exc) {\n-      if (isConnectionException(exc)) {\n-        try {\n-          client = reconnect(client);\n-        } catch (Exception ignored) {\n-          // if reconnection throws any exception, rethrow the original failure\n-          throw reconnectExc.cast(exc);\n-        }\n-\n-        return action.run(client);\n-      }\n-\n-      throw exc;\n-\n-    } finally {\n-      release(client);\n-    }\n-  }\n-\n-  protected abstract C newClient();\n-\n-  protected abstract C reconnect(C client);\n-\n-  protected boolean isConnectionException(Exception exc) {\n-    return reconnectExc.isInstance(exc);\n-  }\n-\n-  protected abstract void close(C client);\n-\n-  @Override\n-  public void close() {\n-    this.closed = true;\n-    try {\n-      while (currentSize > 0) {\n-        if (!clients.isEmpty()) {\n-          synchronized (this) {\n-            if (!clients.isEmpty()) {\n-              C client = clients.removeFirst();\n-              close(client);\n-              currentSize -= 1;\n-            }\n-          }\n-        }\n-        if (clients.isEmpty() && currentSize > 0) {\n-          // wake every second in case this missed the signal\n-          synchronized (signal) {\n-            signal.wait(1000);\n-          }\n-        }\n-      }\n-\n-    } catch (InterruptedException e) {\n-      Thread.currentThread().interrupt();\n-      LOG.warn(\"Interrupted while shutting down pool. Some clients may not be closed.\", e);\n-    }\n-  }\n-\n-  @VisibleForTesting\n-  int poolSize() {\n-    return poolSize;\n-  }\n-\n-  private C get() throws InterruptedException {\n-    Preconditions.checkState(!closed, \"Cannot get a client from a closed pool\");\n-    while (true) {\n-      if (!clients.isEmpty() || currentSize < poolSize) {\n-        synchronized (this) {\n-          if (!clients.isEmpty()) {\n-            return clients.removeFirst();\n-          } else if (currentSize < poolSize) {\n-            C client = newClient();\n-            currentSize += 1;\n-            return client;\n-          }\n-        }\n-      }\n-      synchronized (signal) {\n-        // wake every second in case this missed the signal\n-        signal.wait(1000);\n-      }\n-    }\n-  }\n-\n-  private void release(C client) {\n-    synchronized (this) {\n-      clients.addFirst(client);\n-    }\n-    synchronized (signal) {\n-      signal.notify();\n-    }\n-  }\n+  <R> R run(Action<R, C, E> action) throws E, InterruptedException;\n }"
  },
  {
    "sha": "d1a44d318637b0080e4e08bf29dbf37f349c5eb9",
    "filename": "hive-metastore/src/main/java/org/apache/iceberg/hive/ClientPoolImpl.java",
    "status": "added",
    "additions": 145,
    "deletions": 0,
    "changes": 145,
    "blob_url": "https://github.com/apache/iceberg/blob/ac68163045fbe7c91e50197b8e42e677c206bf61/hive-metastore/src/main/java/org/apache/iceberg/hive/ClientPoolImpl.java",
    "raw_url": "https://github.com/apache/iceberg/raw/ac68163045fbe7c91e50197b8e42e677c206bf61/hive-metastore/src/main/java/org/apache/iceberg/hive/ClientPoolImpl.java",
    "contents_url": "https://api.github.com/repos/apache/iceberg/contents/hive-metastore/src/main/java/org/apache/iceberg/hive/ClientPoolImpl.java?ref=ac68163045fbe7c91e50197b8e42e677c206bf61",
    "patch": "@@ -0,0 +1,145 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.hive;\n+\n+import java.io.Closeable;\n+import java.util.ArrayDeque;\n+import java.util.Deque;\n+import org.apache.iceberg.relocated.com.google.common.annotations.VisibleForTesting;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public abstract class ClientPoolImpl<C, E extends Exception> implements Closeable, ClientPool<C, E> {\n+  private static final Logger LOG = LoggerFactory.getLogger(ClientPoolImpl.class);\n+\n+  private final int poolSize;\n+  private final Deque<C> clients;\n+  private final Class<? extends E> reconnectExc;\n+  private final Object signal = new Object();\n+  private volatile int currentSize;\n+  private boolean closed;\n+\n+  ClientPoolImpl(int poolSize, Class<? extends E> reconnectExc) {\n+    this.poolSize = poolSize;\n+    this.reconnectExc = reconnectExc;\n+    this.clients = new ArrayDeque<>(poolSize);\n+    this.currentSize = 0;\n+    this.closed = false;\n+  }\n+\n+  @Override\n+  public <R> R run(Action<R, C, E> action) throws E, InterruptedException {\n+    C client = get();\n+    try {\n+      return action.run(client);\n+\n+    } catch (Exception exc) {\n+      if (isConnectionException(exc)) {\n+        try {\n+          client = reconnect(client);\n+        } catch (Exception ignored) {\n+          // if reconnection throws any exception, rethrow the original failure\n+          throw reconnectExc.cast(exc);\n+        }\n+\n+        return action.run(client);\n+      }\n+\n+      throw exc;\n+\n+    } finally {\n+      release(client);\n+    }\n+  }\n+\n+  protected abstract C newClient();\n+\n+  protected abstract C reconnect(C client);\n+\n+  protected boolean isConnectionException(Exception exc) {\n+    return reconnectExc.isInstance(exc);\n+  }\n+\n+  protected abstract void close(C client);\n+\n+  @Override\n+  public void close() {\n+    this.closed = true;\n+    try {\n+      while (currentSize > 0) {\n+        if (!clients.isEmpty()) {\n+          synchronized (this) {\n+            if (!clients.isEmpty()) {\n+              C client = clients.removeFirst();\n+              close(client);\n+              currentSize -= 1;\n+            }\n+          }\n+        }\n+        if (clients.isEmpty() && currentSize > 0) {\n+          // wake every second in case this missed the signal\n+          synchronized (signal) {\n+            signal.wait(1000);\n+          }\n+        }\n+      }\n+\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      LOG.warn(\"Interrupted while shutting down pool. Some clients may not be closed.\", e);\n+    }\n+  }\n+\n+  private C get() throws InterruptedException {\n+    Preconditions.checkState(!closed, \"Cannot get a client from a closed pool\");\n+    while (true) {\n+      if (!clients.isEmpty() || currentSize < poolSize) {\n+        synchronized (this) {\n+          if (!clients.isEmpty()) {\n+            return clients.removeFirst();\n+          } else if (currentSize < poolSize) {\n+            C client = newClient();\n+            currentSize += 1;\n+            return client;\n+          }\n+        }\n+      }\n+      synchronized (signal) {\n+        // wake every second in case this missed the signal\n+        signal.wait(1000);\n+      }\n+    }\n+  }\n+\n+  private void release(C client) {\n+    synchronized (this) {\n+      clients.addFirst(client);\n+    }\n+    synchronized (signal) {\n+      signal.notify();\n+    }\n+  }\n+\n+  @VisibleForTesting\n+  int poolSize() {\n+    return poolSize;\n+  }\n+}"
  },
  {
    "sha": "e27eb5727dc87ca5bd19272a5ff5bb4be5807b47",
    "filename": "hive-metastore/src/main/java/org/apache/iceberg/hive/HiveCatalog.java",
    "status": "modified",
    "additions": 12,
    "deletions": 42,
    "changes": 54,
    "blob_url": "https://github.com/apache/iceberg/blob/ac68163045fbe7c91e50197b8e42e677c206bf61/hive-metastore/src/main/java/org/apache/iceberg/hive/HiveCatalog.java",
    "raw_url": "https://github.com/apache/iceberg/raw/ac68163045fbe7c91e50197b8e42e677c206bf61/hive-metastore/src/main/java/org/apache/iceberg/hive/HiveCatalog.java",
    "contents_url": "https://api.github.com/repos/apache/iceberg/contents/hive-metastore/src/main/java/org/apache/iceberg/hive/HiveCatalog.java?ref=ac68163045fbe7c91e50197b8e42e677c206bf61",
    "patch": "@@ -19,8 +19,6 @@\n \n package org.apache.iceberg.hive;\n \n-import java.io.Closeable;\n-import java.util.Arrays;\n import java.util.List;\n import java.util.Map;\n import java.util.Set;\n@@ -50,25 +48,22 @@\n import org.apache.iceberg.exceptions.NoSuchTableException;\n import org.apache.iceberg.hadoop.HadoopFileIO;\n import org.apache.iceberg.io.FileIO;\n-import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n import org.apache.iceberg.relocated.com.google.common.base.MoreObjects;\n import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n import org.apache.iceberg.relocated.com.google.common.collect.ImmutableList;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n import org.apache.iceberg.relocated.com.google.common.collect.Maps;\n-import org.apache.iceberg.util.PropertyUtil;\n import org.apache.thrift.TException;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n-public class HiveCatalog extends BaseMetastoreCatalog implements Closeable, SupportsNamespaces, Configurable {\n+public class HiveCatalog extends BaseMetastoreCatalog implements SupportsNamespaces, Configurable {\n   private static final Logger LOG = LoggerFactory.getLogger(HiveCatalog.class);\n \n   private String name;\n-  private HiveClientPool clients;\n   private Configuration conf;\n-  private StackTraceElement[] createStack;\n   private FileIO fileIO;\n-  private boolean closed;\n+  private ClientPool<HiveMetaStoreClient, TException> clients;\n \n   public HiveCatalog() {\n   }\n@@ -83,12 +78,15 @@ public HiveCatalog() {\n   @Deprecated\n   public HiveCatalog(Configuration conf) {\n     this.name = \"hive\";\n-    int clientPoolSize = conf.getInt(CatalogProperties.CLIENT_POOL_SIZE, CatalogProperties.CLIENT_POOL_SIZE_DEFAULT);\n-    this.clients = new HiveClientPool(clientPoolSize, conf);\n     this.conf = conf;\n-    this.createStack = Thread.currentThread().getStackTrace();\n-    this.closed = false;\n     this.fileIO = new HadoopFileIO(conf);\n+    Map<String, String> properties = ImmutableMap.of(\n+            CatalogProperties.CLIENT_POOL_CACHE_EVICTION_INTERVAL_MS,\n+            conf.get(CatalogProperties.CLIENT_POOL_CACHE_EVICTION_INTERVAL_MS),\n+            CatalogProperties.CLIENT_POOL_SIZE,\n+            conf.get(CatalogProperties.CLIENT_POOL_SIZE)\n+    );\n+    this.clients = new CachedClientPool(conf, properties);\n   }\n \n   @Override\n@@ -102,14 +100,10 @@ public void initialize(String inputName, Map<String, String> properties) {\n       this.conf.set(HiveConf.ConfVars.METASTOREWAREHOUSE.varname, properties.get(CatalogProperties.WAREHOUSE_LOCATION));\n     }\n \n-    int clientPoolSize = PropertyUtil.propertyAsInt(properties,\n-        CatalogProperties.CLIENT_POOL_SIZE, CatalogProperties.CLIENT_POOL_SIZE_DEFAULT);\n-    this.clients = new HiveClientPool(clientPoolSize, this.conf);\n-    this.createStack = Thread.currentThread().getStackTrace();\n-    this.closed = false;\n-\n     String fileIOImpl = properties.get(CatalogProperties.FILE_IO_IMPL);\n     this.fileIO = fileIOImpl == null ? new HadoopFileIO(conf) : CatalogUtil.loadFileIO(fileIOImpl, properties, conf);\n+\n+    this.clients = new CachedClientPool(conf, properties);\n   }\n \n   @Override\n@@ -506,30 +500,6 @@ Database convertToDatabase(Namespace namespace, Map<String, String> meta) {\n \n     return database;\n   }\n-\n-  @Override\n-  public void close() {\n-    if (!closed) {\n-      clients.close();\n-      closed = true;\n-    }\n-  }\n-\n-  @SuppressWarnings(\"checkstyle:NoFinalizer\")\n-  @Override\n-  protected void finalize() throws Throwable {\n-    super.finalize();\n-    // todo it is possible that the Catalog is gc-ed before child table operations are done w/ the clients object.\n-    // The closing of the HiveCatalog should take that into account and child TableOperations should own the clients obj\n-    // or the TabaleOperations should be explicitly closed and the Catalog can't be gc-ed/closed till all children are.\n-    if (!closed) {\n-      close(); // releasing resources is more important than printing the warning\n-      String trace = Joiner.on(\"\\n\\t\").join(\n-          Arrays.copyOfRange(createStack, 1, createStack.length));\n-      LOG.warn(\"Unclosed input stream created by:\\n\\t{}\", trace);\n-    }\n-  }\n-\n   @Override\n   public String toString() {\n     return MoreObjects.toStringHelper(this)"
  },
  {
    "sha": "4d8e0133ffae1dfac567280c98eb57ff0cdfaa22",
    "filename": "hive-metastore/src/main/java/org/apache/iceberg/hive/HiveCatalogs.java",
    "status": "modified",
    "additions": 5,
    "deletions": 0,
    "changes": 5,
    "blob_url": "https://github.com/apache/iceberg/blob/ac68163045fbe7c91e50197b8e42e677c206bf61/hive-metastore/src/main/java/org/apache/iceberg/hive/HiveCatalogs.java",
    "raw_url": "https://github.com/apache/iceberg/raw/ac68163045fbe7c91e50197b8e42e677c206bf61/hive-metastore/src/main/java/org/apache/iceberg/hive/HiveCatalogs.java",
    "contents_url": "https://api.github.com/repos/apache/iceberg/contents/hive-metastore/src/main/java/org/apache/iceberg/hive/HiveCatalogs.java?ref=ac68163045fbe7c91e50197b8e42e677c206bf61",
    "patch": "@@ -33,6 +33,11 @@\n   private HiveCatalogs() {\n   }\n \n+  /**\n+   * @deprecated please use the no-arg constructor, setConf and initialize to construct the catalog. Will be removed in\n+   * v0.12.0\n+   */\n+  @Deprecated\n   public static HiveCatalog loadCatalog(Configuration conf) {\n     // metastore URI can be null in local mode\n     String metastoreUri = conf.get(HiveConf.ConfVars.METASTOREURIS.varname, \"\");"
  },
  {
    "sha": "ef31e3ba62983ad2db954bd64bab2ee174cf39c6",
    "filename": "hive-metastore/src/main/java/org/apache/iceberg/hive/HiveClientPool.java",
    "status": "modified",
    "additions": 1,
    "deletions": 1,
    "changes": 2,
    "blob_url": "https://github.com/apache/iceberg/blob/ac68163045fbe7c91e50197b8e42e677c206bf61/hive-metastore/src/main/java/org/apache/iceberg/hive/HiveClientPool.java",
    "raw_url": "https://github.com/apache/iceberg/raw/ac68163045fbe7c91e50197b8e42e677c206bf61/hive-metastore/src/main/java/org/apache/iceberg/hive/HiveClientPool.java",
    "contents_url": "https://api.github.com/repos/apache/iceberg/contents/hive-metastore/src/main/java/org/apache/iceberg/hive/HiveClientPool.java?ref=ac68163045fbe7c91e50197b8e42e677c206bf61",
    "patch": "@@ -28,7 +28,7 @@\n import org.apache.thrift.TException;\n import org.apache.thrift.transport.TTransportException;\n \n-public class HiveClientPool extends ClientPool<HiveMetaStoreClient, TException> {\n+public class HiveClientPool extends ClientPoolImpl<HiveMetaStoreClient, TException> {\n \n   // use appropriate ctor depending on whether we're working with Hive2 or Hive3 dependencies\n   // we need to do this because there is a breaking API change between Hive2 and Hive3"
  },
  {
    "sha": "3d6823b980f1f527a481a4b11f70361c85498852",
    "filename": "hive-metastore/src/main/java/org/apache/iceberg/hive/HiveTableOperations.java",
    "status": "modified",
    "additions": 2,
    "deletions": 2,
    "changes": 4,
    "blob_url": "https://github.com/apache/iceberg/blob/ac68163045fbe7c91e50197b8e42e677c206bf61/hive-metastore/src/main/java/org/apache/iceberg/hive/HiveTableOperations.java",
    "raw_url": "https://github.com/apache/iceberg/raw/ac68163045fbe7c91e50197b8e42e677c206bf61/hive-metastore/src/main/java/org/apache/iceberg/hive/HiveTableOperations.java",
    "contents_url": "https://api.github.com/repos/apache/iceberg/contents/hive-metastore/src/main/java/org/apache/iceberg/hive/HiveTableOperations.java?ref=ac68163045fbe7c91e50197b8e42e677c206bf61",
    "patch": "@@ -91,7 +91,6 @@\n     }\n   }\n \n-  private final HiveClientPool metaClients;\n   private final String fullName;\n   private final String database;\n   private final String tableName;\n@@ -100,8 +99,9 @@\n   private final long lockCheckMinWaitTime;\n   private final long lockCheckMaxWaitTime;\n   private final FileIO fileIO;\n+  private final ClientPool<HiveMetaStoreClient, TException> metaClients;\n \n-  protected HiveTableOperations(Configuration conf, HiveClientPool metaClients, FileIO fileIO,\n+  protected HiveTableOperations(Configuration conf, ClientPool metaClients, FileIO fileIO,\n                                 String catalogName, String database, String table) {\n     this.conf = conf;\n     this.metaClients = metaClients;"
  },
  {
    "sha": "f98e1a5d90fe8abfde1afc18d35c1d9c680b3c35",
    "filename": "hive-metastore/src/test/java/org/apache/iceberg/hive/HiveMetastoreTest.java",
    "status": "modified",
    "additions": 5,
    "deletions": 2,
    "changes": 7,
    "blob_url": "https://github.com/apache/iceberg/blob/ac68163045fbe7c91e50197b8e42e677c206bf61/hive-metastore/src/test/java/org/apache/iceberg/hive/HiveMetastoreTest.java",
    "raw_url": "https://github.com/apache/iceberg/raw/ac68163045fbe7c91e50197b8e42e677c206bf61/hive-metastore/src/test/java/org/apache/iceberg/hive/HiveMetastoreTest.java",
    "contents_url": "https://api.github.com/repos/apache/iceberg/contents/hive-metastore/src/test/java/org/apache/iceberg/hive/HiveMetastoreTest.java?ref=ac68163045fbe7c91e50197b8e42e677c206bf61",
    "patch": "@@ -20,9 +20,11 @@\n package org.apache.iceberg.hive;\n \n import java.util.HashMap;\n+import java.util.concurrent.TimeUnit;\n import org.apache.hadoop.hive.conf.HiveConf;\n import org.apache.hadoop.hive.metastore.HiveMetaStoreClient;\n import org.apache.hadoop.hive.metastore.api.Database;\n+import org.apache.iceberg.CatalogProperties;\n import org.apache.iceberg.CatalogUtil;\n import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n import org.junit.AfterClass;\n@@ -31,6 +33,7 @@\n public abstract class HiveMetastoreTest {\n \n   protected static final String DB_NAME = \"hivedb\";\n+  protected static final long EVICTION_INTERVAL = TimeUnit.SECONDS.toMillis(10);\n \n   protected static HiveMetaStoreClient metastoreClient;\n   protected static HiveCatalog catalog;\n@@ -47,12 +50,12 @@ public static void startMetastore() throws Exception {\n     Database db = new Database(DB_NAME, \"description\", dbPath, new HashMap<>());\n     metastoreClient.createDatabase(db);\n     HiveMetastoreTest.catalog = (HiveCatalog)\n-        CatalogUtil.loadCatalog(HiveCatalog.class.getName(), \"hive\", ImmutableMap.of(), hiveConf);\n+        CatalogUtil.loadCatalog(HiveCatalog.class.getName(), CatalogUtil.ICEBERG_CATALOG_TYPE_HIVE, ImmutableMap.of(\n+                CatalogProperties.CLIENT_POOL_CACHE_EVICTION_INTERVAL_MS, String.valueOf(EVICTION_INTERVAL)), hiveConf);\n   }\n \n   @AfterClass\n   public static void stopMetastore() {\n-    catalog.close();\n     HiveMetastoreTest.catalog = null;\n \n     metastoreClient.close();"
  },
  {
    "sha": "7c1f3c4028fb3ba12dc9e412545042fa21a1a0c5",
    "filename": "hive-metastore/src/test/java/org/apache/iceberg/hive/TestCachedClientPool.java",
    "status": "added",
    "additions": 43,
    "deletions": 0,
    "changes": 43,
    "blob_url": "https://github.com/apache/iceberg/blob/ac68163045fbe7c91e50197b8e42e677c206bf61/hive-metastore/src/test/java/org/apache/iceberg/hive/TestCachedClientPool.java",
    "raw_url": "https://github.com/apache/iceberg/raw/ac68163045fbe7c91e50197b8e42e677c206bf61/hive-metastore/src/test/java/org/apache/iceberg/hive/TestCachedClientPool.java",
    "contents_url": "https://api.github.com/repos/apache/iceberg/contents/hive-metastore/src/test/java/org/apache/iceberg/hive/TestCachedClientPool.java?ref=ac68163045fbe7c91e50197b8e42e677c206bf61",
    "patch": "@@ -0,0 +1,43 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.hive;\n+\n+import java.util.Collections;\n+import java.util.concurrent.TimeUnit;\n+import org.apache.hadoop.hive.conf.HiveConf;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+public class TestCachedClientPool extends HiveMetastoreTest {\n+\n+  @Test\n+  public void testClientPoolCleaner() throws InterruptedException {\n+    String metastoreUri = hiveConf.get(HiveConf.ConfVars.METASTOREURIS.varname, \"\");\n+    CachedClientPool clientPool = new CachedClientPool(hiveConf, Collections.emptyMap());\n+    HiveClientPool clientPool1 = clientPool.clientPool();\n+    Assert.assertTrue(CachedClientPool.clientPoolCache().getIfPresent(metastoreUri) == clientPool1);\n+    TimeUnit.MILLISECONDS.sleep(EVICTION_INTERVAL - TimeUnit.SECONDS.toMillis(2));\n+    HiveClientPool clientPool2 = clientPool.clientPool();\n+    Assert.assertTrue(clientPool1 == clientPool2);\n+    TimeUnit.MILLISECONDS.sleep(EVICTION_INTERVAL + TimeUnit.SECONDS.toMillis(5));\n+    Assert.assertNull(CachedClientPool.clientPoolCache().getIfPresent(metastoreUri));\n+  }\n+\n+}"
  },
  {
    "sha": "c35247dfed43f3b371400008b9b0c3a39c3a0443",
    "filename": "hive-metastore/src/test/java/org/apache/iceberg/hive/TestClientPoolImpl.java",
    "status": "renamed",
    "additions": 1,
    "deletions": 1,
    "changes": 2,
    "blob_url": "https://github.com/apache/iceberg/blob/ac68163045fbe7c91e50197b8e42e677c206bf61/hive-metastore/src/test/java/org/apache/iceberg/hive/TestClientPoolImpl.java",
    "raw_url": "https://github.com/apache/iceberg/raw/ac68163045fbe7c91e50197b8e42e677c206bf61/hive-metastore/src/test/java/org/apache/iceberg/hive/TestClientPoolImpl.java",
    "contents_url": "https://api.github.com/repos/apache/iceberg/contents/hive-metastore/src/test/java/org/apache/iceberg/hive/TestClientPoolImpl.java?ref=ac68163045fbe7c91e50197b8e42e677c206bf61",
    "patch": "@@ -36,7 +36,7 @@\n import org.junit.Test;\n import org.mockito.Mockito;\n \n-public class TestClientPool {\n+public class TestClientPoolImpl {\n \n   HiveClientPool clients;\n ",
    "previous_filename": "hive-metastore/src/test/java/org/apache/iceberg/hive/TestClientPool.java"
  },
  {
    "sha": "531e511ac54ab243b36abfc3bc6fcca4138ee7b6",
    "filename": "hive-metastore/src/test/java/org/apache/iceberg/hive/TestHiveCommitLocks.java",
    "status": "modified",
    "additions": 7,
    "deletions": 1,
    "changes": 8,
    "blob_url": "https://github.com/apache/iceberg/blob/ac68163045fbe7c91e50197b8e42e677c206bf61/hive-metastore/src/test/java/org/apache/iceberg/hive/TestHiveCommitLocks.java",
    "raw_url": "https://github.com/apache/iceberg/raw/ac68163045fbe7c91e50197b8e42e677c206bf61/hive-metastore/src/test/java/org/apache/iceberg/hive/TestHiveCommitLocks.java",
    "contents_url": "https://api.github.com/repos/apache/iceberg/contents/hive-metastore/src/test/java/org/apache/iceberg/hive/TestHiveCommitLocks.java?ref=ac68163045fbe7c91e50197b8e42e677c206bf61",
    "patch": "@@ -19,6 +19,7 @@\n \n package org.apache.iceberg.hive;\n \n+import java.util.Collections;\n import java.util.concurrent.atomic.AtomicReference;\n import org.apache.hadoop.conf.Configuration;\n import org.apache.hadoop.hive.metastore.HiveMetaStoreClient;\n@@ -47,6 +48,7 @@\n public class TestHiveCommitLocks extends HiveTableBaseTest {\n   private static HiveTableOperations spyOps = null;\n   private static HiveClientPool spyClientPool = null;\n+  private static CachedClientPool spyCachedClientPool = null;\n   private static Configuration overriddenHiveConf = new Configuration(hiveConf);\n   private static AtomicReference<HiveMetaStoreClient> spyClientRef = new AtomicReference<>();\n   private static HiveMetaStoreClient spyClient = null;\n@@ -75,6 +77,10 @@ public static void initializeSpies() throws Exception {\n     });\n \n     spyClientPool.run(HiveMetaStoreClient::isLocalMetaStore); // To ensure new client is created.\n+\n+    spyCachedClientPool = spy(new CachedClientPool(hiveConf, Collections.emptyMap()));\n+    when(spyCachedClientPool.clientPool()).thenAnswer(invocation -> spyClientPool);\n+\n     Assert.assertNotNull(spyClientRef.get());\n \n     spyClient = spyClientRef.get();\n@@ -99,7 +105,7 @@ public void before() throws Exception {\n \n     Assert.assertEquals(2, ops.current().schema().columns().size());\n \n-    spyOps = spy(new HiveTableOperations(overriddenHiveConf, spyClientPool, ops.io(), catalog.name(),\n+    spyOps = spy(new HiveTableOperations(overriddenHiveConf, spyCachedClientPool, ops.io(), catalog.name(),\n             dbName, tableName));\n   }\n "
  },
  {
    "sha": "c60bc47d52006d3e79d4712a21fa994519d70aa7",
    "filename": "mr/src/main/java/org/apache/iceberg/mr/Catalogs.java",
    "status": "modified",
    "additions": 5,
    "deletions": 2,
    "changes": 7,
    "blob_url": "https://github.com/apache/iceberg/blob/ac68163045fbe7c91e50197b8e42e677c206bf61/mr/src/main/java/org/apache/iceberg/mr/Catalogs.java",
    "raw_url": "https://github.com/apache/iceberg/raw/ac68163045fbe7c91e50197b8e42e677c206bf61/mr/src/main/java/org/apache/iceberg/mr/Catalogs.java",
    "contents_url": "https://api.github.com/repos/apache/iceberg/contents/mr/src/main/java/org/apache/iceberg/mr/Catalogs.java?ref=ac68163045fbe7c91e50197b8e42e677c206bf61",
    "patch": "@@ -25,6 +25,7 @@\n import java.util.Properties;\n import java.util.Set;\n import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.CatalogUtil;\n import org.apache.iceberg.PartitionSpec;\n import org.apache.iceberg.PartitionSpecParser;\n import org.apache.iceberg.Schema;\n@@ -36,9 +37,10 @@\n import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n import org.apache.iceberg.hadoop.HadoopCatalog;\n import org.apache.iceberg.hadoop.HadoopTables;\n-import org.apache.iceberg.hive.HiveCatalogs;\n+import org.apache.iceberg.hive.HiveCatalog;\n import org.apache.iceberg.relocated.com.google.common.annotations.VisibleForTesting;\n import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n import org.apache.iceberg.relocated.com.google.common.collect.ImmutableSet;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n@@ -212,7 +214,8 @@ public static boolean hiveCatalog(Configuration conf) {\n           LOG.info(\"Loaded Hadoop catalog {}\", catalog);\n           return Optional.of(catalog);\n         case HIVE:\n-          catalog = HiveCatalogs.loadCatalog(conf);\n+          catalog = CatalogUtil.loadCatalog(HiveCatalog.class.getName(), CatalogUtil.ICEBERG_CATALOG_TYPE_HIVE,\n+                  ImmutableMap.of(), conf);\n           LOG.info(\"Loaded Hive Metastore catalog {}\", catalog);\n           return Optional.of(catalog);\n         default:"
  },
  {
    "sha": "55c7b584c2191ee170d5af7b025d076890e551cc",
    "filename": "mr/src/test/java/org/apache/iceberg/mr/hive/TestTables.java",
    "status": "modified",
    "additions": 4,
    "deletions": 2,
    "changes": 6,
    "blob_url": "https://github.com/apache/iceberg/blob/ac68163045fbe7c91e50197b8e42e677c206bf61/mr/src/test/java/org/apache/iceberg/mr/hive/TestTables.java",
    "raw_url": "https://github.com/apache/iceberg/raw/ac68163045fbe7c91e50197b8e42e677c206bf61/mr/src/test/java/org/apache/iceberg/mr/hive/TestTables.java",
    "contents_url": "https://api.github.com/repos/apache/iceberg/contents/mr/src/test/java/org/apache/iceberg/mr/hive/TestTables.java?ref=ac68163045fbe7c91e50197b8e42e677c206bf61",
    "patch": "@@ -30,6 +30,7 @@\n import java.util.Map;\n import java.util.stream.Collectors;\n import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.CatalogUtil;\n import org.apache.iceberg.FileFormat;\n import org.apache.iceberg.PartitionSpec;\n import org.apache.iceberg.PartitionSpecParser;\n@@ -45,7 +46,7 @@\n import org.apache.iceberg.data.Record;\n import org.apache.iceberg.hadoop.HadoopCatalog;\n import org.apache.iceberg.hadoop.HadoopTables;\n-import org.apache.iceberg.hive.HiveCatalogs;\n+import org.apache.iceberg.hive.HiveCatalog;\n import org.apache.iceberg.hive.MetastoreUtil;\n import org.apache.iceberg.mr.InputFormatConfig;\n import org.apache.iceberg.mr.TestCatalogs;\n@@ -382,7 +383,8 @@ public Table loadTable(TableIdentifier identifier) {\n   static class HiveTestTables extends TestTables {\n \n     HiveTestTables(Configuration conf, TemporaryFolder temp) {\n-      super(HiveCatalogs.loadCatalog(conf), temp);\n+      super(CatalogUtil.loadCatalog(HiveCatalog.class.getName(), CatalogUtil.ICEBERG_CATALOG_TYPE_HIVE,\n+              ImmutableMap.of(), conf), temp);\n     }\n \n     @Override"
  },
  {
    "sha": "a0685a68434eb564a32c60b2374959e39332864b",
    "filename": "spark/src/test/java/org/apache/iceberg/spark/SparkTestBase.java",
    "status": "modified",
    "additions": 0,
    "deletions": 3,
    "changes": 3,
    "blob_url": "https://github.com/apache/iceberg/blob/ac68163045fbe7c91e50197b8e42e677c206bf61/spark/src/test/java/org/apache/iceberg/spark/SparkTestBase.java",
    "raw_url": "https://github.com/apache/iceberg/raw/ac68163045fbe7c91e50197b8e42e677c206bf61/spark/src/test/java/org/apache/iceberg/spark/SparkTestBase.java",
    "contents_url": "https://api.github.com/repos/apache/iceberg/contents/spark/src/test/java/org/apache/iceberg/spark/SparkTestBase.java?ref=ac68163045fbe7c91e50197b8e42e677c206bf61",
    "patch": "@@ -76,9 +76,6 @@ public static void startMetastoreAndSpark() {\n \n   @AfterClass\n   public static void stopMetastoreAndSpark() {\n-    if (catalog != null) {\n-      catalog.close();\n-    }\n     SparkTestBase.catalog = null;\n     metastore.stop();\n     SparkTestBase.metastore = null;"
  },
  {
    "sha": "75b37c75f76cdb8b1b6c8c4eac87e8b212c2ab48",
    "filename": "spark/src/test/java/org/apache/iceberg/spark/source/TestSparkReaderDeletes.java",
    "status": "modified",
    "additions": 0,
    "deletions": 1,
    "changes": 1,
    "blob_url": "https://github.com/apache/iceberg/blob/ac68163045fbe7c91e50197b8e42e677c206bf61/spark/src/test/java/org/apache/iceberg/spark/source/TestSparkReaderDeletes.java",
    "raw_url": "https://github.com/apache/iceberg/raw/ac68163045fbe7c91e50197b8e42e677c206bf61/spark/src/test/java/org/apache/iceberg/spark/source/TestSparkReaderDeletes.java",
    "contents_url": "https://api.github.com/repos/apache/iceberg/contents/spark/src/test/java/org/apache/iceberg/spark/source/TestSparkReaderDeletes.java?ref=ac68163045fbe7c91e50197b8e42e677c206bf61",
    "patch": "@@ -94,7 +94,6 @@ public static void startMetastoreAndSpark() {\n \n   @AfterClass\n   public static void stopMetastoreAndSpark() {\n-    catalog.close();\n     catalog = null;\n     metastore.stop();\n     metastore = null;"
  }
]
