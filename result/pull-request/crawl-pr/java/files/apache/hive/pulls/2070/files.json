[
  {
    "sha": "d388f88e51bbe24a2dde588edbea655046113a5b",
    "filename": "itests/hive-unit/src/test/java/org/apache/hive/jdbc/TestHiveQueryResultSet.java",
    "status": "added",
    "additions": 143,
    "deletions": 0,
    "changes": 143,
    "blob_url": "https://github.com/apache/hive/blob/c6075b9ccde7d0799d3e89aa7943f7c6880cf495/itests/hive-unit/src/test/java/org/apache/hive/jdbc/TestHiveQueryResultSet.java",
    "raw_url": "https://github.com/apache/hive/raw/c6075b9ccde7d0799d3e89aa7943f7c6880cf495/itests/hive-unit/src/test/java/org/apache/hive/jdbc/TestHiveQueryResultSet.java",
    "contents_url": "https://api.github.com/repos/apache/hive/contents/itests/hive-unit/src/test/java/org/apache/hive/jdbc/TestHiveQueryResultSet.java?ref=c6075b9ccde7d0799d3e89aa7943f7c6880cf495",
    "patch": "@@ -0,0 +1,143 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hive.jdbc;\n+\n+import java.sql.ResultSet;\n+import java.sql.Statement;\n+import java.util.Properties;\n+\n+import org.junit.Test;\n+\n+import org.apache.hadoop.hive.conf.HiveConf;\n+import org.apache.hadoop.hive.metastore.api.FieldSchema;\n+import org.apache.hadoop.hive.metastore.api.Schema;\n+import org.apache.hive.service.cli.RowSet;\n+import org.apache.hive.service.cli.RowSetFactory;\n+import org.apache.hive.service.cli.TableSchema;\n+import org.apache.hive.service.cli.thrift.EmbeddedThriftBinaryCLIService;\n+import org.apache.hive.service.rpc.thrift.TFetchResultsReq;\n+import org.apache.hive.service.rpc.thrift.TFetchResultsResp;\n+import org.apache.hive.service.rpc.thrift.TRowSet;\n+import org.apache.hive.service.rpc.thrift.TStatus;\n+import org.apache.hive.service.rpc.thrift.TStatusCode;\n+import org.apache.thrift.TException;\n+\n+import static org.apache.hive.jdbc.EmbeddedCLIServicePortal.EMBEDDED_CLISERVICE;\n+import static org.apache.hive.jdbc.Utils.URL_PREFIX;\n+import static org.apache.hive.service.rpc.thrift.TProtocolVersion.HIVE_CLI_SERVICE_PROTOCOL_V10;\n+import static org.junit.Assert.assertEquals;\n+\n+public class TestHiveQueryResultSet {\n+  private static final String EMIT_EMPTY_ROWS = \"hive.test.emit.empty.rows\";\n+  private static final String EMIT_NUM_ROWS = \"hive.test.emit.num.rows\";\n+\n+  // Create subclass of EmbeddedThriftBinaryCLIService\n+  public static class MyThriftBinaryCLIService extends EmbeddedThriftBinaryCLIService {\n+    private TStatus success = new TStatus(TStatusCode.SUCCESS_STATUS);\n+    private boolean emitEmptyRows;\n+    private int numRows;\n+    private int position;\n+    private int emptyRowPos;\n+\n+    @Override\n+    public synchronized void init(HiveConf hiveConf) {\n+      hiveConf.setBoolean(\"hive.support.concurrency\", false);\n+      this.emitEmptyRows = hiveConf.getBoolean(EMIT_EMPTY_ROWS, false);\n+      this.numRows = hiveConf.getInt(EMIT_NUM_ROWS, 10);\n+      this.emptyRowPos = (numRows / 2);\n+      this.position = 0;\n+      super.init(hiveConf);\n+    }\n+\n+    @Override\n+    public TFetchResultsResp FetchResults(TFetchResultsReq req) throws TException {\n+      position ++;\n+      TFetchResultsResp resp = new TFetchResultsResp();\n+      resp.setStatus(success);\n+      if (position > numRows) {\n+        resp.setHasMoreRows(false);\n+        resp.setResults(new TRowSet());\n+        return resp;\n+      }\n+\n+      resp.setResults(getTRowSet());\n+      if (emitEmptyRows) {\n+        resp.setHasMoreRows(true);\n+        if (position == emptyRowPos) {\n+          resp.setResults(new TRowSet());\n+        }\n+      } else {\n+        resp.setHasMoreRows(false);\n+      }\n+      return resp;\n+    }\n+\n+    private TRowSet getTRowSet() {\n+      Schema schema = new Schema();\n+      FieldSchema fieldSchema = new FieldSchema();\n+      fieldSchema.setName(\"_col0\");\n+      fieldSchema.setType(\"string\");\n+      schema.addToFieldSchemas(fieldSchema);\n+      TableSchema tableSchema = new TableSchema(schema);\n+      RowSet rowSet = RowSetFactory.create(tableSchema, HIVE_CLI_SERVICE_PROTOCOL_V10, false);\n+      String moreRows = \"more rows\";\n+      rowSet.addRow(new String[]{moreRows});\n+      return rowSet.toTRowSet();\n+    }\n+  }\n+\n+  @Test\n+  public void testHasMoreRows() throws Exception {\n+    // 9 row + 1 empty row, ResultSet.next return 9 times\n+    verifyRowNum(true, 10);\n+    // 10 row, ResultSet.next return 10 times\n+    verifyRowNum(false, 10);\n+    // 4 row + 1 empty row, ResultSet.next return 4 times\n+    verifyRowNum(true, 5);\n+    // 5 row, ResultSet.next return 5 times\n+    verifyRowNum(false, 5);\n+  }\n+\n+  private void verifyRowNum(boolean emitEmptyRows, int numRows) throws Exception {\n+    Properties properties = new Properties();\n+    properties.put(\"hiveconf:\" + EMIT_EMPTY_ROWS, emitEmptyRows + \"\");\n+    properties.put(\"hiveconf:\" + EMIT_NUM_ROWS, numRows + \"\");\n+    properties.put(\"hiveconf:\" + EMBEDDED_CLISERVICE, MyThriftBinaryCLIService.class.getName());\n+    try (HiveConnection connection = new HiveConnection(URL_PREFIX, properties);\n+        Statement statement = connection.createStatement()) {\n+      boolean hasResult = statement.execute(\"select 'more rows'\");\n+      if (hasResult) {\n+        int total = 0;\n+        try (ResultSet resultSet\n+            = statement.getResultSet()) {\n+          while (resultSet.next()) {\n+            String res = resultSet.getString(1);\n+            assertEquals(\"more rows\", res);\n+            total ++;\n+          }\n+          int expectedNum = emitEmptyRows ? (numRows - 1) : numRows;\n+          assertEquals(expectedNum, total);\n+        }\n+      } else {\n+        throw new RuntimeException(\"The query should generate a result set\");\n+      }\n+    }\n+  }\n+\n+}"
  },
  {
    "sha": "f49234d6ddba1a80b99449224588684b64ec929d",
    "filename": "jdbc/src/java/org/apache/hive/jdbc/EmbeddedCLIServicePortal.java",
    "status": "modified",
    "additions": 11,
    "deletions": 2,
    "changes": 13,
    "blob_url": "https://github.com/apache/hive/blob/c6075b9ccde7d0799d3e89aa7943f7c6880cf495/jdbc/src/java/org/apache/hive/jdbc/EmbeddedCLIServicePortal.java",
    "raw_url": "https://github.com/apache/hive/raw/c6075b9ccde7d0799d3e89aa7943f7c6880cf495/jdbc/src/java/org/apache/hive/jdbc/EmbeddedCLIServicePortal.java",
    "contents_url": "https://api.github.com/repos/apache/hive/contents/jdbc/src/java/org/apache/hive/jdbc/EmbeddedCLIServicePortal.java?ref=c6075b9ccde7d0799d3e89aa7943f7c6880cf495",
    "patch": "@@ -20,18 +20,27 @@\n \n import java.util.Map;\n \n+import org.apache.commons.lang3.StringUtils;\n import org.apache.hadoop.hive.conf.HiveConf;\n import org.apache.hive.service.Service;\n import org.apache.hive.service.rpc.thrift.TCLIService;\n import org.apache.hive.service.rpc.thrift.TCLIService.Iface;\n \n public class EmbeddedCLIServicePortal {\n \n+  public static final String EMBEDDED_CLISERVICE = \"embeddedCliServiceClass\";\n+\n   public static Iface get(Map<String, String> hiveConfs) {\n     TCLIService.Iface embeddedClient;\n     try {\n-      Class<TCLIService.Iface> clazz =\n-          (Class<Iface>) Class.forName(\"org.apache.hive.service.cli.thrift.EmbeddedThriftBinaryCLIService\");\n+      String embeddedClass = \"org.apache.hive.service.cli.thrift.EmbeddedThriftBinaryCLIService\";\n+      if (hiveConfs != null) {\n+        String cls = hiveConfs.get(EMBEDDED_CLISERVICE);\n+        if (!StringUtils.isEmpty(cls)) {\n+          embeddedClass = cls;\n+        }\n+      }\n+      Class<TCLIService.Iface> clazz = (Class<Iface>) Class.forName(embeddedClass);\n       embeddedClient = clazz.newInstance();\n       ((Service) embeddedClient).init(buildOverlayedConf(hiveConfs));\n     } catch (ClassNotFoundException e) {"
  },
  {
    "sha": "11aa8f11c1ec7996f20d468e897d1c680b4867cf",
    "filename": "jdbc/src/java/org/apache/hive/jdbc/HiveQueryResultSet.java",
    "status": "modified",
    "additions": 5,
    "deletions": 2,
    "changes": 7,
    "blob_url": "https://github.com/apache/hive/blob/c6075b9ccde7d0799d3e89aa7943f7c6880cf495/jdbc/src/java/org/apache/hive/jdbc/HiveQueryResultSet.java",
    "raw_url": "https://github.com/apache/hive/raw/c6075b9ccde7d0799d3e89aa7943f7c6880cf495/jdbc/src/java/org/apache/hive/jdbc/HiveQueryResultSet.java",
    "contents_url": "https://api.github.com/repos/apache/hive/contents/jdbc/src/java/org/apache/hive/jdbc/HiveQueryResultSet.java?ref=c6075b9ccde7d0799d3e89aa7943f7c6880cf495",
    "patch": "@@ -338,17 +338,20 @@ public boolean next() throws SQLException {\n         fetchedRowsItr = null;\n         fetchFirst = false;\n       }\n-      if (fetchedRows == null || !fetchedRowsItr.hasNext()) {\n+      while (fetchedRows == null || !fetchedRowsItr.hasNext()) {\n         TFetchResultsReq fetchReq = new TFetchResultsReq(stmtHandle,\n             orientation, fetchSize);\n         LOG.debug(\"HiveQueryResultsFetchReq: {}\", fetchReq);\n         TFetchResultsResp fetchResp;\n         fetchResp = client.FetchResults(fetchReq);\n         Utils.verifySuccessWithInfo(fetchResp.getStatus());\n-\n         TRowSet results = fetchResp.getResults();\n         fetchedRows = RowSetFactory.create(results, protocol);\n         fetchedRowsItr = fetchedRows.iterator();\n+        if (fetchResp.isHasMoreRows() && !fetchedRowsItr.hasNext()) {\n+          continue;\n+        }\n+        break;\n       }\n \n       if (!fetchedRowsItr.hasNext()) {"
  },
  {
    "sha": "8a9b4f5057b8544f4fcedd6ea8afe00e5cb78c36",
    "filename": "jdbc/src/java/org/apache/hive/jdbc/Utils.java",
    "status": "modified",
    "additions": 15,
    "deletions": 13,
    "changes": 28,
    "blob_url": "https://github.com/apache/hive/blob/c6075b9ccde7d0799d3e89aa7943f7c6880cf495/jdbc/src/java/org/apache/hive/jdbc/Utils.java",
    "raw_url": "https://github.com/apache/hive/raw/c6075b9ccde7d0799d3e89aa7943f7c6880cf495/jdbc/src/java/org/apache/hive/jdbc/Utils.java",
    "contents_url": "https://api.github.com/repos/apache/hive/contents/jdbc/src/java/org/apache/hive/jdbc/Utils.java?ref=c6075b9ccde7d0799d3e89aa7943f7c6880cf495",
    "patch": "@@ -420,6 +420,20 @@ public static JdbcConnectionParams extractURLComponents(String uri, Properties i\n       throw new JdbcUriParseException(\"Bad URL format: Missing prefix \" + URL_PREFIX);\n     }\n \n+    // Apply configs supplied in the JDBC connection properties object\n+    for (Map.Entry<Object, Object> kv : info.entrySet()) {\n+      if ((kv.getKey() instanceof String)) {\n+        String key = (String) kv.getKey();\n+        if (key.startsWith(JdbcConnectionParams.HIVE_VAR_PREFIX)) {\n+          connParams.getHiveVars().put(key.substring(JdbcConnectionParams.HIVE_VAR_PREFIX.length()),\n+              info.getProperty(key));\n+        } else if (key.startsWith(JdbcConnectionParams.HIVE_CONF_PREFIX)) {\n+          connParams.getHiveConfs().put(\n+              key.substring(JdbcConnectionParams.HIVE_CONF_PREFIX.length()), info.getProperty(key));\n+        }\n+      }\n+    }\n+\n     // For URLs with no other configuration\n     // Don't parse them, but set embedded mode as true\n     if (uri.equalsIgnoreCase(URL_PREFIX)) {\n@@ -494,19 +508,7 @@ public static JdbcConnectionParams extractURLComponents(String uri, Properties i\n       }\n     }\n \n-    // Apply configs supplied in the JDBC connection properties object\n-    for (Map.Entry<Object, Object> kv : info.entrySet()) {\n-      if ((kv.getKey() instanceof String)) {\n-        String key = (String) kv.getKey();\n-        if (key.startsWith(JdbcConnectionParams.HIVE_VAR_PREFIX)) {\n-          connParams.getHiveVars().put(key.substring(JdbcConnectionParams.HIVE_VAR_PREFIX.length()),\n-              info.getProperty(key));\n-        } else if (key.startsWith(JdbcConnectionParams.HIVE_CONF_PREFIX)) {\n-          connParams.getHiveConfs().put(\n-              key.substring(JdbcConnectionParams.HIVE_CONF_PREFIX.length()), info.getProperty(key));\n-        }\n-      }\n-    }\n+\n \n     // Extract user/password from JDBC connection properties if its not supplied\n     // in the connection URL"
  }
]
