[
  {
    "sha": "3e7c1325c52256af4b2ade1ceec40a3c31ebd34d",
    "filename": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/bigquery/BatchLoads.java",
    "status": "modified",
    "additions": 12,
    "deletions": 13,
    "changes": 25,
    "blob_url": "https://github.com/apache/beam/blob/6f4d272a28a1e2a31728618a841bdb4bbb608a56/sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/bigquery/BatchLoads.java",
    "raw_url": "https://github.com/apache/beam/raw/6f4d272a28a1e2a31728618a841bdb4bbb608a56/sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/bigquery/BatchLoads.java",
    "contents_url": "https://api.github.com/repos/apache/beam/contents/sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/bigquery/BatchLoads.java?ref=6f4d272a28a1e2a31728618a841bdb4bbb608a56",
    "patch": "@@ -34,7 +34,6 @@\n import org.apache.beam.sdk.coders.NullableCoder;\n import org.apache.beam.sdk.coders.ShardedKeyCoder;\n import org.apache.beam.sdk.coders.StringUtf8Coder;\n-import org.apache.beam.sdk.coders.VoidCoder;\n import org.apache.beam.sdk.extensions.gcp.util.gcsfs.GcsPath;\n import org.apache.beam.sdk.io.gcp.bigquery.BigQueryIO.Write.CreateDisposition;\n import org.apache.beam.sdk.io.gcp.bigquery.BigQueryIO.Write.SchemaUpdateOption;\n@@ -277,7 +276,7 @@ private WriteResult expandTriggered(PCollection<KV<DestinationT, ElementT>> inpu\n     final PCollectionView<String> copyJobIdPrefixView = createJobIdPrefixView(p, JobType.COPY);\n     final PCollectionView<String> tempFilePrefixView =\n         createTempFilePrefixView(p, loadJobIdPrefixView);\n-    PCollection<WriteBundlesToFiles.Result<DestinationT>> results;\n+    final PCollection<WriteBundlesToFiles.Result<DestinationT>> results;\n     if (numFileShards > 0) {\n       // The user-supplied triggeringFrequency is often chosen to control how many BigQuery load\n       // jobs are generated, to prevent going over BigQuery's daily quota for load jobs. If this\n@@ -311,7 +310,7 @@ private WriteResult expandTriggered(PCollection<KV<DestinationT, ElementT>> inpu\n     }\n \n     // Apply the user's trigger before we start generating BigQuery load jobs.\n-    results =\n+    final PCollection<WriteBundlesToFiles.Result<DestinationT>> resultsWithUserTrigger =\n         results.apply(\n             \"applyUserTrigger\",\n             Window.<WriteBundlesToFiles.Result<DestinationT>>into(new GlobalWindows())\n@@ -330,11 +329,13 @@ private WriteResult expandTriggered(PCollection<KV<DestinationT, ElementT>> inpu\n     // expandUntriggered. Instead make the result list a main input. Apply a GroupByKey first for\n     // determinism.\n     PCollectionTuple partitions =\n-        results\n-            .apply(\"AttachSingletonKey\", WithKeys.of((Void) null))\n+        resultsWithUserTrigger\n+            .apply(\n+                \"AttachDestinationKey\",\n+                WithKeys.of((Result<DestinationT> result) -> result.destination))\n             .setCoder(\n-                KvCoder.of(VoidCoder.of(), WriteBundlesToFiles.ResultCoder.of(destinationCoder)))\n-            .apply(\"GroupOntoSingleton\", GroupByKey.create())\n+                KvCoder.of(destinationCoder, WriteBundlesToFiles.ResultCoder.of(destinationCoder)))\n+            .apply(\"GroupTempFilesByDestination\", GroupByKey.create())\n             .apply(\"ExtractResultValues\", Values.create())\n             .apply(\n                 \"WritePartitionTriggered\",\n@@ -350,18 +351,16 @@ private WriteResult expandTriggered(PCollection<KV<DestinationT, ElementT>> inpu\n                             rowWriterFactory))\n                     .withSideInputs(tempFilePrefixView)\n                     .withOutputTags(multiPartitionsTag, TupleTagList.of(singlePartitionTag)));\n-    PCollection<KV<TableDestination, String>> tempTables =\n+\n+    final PCollection<KV<TableDestination, String>> tempTables =\n         writeTempTables(partitions.get(multiPartitionsTag), loadJobIdPrefixView);\n \n     tempTables\n         // Now that the load job has happened, we want the rename to happen immediately.\n         .apply(\n             Window.<KV<TableDestination, String>>into(new GlobalWindows())\n                 .triggering(Repeatedly.forever(AfterPane.elementCountAtLeast(1))))\n-        .apply(WithKeys.of((Void) null))\n-        .setCoder(KvCoder.of(VoidCoder.of(), tempTables.getCoder()))\n-        .apply(GroupByKey.create())\n-        .apply(Values.create())\n+        .apply(\"GroupOntoTableDestination\", GroupByKey.create())\n         .apply(\n             \"WriteRenameTriggered\",\n             ParDo.of(\n@@ -424,7 +423,7 @@ public WriteResult expandUntriggered(PCollection<KV<DestinationT, ElementT>> inp\n         writeTempTables(partitions.get(multiPartitionsTag), loadJobIdPrefixView);\n \n     tempTables\n-        .apply(\"ReifyRenameInput\", new ReifyAsIterable<>())\n+        .apply(\"ReifyRenameInput\", new ReifyPerKey<>())\n         .apply(\n             \"WriteRenameUntriggered\",\n             ParDo.of("
  },
  {
    "sha": "49e2f4cf2da99c84579830293b1c81cbe2f96ba0",
    "filename": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/bigquery/ReifyPerKey.java",
    "status": "added",
    "additions": 64,
    "deletions": 0,
    "changes": 64,
    "blob_url": "https://github.com/apache/beam/blob/6f4d272a28a1e2a31728618a841bdb4bbb608a56/sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/bigquery/ReifyPerKey.java",
    "raw_url": "https://github.com/apache/beam/raw/6f4d272a28a1e2a31728618a841bdb4bbb608a56/sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/bigquery/ReifyPerKey.java",
    "contents_url": "https://api.github.com/repos/apache/beam/contents/sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/bigquery/ReifyPerKey.java?ref=6f4d272a28a1e2a31728618a841bdb4bbb608a56",
    "patch": "@@ -0,0 +1,64 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.bigquery;\n+\n+import java.util.Map;\n+import org.apache.beam.sdk.coders.IterableCoder;\n+import org.apache.beam.sdk.coders.KvCoder;\n+import org.apache.beam.sdk.coders.VoidCoder;\n+import org.apache.beam.sdk.transforms.Create;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.View;\n+import org.apache.beam.sdk.values.KV;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PCollectionView;\n+\n+/**\n+ * This transforms turns a side input into a singleton PCollection that can be used as the main\n+ * input for another transform.\n+ */\n+@SuppressWarnings({\n+  \"nullness\" // TODO(https://issues.apache.org/jira/browse/BEAM-10402)\n+})\n+public class ReifyPerKey<K, V>\n+    extends PTransform<PCollection<KV<K, V>>, PCollection<KV<K, Iterable<V>>>> {\n+  @Override\n+  public PCollection<KV<K, Iterable<V>>> expand(PCollection<KV<K, V>> input) {\n+    final PCollectionView<Map<K, Iterable<V>>> view = input.apply(View.asMultimap());\n+    final KvCoder<K, V> kvCoder = (KvCoder<K, V>) input.getCoder();\n+    return input\n+        .getPipeline()\n+        .apply(Create.of((Void) null).withCoder(VoidCoder.of()))\n+        .apply(\n+            ParDo.of(\n+                    new DoFn<Void, KV<K, Iterable<V>>>() {\n+                      @ProcessElement\n+                      public void processElement(ProcessContext c) {\n+                        Map<K, Iterable<V>> outputMap = c.sideInput(view);\n+                        for (Map.Entry<K, Iterable<V>> entry : outputMap.entrySet()) {\n+                          KV<K, Iterable<V>> kv = KV.of(entry.getKey(), entry.getValue());\n+                          c.output(kv);\n+                        }\n+                      }\n+                    })\n+                .withSideInputs(view))\n+        .setCoder(KvCoder.of(kvCoder.getKeyCoder(), IterableCoder.of(kvCoder.getValueCoder())));\n+  }\n+}"
  },
  {
    "sha": "653425f24fe158adc8880695e799573860396e2d",
    "filename": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/bigquery/WriteBundlesToFiles.java",
    "status": "modified",
    "additions": 1,
    "deletions": 1,
    "changes": 2,
    "blob_url": "https://github.com/apache/beam/blob/6f4d272a28a1e2a31728618a841bdb4bbb608a56/sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/bigquery/WriteBundlesToFiles.java",
    "raw_url": "https://github.com/apache/beam/raw/6f4d272a28a1e2a31728618a841bdb4bbb608a56/sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/bigquery/WriteBundlesToFiles.java",
    "contents_url": "https://api.github.com/repos/apache/beam/contents/sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/bigquery/WriteBundlesToFiles.java?ref=6f4d272a28a1e2a31728618a841bdb4bbb608a56",
    "patch": "@@ -77,7 +77,7 @@\n    * The result of the {@link WriteBundlesToFiles} transform. Corresponds to a single output file,\n    * and encapsulates the table it is destined to as well as the file byte size.\n    */\n-  static final class Result<DestinationT> implements Serializable {\n+  public static final class Result<DestinationT> implements Serializable {\n     private static final long serialVersionUID = 1L;\n     public final String filename;\n     public final Long fileByteSize;"
  },
  {
    "sha": "a1d712e405e4f3022ffd622c4147f11990769e74",
    "filename": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/bigquery/WritePartition.java",
    "status": "modified",
    "additions": 3,
    "deletions": 3,
    "changes": 6,
    "blob_url": "https://github.com/apache/beam/blob/6f4d272a28a1e2a31728618a841bdb4bbb608a56/sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/bigquery/WritePartition.java",
    "raw_url": "https://github.com/apache/beam/raw/6f4d272a28a1e2a31728618a841bdb4bbb608a56/sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/bigquery/WritePartition.java",
    "contents_url": "https://api.github.com/repos/apache/beam/contents/sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/bigquery/WritePartition.java?ref=6f4d272a28a1e2a31728618a841bdb4bbb608a56",
    "patch": "@@ -47,8 +47,8 @@\n   private final long maxSizeBytes;\n   private final RowWriterFactory<?, DestinationT> rowWriterFactory;\n \n-  private @Nullable TupleTag<KV<ShardedKey<DestinationT>, List<String>>> multiPartitionsTag;\n-  private TupleTag<KV<ShardedKey<DestinationT>, List<String>>> singlePartitionTag;\n+  private final @Nullable TupleTag<KV<ShardedKey<DestinationT>, List<String>>> multiPartitionsTag;\n+  private final TupleTag<KV<ShardedKey<DestinationT>, List<String>>> singlePartitionTag;\n \n   private static class PartitionData {\n     private int numFiles = 0;\n@@ -101,7 +101,7 @@ boolean canAccept(int numFiles, long numBytes) {\n   }\n \n   private static class DestinationData {\n-    private List<PartitionData> partitions = Lists.newArrayList();\n+    private final List<PartitionData> partitions = Lists.newArrayList();\n \n     private DestinationData() {}\n "
  },
  {
    "sha": "5b607c856297da4af6971fac6f8be6c96ef2f3f7",
    "filename": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/bigquery/WriteRename.java",
    "status": "modified",
    "additions": 6,
    "deletions": 15,
    "changes": 21,
    "blob_url": "https://github.com/apache/beam/blob/6f4d272a28a1e2a31728618a841bdb4bbb608a56/sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/bigquery/WriteRename.java",
    "raw_url": "https://github.com/apache/beam/raw/6f4d272a28a1e2a31728618a841bdb4bbb608a56/sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/bigquery/WriteRename.java",
    "contents_url": "https://api.github.com/repos/apache/beam/contents/sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/bigquery/WriteRename.java?ref=6f4d272a28a1e2a31728618a841bdb4bbb608a56",
    "patch": "@@ -22,9 +22,7 @@\n import com.google.api.services.bigquery.model.JobReference;\n import com.google.api.services.bigquery.model.TableReference;\n import java.io.IOException;\n-import java.util.Collection;\n import java.util.List;\n-import java.util.Map;\n import java.util.stream.Collectors;\n import java.util.stream.StreamSupport;\n import org.apache.beam.sdk.io.gcp.bigquery.BigQueryHelpers.PendingJobManager;\n@@ -36,9 +34,7 @@\n import org.apache.beam.sdk.transforms.display.DisplayData;\n import org.apache.beam.sdk.values.KV;\n import org.apache.beam.sdk.values.PCollectionView;\n-import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ArrayListMultimap;\n import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.Lists;\n-import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.Multimap;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n@@ -49,7 +45,7 @@\n @SuppressWarnings({\n   \"nullness\" // TODO(https://issues.apache.org/jira/browse/BEAM-10402)\n })\n-class WriteRename extends DoFn<Iterable<KV<TableDestination, String>>, Void> {\n+class WriteRename extends DoFn<KV<TableDestination, Iterable<String>>, Void> {\n   private static final Logger LOG = LoggerFactory.getLogger(WriteRename.class);\n \n   private final BigQueryServices bqServices;\n@@ -102,16 +98,11 @@ public void startBundle(StartBundleContext c) {\n \n   @ProcessElement\n   public void processElement(ProcessContext c) throws Exception {\n-    Multimap<TableDestination, String> tempTables = ArrayListMultimap.create();\n-    for (KV<TableDestination, String> entry : c.element()) {\n-      tempTables.put(entry.getKey(), entry.getValue());\n-    }\n-    for (Map.Entry<TableDestination, Collection<String>> entry : tempTables.asMap().entrySet()) {\n-      // Process each destination table.\n-      // Do not copy if no temp tables are provided.\n-      if (!entry.getValue().isEmpty()) {\n-        pendingJobs.add(startWriteRename(entry.getKey(), entry.getValue(), c));\n-      }\n+    final TableDestination tableDestination = c.element().getKey();\n+    final Iterable<String> files = c.element().getValue();\n+    // Do not copy if no temp tables are provided.\n+    if (files.iterator().hasNext()) {\n+      pendingJobs.add(startWriteRename(tableDestination, files, c));\n     }\n   }\n "
  },
  {
    "sha": "60c02175ff799b1a9157e8d016846037309c9e59",
    "filename": "sdks/java/io/google-cloud-platform/src/test/java/org/apache/beam/sdk/io/gcp/bigquery/BigQueryIOWriteTest.java",
    "status": "modified",
    "additions": 4,
    "deletions": 4,
    "changes": 8,
    "blob_url": "https://github.com/apache/beam/blob/6f4d272a28a1e2a31728618a841bdb4bbb608a56/sdks/java/io/google-cloud-platform/src/test/java/org/apache/beam/sdk/io/gcp/bigquery/BigQueryIOWriteTest.java",
    "raw_url": "https://github.com/apache/beam/raw/6f4d272a28a1e2a31728618a841bdb4bbb608a56/sdks/java/io/google-cloud-platform/src/test/java/org/apache/beam/sdk/io/gcp/bigquery/BigQueryIOWriteTest.java",
    "contents_url": "https://api.github.com/repos/apache/beam/contents/sdks/java/io/google-cloud-platform/src/test/java/org/apache/beam/sdk/io/gcp/bigquery/BigQueryIOWriteTest.java?ref=6f4d272a28a1e2a31728618a841bdb4bbb608a56",
    "patch": "@@ -1848,7 +1848,6 @@ public void testWriteRename() throws Exception {\n     Multimap<TableDestination, TableRow> expectedRowsPerTable = ArrayListMultimap.create();\n     String jobIdToken = \"jobIdToken\";\n     Multimap<TableDestination, String> tempTables = ArrayListMultimap.create();\n-    List<KV<TableDestination, String>> tempTablesElement = Lists.newArrayList();\n     for (int i = 0; i < numFinalTables; ++i) {\n       String tableName = \"project-id:dataset-id.table_\" + i;\n       TableDestination tableDestination = new TableDestination(tableName, \"table_\" + i + \"_desc\");\n@@ -1868,7 +1867,6 @@ public void testWriteRename() throws Exception {\n         expectedRowsPerTable.putAll(tableDestination, rows);\n         String tableJson = toJsonString(tempTable);\n         tempTables.put(tableDestination, tableJson);\n-        tempTablesElement.add(KV.of(tableDestination, tableJson));\n       }\n     }\n \n@@ -1884,9 +1882,11 @@ public void testWriteRename() throws Exception {\n             3,\n             \"kms_key\");\n \n-    DoFnTester<Iterable<KV<TableDestination, String>>, Void> tester = DoFnTester.of(writeRename);\n+    DoFnTester<KV<TableDestination, Iterable<String>>, Void> tester = DoFnTester.of(writeRename);\n     tester.setSideInput(jobIdTokenView, GlobalWindow.INSTANCE, jobIdToken);\n-    tester.processElement(tempTablesElement);\n+    for (TableDestination tableDestination : tempTables.keySet()) {\n+      tester.processElement(KV.of(tableDestination, tempTables.get(tableDestination)));\n+    }\n     tester.finishBundle();\n \n     for (Map.Entry<TableDestination, Collection<String>> entry : tempTables.asMap().entrySet()) {"
  }
]
