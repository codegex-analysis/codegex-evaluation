[
  {
    "sha": "be1ea9b92b432b56d8c0c0dbc50d5a3085093a38",
    "filename": "hudi-cli/src/main/java/org/apache/hudi/cli/commands/CommitsCommand.java",
    "status": "modified",
    "additions": 36,
    "deletions": 9,
    "changes": 45,
    "blob_url": "https://github.com/apache/hudi/blob/ed6271f90fe9dc618e8f175e75a06ec9d01be07d/hudi-cli/src/main/java/org/apache/hudi/cli/commands/CommitsCommand.java",
    "raw_url": "https://github.com/apache/hudi/raw/ed6271f90fe9dc618e8f175e75a06ec9d01be07d/hudi-cli/src/main/java/org/apache/hudi/cli/commands/CommitsCommand.java",
    "contents_url": "https://api.github.com/repos/apache/hudi/contents/hudi-cli/src/main/java/org/apache/hudi/cli/commands/CommitsCommand.java?ref=ed6271f90fe9dc618e8f175e75a06ec9d01be07d",
    "patch": "@@ -34,6 +34,7 @@\n import org.apache.hudi.common.table.timeline.HoodieInstant;\n import org.apache.hudi.common.table.timeline.HoodieTimeline;\n import org.apache.hudi.common.util.NumericUtils;\n+import org.apache.hudi.common.util.Option;\n import org.apache.hudi.common.util.StringUtils;\n \n import org.apache.spark.launcher.SparkLauncher;\n@@ -266,12 +267,15 @@ public String showCommitPartitions(\n \n     HoodieActiveTimeline activeTimeline = HoodieCLI.getTableMetaClient().getActiveTimeline();\n     HoodieTimeline timeline = activeTimeline.getCommitsTimeline().filterCompletedInstants();\n-    HoodieInstant commitInstant = new HoodieInstant(false, HoodieTimeline.COMMIT_ACTION, instantTime);\n \n-    if (!timeline.containsInstant(commitInstant)) {\n+    Option<HoodieInstant> hoodieInstantOptional = getCommitOrReplaceCommitInstant(timeline, instantTime);\n+    if (!hoodieInstantOptional.isPresent()) {\n       return \"Commit \" + instantTime + \" not found in Commits \" + timeline;\n     }\n-    HoodieCommitMetadata meta = HoodieCommitMetadata.fromBytes(activeTimeline.getInstantDetails(commitInstant).get(),\n+\n+    HoodieInstant hoodieInstant = hoodieInstantOptional.get();\n+\n+    HoodieCommitMetadata meta = HoodieCommitMetadata.fromBytes(activeTimeline.getInstantDetails(hoodieInstant).get(),\n         HoodieCommitMetadata.class);\n     List<Comparable[]> rows = new ArrayList<>();\n     for (Map.Entry<String, List<HoodieWriteStat>> entry : meta.getPartitionToWriteStats().entrySet()) {\n@@ -328,12 +332,16 @@ public String showWriteStats(\n \n     HoodieActiveTimeline activeTimeline = HoodieCLI.getTableMetaClient().getActiveTimeline();\n     HoodieTimeline timeline = activeTimeline.getCommitsTimeline().filterCompletedInstants();\n-    HoodieInstant commitInstant = new HoodieInstant(false, HoodieTimeline.COMMIT_ACTION, instantTime);\n \n-    if (!timeline.containsInstant(commitInstant)) {\n+    Option<HoodieInstant> hoodieInstantOptional = getCommitOrReplaceCommitInstant(timeline, instantTime);\n+    if (!hoodieInstantOptional.isPresent()) {\n       return \"Commit \" + instantTime + \" not found in Commits \" + timeline;\n     }\n-    HoodieCommitMetadata meta = HoodieCommitMetadata.fromBytes(activeTimeline.getInstantDetails(commitInstant).get(),\n+\n+    HoodieInstant hoodieInstant = hoodieInstantOptional.get();\n+\n+\n+    HoodieCommitMetadata meta = HoodieCommitMetadata.fromBytes(activeTimeline.getInstantDetails(hoodieInstant).get(),\n         HoodieCommitMetadata.class);\n     long recordsWritten = meta.fetchTotalRecordsWritten();\n     long bytesWritten = meta.fetchTotalBytesWritten();\n@@ -367,12 +375,15 @@ public String showCommitFiles(\n \n     HoodieActiveTimeline activeTimeline = HoodieCLI.getTableMetaClient().getActiveTimeline();\n     HoodieTimeline timeline = activeTimeline.getCommitsTimeline().filterCompletedInstants();\n-    HoodieInstant commitInstant = new HoodieInstant(false, HoodieTimeline.COMMIT_ACTION, instantTime);\n \n-    if (!timeline.containsInstant(commitInstant)) {\n+    Option<HoodieInstant> hoodieInstantOptional = getCommitOrReplaceCommitInstant(timeline, instantTime);\n+    if (!hoodieInstantOptional.isPresent()) {\n       return \"Commit \" + instantTime + \" not found in Commits \" + timeline;\n     }\n-    HoodieCommitMetadata meta = HoodieCommitMetadata.fromBytes(activeTimeline.getInstantDetails(commitInstant).get(),\n+\n+    HoodieInstant hoodieInstant = hoodieInstantOptional.get();\n+\n+    HoodieCommitMetadata meta = HoodieCommitMetadata.fromBytes(activeTimeline.getInstantDetails(hoodieInstant).get(),\n         HoodieCommitMetadata.class);\n     List<Comparable[]> rows = new ArrayList<>();\n     for (Map.Entry<String, List<HoodieWriteStat>> entry : meta.getPartitionToWriteStats().entrySet()) {\n@@ -431,4 +442,20 @@ public String syncCommits(@CliOption(key = {\"path\"}, help = \"Path of the table t\n     return \"Load sync state between \" + HoodieCLI.getTableMetaClient().getTableConfig().getTableName() + \" and \"\n         + HoodieCLI.syncTableMetadata.getTableConfig().getTableName();\n   }\n+\n+  /*\n+  Checks whether a commit or replacecommit action exists in the timeline.\n+  * */\n+  private Option<HoodieInstant> getCommitOrReplaceCommitInstant(HoodieTimeline timeline, String instantTime) {\n+    HoodieInstant hoodieInstant = new HoodieInstant(false, HoodieTimeline.COMMIT_ACTION, instantTime);\n+\n+    if (!timeline.containsInstant(hoodieInstant)) {\n+      hoodieInstant = new HoodieInstant(false, HoodieTimeline.REPLACE_COMMIT_ACTION, instantTime);\n+      if (!timeline.containsInstant(hoodieInstant)) {\n+        return Option.empty();\n+      }\n+    }\n+\n+    return Option.of(hoodieInstant);\n+  }\n }"
  },
  {
    "sha": "fb4d3b1e81c37a9f052f9451c6b2fce6b11195f7",
    "filename": "hudi-cli/src/test/java/org/apache/hudi/cli/commands/TestCommitsCommand.java",
    "status": "modified",
    "additions": 106,
    "deletions": 0,
    "changes": 106,
    "blob_url": "https://github.com/apache/hudi/blob/ed6271f90fe9dc618e8f175e75a06ec9d01be07d/hudi-cli/src/test/java/org/apache/hudi/cli/commands/TestCommitsCommand.java",
    "raw_url": "https://github.com/apache/hudi/raw/ed6271f90fe9dc618e8f175e75a06ec9d01be07d/hudi-cli/src/test/java/org/apache/hudi/cli/commands/TestCommitsCommand.java",
    "contents_url": "https://api.github.com/repos/apache/hudi/contents/hudi-cli/src/test/java/org/apache/hudi/cli/commands/TestCommitsCommand.java?ref=ed6271f90fe9dc618e8f175e75a06ec9d01be07d",
    "patch": "@@ -24,6 +24,7 @@\n import org.apache.hudi.cli.TableHeader;\n import org.apache.hudi.cli.testutils.AbstractShellIntegrationTest;\n import org.apache.hudi.cli.testutils.HoodieTestCommitMetadataGenerator;\n+import org.apache.hudi.cli.testutils.HoodieTestReplaceCommitMetadatGenerator;\n import org.apache.hudi.common.fs.FSUtils;\n import org.apache.hudi.common.model.HoodieTableType;\n import org.apache.hudi.common.table.HoodieTableMetaClient;\n@@ -97,6 +98,42 @@ public void init() throws IOException {\n     return data;\n   }\n \n+  /*\n+  * generates both replace commit and commit data\n+  * */\n+  private LinkedHashMap<String, Integer[]> generateMixedData() throws Exception {\n+    // generate data and metadata\n+    LinkedHashMap<String, Integer[]> replaceCommitData = new LinkedHashMap<>();\n+    replaceCommitData.put(\"103\", new Integer[] {15, 10});\n+\n+    LinkedHashMap<String, Integer[]> commitData = new LinkedHashMap<>();\n+    commitData.put(\"102\", new Integer[] {15, 10});\n+    commitData.put(\"101\", new Integer[] {20, 10});\n+\n+    for (Map.Entry<String, Integer[]> entry : commitData.entrySet()) {\n+      String key = entry.getKey();\n+      Integer[] value = entry.getValue();\n+      HoodieTestCommitMetadataGenerator.createCommitFileWithMetadata(tablePath, key, jsc.hadoopConfiguration(),\n+              Option.of(value[0]), Option.of(value[1]));\n+    }\n+\n+    for (Map.Entry<String, Integer[]> entry : replaceCommitData.entrySet()) {\n+      String key = entry.getKey();\n+      Integer[] value = entry.getValue();\n+      HoodieTestReplaceCommitMetadatGenerator.createReplaceCommitFileWithMetadata(tablePath, key, jsc.hadoopConfiguration(),\n+              Option.of(value[0]), Option.of(value[1]));\n+    }\n+\n+    metaClient = HoodieTableMetaClient.reload(HoodieCLI.getTableMetaClient());\n+    assertEquals(3, metaClient.reloadActiveTimeline().getCommitsTimeline().countInstants(),\n+            \"There should have 3 commits\");\n+\n+    LinkedHashMap<String, Integer[]> data = replaceCommitData;\n+    replaceCommitData.putAll(commitData);\n+\n+    return data;\n+  }\n+\n   private String generateExpectData(int records, Map<String, Integer[]> data) throws IOException {\n     FileSystem fs = FileSystem.get(jsc.hadoopConfiguration());\n     List<String> partitionPaths =\n@@ -237,6 +274,42 @@ public void testShowCommitPartitions() throws Exception {\n     assertEquals(expected, got);\n   }\n \n+  @Test\n+  public void testShowCommitPartitionsWithReplaceCommits() throws Exception {\n+    Map<String, Integer[]> data = generateMixedData();\n+\n+    for (String commitInstant: data.keySet()) {\n+      CommandResult cr = getShell().executeCommand(String.format(\"commit showpartitions --commit %s\", commitInstant));\n+\n+      assertTrue(cr.isSuccess());\n+\n+      Integer[] value = data.get(commitInstant);\n+      List<Comparable[]> rows = new ArrayList<>();\n+      // prevCommit not null, so add 0, update 1\n+      Arrays.asList(HoodieTestDataGenerator.DEFAULT_FIRST_PARTITION_PATH,\n+              HoodieTestDataGenerator.DEFAULT_SECOND_PARTITION_PATH).stream().forEach(partition ->\n+              rows.add(new Comparable[] {partition, 0, 1, 0, value[1], HoodieTestCommitMetadataGenerator.DEFAULT_TOTAL_WRITE_BYTES, 0})\n+      );\n+\n+      Map<String, Function<Object, String>> fieldNameToConverterMap = new HashMap<>();\n+      fieldNameToConverterMap.put(HoodieTableHeaderFields.HEADER_TOTAL_BYTES_WRITTEN,\n+              entry -> NumericUtils.humanReadableByteCount((Long.parseLong(entry.toString()))));\n+\n+      TableHeader header = new TableHeader().addTableHeaderField(HoodieTableHeaderFields.HEADER_PARTITION_PATH)\n+              .addTableHeaderField(HoodieTableHeaderFields.HEADER_TOTAL_FILES_ADDED)\n+              .addTableHeaderField(HoodieTableHeaderFields.HEADER_TOTAL_FILES_UPDATED)\n+              .addTableHeaderField(HoodieTableHeaderFields.HEADER_TOTAL_RECORDS_INSERTED)\n+              .addTableHeaderField(HoodieTableHeaderFields.HEADER_TOTAL_RECORDS_UPDATED)\n+              .addTableHeaderField(HoodieTableHeaderFields.HEADER_TOTAL_BYTES_WRITTEN)\n+              .addTableHeaderField(HoodieTableHeaderFields.HEADER_TOTAL_ERRORS);\n+\n+      String expected = HoodiePrintHelper.print(header, fieldNameToConverterMap, \"\", false, -1, false, rows);\n+      expected = removeNonWordAndStripSpace(expected);\n+      String got = removeNonWordAndStripSpace(cr.getResult().toString());\n+      assertEquals(expected, got);\n+    }\n+  }\n+\n   /**\n    * Test case of 'commit showfiles' command.\n    */\n@@ -272,6 +345,39 @@ public void testShowCommitFiles() throws Exception {\n     assertEquals(expected, got);\n   }\n \n+  @Test\n+  public void testShowCommitFilesWithReplaceCommits() throws Exception {\n+    Map<String, Integer[]> data = generateMixedData();\n+\n+    for (String commitInstant : data.keySet()) {\n+      CommandResult cr = getShell().executeCommand(String.format(\"commit showfiles --commit %s\", commitInstant));\n+      assertTrue(cr.isSuccess());\n+\n+      Integer[] value = data.get(commitInstant);\n+      List<Comparable[]> rows = new ArrayList<>();\n+      Arrays.asList(HoodieTestDataGenerator.DEFAULT_FIRST_PARTITION_PATH,\n+              HoodieTestDataGenerator.DEFAULT_SECOND_PARTITION_PATH).stream().forEach(partition ->\n+              rows.add(new Comparable[]{partition, HoodieTestCommitMetadataGenerator.DEFAULT_FILEID,\n+                      HoodieTestCommitMetadataGenerator.DEFAULT_PRE_COMMIT,\n+                      value[1], value[0], HoodieTestCommitMetadataGenerator.DEFAULT_TOTAL_WRITE_BYTES,\n+                      // default 0 errors and blank file with 0 size\n+                      0, 0}));\n+      TableHeader header = new TableHeader().addTableHeaderField(HoodieTableHeaderFields.HEADER_PARTITION_PATH)\n+              .addTableHeaderField(HoodieTableHeaderFields.HEADER_FILE_ID)\n+              .addTableHeaderField(HoodieTableHeaderFields.HEADER_PREVIOUS_COMMIT)\n+              .addTableHeaderField(HoodieTableHeaderFields.HEADER_TOTAL_RECORDS_UPDATED)\n+              .addTableHeaderField(HoodieTableHeaderFields.HEADER_TOTAL_RECORDS_WRITTEN)\n+              .addTableHeaderField(HoodieTableHeaderFields.HEADER_TOTAL_BYTES_WRITTEN)\n+              .addTableHeaderField(HoodieTableHeaderFields.HEADER_TOTAL_ERRORS)\n+              .addTableHeaderField(HoodieTableHeaderFields.HEADER_FILE_SIZE);\n+\n+      String expected = HoodiePrintHelper.print(header, new HashMap<>(), \"\", false, -1, false, rows);\n+      expected = removeNonWordAndStripSpace(expected);\n+      String got = removeNonWordAndStripSpace(cr.getResult().toString());\n+      assertEquals(expected, got);\n+    }\n+  }\n+\n   /**\n    * Test case of 'commits compare' command.\n    */"
  },
  {
    "sha": "2742f7454e8d4445c6c4f3c331f795a22453c00f",
    "filename": "hudi-cli/src/test/java/org/apache/hudi/cli/testutils/HoodieTestCommitMetadataGenerator.java",
    "status": "modified",
    "additions": 15,
    "deletions": 8,
    "changes": 23,
    "blob_url": "https://github.com/apache/hudi/blob/ed6271f90fe9dc618e8f175e75a06ec9d01be07d/hudi-cli/src/test/java/org/apache/hudi/cli/testutils/HoodieTestCommitMetadataGenerator.java",
    "raw_url": "https://github.com/apache/hudi/raw/ed6271f90fe9dc618e8f175e75a06ec9d01be07d/hudi-cli/src/test/java/org/apache/hudi/cli/testutils/HoodieTestCommitMetadataGenerator.java",
    "contents_url": "https://api.github.com/repos/apache/hudi/contents/hudi-cli/src/test/java/org/apache/hudi/cli/testutils/HoodieTestCommitMetadataGenerator.java?ref=ed6271f90fe9dc618e8f175e75a06ec9d01be07d",
    "patch": "@@ -20,6 +20,7 @@\n \n import org.apache.hudi.common.fs.FSUtils;\n import org.apache.hudi.common.model.HoodieCommitMetadata;\n+import org.apache.hudi.common.model.HoodieReplaceCommitMetadata;\n import org.apache.hudi.common.model.HoodieWriteStat;\n import org.apache.hudi.common.table.HoodieTableMetaClient;\n import org.apache.hudi.common.table.timeline.HoodieTimeline;\n@@ -31,6 +32,7 @@\n import org.apache.hadoop.fs.FSDataOutputStream;\n import org.apache.hadoop.fs.Path;\n \n+import java.io.IOException;\n import java.nio.charset.StandardCharsets;\n import java.util.Arrays;\n import java.util.HashMap;\n@@ -76,14 +78,17 @@ public static void createCommitFileWithMetadata(String basePath, String commitTi\n     List<String> commitFileNames = Arrays.asList(HoodieTimeline.makeCommitFileName(commitTime), HoodieTimeline.makeInflightCommitFileName(commitTime),\n         HoodieTimeline.makeRequestedCommitFileName(commitTime));\n     for (String name : commitFileNames) {\n-      Path commitFilePath = new Path(basePath + \"/\" + HoodieTableMetaClient.METAFOLDER_NAME + \"/\" + name);\n-      try (FSDataOutputStream os = FSUtils.getFs(basePath, configuration).create(commitFilePath, true)) {\n-        // Generate commitMetadata\n-        HoodieCommitMetadata commitMetadata =\n-            generateCommitMetadata(basePath, commitTime, fileId1, fileId2, writes, updates);\n-        // Write empty commit metadata\n-        os.writeBytes(new String(commitMetadata.toJsonString().getBytes(StandardCharsets.UTF_8)));\n-      }\n+      HoodieCommitMetadata commitMetadata =\n+              generateCommitMetadata(basePath, commitTime, fileId1, fileId2, writes, updates);\n+      String content = commitMetadata.toJsonString();\n+      createFileWithMetadata(basePath, configuration, name, content);\n+    }\n+  }\n+\n+  static void createFileWithMetadata(String basePath, Configuration configuration, String name, String content) throws IOException {\n+    Path commitFilePath = new Path(basePath + \"/\" + HoodieTableMetaClient.METAFOLDER_NAME + \"/\" + name);\n+    try (FSDataOutputStream os = FSUtils.getFs(basePath, configuration).create(commitFilePath, true)) {\n+      os.writeBytes(new String(content.getBytes(StandardCharsets.UTF_8)));\n     }\n   }\n \n@@ -133,4 +138,6 @@ private static HoodieCommitMetadata generateCommitMetadata(Map<String, List<Stri\n     }));\n     return metadata;\n   }\n+\n+\n }"
  },
  {
    "sha": "ebb346599084b0a2dfcb5c5195b7fafee50ebdce",
    "filename": "hudi-cli/src/test/java/org/apache/hudi/cli/testutils/HoodieTestReplaceCommitMetadatGenerator.java",
    "status": "added",
    "additions": 74,
    "deletions": 0,
    "changes": 74,
    "blob_url": "https://github.com/apache/hudi/blob/ed6271f90fe9dc618e8f175e75a06ec9d01be07d/hudi-cli/src/test/java/org/apache/hudi/cli/testutils/HoodieTestReplaceCommitMetadatGenerator.java",
    "raw_url": "https://github.com/apache/hudi/raw/ed6271f90fe9dc618e8f175e75a06ec9d01be07d/hudi-cli/src/test/java/org/apache/hudi/cli/testutils/HoodieTestReplaceCommitMetadatGenerator.java",
    "contents_url": "https://api.github.com/repos/apache/hudi/contents/hudi-cli/src/test/java/org/apache/hudi/cli/testutils/HoodieTestReplaceCommitMetadatGenerator.java?ref=ed6271f90fe9dc618e8f175e75a06ec9d01be07d",
    "patch": "@@ -0,0 +1,74 @@\n+package org.apache.hudi.cli.testutils;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hudi.common.model.HoodieReplaceCommitMetadata;\n+import org.apache.hudi.common.model.HoodieWriteStat;\n+import org.apache.hudi.common.table.timeline.HoodieTimeline;\n+import org.apache.hudi.common.testutils.FileCreateUtils;\n+import org.apache.hudi.common.util.Option;\n+\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.UUID;\n+\n+import static org.apache.hudi.common.testutils.FileCreateUtils.baseFileName;\n+import static org.apache.hudi.common.util.CollectionUtils.createImmutableList;\n+\n+public class HoodieTestReplaceCommitMetadatGenerator extends HoodieTestCommitMetadataGenerator{\n+    public static void createReplaceCommitFileWithMetadata(String basePath, String commitTime, Configuration configuration,\n+                                                           Option<Integer> writes, Option<Integer> updates) throws Exception {\n+        createReplaceCommitFileWithMetadata(basePath, commitTime, configuration, UUID.randomUUID().toString(),\n+                UUID.randomUUID().toString(), writes, updates);\n+    }\n+\n+    private static void createReplaceCommitFileWithMetadata(String basePath, String commitTime, Configuration configuration,\n+                                                            String fileId1, String fileId2, Option<Integer> writes,\n+                                                            Option<Integer> updates) throws Exception {\n+        List<String> commitFileNames = Arrays.asList(HoodieTimeline.makeCommitFileName(commitTime),\n+                HoodieTimeline.makeInflightCommitFileName(commitTime),\n+                HoodieTimeline.makeRequestedCommitFileName(commitTime));\n+\n+        for (String name : commitFileNames) {\n+            HoodieReplaceCommitMetadata commitMetadata =\n+                    generateReplaceCommitMetadata(basePath, commitTime, fileId1, fileId2, writes, updates);\n+            String content = commitMetadata.toJsonString();\n+            createFileWithMetadata(basePath, configuration, name, content);\n+        }\n+    }\n+\n+    private static HoodieReplaceCommitMetadata generateReplaceCommitMetadata(String basePath, String commitTime, String fileId1, String fileId2, Option<Integer> writes, Option<Integer> updates) throws Exception {\n+        FileCreateUtils.createBaseFile(basePath, DEFAULT_FIRST_PARTITION_PATH, commitTime, fileId1);\n+        FileCreateUtils.createBaseFile(basePath, DEFAULT_SECOND_PARTITION_PATH, commitTime, fileId2);\n+        return generateReplaceCommitMetadata(new HashMap<String, List<String>>() {\n+            {\n+                put(DEFAULT_FIRST_PARTITION_PATH, createImmutableList(baseFileName(DEFAULT_FIRST_PARTITION_PATH, fileId1)));\n+                put(DEFAULT_SECOND_PARTITION_PATH, createImmutableList(baseFileName(DEFAULT_SECOND_PARTITION_PATH, fileId2)));\n+            }\n+        }, writes, updates);\n+    }\n+\n+    private static HoodieReplaceCommitMetadata generateReplaceCommitMetadata(HashMap<String, List<String>> partitionToFilePaths, Option<Integer> writes, Option<Integer> updates) {\n+        HoodieReplaceCommitMetadata metadata = new HoodieReplaceCommitMetadata();\n+        partitionToFilePaths.forEach((key, value) -> value.forEach(f -> {\n+            HoodieWriteStat writeStat = new HoodieWriteStat();\n+            writeStat.setPartitionPath(key);\n+            writeStat.setPath(DEFAULT_PATH);\n+            writeStat.setFileId(DEFAULT_FILEID);\n+            writeStat.setTotalWriteBytes(DEFAULT_TOTAL_WRITE_BYTES);\n+            writeStat.setPrevCommit(DEFAULT_PRE_COMMIT);\n+            writeStat.setNumWrites(writes.orElse(DEFAULT_NUM_WRITES));\n+            writeStat.setNumUpdateWrites(updates.orElse(DEFAULT_NUM_UPDATE_WRITES));\n+            writeStat.setTotalLogBlocks(DEFAULT_TOTAL_LOG_BLOCKS);\n+            writeStat.setTotalLogRecords(DEFAULT_TOTAL_LOG_RECORDS);\n+            metadata.addWriteStat(key, writeStat);\n+        }));\n+        metadata.setPartitionToReplaceFileIds(new HashMap<String, List<String>>() {\n+            {\n+                //TODO fix\n+                put(DEFAULT_FIRST_PARTITION_PATH, createImmutableList(baseFileName(DEFAULT_FIRST_PARTITION_PATH, \"1\")));\n+            }\n+        });\n+        return metadata;\n+    }\n+}"
  }
]
