[
  {
    "sha": "62ea4c1a4c9e89c4e7f2d636b0b8652f8be977f9",
    "filename": "docker/hoodie/hadoop/hive_base/pom.xml",
    "status": "modified",
    "additions": 1,
    "deletions": 1,
    "changes": 2,
    "blob_url": "https://github.com/apache/hudi/blob/0d365b98b055d110200897a26f968d3d865cd84a/docker/hoodie/hadoop/hive_base/pom.xml",
    "raw_url": "https://github.com/apache/hudi/raw/0d365b98b055d110200897a26f968d3d865cd84a/docker/hoodie/hadoop/hive_base/pom.xml",
    "contents_url": "https://api.github.com/repos/apache/hudi/contents/docker/hoodie/hadoop/hive_base/pom.xml?ref=0d365b98b055d110200897a26f968d3d865cd84a",
    "patch": "@@ -58,7 +58,7 @@\n               <tasks>\n                 <copy file=\"${project.basedir}/../../../../packaging/hudi-hadoop-mr-bundle/target/hudi-hadoop-mr-bundle-${project.version}.jar\" tofile=\"target/hoodie-hadoop-mr-bundle.jar\" />\n                 <copy file=\"${project.basedir}/../../../../packaging/hudi-hive-sync-bundle/target/hudi-hive-sync-bundle-${project.version}.jar\" tofile=\"target/hoodie-hive-sync-bundle.jar\" />\n-                <copy file=\"${project.basedir}/../../../../packaging/hudi-spark-bundle/target/hudi-spark-bundle_${scala.binary.version}-${project.version}.jar\" tofile=\"target/hoodie-spark-bundle.jar\" />\n+                <copy file=\"${project.basedir}/../../../../packaging/hudi-spark-bundle/target/hudi-spark${sparkbundle.version}-bundle_${scala.binary.version}-${project.version}.jar\" tofile=\"target/hoodie-spark-bundle.jar\" />\n                 <copy file=\"${project.basedir}/../../../../packaging/hudi-utilities-bundle/target/hudi-utilities-bundle_${scala.binary.version}-${project.version}.jar\" tofile=\"target/hoodie-utilities.jar\" />\n               </tasks>\n             </configuration>"
  },
  {
    "sha": "612067d2e4418b6fb8cd16a25ad3177b90fb4299",
    "filename": "docker/hoodie/hadoop/pom.xml",
    "status": "modified",
    "additions": 1,
    "deletions": 1,
    "changes": 2,
    "blob_url": "https://github.com/apache/hudi/blob/0d365b98b055d110200897a26f968d3d865cd84a/docker/hoodie/hadoop/pom.xml",
    "raw_url": "https://github.com/apache/hudi/raw/0d365b98b055d110200897a26f968d3d865cd84a/docker/hoodie/hadoop/pom.xml",
    "contents_url": "https://api.github.com/repos/apache/hudi/contents/docker/hoodie/hadoop/pom.xml?ref=0d365b98b055d110200897a26f968d3d865cd84a",
    "patch": "@@ -42,7 +42,7 @@\n   <dependencies>\n     <dependency>\n       <groupId>org.apache.hudi</groupId>\n-      <artifactId>hudi-spark-bundle_${scala.binary.version}</artifactId>\n+      <artifactId>hudi-spark${sparkbundle.version}-bundle_${scala.binary.version}</artifactId>\n       <version>${project.version}</version>\n     </dependency>\n   </dependencies>"
  },
  {
    "sha": "336fc8d41680121620305ebac2449a18cfc7cbb8",
    "filename": "packaging/hudi-spark-bundle/pom.xml",
    "status": "modified",
    "additions": 1,
    "deletions": 1,
    "changes": 2,
    "blob_url": "https://github.com/apache/hudi/blob/0d365b98b055d110200897a26f968d3d865cd84a/packaging/hudi-spark-bundle/pom.xml",
    "raw_url": "https://github.com/apache/hudi/raw/0d365b98b055d110200897a26f968d3d865cd84a/packaging/hudi-spark-bundle/pom.xml",
    "contents_url": "https://api.github.com/repos/apache/hudi/contents/packaging/hudi-spark-bundle/pom.xml?ref=0d365b98b055d110200897a26f968d3d865cd84a",
    "patch": "@@ -23,7 +23,7 @@\n     <relativePath>../../pom.xml</relativePath>\n   </parent>\n   <modelVersion>4.0.0</modelVersion>\n-  <artifactId>hudi-spark-bundle_${scala.binary.version}</artifactId>\n+  <artifactId>hudi-spark${sparkbundle.version}-bundle_${scala.binary.version}</artifactId>\n   <packaging>jar</packaging>\n \n   <properties>"
  },
  {
    "sha": "81e415a7b83d51ea178d4e084b180de375029c72",
    "filename": "pom.xml",
    "status": "modified",
    "additions": 4,
    "deletions": 0,
    "changes": 4,
    "blob_url": "https://github.com/apache/hudi/blob/0d365b98b055d110200897a26f968d3d865cd84a/pom.xml",
    "raw_url": "https://github.com/apache/hudi/raw/0d365b98b055d110200897a26f968d3d865cd84a/pom.xml",
    "contents_url": "https://api.github.com/repos/apache/hudi/contents/pom.xml?ref=0d365b98b055d110200897a26f968d3d865cd84a",
    "patch": "@@ -106,9 +106,12 @@\n     <prometheus.version>0.8.0</prometheus.version>\n     <http.version>4.4.1</http.version>\n     <spark.version>${spark2.version}</spark.version>\n+    <sparkbundle.version>${spark2bundle.version}</sparkbundle.version>\n     <flink.version>1.11.2</flink.version>\n     <spark2.version>2.4.4</spark2.version>\n     <spark3.version>3.0.0</spark3.version>\n+    <spark2bundle.version></spark2bundle.version>\n+    <spark3bundle.version>3</spark3bundle.version>\n     <avro.version>1.8.2</avro.version>\n     <scala11.version>2.11.12</scala11.version>\n     <scala12.version>2.12.10</scala12.version>\n@@ -1374,6 +1377,7 @@\n       <id>spark3</id>\n       <properties>\n         <spark.version>${spark3.version}</spark.version>\n+        <sparkbundle.version>${spark3bundle.version}</sparkbundle.version>\n         <scala.version>${scala12.version}</scala.version>\n         <scala.binary.version>2.12</scala.binary.version>\n         <kafka.version>2.4.1</kafka.version>"
  },
  {
    "sha": "c4e9319326082e5e5cf42017eba18056aa65a884",
    "filename": "scripts/release/deploy_staging_jars.sh",
    "status": "modified",
    "additions": 4,
    "deletions": 2,
    "changes": 6,
    "blob_url": "https://github.com/apache/hudi/blob/0d365b98b055d110200897a26f968d3d865cd84a/scripts/release/deploy_staging_jars.sh",
    "raw_url": "https://github.com/apache/hudi/raw/0d365b98b055d110200897a26f968d3d865cd84a/scripts/release/deploy_staging_jars.sh",
    "contents_url": "https://api.github.com/repos/apache/hudi/contents/scripts/release/deploy_staging_jars.sh?ref=0d365b98b055d110200897a26f968d3d865cd84a",
    "patch": "@@ -21,7 +21,7 @@\n ## Variables with defaults (if not overwritten by environment)\n ##\n MVN=${MVN:-mvn}\n-\n+SPARK_VERSION=2\n # fail immediately\n set -o errexit\n set -o nounset\n@@ -44,6 +44,8 @@ else\n     do\n \tif [[ $param =~ --scala_version\\=(2\\.1[1-2]) ]]; then\n \t\tSCALA_VERSION=${BASH_REMATCH[1]}\n+        elif [[ $param =~ --spark_version\\=([2-3]) ]]; then\n+                SPARK_VERSION=${BASH_REMATCH[0]}\n \tfi\n     done\n fi\n@@ -54,5 +56,5 @@ cd ..\n \n echo \"Deploying to repository.apache.org with scala version ${SCALA_VERSION}\"\n \n-COMMON_OPTIONS=\"-Dscala-${SCALA_VERSION} -Prelease -DskipTests -DretryFailedDeploymentCount=10 -DdeployArtifacts=true\"\n+COMMON_OPTIONS=\"-Dscala-${SCALA_VERSION} -Dspark${SPARK_VERSION} -Prelease -DskipTests -DretryFailedDeploymentCount=10 -DdeployArtifacts=true\"\n $MVN clean deploy $COMMON_OPTIONS"
  }
]
