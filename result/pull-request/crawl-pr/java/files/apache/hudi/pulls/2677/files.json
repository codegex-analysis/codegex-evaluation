[
  {
    "sha": "f64c6aaf8cc6eafaab10ddbb6161a6a96ed97a6c",
    "filename": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/table/HoodieTimelineArchiveLog.java",
    "status": "modified",
    "additions": 4,
    "deletions": 2,
    "changes": 6,
    "blob_url": "https://github.com/apache/hudi/blob/06cc8d87c6080d7c1540dd3ebfad4cb80957a244/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/table/HoodieTimelineArchiveLog.java",
    "raw_url": "https://github.com/apache/hudi/raw/06cc8d87c6080d7c1540dd3ebfad4cb80957a244/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/table/HoodieTimelineArchiveLog.java",
    "contents_url": "https://api.github.com/repos/apache/hudi/contents/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/table/HoodieTimelineArchiveLog.java?ref=06cc8d87c6080d7c1540dd3ebfad4cb80957a244",
    "patch": "@@ -412,8 +412,10 @@ private IndexedRecord convertToAvroRecord(HoodieTimeline commitTimeline, HoodieI\n         break;\n       }\n       case HoodieTimeline.ROLLBACK_ACTION: {\n-        archivedMetaWrapper.setHoodieRollbackMetadata(TimelineMetadataUtils.deserializeAvroMetadata(\n-            commitTimeline.getInstantDetails(hoodieInstant).get(), HoodieRollbackMetadata.class));\n+        if (hoodieInstant.isCompleted()) {\n+          archivedMetaWrapper.setHoodieRollbackMetadata(TimelineMetadataUtils.deserializeAvroMetadata(\n+                  commitTimeline.getInstantDetails(hoodieInstant).get(), HoodieRollbackMetadata.class));\n+        }\n         archivedMetaWrapper.setActionType(ActionType.rollback.name());\n         break;\n       }"
  },
  {
    "sha": "bf279485a6ec5913aa86b536e14482d2fdb7b56c",
    "filename": "hudi-client/hudi-spark-client/src/test/java/org/apache/hudi/io/TestHoodieTimelineArchiveLog.java",
    "status": "modified",
    "additions": 210,
    "deletions": 0,
    "changes": 210,
    "blob_url": "https://github.com/apache/hudi/blob/06cc8d87c6080d7c1540dd3ebfad4cb80957a244/hudi-client/hudi-spark-client/src/test/java/org/apache/hudi/io/TestHoodieTimelineArchiveLog.java",
    "raw_url": "https://github.com/apache/hudi/raw/06cc8d87c6080d7c1540dd3ebfad4cb80957a244/hudi-client/hudi-spark-client/src/test/java/org/apache/hudi/io/TestHoodieTimelineArchiveLog.java",
    "contents_url": "https://api.github.com/repos/apache/hudi/contents/hudi-client/hudi-spark-client/src/test/java/org/apache/hudi/io/TestHoodieTimelineArchiveLog.java?ref=06cc8d87c6080d7c1540dd3ebfad4cb80957a244",
    "patch": "@@ -22,6 +22,7 @@\n import org.apache.hudi.avro.model.HoodieCleanMetadata;\n import org.apache.hudi.avro.model.HoodieCleanerPlan;\n import org.apache.hudi.avro.model.HoodieRequestedReplaceMetadata;\n+import org.apache.hudi.avro.model.HoodieRollbackMetadata;\n import org.apache.hudi.common.HoodieCleanStat;\n import org.apache.hudi.common.fs.FSUtils;\n import org.apache.hudi.common.fs.HoodieWrapperFileSystem;\n@@ -60,9 +61,11 @@\n import java.util.HashMap;\n import java.util.HashSet;\n import java.util.List;\n+import java.util.Map;\n import java.util.Random;\n import java.util.Set;\n import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n \n import static org.apache.hudi.common.util.CleanerUtils.convertCleanMetadata;\n import static org.junit.jupiter.api.Assertions.assertEquals;\n@@ -388,6 +391,31 @@ public void testArchiveCommitSavepointNoHole() throws IOException {\n         \"Archived commits should always be safe\");\n   }\n \n+  @Test\n+  public void testArchiveRollbacks() throws IOException {\n+    HoodieWriteConfig cfg = HoodieWriteConfig.newBuilder().withPath(basePath)\n+            .withSchema(HoodieTestDataGenerator.TRIP_EXAMPLE_SCHEMA).withParallelism(2, 2).forTable(\"test-trip-table\")\n+            .withCompactionConfig(HoodieCompactionConfig.newBuilder().retainCommits(1).archiveCommitsWith(2, 3).build())\n+            .build();\n+\n+    createCommitAndRollbackFile(\"100\", \"101\", false);\n+    createCommitAndRollbackFile(\"102\", \"103\", false);\n+    createCommitAndRollbackFile(\"104\", \"105\", false);\n+    createCommitAndRollbackFile(\"106\", \"107\", false);\n+\n+    HoodieTable table = HoodieSparkTable.create(cfg, context);\n+    HoodieTimelineArchiveLog archiveLog = new HoodieTimelineArchiveLog(cfg, table);\n+\n+    assertTrue(archiveLog.archiveIfRequired(context));\n+    HoodieTimeline timeline = metaClient.getActiveTimeline().reload().getCommitsTimeline().filterCompletedInstants();\n+    assertEquals(2, timeline.countInstants(),\n+            \"first two commits must have been archived\");\n+    assertFalse(metaClient.getActiveTimeline().containsInstant(new HoodieInstant(false, HoodieTimeline.ROLLBACK_ACTION, \"101\")),\n+            \"first rollback must have been archived\");\n+    assertFalse(metaClient.getActiveTimeline().containsInstant(new HoodieInstant(false, HoodieTimeline.ROLLBACK_ACTION, \"103\")),\n+            \"second rollback must have been archived\");\n+  }\n+\n   @Test\n   public void testArchiveCommitCompactionNoHole() throws IOException {\n     HoodieWriteConfig cfg = HoodieWriteConfig.newBuilder().withPath(basePath)\n@@ -491,6 +519,166 @@ public void testConvertCommitMetadata() {\n     assertEquals(expectedCommitMetadata.getOperationType(), WriteOperationType.INSERT.toString());\n   }\n \n+  @Test\n+  public void testArchiveCompletedClean() throws IOException {\n+    HoodieWriteConfig cfg =\n+            HoodieWriteConfig.newBuilder().withPath(basePath).withSchema(HoodieTestDataGenerator.TRIP_EXAMPLE_SCHEMA)\n+                    .withParallelism(2, 2).forTable(\"test-trip-table\")\n+                    .withCompactionConfig(HoodieCompactionConfig.newBuilder().retainCommits(1).archiveCommitsWith(2, 3).build())\n+                    .build();\n+    metaClient = HoodieTableMetaClient.reload(metaClient);\n+\n+    createCleanMetadata(\"10\", false);\n+    createCleanMetadata(\"11\", false);\n+    createCleanMetadata(\"12\", false);\n+    HoodieInstant notArchivedInstant1 = new HoodieInstant(State.COMPLETED, \"clean\", \"12\");\n+    createCleanMetadata(\"13\", false);\n+    HoodieInstant notArchivedInstant2 = new HoodieInstant(State.COMPLETED, \"clean\", \"13\");\n+\n+    HoodieTable table = HoodieSparkTable.create(cfg, context, metaClient);\n+    HoodieTimelineArchiveLog archiveLog = new HoodieTimelineArchiveLog(cfg, table);\n+\n+    archiveLog.archiveIfRequired(context);\n+\n+    List<HoodieInstant> notArchivedInstants = metaClient.getActiveTimeline().reload().getInstants().collect(Collectors.toList());\n+    //There will be 3 * 2 files but due to TimelineLayoutV1 this will show as 2.\n+    assertEquals(2, notArchivedInstants.size(), \"Not archived instants should be 2\");\n+    assertEquals(notArchivedInstants, Arrays.asList(notArchivedInstant1, notArchivedInstant2), \"\");\n+  }\n+\n+  @Test\n+  public void testArchiveCompletedRollback() throws IOException {\n+    HoodieWriteConfig cfg =\n+            HoodieWriteConfig.newBuilder().withPath(basePath).withSchema(HoodieTestDataGenerator.TRIP_EXAMPLE_SCHEMA)\n+                    .withParallelism(2, 2).forTable(\"test-trip-table\")\n+                    .withCompactionConfig(HoodieCompactionConfig.newBuilder().retainCommits(1).archiveCommitsWith(2, 3).build())\n+                    .build();\n+    metaClient = HoodieTableMetaClient.reload(metaClient);\n+\n+    createCommitAndRollbackFile(\"6\", \"10\", false);\n+    createCommitAndRollbackFile(\"8\", \"11\", false);\n+    createCommitAndRollbackFile(\"7\", \"12\", false);\n+    HoodieInstant notArchivedInstant1 = new HoodieInstant(State.COMPLETED, \"rollback\", \"12\");\n+\n+    createCommitAndRollbackFile(\"5\", \"13\", false);\n+    HoodieInstant notArchivedInstant2 = new HoodieInstant(State.COMPLETED, \"rollback\", \"13\");\n+\n+    HoodieTable table = HoodieSparkTable.create(cfg, context, metaClient);\n+    HoodieTimelineArchiveLog archiveLog = new HoodieTimelineArchiveLog(cfg, table);\n+\n+    archiveLog.archiveIfRequired(context);\n+\n+    List<HoodieInstant> notArchivedInstants = metaClient.getActiveTimeline().reload().getRollbackTimeline().getInstants().collect(Collectors.toList());\n+    //There will be 2 * 2 files but due to TimelineLayoutV1 this will show as 2.\n+    assertEquals(2, notArchivedInstants.size(), \"Not archived instants should be 2\");\n+    assertEquals(notArchivedInstants, Arrays.asList(notArchivedInstant1, notArchivedInstant2), \"\");\n+  }\n+\n+  @Test\n+  public void testArchiveCompletedShouldRetainMinInstantsIfInstantsGreaterThanMaxtoKeep() throws IOException {\n+    int minInstants = 2;\n+    int maxInstants = 10;\n+    HoodieWriteConfig cfg =\n+            HoodieWriteConfig.newBuilder().withPath(basePath).withSchema(HoodieTestDataGenerator.TRIP_EXAMPLE_SCHEMA)\n+                    .withParallelism(2, 2).forTable(\"test-trip-table\")\n+                    .withCompactionConfig(HoodieCompactionConfig.newBuilder().retainCommits(1).archiveCommitsWith(minInstants, maxInstants).build())\n+                    .build();\n+    metaClient = HoodieTableMetaClient.reload(metaClient);\n+    for (int i = 0; i < maxInstants + 2; i++) {\n+      createCleanMetadata(i + \"\", false);\n+    }\n+\n+    HoodieTable table = HoodieSparkTable.create(cfg, context, metaClient);\n+    HoodieTimelineArchiveLog archiveLog = new HoodieTimelineArchiveLog(cfg, table);\n+\n+    archiveLog.archiveIfRequired(context);\n+    assertEquals(minInstants, metaClient.getActiveTimeline().reload().getInstants().count());\n+  }\n+\n+  @Test\n+  public void testArchiveCompletedShouldNotArchiveIfInstantsLessThanMaxtoKeep() throws IOException {\n+    int minInstants = 2;\n+    int maxInstants = 10;\n+    HoodieWriteConfig cfg =\n+            HoodieWriteConfig.newBuilder().withPath(basePath).withSchema(HoodieTestDataGenerator.TRIP_EXAMPLE_SCHEMA)\n+                    .withParallelism(2, 2).forTable(\"test-trip-table\")\n+                    .withCompactionConfig(HoodieCompactionConfig.newBuilder().retainCommits(1).archiveCommitsWith(minInstants, maxInstants).build())\n+                    .build();\n+    metaClient = HoodieTableMetaClient.reload(metaClient);\n+    for (int i = 0; i < maxInstants; i++) {\n+      createCleanMetadata(i + \"\", false);\n+    }\n+\n+    HoodieTable table = HoodieSparkTable.create(cfg, context, metaClient);\n+    HoodieTimelineArchiveLog archiveLog = new HoodieTimelineArchiveLog(cfg, table);\n+\n+    archiveLog.archiveIfRequired(context);\n+    assertEquals(maxInstants, metaClient.getActiveTimeline().reload().getInstants().count());\n+  }\n+\n+  @Test\n+  public void testArchiveCompletedRollbackAndClean() throws IOException {\n+    int minInstantsToKeep = 2;\n+    int maxInstantsToKeep = 10;\n+    HoodieWriteConfig cfg =\n+            HoodieWriteConfig.newBuilder().withPath(basePath).withSchema(HoodieTestDataGenerator.TRIP_EXAMPLE_SCHEMA)\n+                    .withParallelism(2, 2).forTable(\"test-trip-table\")\n+                    .withCompactionConfig(HoodieCompactionConfig.newBuilder().retainCommits(1).archiveCommitsWith(minInstantsToKeep, maxInstantsToKeep).build())\n+                    .build();\n+    metaClient = HoodieTableMetaClient.reload(metaClient);\n+\n+    int startInstant = 1;\n+    for (int i = 0; i < maxInstantsToKeep + 1; i++, startInstant++) {\n+      createCleanMetadata(startInstant + \"\", false);\n+    }\n+\n+    for (int i = 0; i < maxInstantsToKeep + 1; i++, startInstant += 2) {\n+      createCommitAndRollbackFile(startInstant + 1 + \"\", startInstant + \"\", false);\n+    }\n+\n+    HoodieTable table = HoodieSparkTable.create(cfg, context, metaClient);\n+    HoodieTimelineArchiveLog archiveLog = new HoodieTimelineArchiveLog(cfg, table);\n+\n+    archiveLog.archiveIfRequired(context);\n+\n+    Stream<HoodieInstant> currentInstants = metaClient.getActiveTimeline().reload().getInstants();\n+    Map<Object, List<HoodieInstant>> actionInstantMap = currentInstants.collect(Collectors.groupingBy(HoodieInstant::getAction));\n+\n+    assertTrue(actionInstantMap.containsKey(\"clean\"), \"Clean Action key must be preset\");\n+    assertEquals(minInstantsToKeep, actionInstantMap.get(\"clean\").size(), \"Should have min instant\");\n+\n+    assertTrue(actionInstantMap.containsKey(\"rollback\"), \"Rollback Action key must be preset\");\n+    assertEquals(minInstantsToKeep, actionInstantMap.get(\"rollback\").size(), \"Should have min instant\");\n+  }\n+\n+  @Test\n+  public void testArchiveInflightRollbackAndClean() throws IOException {\n+    HoodieWriteConfig cfg =\n+            HoodieWriteConfig.newBuilder().withPath(basePath).withSchema(HoodieTestDataGenerator.TRIP_EXAMPLE_SCHEMA)\n+                    .withParallelism(2, 2).forTable(\"test-trip-table\")\n+                    .withCompactionConfig(HoodieCompactionConfig.newBuilder().retainCommits(1).archiveCommitsWith(2, 3).build())\n+                    .build();\n+    metaClient = HoodieTableMetaClient.reload(metaClient);\n+\n+    createCleanMetadata(\"10\", false);\n+    createCleanMetadata(\"11\", false);\n+    createCleanMetadata(\"12\", false);\n+    HoodieInstant notArchivedInstant1 = new HoodieInstant(State.COMPLETED, \"clean\", \"12\");\n+    createCleanMetadata(\"13\", false);\n+    HoodieInstant notArchivedInstant2 = new HoodieInstant(State.COMPLETED, \"clean\", \"13\");\n+    createCleanMetadata(\"14\", true);\n+    HoodieInstant notArchivedInstant3 = new HoodieInstant(State.INFLIGHT, \"clean\", \"14\");\n+\n+    HoodieTable table = HoodieSparkTable.create(cfg, context, metaClient);\n+    HoodieTimelineArchiveLog archiveLog = new HoodieTimelineArchiveLog(cfg, table);\n+\n+    archiveLog.archiveIfRequired(context);\n+\n+    List<HoodieInstant> notArchivedInstants = metaClient.getActiveTimeline().reload().getInstants().collect(Collectors.toList());\n+    assertEquals(3, notArchivedInstants.size(), \"Not archived instants should be 3\");\n+    assertEquals(notArchivedInstants, Arrays.asList(notArchivedInstant1, notArchivedInstant2, notArchivedInstant3), \"\");\n+  }\n+\n   private void createReplaceMetadata(String instantTime) throws Exception {\n     String fileId1 = \"file-\" + instantTime + \"-1\";\n     String fileId2 = \"file-\" + instantTime + \"-2\";\n@@ -526,4 +714,26 @@ private void createCleanMetadata(String instantTime, boolean inflightOnly) throw\n       HoodieTestTable.of(metaClient).addClean(instantTime, cleanerPlan, cleanMetadata);\n     }\n   }\n+\n+  private void createCommitAndRollbackFile(String commitToRollback, String rollbackTIme, boolean isRollbackInflight) throws IOException {\n+    HoodieTestDataGenerator.createCommitFile(basePath, commitToRollback, wrapperFs.getConf());\n+    createRollbackMetadata(rollbackTIme, commitToRollback, isRollbackInflight);\n+  }\n+\n+  private void createRollbackMetadata(String rollbackTime, String commitToRollback, boolean inflight) throws IOException {\n+    if (inflight) {\n+      HoodieTestTable.of(metaClient).addInflightRollback(rollbackTime);\n+    } else {\n+      HoodieRollbackMetadata hoodieRollbackMetadata = HoodieRollbackMetadata.newBuilder()\n+              .setVersion(1)\n+              .setStartRollbackTime(rollbackTime)\n+              .setTotalFilesDeleted(1)\n+              .setTimeTakenInMillis(1000)\n+              .setCommitsRollback(Collections.singletonList(commitToRollback))\n+              .setPartitionMetadata(Collections.emptyMap())\n+              .setInstantsRollback(Collections.emptyList())\n+              .build();\n+      HoodieTestTable.of(metaClient).addRollback(rollbackTime, hoodieRollbackMetadata);\n+    }\n+  }\n }"
  },
  {
    "sha": "adb49e080cefec070ec15fafeb0ed3f153cfa6dd",
    "filename": "hudi-common/src/test/java/org/apache/hudi/common/testutils/FileCreateUtils.java",
    "status": "modified",
    "additions": 10,
    "deletions": 0,
    "changes": 10,
    "blob_url": "https://github.com/apache/hudi/blob/06cc8d87c6080d7c1540dd3ebfad4cb80957a244/hudi-common/src/test/java/org/apache/hudi/common/testutils/FileCreateUtils.java",
    "raw_url": "https://github.com/apache/hudi/raw/06cc8d87c6080d7c1540dd3ebfad4cb80957a244/hudi-common/src/test/java/org/apache/hudi/common/testutils/FileCreateUtils.java",
    "contents_url": "https://api.github.com/repos/apache/hudi/contents/hudi-common/src/test/java/org/apache/hudi/common/testutils/FileCreateUtils.java?ref=06cc8d87c6080d7c1540dd3ebfad4cb80957a244",
    "patch": "@@ -22,6 +22,7 @@\n import org.apache.hudi.avro.model.HoodieCleanMetadata;\n import org.apache.hudi.avro.model.HoodieCleanerPlan;\n import org.apache.hudi.avro.model.HoodieRequestedReplaceMetadata;\n+import org.apache.hudi.avro.model.HoodieRollbackMetadata;\n import org.apache.hudi.common.fs.FSUtils;\n import org.apache.hudi.common.model.HoodieFileFormat;\n import org.apache.hudi.common.model.HoodiePartitionMetadata;\n@@ -47,6 +48,7 @@\n \n import static org.apache.hudi.common.table.timeline.TimelineMetadataUtils.serializeCleanMetadata;\n import static org.apache.hudi.common.table.timeline.TimelineMetadataUtils.serializeCleanerPlan;\n+import static org.apache.hudi.common.table.timeline.TimelineMetadataUtils.serializeRollbackMetadata;\n \n public class FileCreateUtils {\n \n@@ -170,6 +172,14 @@ public static void createInflightCleanFile(String basePath, String instantTime,\n     createMetaFile(basePath, instantTime, HoodieTimeline.INFLIGHT_CLEAN_EXTENSION, serializeCleanerPlan(cleanerPlan).get());\n   }\n \n+  public static void createInflightRollbackFile(String basePath, String instantTime) throws IOException {\n+    createMetaFile(basePath, instantTime, HoodieTimeline.INFLIGHT_ROLLBACK_EXTENSION);\n+  }\n+\n+  public static void createRollbackFile(String basePath, String instantTime, HoodieRollbackMetadata hoodieRollbackMetadata) throws IOException {\n+    createMetaFile(basePath, instantTime, HoodieTimeline.ROLLBACK_EXTENSION, serializeRollbackMetadata(hoodieRollbackMetadata).get());\n+  }\n+\n   private static void createAuxiliaryMetaFile(String basePath, String instantTime, String suffix) throws IOException {\n     Path parentPath = Paths.get(basePath, HoodieTableMetaClient.AUXILIARYFOLDER_NAME);\n     Files.createDirectories(parentPath);"
  },
  {
    "sha": "7499894c26ce17f8cc913792f58a1461a586b6d0",
    "filename": "hudi-common/src/test/java/org/apache/hudi/common/testutils/HoodieTestDataGenerator.java",
    "status": "modified",
    "additions": 9,
    "deletions": 1,
    "changes": 10,
    "blob_url": "https://github.com/apache/hudi/blob/06cc8d87c6080d7c1540dd3ebfad4cb80957a244/hudi-common/src/test/java/org/apache/hudi/common/testutils/HoodieTestDataGenerator.java",
    "raw_url": "https://github.com/apache/hudi/raw/06cc8d87c6080d7c1540dd3ebfad4cb80957a244/hudi-common/src/test/java/org/apache/hudi/common/testutils/HoodieTestDataGenerator.java",
    "contents_url": "https://api.github.com/repos/apache/hudi/contents/hudi-common/src/test/java/org/apache/hudi/common/testutils/HoodieTestDataGenerator.java?ref=06cc8d87c6080d7c1540dd3ebfad4cb80957a244",
    "patch": "@@ -341,14 +341,22 @@ public static void createCommitFile(String basePath, String instantTime, Configu\n   }\n \n   private static void createMetadataFile(String f, String basePath, Configuration configuration, HoodieCommitMetadata commitMetadata) {\n+    try {\n+      createMetadataFile(f, basePath, configuration, commitMetadata.toJsonString().getBytes(StandardCharsets.UTF_8));\n+    } catch (IOException e) {\n+      throw new HoodieIOException(e.getMessage(), e);\n+    }\n+  }\n+\n+  private static void createMetadataFile(String f, String basePath, Configuration configuration, byte[] content) {\n     Path commitFile = new Path(\n         basePath + \"/\" + HoodieTableMetaClient.METAFOLDER_NAME + \"/\" + f);\n     FSDataOutputStream os = null;\n     try {\n       FileSystem fs = FSUtils.getFs(basePath, configuration);\n       os = fs.create(commitFile, true);\n       // Write empty commit metadata\n-      os.writeBytes(new String(commitMetadata.toJsonString().getBytes(StandardCharsets.UTF_8)));\n+      os.write(content);\n     } catch (IOException ioe) {\n       throw new HoodieIOException(ioe.getMessage(), ioe);\n     } finally {"
  },
  {
    "sha": "d8e0150186b1a8d6a7d1a8d217b11ffd20352c3e",
    "filename": "hudi-common/src/test/java/org/apache/hudi/common/testutils/HoodieTestTable.java",
    "status": "modified",
    "additions": 18,
    "deletions": 0,
    "changes": 18,
    "blob_url": "https://github.com/apache/hudi/blob/06cc8d87c6080d7c1540dd3ebfad4cb80957a244/hudi-common/src/test/java/org/apache/hudi/common/testutils/HoodieTestTable.java",
    "raw_url": "https://github.com/apache/hudi/raw/06cc8d87c6080d7c1540dd3ebfad4cb80957a244/hudi-common/src/test/java/org/apache/hudi/common/testutils/HoodieTestTable.java",
    "contents_url": "https://api.github.com/repos/apache/hudi/contents/hudi-common/src/test/java/org/apache/hudi/common/testutils/HoodieTestTable.java?ref=06cc8d87c6080d7c1540dd3ebfad4cb80957a244",
    "patch": "@@ -23,6 +23,7 @@\n import org.apache.hudi.avro.model.HoodieCleanerPlan;\n import org.apache.hudi.avro.model.HoodieCompactionPlan;\n import org.apache.hudi.avro.model.HoodieRequestedReplaceMetadata;\n+import org.apache.hudi.avro.model.HoodieRollbackMetadata;\n import org.apache.hudi.common.model.FileSlice;\n import org.apache.hudi.common.model.HoodieFileFormat;\n import org.apache.hudi.common.model.HoodieReplaceCommitMetadata;\n@@ -65,13 +66,15 @@\n import static org.apache.hudi.common.testutils.FileCreateUtils.createInflightCompaction;\n import static org.apache.hudi.common.testutils.FileCreateUtils.createInflightDeltaCommit;\n import static org.apache.hudi.common.testutils.FileCreateUtils.createInflightReplaceCommit;\n+import static org.apache.hudi.common.testutils.FileCreateUtils.createInflightRollbackFile;\n import static org.apache.hudi.common.testutils.FileCreateUtils.createMarkerFile;\n import static org.apache.hudi.common.testutils.FileCreateUtils.createReplaceCommit;\n import static org.apache.hudi.common.testutils.FileCreateUtils.createRequestedCleanFile;\n import static org.apache.hudi.common.testutils.FileCreateUtils.createRequestedCommit;\n import static org.apache.hudi.common.testutils.FileCreateUtils.createRequestedCompaction;\n import static org.apache.hudi.common.testutils.FileCreateUtils.createRequestedDeltaCommit;\n import static org.apache.hudi.common.testutils.FileCreateUtils.createRequestedReplaceCommit;\n+import static org.apache.hudi.common.testutils.FileCreateUtils.createRollbackFile;\n import static org.apache.hudi.common.testutils.FileCreateUtils.logFileName;\n \n public class HoodieTestTable {\n@@ -433,6 +436,21 @@ public String getBaseFileNameById(String fileId) {\n     return FileSystemTestUtils.listRecursive(fs, new Path(Paths.get(basePath, HoodieTableMetaClient.TEMPFOLDER_NAME).toString())).toArray(new FileStatus[0]);\n   }\n \n+  public HoodieTestTable addInflightRollback(String instantTime) throws IOException {\n+    createInflightRollbackFile(basePath, instantTime);\n+    currentInstantTime = instantTime;\n+    metaClient = HoodieTableMetaClient.reload(metaClient);\n+    return this;\n+  }\n+\n+  public HoodieTestTable addRollback(String instantTime, HoodieRollbackMetadata rollbackMetadata) throws IOException {\n+    createInflightRollbackFile(basePath, instantTime);\n+    createRollbackFile(basePath, instantTime, rollbackMetadata);\n+    currentInstantTime = instantTime;\n+    metaClient = HoodieTableMetaClient.reload(metaClient);\n+    return this;\n+  }\n+\n   public static class HoodieTestTableException extends RuntimeException {\n     public HoodieTestTableException(Throwable t) {\n       super(t);"
  }
]
