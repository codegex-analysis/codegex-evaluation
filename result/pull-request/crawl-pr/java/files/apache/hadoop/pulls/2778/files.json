[
  {
    "sha": "c4b8f6e3c468384bb0d20bcd3633e965ac6cf4f8",
    "filename": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/Constants.java",
    "status": "modified",
    "additions": 23,
    "deletions": 4,
    "changes": 27,
    "blob_url": "https://github.com/apache/hadoop/blob/23fe6f44281618c7fdef773b90d617214086819a/hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/Constants.java",
    "raw_url": "https://github.com/apache/hadoop/raw/23fe6f44281618c7fdef773b90d617214086819a/hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/Constants.java",
    "contents_url": "https://api.github.com/repos/apache/hadoop/contents/hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/Constants.java?ref=23fe6f44281618c7fdef773b90d617214086819a",
    "patch": "@@ -160,14 +160,33 @@ private Constants() {\n       DEFAULT_SSL_CHANNEL_MODE =\n           DelegatingSSLSocketFactory.SSLChannelMode.Default_JSSE;\n \n-  //use a custom endpoint?\n+  /**\n+   * Endpoint. For v4 signing and/or better performance,\n+   * this should be the specific endpoint of the region\n+   * in which the bucket is hosted.\n+   */\n   public static final String ENDPOINT = \"fs.s3a.endpoint\";\n \n   /**\n-   * Default value of s3 endpoint. If not set explicitly using\n-   * {@code AmazonS3#setEndpoint()}, this is used.\n+   * Default value of s3 endpoint: {@value}.\n+   * It tells the AWS client to work it out by asking the central\n+   * endpoint where the bucket lives; caching that\n+   * value in the client for the life of the process.\n+   * <p>\n+   * Note: previously this constant was defined as\n+   * {@link #CENTRAL_ENDPOINT}, however the actual\n+   * S3A client code used \"\" as the default when\n+   * {@link #ENDPOINT} was unset.\n+   * As core-default.xml also set the endpoint to \"\",\n+   * the empty string has long been the <i>real</i>\n+   * default value.\n+   */\n+  public static final String DEFAULT_ENDPOINT = \"\";\n+\n+  /**\n+   * The central endpoint :{@value}.\n    */\n-  public static final String DEFAULT_ENDPOINT = \"s3.amazonaws.com\";\n+  public static final String CENTRAL_ENDPOINT = \"s3.amazonaws.com\";\n \n   //Enable path style access? Overrides default virtual hosting\n   public static final String PATH_STYLE_ACCESS = \"fs.s3a.path.style.access\";"
  },
  {
    "sha": "ae50bd1459bcd53c80e7919ef843041d6dbdd30d",
    "filename": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/DefaultS3ClientFactory.java",
    "status": "modified",
    "additions": 44,
    "deletions": 125,
    "changes": 169,
    "blob_url": "https://github.com/apache/hadoop/blob/23fe6f44281618c7fdef773b90d617214086819a/hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/DefaultS3ClientFactory.java",
    "raw_url": "https://github.com/apache/hadoop/raw/23fe6f44281618c7fdef773b90d617214086819a/hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/DefaultS3ClientFactory.java",
    "contents_url": "https://api.github.com/repos/apache/hadoop/contents/hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/DefaultS3ClientFactory.java?ref=23fe6f44281618c7fdef773b90d617214086819a",
    "patch": "@@ -22,9 +22,8 @@\n import java.net.URI;\n \n import com.amazonaws.ClientConfiguration;\n-import com.amazonaws.auth.AWSCredentialsProvider;\n import com.amazonaws.client.builder.AwsClientBuilder;\n-import com.amazonaws.metrics.RequestMetricCollector;\n+import com.amazonaws.handlers.RequestHandler2;\n import com.amazonaws.services.s3.AmazonS3;\n import com.amazonaws.services.s3.AmazonS3Client;\n import com.amazonaws.services.s3.AmazonS3ClientBuilder;\n@@ -41,27 +40,22 @@\n import org.apache.hadoop.classification.InterfaceStability;\n import org.apache.hadoop.conf.Configuration;\n import org.apache.hadoop.conf.Configured;\n-import org.apache.hadoop.fs.s3a.statistics.StatisticsFromAwsSdk;\n import org.apache.hadoop.fs.s3a.statistics.impl.AwsStatisticsCollector;\n \n import static org.apache.hadoop.fs.s3a.Constants.EXPERIMENTAL_AWS_INTERNAL_THROTTLING;\n-import static org.apache.hadoop.fs.s3a.Constants.ENDPOINT;\n import static org.apache.hadoop.fs.s3a.Constants.EXPERIMENTAL_AWS_INTERNAL_THROTTLING_DEFAULT;\n-import static org.apache.hadoop.fs.s3a.Constants.PATH_STYLE_ACCESS;\n \n /**\n  * The default {@link S3ClientFactory} implementation.\n  * This calls the AWS SDK to configure and create an\n- * {@link AmazonS3Client} that communicates with the S3 service.\n+ * {@code AmazonS3Client} that communicates with the S3 service.\n  */\n @InterfaceAudience.Private\n @InterfaceStability.Unstable\n public class DefaultS3ClientFactory extends Configured\n     implements S3ClientFactory {\n \n   private static final String S3_SERVICE_NAME = \"s3\";\n-  private static final String S3_SIGNER = \"S3SignerType\";\n-  private static final String S3_V4_SIGNER = \"AWSS3V4SignerType\";\n \n   /**\n    * Subclasses refer to this.\n@@ -70,22 +64,21 @@\n       LoggerFactory.getLogger(DefaultS3ClientFactory.class);\n \n   /**\n-   * Create the client.\n-   * <p>\n-   * If the AWS stats are not null then a {@link AwsStatisticsCollector}.\n-   * is created to bind to the two.\n-   * <i>Important: until this binding works properly across regions,\n-   * this should be null.</i>\n+   * Create the client by preparing the AwsConf configuration\n+   * and then invoking {@code buildAmazonS3Client()}.\n    */\n   @Override\n-  public AmazonS3 createS3Client(URI name,\n-      final String bucket,\n-      final AWSCredentialsProvider credentials,\n-      final String userAgentSuffix,\n-      final StatisticsFromAwsSdk statisticsFromAwsSdk) throws IOException {\n+  public AmazonS3 createS3Client(\n+      final URI uri,\n+      final S3ClientCreationParameters parameters) throws IOException {\n     Configuration conf = getConf();\n     final ClientConfiguration awsConf = S3AUtils\n-        .createAwsConf(conf, bucket, Constants.AWS_SERVICE_IDENTIFIER_S3);\n+        .createAwsConf(conf,\n+            uri.getHost(),\n+            Constants.AWS_SERVICE_IDENTIFIER_S3);\n+    // add any headers\n+    parameters.getHeaders().forEach((h, v) ->\n+        awsConf.addHeader(h, v));\n \n     // When EXPERIMENTAL_AWS_INTERNAL_THROTTLING is false\n     // throttling is explicitly disabled on the S3 client so that\n@@ -96,111 +89,62 @@ public AmazonS3 createS3Client(URI name,\n         conf.getBoolean(EXPERIMENTAL_AWS_INTERNAL_THROTTLING,\n             EXPERIMENTAL_AWS_INTERNAL_THROTTLING_DEFAULT));\n \n-    if (!StringUtils.isEmpty(userAgentSuffix)) {\n-      awsConf.setUserAgentSuffix(userAgentSuffix);\n+    if (!StringUtils.isEmpty(parameters.getUserAgentSuffix())) {\n+      awsConf.setUserAgentSuffix(parameters.getUserAgentSuffix());\n     }\n-    // optional metrics\n-    RequestMetricCollector metrics = statisticsFromAwsSdk != null\n-        ? new AwsStatisticsCollector(statisticsFromAwsSdk)\n-        : null;\n \n-    return newAmazonS3Client(\n-        credentials,\n+    return buildAmazonS3Client(\n         awsConf,\n-        metrics,\n-        conf.getTrimmed(ENDPOINT, \"\"),\n-        conf.getBoolean(PATH_STYLE_ACCESS, false));\n-  }\n-\n-  /**\n-   * Create an {@link AmazonS3} client.\n-   * Override this to provide an extended version of the client\n-   * @param credentials credentials to use\n-   * @param awsConf  AWS configuration\n-   * @param metrics metrics collector or null\n-   * @param endpoint endpoint string; may be \"\"\n-   * @param pathStyleAccess enable path style access?\n-   * @return new AmazonS3 client\n-   */\n-  protected AmazonS3 newAmazonS3Client(\n-      final AWSCredentialsProvider credentials,\n-      final ClientConfiguration awsConf,\n-      final RequestMetricCollector metrics,\n-      final String endpoint,\n-      final boolean pathStyleAccess) {\n-    if (metrics != null) {\n-      LOG.debug(\"Building S3 client using the SDK builder API\");\n-      return buildAmazonS3Client(credentials, awsConf, metrics, endpoint,\n-          pathStyleAccess);\n-    } else {\n-      LOG.debug(\"Building S3 client using the SDK builder API\");\n-      return classicAmazonS3Client(credentials, awsConf, endpoint,\n-          pathStyleAccess);\n-    }\n+        parameters);\n   }\n \n   /**\n-   * Use the (newer) Builder SDK to create a an AWS S3 client.\n+   * Use the Builder API to create an AWS S3 client.\n    * <p>\n-   * This has a more complex endpoint configuration in a\n-   * way which does not yet work in this code in a way\n-   * which doesn't trigger regressions. So it is only used\n-   * when SDK metrics are supplied.\n-   * @param credentials credentials to use\n+   * This has a more complex endpoint configuration mechanism\n+   * which initially caused problems; the\n+   * {@code withForceGlobalBucketAccessEnabled(true)}\n+   * command is critical here.\n    * @param awsConf  AWS configuration\n-   * @param metrics metrics collector or null\n-   * @param endpoint endpoint string; may be \"\"\n-   * @param pathStyleAccess enable path style access?\n+   * @param parameters parameters\n    * @return new AmazonS3 client\n    */\n-  private AmazonS3 buildAmazonS3Client(\n-      final AWSCredentialsProvider credentials,\n+  protected AmazonS3 buildAmazonS3Client(\n       final ClientConfiguration awsConf,\n-      final RequestMetricCollector metrics,\n-      final String endpoint,\n-      final boolean pathStyleAccess) {\n+      final S3ClientCreationParameters parameters) {\n     AmazonS3ClientBuilder b = AmazonS3Client.builder();\n-    b.withCredentials(credentials);\n+    b.withCredentials(parameters.getCredentialSet());\n     b.withClientConfiguration(awsConf);\n-    b.withPathStyleAccessEnabled(pathStyleAccess);\n-    if (metrics != null) {\n-      b.withMetricsCollector(metrics);\n+    b.withPathStyleAccessEnabled(parameters.isPathStyleAccess());\n+\n+    if (parameters.getMetrics() != null) {\n+      b.withMetricsCollector(\n+          new AwsStatisticsCollector(parameters.getMetrics()));\n+    }\n+    if (parameters.getRequestHandlers() != null) {\n+      b.withRequestHandlers(\n+          parameters.getRequestHandlers().toArray(new RequestHandler2[0]));\n+    }\n+    if (parameters.getMonitoringListener() != null) {\n+      b.withMonitoringListener(parameters.getMonitoringListener());\n     }\n \n     // endpoint set up is a PITA\n-    //  client.setEndpoint(\"\") is no longer available\n     AwsClientBuilder.EndpointConfiguration epr\n-        = createEndpointConfiguration(endpoint, awsConf);\n+        = createEndpointConfiguration(parameters.getEndpoint(),\n+        awsConf);\n     if (epr != null) {\n       // an endpoint binding was constructed: use it.\n       b.withEndpointConfiguration(epr);\n+    } else {\n+      // no idea what the endpoint is, so tell the SDK\n+      // to work it out at the cost of an extra HEAD request\n+      b.withForceGlobalBucketAccessEnabled(true);\n     }\n     final AmazonS3 client = b.build();\n     return client;\n   }\n \n-  /**\n-   * Wrapper around constructor for {@link AmazonS3} client.\n-   * Override this to provide an extended version of the client.\n-   * <p>\n-   * This uses a deprecated constructor -it is currently\n-   * the only one which works for us.\n-   * @param credentials credentials to use\n-   * @param awsConf  AWS configuration\n-   * @param endpoint endpoint string; may be \"\"\n-   * @param pathStyleAccess enable path style access?\n-   * @return new AmazonS3 client\n-   */\n-  @SuppressWarnings(\"deprecation\")\n-  private AmazonS3 classicAmazonS3Client(\n-      AWSCredentialsProvider credentials,\n-      ClientConfiguration awsConf,\n-      final String endpoint,\n-      final boolean pathStyleAccess) {\n-    final AmazonS3 client = new AmazonS3Client(credentials, awsConf);\n-    return configureAmazonS3Client(client, endpoint, pathStyleAccess);\n-  }\n-\n   /**\n    * Configure classic S3 client.\n    * <p>\n@@ -226,31 +170,6 @@ protected static AmazonS3 configureAmazonS3Client(AmazonS3 s3,\n         throw new IllegalArgumentException(msg, e);\n       }\n     }\n-    return applyS3ClientOptions(s3, pathStyleAccess);\n-  }\n-\n-  /**\n-   * Perform any tuning of the {@code S3ClientOptions} settings based on\n-   * the Hadoop configuration.\n-   * This is different from the general AWS configuration creation as\n-   * it is unique to S3 connections.\n-   * <p>\n-   * The {@link Constants#PATH_STYLE_ACCESS} option enables path-style access\n-   * to S3 buckets if configured.  By default, the\n-   * behavior is to use virtual hosted-style access with URIs of the form\n-   * {@code http://bucketname.s3.amazonaws.com}\n-   * <p>\n-   * Enabling path-style access and a\n-   * region-specific endpoint switches the behavior to use URIs of the form\n-   * {@code http://s3-eu-west-1.amazonaws.com/bucketname}.\n-   * It is common to use this when connecting to private S3 servers, as it\n-   * avoids the need to play with DNS entries.\n-   * @param s3 S3 client\n-   * @param pathStyleAccess enable path style access?\n-   * @return the S3 client\n-   */\n-  protected static AmazonS3 applyS3ClientOptions(AmazonS3 s3,\n-      final boolean pathStyleAccess) {\n     if (pathStyleAccess) {\n       LOG.debug(\"Enabling path style access!\");\n       s3.setS3ClientOptions(S3ClientOptions.builder()"
  },
  {
    "sha": "c11581f1d5d788be7653493b77127d7e919fc047",
    "filename": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/InconsistentS3ClientFactory.java",
    "status": "modified",
    "additions": 11,
    "deletions": 19,
    "changes": 30,
    "blob_url": "https://github.com/apache/hadoop/blob/23fe6f44281618c7fdef773b90d617214086819a/hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/InconsistentS3ClientFactory.java",
    "raw_url": "https://github.com/apache/hadoop/raw/23fe6f44281618c7fdef773b90d617214086819a/hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/InconsistentS3ClientFactory.java",
    "contents_url": "https://api.github.com/repos/apache/hadoop/contents/hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/InconsistentS3ClientFactory.java?ref=23fe6f44281618c7fdef773b90d617214086819a",
    "patch": "@@ -19,8 +19,6 @@\n package org.apache.hadoop.fs.s3a;\n \n import com.amazonaws.ClientConfiguration;\n-import com.amazonaws.auth.AWSCredentialsProvider;\n-import com.amazonaws.metrics.RequestMetricCollector;\n import com.amazonaws.services.s3.AmazonS3;\n \n import org.apache.hadoop.classification.InterfaceAudience;\n@@ -31,31 +29,25 @@\n  * This client is for testing <i>only</i>; it is in the production\n  * {@code hadoop-aws} module to enable integration tests to use this\n  * just by editing the Hadoop configuration used to bring up the client.\n+ *\n+ * The factory uses the older constructor-based instantiation/configuration\n+ * of the client, so does not wire up metrics, handlers etc.\n  */\n @InterfaceAudience.Private\n @InterfaceStability.Unstable\n public class InconsistentS3ClientFactory extends DefaultS3ClientFactory {\n \n-  /**\n-   * Create the inconsistent client.\n-   * Logs a warning that this is being done.\n-   * @param credentials credentials to use\n-   * @param awsConf  AWS configuration\n-   * @param metrics metric collector\n-   * @param endpoint AWS endpoint\n-   * @param pathStyleAccess should path style access be supported?\n-   * @return an inconsistent client.\n-   */\n   @Override\n-  protected AmazonS3 newAmazonS3Client(AWSCredentialsProvider credentials,\n-      ClientConfiguration awsConf,\n-      final RequestMetricCollector metrics,\n-      final String endpoint,\n-      final boolean pathStyleAccess) {\n+  protected AmazonS3 buildAmazonS3Client(\n+      final ClientConfiguration awsConf,\n+      final S3ClientCreationParameters parameters) {\n     LOG.warn(\"** FAILURE INJECTION ENABLED.  Do not run in production! **\");\n     InconsistentAmazonS3Client s3\n-        = new InconsistentAmazonS3Client(credentials, awsConf, getConf());\n-    configureAmazonS3Client(s3, endpoint, pathStyleAccess);\n+        = new InconsistentAmazonS3Client(\n+            parameters.getCredentialSet(), awsConf, getConf());\n+    configureAmazonS3Client(s3,\n+        parameters.getEndpoint(),\n+        parameters.isPathStyleAccess());\n     return s3;\n   }\n }"
  },
  {
    "sha": "8db5d51def84eb70e8e3310ad0999b94fde73b57",
    "filename": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java",
    "status": "modified",
    "additions": 14,
    "deletions": 12,
    "changes": 26,
    "blob_url": "https://github.com/apache/hadoop/blob/23fe6f44281618c7fdef773b90d617214086819a/hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java",
    "raw_url": "https://github.com/apache/hadoop/raw/23fe6f44281618c7fdef773b90d617214086819a/hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java",
    "contents_url": "https://api.github.com/repos/apache/hadoop/contents/hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java?ref=23fe6f44281618c7fdef773b90d617214086819a",
    "patch": "@@ -69,7 +69,6 @@\n import com.amazonaws.services.s3.model.ObjectMetadata;\n import com.amazonaws.services.s3.model.PutObjectRequest;\n import com.amazonaws.services.s3.model.PutObjectResult;\n-\n import com.amazonaws.services.s3.model.SSEAwsKeyManagementParams;\n import com.amazonaws.services.s3.model.SSECustomerKey;\n import com.amazonaws.services.s3.model.UploadPartRequest;\n@@ -83,7 +82,6 @@\n import com.amazonaws.event.ProgressListener;\n import org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting;\n import org.apache.hadoop.thirdparty.com.google.common.base.Preconditions;\n-import org.apache.hadoop.thirdparty.com.google.common.util.concurrent.ListeningExecutorService;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n@@ -166,7 +164,6 @@\n import org.apache.hadoop.fs.s3a.statistics.BlockOutputStreamStatistics;\n import org.apache.hadoop.fs.s3a.statistics.CommitterStatistics;\n import org.apache.hadoop.fs.s3a.statistics.S3AStatisticsContext;\n-import org.apache.hadoop.fs.s3a.statistics.StatisticsFromAwsSdk;\n import org.apache.hadoop.fs.s3a.statistics.impl.BondedS3AStatisticsContext;\n import org.apache.hadoop.fs.s3native.S3xLoginHelper;\n import org.apache.hadoop.io.retry.RetryPolicies;\n@@ -198,7 +195,6 @@\n import static org.apache.hadoop.fs.s3a.impl.CallableSupplier.waitForCompletionIgnoringExceptions;\n import static org.apache.hadoop.fs.s3a.impl.ErrorTranslation.isObjectNotFound;\n import static org.apache.hadoop.fs.s3a.impl.ErrorTranslation.isUnknownBucket;\n-import static org.apache.hadoop.fs.s3a.impl.InternalConstants.AWS_SDK_METRICS_ENABLED;\n import static org.apache.hadoop.fs.s3a.impl.InternalConstants.SC_404;\n import static org.apache.hadoop.fs.s3a.impl.NetworkBinding.fixBucketRegion;\n import static org.apache.hadoop.fs.s3a.impl.NetworkBinding.logDnsLookup;\n@@ -376,6 +372,11 @@ public void initialize(URI name, Configuration originalConf)\n       LOG.debug(\"Initializing S3AFileSystem for {}\", bucket);\n       // clone the configuration into one with propagated bucket options\n       Configuration conf = propagateBucketOptions(originalConf, bucket);\n+      // fix up the classloader of the configuration to be whatever\n+      // classloader loaded this filesystem.\n+      // See: HADOOP-17372\n+      conf.setClassLoader(this.getClass().getClassLoader());\n+\n       // patch the Hadoop security providers\n       patchSecurityCredentialProviders(conf);\n       // look for delegation token support early.\n@@ -740,16 +741,17 @@ private void bindAWSClient(URI name, boolean dtEnabled) throws IOException {\n         S3_CLIENT_FACTORY_IMPL, DEFAULT_S3_CLIENT_FACTORY_IMPL,\n         S3ClientFactory.class);\n \n-    StatisticsFromAwsSdk awsStats = null;\n-    //  TODO: HADOOP-16830 when the S3 client building code works\n-    //   with different regions,\n-    //   then non-null stats can be passed in here.\n-    if (AWS_SDK_METRICS_ENABLED) {\n-      awsStats = statisticsContext.newStatisticsFromAwsSdk();\n-    }\n+    S3ClientFactory.S3ClientCreationParameters parameters = null;\n+    parameters = new S3ClientFactory.S3ClientCreationParameters()\n+        .withCredentialSet(credentials)\n+        .withEndpoint(conf.getTrimmed(ENDPOINT, DEFAULT_ENDPOINT))\n+        .withMetrics(statisticsContext.newStatisticsFromAwsSdk())\n+        .withPathStyleAccess(conf.getBoolean(PATH_STYLE_ACCESS, false))\n+        .withUserAgentSuffix(uaSuffix);\n \n     s3 = ReflectionUtils.newInstance(s3ClientFactoryClass, conf)\n-        .createS3Client(getUri(), bucket, credentials, uaSuffix, awsStats);\n+        .createS3Client(getUri(),\n+            parameters);\n   }\n \n   /**"
  },
  {
    "sha": "dbb39fb662408230115e84ec4e23c6a3d74499bd",
    "filename": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3ClientFactory.java",
    "status": "modified",
    "additions": 220,
    "deletions": 12,
    "changes": 232,
    "blob_url": "https://github.com/apache/hadoop/blob/23fe6f44281618c7fdef773b90d617214086819a/hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3ClientFactory.java",
    "raw_url": "https://github.com/apache/hadoop/raw/23fe6f44281618c7fdef773b90d617214086819a/hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3ClientFactory.java",
    "contents_url": "https://api.github.com/repos/apache/hadoop/contents/hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3ClientFactory.java?ref=23fe6f44281618c7fdef773b90d617214086819a",
    "patch": "@@ -18,38 +18,246 @@\n \n package org.apache.hadoop.fs.s3a;\n \n+import javax.annotation.Nullable;\n import java.io.IOException;\n import java.net.URI;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n \n import com.amazonaws.auth.AWSCredentialsProvider;\n+import com.amazonaws.handlers.RequestHandler2;\n+import com.amazonaws.monitoring.MonitoringListener;\n import com.amazonaws.services.s3.AmazonS3;\n \n import org.apache.hadoop.classification.InterfaceAudience;\n import org.apache.hadoop.classification.InterfaceStability;\n import org.apache.hadoop.fs.s3a.statistics.StatisticsFromAwsSdk;\n \n+import static org.apache.hadoop.fs.s3a.Constants.DEFAULT_ENDPOINT;\n+\n /**\n  * Factory for creation of {@link AmazonS3} client instances.\n+ * Important: HBase's HBoss module implements this interface in its\n+ * tests.\n+ * Take care when updating this interface to ensure that a client\n+ * implementing only the deprecated method will work.\n+ * See https://github.com/apache/hbase-filesystem\n+ *\n  */\n-@InterfaceAudience.Private\n-@InterfaceStability.Unstable\n+@InterfaceAudience.LimitedPrivate(\"HBoss\")\n+@InterfaceStability.Evolving\n public interface S3ClientFactory {\n \n   /**\n    * Creates a new {@link AmazonS3} client.\n    *\n-   * @param name raw input S3A file system URI\n-   * @param bucket Optional bucket to use to look up per-bucket proxy secrets\n-   * @param credentialSet credentials to use\n-   * @param userAgentSuffix optional suffix for the UA field.\n-   * @param statisticsFromAwsSdk binding for AWS stats - may be null\n+   * @param uri S3A file system URI\n+   * @param parameters parameter object\n    * @return S3 client\n    * @throws IOException IO problem\n    */\n-  AmazonS3 createS3Client(URI name,\n-      String bucket,\n-      AWSCredentialsProvider credentialSet,\n-      String userAgentSuffix,\n-      StatisticsFromAwsSdk statisticsFromAwsSdk) throws IOException;\n+  AmazonS3 createS3Client(URI uri,\n+      S3ClientCreationParameters parameters) throws IOException;\n+\n+  /**\n+   * Settings for the S3 Client.\n+   * Implemented as a class to pass in so that adding\n+   * new parameters does not break the binding of\n+   * external implementations of the factory.\n+   */\n+  final class S3ClientCreationParameters {\n+\n+    /**\n+     * Credentials.\n+     */\n+    private AWSCredentialsProvider credentialSet;\n+\n+    /**\n+     * Endpoint.\n+     */\n+    private String endpoint = DEFAULT_ENDPOINT;\n+\n+    /**\n+     * Custom Headers.\n+     */\n+    private final Map<String, String> headers = new HashMap<>();\n+\n+    /**\n+     * Monitoring listener.\n+     */\n+    private MonitoringListener monitoringListener;\n+\n+    /**\n+     * RequestMetricCollector metrics...if not-null will be wrapped\n+     * with an {@code AwsStatisticsCollector} and passed to\n+     * the client.\n+     */\n+    private StatisticsFromAwsSdk metrics;\n+\n+    /**\n+     * Use (deprecated) path style access.\n+     */\n+    private boolean pathStyleAccess;\n+\n+    /**\n+     * This is in the settings awaiting wiring up and testing.\n+     */\n+    private boolean requesterPays;\n+\n+    /**\n+     * Request handlers; used for auditing, X-Ray etc.\n+     */\n+    private List<RequestHandler2> requestHandlers;\n+\n+    /**\n+     * Suffix to UA.\n+     */\n+    private String userAgentSuffix = \"\";\n+\n+    public List<RequestHandler2> getRequestHandlers() {\n+      return requestHandlers;\n+    }\n+\n+    /**\n+     * List of request handlers.\n+     * @param handlers handler list.\n+     * @return this object\n+     */\n+    public S3ClientCreationParameters withRequestHandlers(\n+        @Nullable final List<RequestHandler2> handlers) {\n+      requestHandlers = handlers;\n+      return this;\n+    }\n+\n+    public MonitoringListener getMonitoringListener() {\n+      return monitoringListener;\n+    }\n+\n+    /**\n+     * listener for AWS monitoring events.\n+     * @param listener listener\n+     * @return this object\n+     */\n+    public S3ClientCreationParameters withMonitoringListener(\n+        @Nullable final MonitoringListener listener) {\n+      monitoringListener = listener;\n+      return this;\n+    }\n+\n+    public StatisticsFromAwsSdk getMetrics() {\n+      return metrics;\n+    }\n+\n+    /**\n+     * Metrics binding. This is the S3A-level\n+     * statistics interface, which will be wired\n+     * up to the AWS callbacks.\n+     * @param statistics statistics implementation\n+     * @return this object\n+     */\n+    public S3ClientCreationParameters withMetrics(\n+        @Nullable final StatisticsFromAwsSdk statistics) {\n+      metrics = statistics;\n+      return this;\n+    }\n+\n+    /**\n+     * Requester pays option. Not yet wired up.\n+     * @param value new value\n+     * @return the builder\n+     */\n+    public S3ClientCreationParameters withRequesterPays(\n+        final boolean value) {\n+      requesterPays = value;\n+      return this;\n+    }\n+\n+    public boolean isRequesterPays() {\n+      return requesterPays;\n+    }\n+\n+    public AWSCredentialsProvider getCredentialSet() {\n+      return credentialSet;\n+    }\n+\n+    /**\n+     * Set credentials.\n+     * @param value new value\n+     * @return the builder\n+     */\n+\n+    public S3ClientCreationParameters withCredentialSet(\n+        final AWSCredentialsProvider value) {\n+      credentialSet = value;\n+      return this;\n+    }\n+\n+    public String getUserAgentSuffix() {\n+      return userAgentSuffix;\n+    }\n+\n+    /**\n+     * Set UA suffix.\n+     * @param value new value\n+     * @return the builder\n+     */\n+\n+    public S3ClientCreationParameters withUserAgentSuffix(\n+        final String value) {\n+      userAgentSuffix = value;\n+      return this;\n+    }\n+\n+    public String getEndpoint() {\n+      return endpoint;\n+    }\n+\n+    /**\n+     * Set endpoint.\n+     * @param value new value\n+     * @return the builder\n+     */\n+\n+    public S3ClientCreationParameters withEndpoint(\n+        final String value) {\n+      endpoint = value;\n+      return this;\n+    }\n+\n+    public boolean isPathStyleAccess() {\n+      return pathStyleAccess;\n+    }\n+\n+    /**\n+     * Set path access option.\n+     * @param value new value\n+     * @return the builder\n+     */\n+    public S3ClientCreationParameters withPathStyleAccess(\n+        final boolean value) {\n+      pathStyleAccess = value;\n+      return this;\n+    }\n+\n+    /**\n+     * Add a custom header.\n+     * @param header header name\n+     * @param value new value\n+     * @return the builder\n+     */\n+    public S3ClientCreationParameters withHeader(\n+        String header, String value) {\n+      headers.put(header, value);\n+      return this;\n+    }\n \n+    /**\n+     * Get the map of headers.\n+     * @return (mutable) header map\n+     */\n+    public Map<String, String> getHeaders() {\n+      return headers;\n+    }\n+  }\n }"
  },
  {
    "sha": "a5ce1f68ad3fc339e974466ff4511dfdbf2a34ae",
    "filename": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/impl/InternalConstants.java",
    "status": "modified",
    "additions": 0,
    "deletions": 6,
    "changes": 6,
    "blob_url": "https://github.com/apache/hadoop/blob/23fe6f44281618c7fdef773b90d617214086819a/hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/impl/InternalConstants.java",
    "raw_url": "https://github.com/apache/hadoop/raw/23fe6f44281618c7fdef773b90d617214086819a/hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/impl/InternalConstants.java",
    "contents_url": "https://api.github.com/repos/apache/hadoop/contents/hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/impl/InternalConstants.java?ref=23fe6f44281618c7fdef773b90d617214086819a",
    "patch": "@@ -111,10 +111,4 @@ private InternalConstants() {\n    */\n   public static final int DEFAULT_UPLOAD_PART_COUNT_LIMIT = 10000;\n \n-  /**\n-   * Flag to enable AWS Statistics binding. As this is triggering\n-   * problems related to region/endpoint setup, it is currently\n-   * disabled.\n-   */\n-  public static final boolean AWS_SDK_METRICS_ENABLED = true;\n }"
  },
  {
    "sha": "bd121ba2728ebcfad372966fc41a5426e1c00f79",
    "filename": "hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/MockS3ClientFactory.java",
    "status": "modified",
    "additions": 3,
    "deletions": 8,
    "changes": 11,
    "blob_url": "https://github.com/apache/hadoop/blob/23fe6f44281618c7fdef773b90d617214086819a/hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/MockS3ClientFactory.java",
    "raw_url": "https://github.com/apache/hadoop/raw/23fe6f44281618c7fdef773b90d617214086819a/hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/MockS3ClientFactory.java",
    "contents_url": "https://api.github.com/repos/apache/hadoop/contents/hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/MockS3ClientFactory.java?ref=23fe6f44281618c7fdef773b90d617214086819a",
    "patch": "@@ -23,26 +23,21 @@\n import java.net.URI;\n import java.util.ArrayList;\n \n-import com.amazonaws.auth.AWSCredentialsProvider;\n import com.amazonaws.services.s3.AmazonS3;\n import com.amazonaws.services.s3.model.MultipartUploadListing;\n import com.amazonaws.services.s3.model.Region;\n \n-import org.apache.hadoop.fs.s3a.statistics.StatisticsFromAwsSdk;\n-\n /**\n  * An {@link S3ClientFactory} that returns Mockito mocks of the {@link AmazonS3}\n  * interface suitable for unit testing.\n  */\n public class MockS3ClientFactory implements S3ClientFactory {\n \n   @Override\n-  public AmazonS3 createS3Client(URI name,\n-      final String bucket,\n-      final AWSCredentialsProvider credentialSet,\n-      final String userAgentSuffix,\n-      final StatisticsFromAwsSdk statisticsFromAwsSdks) {\n+  public AmazonS3 createS3Client(URI uri,\n+      final S3ClientCreationParameters parameters) {\n     AmazonS3 s3 = mock(AmazonS3.class);\n+    String bucket = uri.getHost();\n     when(s3.doesBucketExist(bucket)).thenReturn(true);\n     when(s3.doesBucketExistV2(bucket)).thenReturn(true);\n     // this listing is used in startup if purging is enabled, so"
  },
  {
    "sha": "72af1752b12534729cdf5a1581f9e65b7a4237bf",
    "filename": "hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/auth/ITestCustomSigner.java",
    "status": "modified",
    "additions": 57,
    "deletions": 21,
    "changes": 78,
    "blob_url": "https://github.com/apache/hadoop/blob/23fe6f44281618c7fdef773b90d617214086819a/hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/auth/ITestCustomSigner.java",
    "raw_url": "https://github.com/apache/hadoop/raw/23fe6f44281618c7fdef773b90d617214086819a/hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/auth/ITestCustomSigner.java",
    "contents_url": "https://api.github.com/repos/apache/hadoop/contents/hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/auth/ITestCustomSigner.java?ref=23fe6f44281618c7fdef773b90d617214086819a",
    "patch": "@@ -23,12 +23,11 @@\n import java.util.HashMap;\n import java.util.Map;\n import java.util.Objects;\n+import java.util.concurrent.atomic.AtomicInteger;\n \n import com.amazonaws.SignableRequest;\n import com.amazonaws.auth.AWSCredentials;\n import com.amazonaws.auth.Signer;\n-import com.amazonaws.services.s3.AmazonS3;\n-import com.amazonaws.services.s3.AmazonS3ClientBuilder;\n import com.amazonaws.services.s3.internal.AWSS3V4Signer;\n import org.assertj.core.api.Assertions;\n import org.junit.Test;\n@@ -40,14 +39,15 @@\n import org.apache.hadoop.fs.FileSystem;\n import org.apache.hadoop.fs.Path;\n import org.apache.hadoop.fs.s3a.AbstractS3ATestBase;\n-import org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider;\n+import org.apache.hadoop.fs.s3a.Constants;\n+import org.apache.hadoop.fs.s3a.S3AFileSystem;\n import org.apache.hadoop.fs.s3a.auth.ITestCustomSigner.CustomSignerInitializer.StoreValue;\n import org.apache.hadoop.fs.s3a.auth.delegation.DelegationTokenProvider;\n import org.apache.hadoop.security.UserGroupInformation;\n \n import static org.apache.hadoop.fs.s3a.Constants.CUSTOM_SIGNERS;\n import static org.apache.hadoop.fs.s3a.Constants.SIGNING_ALGORITHM_S3;\n-import static org.apache.hadoop.fs.s3a.impl.NetworkBinding.fixBucketRegion;\n+import static org.apache.hadoop.fs.s3a.S3ATestUtils.disableFilesystemCaching;\n \n /**\n  * Tests for custom Signers and SignerInitializers.\n@@ -62,23 +62,32 @@\n \n   private String regionName;\n \n+  private String endpoint;\n+\n   @Override\n   public void setup() throws Exception {\n     super.setup();\n-    regionName = determineRegion(getFileSystem().getBucket());\n+    final S3AFileSystem fs = getFileSystem();\n+    regionName = determineRegion(fs.getBucket());\n     LOG.info(\"Determined region name to be [{}] for bucket [{}]\", regionName,\n-        getFileSystem().getBucket());\n+        fs.getBucket());\n+    endpoint = fs.getConf()\n+        .get(Constants.ENDPOINT, Constants.CENTRAL_ENDPOINT);\n+    LOG.info(\"Test endpoint is {}\", endpoint);\n   }\n \n   @Test\n   public void testCustomSignerAndInitializer()\n       throws IOException, InterruptedException {\n \n+    final Path basePath = path(getMethodName());\n     UserGroupInformation ugi1 = UserGroupInformation.createRemoteUser(\"user1\");\n-    FileSystem fs1 = runMkDirAndVerify(ugi1, \"/customsignerpath1\", \"id1\");\n+    FileSystem fs1 = runMkDirAndVerify(ugi1,\n+        new Path(basePath, \"customsignerpath1\"), \"id1\");\n \n     UserGroupInformation ugi2 = UserGroupInformation.createRemoteUser(\"user2\");\n-    FileSystem fs2 = runMkDirAndVerify(ugi2, \"/customsignerpath2\", \"id2\");\n+    FileSystem fs2 = runMkDirAndVerify(ugi2,\n+        new Path(basePath, \"customsignerpath2\"), \"id2\");\n \n     Assertions.assertThat(CustomSignerInitializer.knownStores.size())\n         .as(\"Num registered stores mismatch\").isEqualTo(2);\n@@ -91,20 +100,19 @@ public void testCustomSignerAndInitializer()\n   }\n \n   private FileSystem runMkDirAndVerify(UserGroupInformation ugi,\n-      String pathString, String identifier)\n+      Path finalPath, String identifier)\n       throws IOException, InterruptedException {\n     Configuration conf = createTestConfig(identifier);\n-    Path path = new Path(pathString);\n-    path = path.makeQualified(getFileSystem().getUri(),\n-        getFileSystem().getWorkingDirectory());\n-\n-    Path finalPath = path;\n     return ugi.doAs((PrivilegedExceptionAction<FileSystem>) () -> {\n-      int invocationCount = CustomSigner.invocationCount;\n+      int instantiationCount = CustomSigner.getInstantiationCount();\n+      int invocationCount = CustomSigner.getInvocationCount();\n       FileSystem fs = finalPath.getFileSystem(conf);\n       fs.mkdirs(finalPath);\n-      Assertions.assertThat(CustomSigner.invocationCount)\n-          .as(\"Invocation count lower than expected\")\n+      Assertions.assertThat(CustomSigner.getInstantiationCount())\n+          .as(\"CustomSigner Instantiation count lower than expected\")\n+          .isGreaterThan(instantiationCount);\n+      Assertions.assertThat(CustomSigner.getInvocationCount())\n+          .as(\"CustomSigner Invocation count lower than expected\")\n           .isGreaterThan(invocationCount);\n \n       Assertions.assertThat(CustomSigner.lastStoreValue)\n@@ -118,6 +126,12 @@ private FileSystem runMkDirAndVerify(UserGroupInformation ugi,\n     });\n   }\n \n+  /**\n+   * Create a test conf with the custom signer; fixes up\n+   * endpoint to be that of the test FS.\n+   * @param identifier test key.\n+   * @return a configuration for a filesystem.\n+   */\n   private Configuration createTestConfig(String identifier) {\n     Configuration conf = createConfiguration();\n \n@@ -128,24 +142,38 @@ private Configuration createTestConfig(String identifier) {\n \n     conf.set(TEST_ID_KEY, identifier);\n     conf.set(TEST_REGION_KEY, regionName);\n+    conf.set(Constants.ENDPOINT, endpoint);\n+    // make absolutely sure there is no caching.\n+    disableFilesystemCaching(conf);\n \n     return conf;\n   }\n \n   private String determineRegion(String bucketName) throws IOException {\n-    String region = getFileSystem().getBucketLocation(bucketName);\n-    return fixBucketRegion(region);\n+    return getFileSystem().getBucketLocation(bucketName);\n   }\n \n   @Private\n   public static final class CustomSigner implements Signer {\n \n-    private static int invocationCount = 0;\n+\n+    private static final AtomicInteger INSTANTIATION_COUNT =\n+        new AtomicInteger(0);\n+    private static final AtomicInteger INVOCATION_COUNT =\n+        new AtomicInteger(0);\n+\n     private static StoreValue lastStoreValue;\n \n+    public CustomSigner() {\n+      int c = INSTANTIATION_COUNT.incrementAndGet();\n+      LOG.info(\"Creating Signer #{}\", c);\n+    }\n+\n     @Override\n     public void sign(SignableRequest<?> request, AWSCredentials credentials) {\n-      invocationCount++;\n+      int c = INVOCATION_COUNT.incrementAndGet();\n+      LOG.info(\"Signing request #{}\", c);\n+\n       String host = request.getEndpoint().getHost();\n       String bucketName = host.split(\"\\\\.\")[0];\n       try {\n@@ -159,6 +187,14 @@ public void sign(SignableRequest<?> request, AWSCredentials credentials) {\n       realSigner.setRegionName(lastStoreValue.conf.get(TEST_REGION_KEY));\n       realSigner.sign(request, credentials);\n     }\n+\n+    public static int getInstantiationCount() {\n+      return INSTANTIATION_COUNT.get();\n+    }\n+\n+    public static int getInvocationCount() {\n+      return INVOCATION_COUNT.get();\n+    }\n   }\n \n   @Private"
  },
  {
    "sha": "26655de9d4417041941adfa486cf6afe74f79684",
    "filename": "hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/auth/delegation/ITestSessionDelegationInFileystem.java",
    "status": "modified",
    "additions": 11,
    "deletions": 13,
    "changes": 24,
    "blob_url": "https://github.com/apache/hadoop/blob/23fe6f44281618c7fdef773b90d617214086819a/hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/auth/delegation/ITestSessionDelegationInFileystem.java",
    "raw_url": "https://github.com/apache/hadoop/raw/23fe6f44281618c7fdef773b90d617214086819a/hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/auth/delegation/ITestSessionDelegationInFileystem.java",
    "contents_url": "https://api.github.com/repos/apache/hadoop/contents/hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/auth/delegation/ITestSessionDelegationInFileystem.java?ref=23fe6f44281618c7fdef773b90d617214086819a",
    "patch": "@@ -43,8 +43,8 @@\n import org.apache.hadoop.fs.s3a.S3AEncryptionMethods;\n import org.apache.hadoop.fs.s3a.S3AFileSystem;\n import org.apache.hadoop.fs.s3a.S3ATestUtils;\n+import org.apache.hadoop.fs.s3a.S3ClientFactory;\n import org.apache.hadoop.fs.s3a.Statistic;\n-import org.apache.hadoop.fs.s3a.statistics.StatisticsFromAwsSdk;\n import org.apache.hadoop.fs.s3a.statistics.impl.EmptyS3AStatisticsContext;\n import org.apache.hadoop.hdfs.tools.DelegationTokenFetcher;\n import org.apache.hadoop.io.Text;\n@@ -72,7 +72,6 @@\n import static org.apache.hadoop.fs.s3a.auth.delegation.MiniKerberizedHadoopCluster.ALICE;\n import static org.apache.hadoop.fs.s3a.auth.delegation.MiniKerberizedHadoopCluster.assertSecurityEnabled;\n import static org.apache.hadoop.fs.s3a.auth.delegation.S3ADelegationTokens.lookupS3ADelegationToken;\n-import static org.apache.hadoop.fs.s3a.impl.InternalConstants.AWS_SDK_METRICS_ENABLED;\n import static org.apache.hadoop.test.LambdaTestUtils.doAs;\n import static org.apache.hadoop.test.LambdaTestUtils.intercept;\n import static org.hamcrest.Matchers.containsString;\n@@ -557,23 +556,22 @@ public void testDelegationBindingMismatch2() throws Throwable {\n    */\n   protected ObjectMetadata readLandsatMetadata(final S3AFileSystem delegatedFS)\n       throws Exception {\n-    AWSCredentialProviderList testing\n+    AWSCredentialProviderList testingCreds\n         = delegatedFS.shareCredentials(\"testing\");\n \n     URI landsat = new URI(DEFAULT_CSVTEST_FILE);\n     DefaultS3ClientFactory factory\n         = new DefaultS3ClientFactory();\n-    Configuration conf = new Configuration(delegatedFS.getConf());\n-    conf.set(ENDPOINT, \"\");\n-    factory.setConf(conf);\n+    factory.setConf(new Configuration(delegatedFS.getConf()));\n     String host = landsat.getHost();\n-    StatisticsFromAwsSdk awsStats = null;\n-    if (AWS_SDK_METRICS_ENABLED) {\n-      awsStats = new EmptyS3AStatisticsContext()\n-          .newStatisticsFromAwsSdk();\n-    }\n-    AmazonS3 s3 = factory.createS3Client(landsat, host, testing,\n-        \"ITestSessionDelegationInFileystem\", awsStats);\n+    S3ClientFactory.S3ClientCreationParameters parameters = null;\n+    parameters = new S3ClientFactory.S3ClientCreationParameters()\n+        .withCredentialSet(testingCreds)\n+        .withEndpoint(DEFAULT_ENDPOINT)\n+        .withMetrics(new EmptyS3AStatisticsContext()\n+            .newStatisticsFromAwsSdk())\n+        .withUserAgentSuffix(\"ITestSessionDelegationInFileystem\");\n+    AmazonS3 s3 = factory.createS3Client(landsat, parameters);\n \n     return Invoker.once(\"HEAD\", host,\n         () -> s3.getObjectMetadata(host, landsat.getPath().substring(1)));"
  },
  {
    "sha": "4d7f81d019b748f74b4bc63566634bb39a74b0aa",
    "filename": "hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/commit/ITestCommitOperations.java",
    "status": "modified",
    "additions": 1,
    "deletions": 0,
    "changes": 1,
    "blob_url": "https://github.com/apache/hadoop/blob/23fe6f44281618c7fdef773b90d617214086819a/hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/commit/ITestCommitOperations.java",
    "raw_url": "https://github.com/apache/hadoop/raw/23fe6f44281618c7fdef773b90d617214086819a/hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/commit/ITestCommitOperations.java",
    "contents_url": "https://api.github.com/repos/apache/hadoop/contents/hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/commit/ITestCommitOperations.java?ref=23fe6f44281618c7fdef773b90d617214086819a",
    "patch": "@@ -175,6 +175,7 @@ public void testCreateAbortEmptyFile() throws Throwable {\n     Path destFile = methodPath(filename);\n     Path pendingFilePath = makeMagic(destFile);\n     touch(fs, pendingFilePath);\n+    waitForConsistency();\n     validateIntermediateAndFinalPaths(pendingFilePath, destFile);\n     Path pendingDataPath = validatePendingCommitData(filename,\n         pendingFilePath);"
  },
  {
    "sha": "e7696996dbd1a8eb943c114582455345f850e354",
    "filename": "hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/statistics/ITestAWSStatisticCollection.java",
    "status": "added",
    "additions": 82,
    "deletions": 0,
    "changes": 82,
    "blob_url": "https://github.com/apache/hadoop/blob/23fe6f44281618c7fdef773b90d617214086819a/hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/statistics/ITestAWSStatisticCollection.java",
    "raw_url": "https://github.com/apache/hadoop/raw/23fe6f44281618c7fdef773b90d617214086819a/hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/statistics/ITestAWSStatisticCollection.java",
    "contents_url": "https://api.github.com/repos/apache/hadoop/contents/hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/statistics/ITestAWSStatisticCollection.java?ref=23fe6f44281618c7fdef773b90d617214086819a",
    "patch": "@@ -0,0 +1,82 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.s3a.statistics;\n+\n+import org.junit.Test;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.s3a.AbstractS3ATestBase;\n+import org.apache.hadoop.fs.s3a.S3AFileSystem;\n+import org.apache.hadoop.fs.statistics.IOStatistics;\n+\n+import static org.apache.hadoop.fs.s3a.Constants.DEFAULT_ENDPOINT;\n+import static org.apache.hadoop.fs.s3a.Constants.ENDPOINT;\n+import static org.apache.hadoop.fs.s3a.S3ATestUtils.getLandsatCSVPath;\n+import static org.apache.hadoop.fs.s3a.Statistic.STORE_IO_REQUEST;\n+import static org.apache.hadoop.fs.statistics.IOStatisticAssertions.assertThatStatisticCounter;\n+\n+/**\n+ * Verify that AWS SDK statistics are wired up.\n+ * This test tries to read data from US-east-1 and us-west-2 buckets\n+ * so as to be confident that the nuances of region mapping\n+ * are handed correctly (HADOOP-13551).\n+ * The statistics are probed to verify that the wiring up is complete.\n+ */\n+public class ITestAWSStatisticCollection extends AbstractS3ATestBase {\n+\n+  private static final Path COMMON_CRAWL_PATH\n+      = new Path(\"s3a://osm-pds/planet/planet-latest.orc\");\n+\n+  @Test\n+  public void testLandsatStatistics() throws Throwable {\n+    final Configuration conf = getConfiguration();\n+    // skips the tests if the landsat path isn't the default.\n+    Path path = getLandsatCSVPath(conf);\n+    conf.set(ENDPOINT, DEFAULT_ENDPOINT);\n+    conf.unset(\"fs.s3a.bucket.landsat-pds.endpoint\");\n+\n+    try (S3AFileSystem fs = (S3AFileSystem) path.getFileSystem(conf)) {\n+      fs.getObjectMetadata(path);\n+      IOStatistics iostats = fs.getIOStatistics();\n+      assertThatStatisticCounter(iostats,\n+          STORE_IO_REQUEST.getSymbol())\n+          .isGreaterThanOrEqualTo(1);\n+    }\n+  }\n+\n+  @Test\n+  public void testCommonCrawlStatistics() throws Throwable {\n+    final Configuration conf = getConfiguration();\n+    // skips the tests if the landsat path isn't the default.\n+    getLandsatCSVPath(conf);\n+\n+    Path path = COMMON_CRAWL_PATH;\n+    conf.set(ENDPOINT, DEFAULT_ENDPOINT);\n+\n+    try (S3AFileSystem fs = (S3AFileSystem) path.getFileSystem(conf)) {\n+      fs.getObjectMetadata(path);\n+      IOStatistics iostats = fs.getIOStatistics();\n+      assertThatStatisticCounter(iostats,\n+          STORE_IO_REQUEST.getSymbol())\n+          .isGreaterThanOrEqualTo(1);\n+    }\n+  }\n+\n+}"
  }
]
