[
  {
    "sha": "0587193d8fef24878e34cebff8affb201dec7251",
    "filename": "processing/src/main/java/org/apache/druid/query/groupby/strategy/GroupByStrategyV2.java",
    "status": "modified",
    "additions": 20,
    "deletions": 7,
    "changes": 27,
    "blob_url": "https://github.com/apache/druid/blob/4745f52ee8d0f6fac4e8c3efdce194b724469cf6/processing/src/main/java/org/apache/druid/query/groupby/strategy/GroupByStrategyV2.java",
    "raw_url": "https://github.com/apache/druid/raw/4745f52ee8d0f6fac4e8c3efdce194b724469cf6/processing/src/main/java/org/apache/druid/query/groupby/strategy/GroupByStrategyV2.java",
    "contents_url": "https://api.github.com/repos/apache/druid/contents/processing/src/main/java/org/apache/druid/query/groupby/strategy/GroupByStrategyV2.java?ref=4745f52ee8d0f6fac4e8c3efdce194b724469cf6",
    "patch": "@@ -116,8 +116,7 @@ public GroupByStrategyV2(\n   @Override\n   public GroupByQueryResource prepareResource(GroupByQuery query)\n   {\n-    final int requiredMergeBufferNum = countRequiredMergeBufferNum(query, 1) +\n-                                       numMergeBuffersNeededForSubtotalsSpec(query);\n+    final int requiredMergeBufferNum = countRequiredMergeBufferNum(query);\n \n     if (requiredMergeBufferNum > mergeBufferPool.maxSize()) {\n       throw new ResourceLimitExceededException(\n@@ -146,7 +145,12 @@ public GroupByQueryResource prepareResource(GroupByQuery query)\n     }\n   }\n \n-  private static int countRequiredMergeBufferNum(Query query, int foundNum)\n+  public static int countRequiredMergeBufferNum(GroupByQuery query)\n+  {\n+    return countRequiredMergeBufferNumWithoutSubtotal(query, 1) + numMergeBuffersNeededForSubtotalsSpec(query);\n+  }\n+\n+  private static int countRequiredMergeBufferNumWithoutSubtotal(Query query, int foundNum)\n   {\n     // Note: A broker requires merge buffers for processing the groupBy layers beyond the inner-most one.\n     // For example, the number of required merge buffers for a nested groupBy (groupBy -> groupBy -> table) is 1.\n@@ -159,7 +163,7 @@ private static int countRequiredMergeBufferNum(Query query, int foundNum)\n     if (foundNum == MAX_MERGE_BUFFER_NUM + 1 || !(dataSource instanceof QueryDataSource)) {\n       return foundNum - 1;\n     } else {\n-      return countRequiredMergeBufferNum(((QueryDataSource) dataSource).getQuery(), foundNum + 1);\n+      return countRequiredMergeBufferNumWithoutSubtotal(((QueryDataSource) dataSource).getQuery(), foundNum + 1);\n     }\n   }\n \n@@ -522,11 +526,20 @@ public boolean doMergeResults(final GroupByQuery query)\n     return aggsAndPostAggs;\n   }\n \n-  private int numMergeBuffersNeededForSubtotalsSpec(GroupByQuery query)\n+  private static int numMergeBuffersNeededForSubtotalsSpec(GroupByQuery query)\n   {\n     List<List<String>> subtotalSpecs = query.getSubtotalsSpec();\n+    final DataSource dataSource = query.getDataSource();\n+    int numMergeBuffersNeededForSubQuerySubtotal = 0;\n+    if (dataSource instanceof QueryDataSource) {\n+      Query<?> subQuery = ((QueryDataSource) dataSource).getQuery();\n+      if (subQuery instanceof GroupByQuery) {\n+        numMergeBuffersNeededForSubQuerySubtotal = numMergeBuffersNeededForSubtotalsSpec((GroupByQuery) subQuery);\n+      }\n+\n+    }\n     if (subtotalSpecs == null || subtotalSpecs.size() == 0) {\n-      return 0;\n+      return numMergeBuffersNeededForSubQuerySubtotal;\n     }\n \n     List<String> queryDimOutputNames = query.getDimensions().stream().map(DimensionSpec::getOutputName).collect(\n@@ -537,7 +550,7 @@ private int numMergeBuffersNeededForSubtotalsSpec(GroupByQuery query)\n       }\n     }\n \n-    return 1;\n+    return Math.max(1, numMergeBuffersNeededForSubQuerySubtotal);\n   }\n \n   @Override"
  },
  {
    "sha": "ae0c269adf6bfe11895a930a1f9b6aa5cd9055e3",
    "filename": "server/src/test/java/org/apache/druid/query/QueryRunnerBasedOnClusteredClientTestBase.java",
    "status": "modified",
    "additions": 4,
    "deletions": 1,
    "changes": 5,
    "blob_url": "https://github.com/apache/druid/blob/4745f52ee8d0f6fac4e8c3efdce194b724469cf6/server/src/test/java/org/apache/druid/query/QueryRunnerBasedOnClusteredClientTestBase.java",
    "raw_url": "https://github.com/apache/druid/raw/4745f52ee8d0f6fac4e8c3efdce194b724469cf6/server/src/test/java/org/apache/druid/query/QueryRunnerBasedOnClusteredClientTestBase.java",
    "contents_url": "https://api.github.com/repos/apache/druid/contents/server/src/test/java/org/apache/druid/query/QueryRunnerBasedOnClusteredClientTestBase.java?ref=4745f52ee8d0f6fac4e8c3efdce194b724469cf6",
    "patch": "@@ -139,7 +139,10 @@ public void setupTestBase()\n         new ForegroundCachePopulator(objectMapper, new CachePopulatorStats(), 0),\n         new CacheConfig(),\n         new DruidHttpClientConfig(),\n-        QueryStackTests.getProcessingConfig(USE_PARALLEL_MERGE_POOL_CONFIGURED),\n+        QueryStackTests.getProcessingConfig(\n+            USE_PARALLEL_MERGE_POOL_CONFIGURED,\n+            DruidProcessingConfig.DEFAULT_NUM_MERGE_BUFFERS\n+        ),\n         ForkJoinPool.commonPool(),\n         QueryStackTests.DEFAULT_NOOP_SCHEDULER,\n         new MapJoinableFactory(ImmutableSet.of(), ImmutableMap.of())"
  },
  {
    "sha": "074649f26a612376f78f35872fb1e70a7e2e0b27",
    "filename": "server/src/test/java/org/apache/druid/server/QueryStackTests.java",
    "status": "modified",
    "additions": 15,
    "deletions": 5,
    "changes": 20,
    "blob_url": "https://github.com/apache/druid/blob/4745f52ee8d0f6fac4e8c3efdce194b724469cf6/server/src/test/java/org/apache/druid/server/QueryStackTests.java",
    "raw_url": "https://github.com/apache/druid/raw/4745f52ee8d0f6fac4e8c3efdce194b724469cf6/server/src/test/java/org/apache/druid/server/QueryStackTests.java",
    "contents_url": "https://api.github.com/repos/apache/druid/contents/server/src/test/java/org/apache/druid/server/QueryStackTests.java?ref=4745f52ee8d0f6fac4e8c3efdce194b724469cf6",
    "patch": "@@ -180,7 +180,10 @@ public static LocalQuerySegmentWalker createLocalQuerySegmentWalker(\n     );\n   }\n \n-  public static DruidProcessingConfig getProcessingConfig(boolean useParallelMergePoolConfigured)\n+  public static DruidProcessingConfig getProcessingConfig(\n+      boolean useParallelMergePoolConfigured,\n+      final int mergeBuffers\n+  )\n   {\n     return new DruidProcessingConfig()\n     {\n@@ -206,9 +209,10 @@ public int getNumThreads()\n       @Override\n       public int getNumMergeBuffers()\n       {\n-        // Need 3 buffers for CalciteQueryTest.testDoubleNestedGroupby.\n-        // Two buffers for the broker and one for the queryable.\n-        return 3;\n+        if (mergeBuffers == DEFAULT_NUM_MERGE_BUFFERS) {\n+          return 2;\n+        }\n+        return mergeBuffers;\n       }\n \n       @Override\n@@ -230,9 +234,15 @@ public static QueryRunnerFactoryConglomerate createQueryRunnerFactoryConglomerat\n   public static QueryRunnerFactoryConglomerate createQueryRunnerFactoryConglomerate(\n       final Closer closer,\n       final boolean useParallelMergePoolConfigured\n+\n   )\n   {\n-    return createQueryRunnerFactoryConglomerate(closer, getProcessingConfig(useParallelMergePoolConfigured));\n+    return createQueryRunnerFactoryConglomerate(closer,\n+                                                getProcessingConfig(\n+                                                    useParallelMergePoolConfigured,\n+                                                    DruidProcessingConfig.DEFAULT_NUM_MERGE_BUFFERS\n+                                                )\n+    );\n   }\n \n   public static QueryRunnerFactoryConglomerate createQueryRunnerFactoryConglomerate("
  },
  {
    "sha": "f8da5cbb0fb825e9d4c15d20de5f8e2eba9efbfa",
    "filename": "sql/src/main/java/org/apache/druid/sql/calcite/planner/PlannerConfig.java",
    "status": "modified",
    "additions": 14,
    "deletions": 0,
    "changes": 14,
    "blob_url": "https://github.com/apache/druid/blob/4745f52ee8d0f6fac4e8c3efdce194b724469cf6/sql/src/main/java/org/apache/druid/sql/calcite/planner/PlannerConfig.java",
    "raw_url": "https://github.com/apache/druid/raw/4745f52ee8d0f6fac4e8c3efdce194b724469cf6/sql/src/main/java/org/apache/druid/sql/calcite/planner/PlannerConfig.java",
    "contents_url": "https://api.github.com/repos/apache/druid/contents/sql/src/main/java/org/apache/druid/sql/calcite/planner/PlannerConfig.java?ref=4745f52ee8d0f6fac4e8c3efdce194b724469cf6",
    "patch": "@@ -30,6 +30,7 @@\n public class PlannerConfig\n {\n   public static final String CTX_KEY_USE_APPROXIMATE_COUNT_DISTINCT = \"useApproximateCountDistinct\";\n+  public static final String CTX_KEY_USE_GROUPING_SET_FOR_EXACT_DISTINCT = \"useGroupingSetForExactDistinct\";\n   public static final String CTX_KEY_USE_APPROXIMATE_TOPN = \"useApproximateTopN\";\n \n   @JsonProperty\n@@ -59,6 +60,9 @@\n   @JsonProperty\n   private long metadataSegmentPollPeriod = 60000;\n \n+  @JsonProperty\n+  private boolean useGroupingSetForExactDistinct = false;\n+\n   public long getMetadataSegmentPollPeriod()\n   {\n     return metadataSegmentPollPeriod;\n@@ -86,6 +90,11 @@ public boolean isUseApproximateCountDistinct()\n     return useApproximateCountDistinct;\n   }\n \n+  public boolean isUseGroupingSetForExactDistinct()\n+  {\n+    return useGroupingSetForExactDistinct;\n+  }\n+\n   public boolean isUseApproximateTopN()\n   {\n     return useApproximateTopN;\n@@ -125,6 +134,11 @@ public PlannerConfig withOverrides(final Map<String, Object> context)\n         CTX_KEY_USE_APPROXIMATE_COUNT_DISTINCT,\n         isUseApproximateCountDistinct()\n     );\n+    newConfig.useGroupingSetForExactDistinct = getContextBoolean(\n+        context,\n+        CTX_KEY_USE_GROUPING_SET_FOR_EXACT_DISTINCT,\n+        isUseGroupingSetForExactDistinct()\n+    );\n     newConfig.useApproximateTopN = getContextBoolean(\n         context,\n         CTX_KEY_USE_APPROXIMATE_TOPN,"
  },
  {
    "sha": "8425d55bc3078a2b7d7a52ba050f1cda34f5d2e0",
    "filename": "sql/src/main/java/org/apache/druid/sql/calcite/planner/Rules.java",
    "status": "modified",
    "additions": 5,
    "deletions": 3,
    "changes": 8,
    "blob_url": "https://github.com/apache/druid/blob/4745f52ee8d0f6fac4e8c3efdce194b724469cf6/sql/src/main/java/org/apache/druid/sql/calcite/planner/Rules.java",
    "raw_url": "https://github.com/apache/druid/raw/4745f52ee8d0f6fac4e8c3efdce194b724469cf6/sql/src/main/java/org/apache/druid/sql/calcite/planner/Rules.java",
    "contents_url": "https://api.github.com/repos/apache/druid/contents/sql/src/main/java/org/apache/druid/sql/calcite/planner/Rules.java?ref=4745f52ee8d0f6fac4e8c3efdce194b724469cf6",
    "patch": "@@ -268,9 +268,11 @@ private static Program buildHepProgram(Iterable<? extends RelOptRule> rules,\n     rules.addAll(ABSTRACT_RELATIONAL_RULES);\n \n     if (!plannerConfig.isUseApproximateCountDistinct()) {\n-      // For some reason, even though we support grouping sets, using AggregateExpandDistinctAggregatesRule.INSTANCE\n-      // here causes CalciteQueryTest#testExactCountDistinctWithGroupingAndOtherAggregators to fail.\n-      rules.add(AggregateExpandDistinctAggregatesRule.JOIN);\n+      if (plannerConfig.isUseGroupingSetForExactDistinct()) {\n+        rules.add(AggregateExpandDistinctAggregatesRule.INSTANCE);\n+      } else {\n+        rules.add(AggregateExpandDistinctAggregatesRule.JOIN);\n+      }\n     }\n \n     // Rules that we wrote."
  },
  {
    "sha": "8396d380043ceba5dbb2243b78912bb9a0663c13",
    "filename": "sql/src/test/java/org/apache/druid/sql/calcite/BaseCalciteQueryTest.java",
    "status": "modified",
    "additions": 12,
    "deletions": 0,
    "changes": 12,
    "blob_url": "https://github.com/apache/druid/blob/4745f52ee8d0f6fac4e8c3efdce194b724469cf6/sql/src/test/java/org/apache/druid/sql/calcite/BaseCalciteQueryTest.java",
    "raw_url": "https://github.com/apache/druid/raw/4745f52ee8d0f6fac4e8c3efdce194b724469cf6/sql/src/test/java/org/apache/druid/sql/calcite/BaseCalciteQueryTest.java",
    "contents_url": "https://api.github.com/repos/apache/druid/contents/sql/src/test/java/org/apache/druid/sql/calcite/BaseCalciteQueryTest.java?ref=4745f52ee8d0f6fac4e8c3efdce194b724469cf6",
    "patch": "@@ -891,4 +891,16 @@ protected void skipVectorize()\n     newContext.put(QueryContexts.SQL_JOIN_LEFT_SCAN_DIRECT, true);\n     return newContext;\n   }\n+\n+  /**\n+   * Reset the walker and conglomerate with required number of merge buffers. Default value is 2.\n+   */\n+  protected void requireMergeBuffers(int numMergeBuffers) throws IOException\n+  {\n+    conglomerate = QueryStackTests.createQueryRunnerFactoryConglomerate(\n+        resourceCloser,\n+        QueryStackTests.getProcessingConfig(true, numMergeBuffers)\n+    );\n+    walker = CalciteTests.createMockWalker(conglomerate, temporaryFolder.newFolder());\n+  }\n }"
  },
  {
    "sha": "46c39915ff955d77152dae030887c3a10f4a9be0",
    "filename": "sql/src/test/java/org/apache/druid/sql/calcite/CalciteCorrelatedQueryTest.java",
    "status": "modified",
    "additions": 11,
    "deletions": 74,
    "changes": 85,
    "blob_url": "https://github.com/apache/druid/blob/4745f52ee8d0f6fac4e8c3efdce194b724469cf6/sql/src/test/java/org/apache/druid/sql/calcite/CalciteCorrelatedQueryTest.java",
    "raw_url": "https://github.com/apache/druid/raw/4745f52ee8d0f6fac4e8c3efdce194b724469cf6/sql/src/test/java/org/apache/druid/sql/calcite/CalciteCorrelatedQueryTest.java",
    "contents_url": "https://api.github.com/repos/apache/druid/contents/sql/src/test/java/org/apache/druid/sql/calcite/CalciteCorrelatedQueryTest.java?ref=4745f52ee8d0f6fac4e8c3efdce194b724469cf6",
    "patch": "@@ -20,12 +20,8 @@\n package org.apache.druid.sql.calcite;\n \n import com.google.common.collect.ImmutableList;\n-import com.google.common.collect.ImmutableMap;\n import junitparams.JUnitParamsRunner;\n import junitparams.Parameters;\n-import org.apache.druid.data.input.InputRow;\n-import org.apache.druid.data.input.MapBasedInputRow;\n-import org.apache.druid.java.util.common.DateTimes;\n import org.apache.druid.java.util.common.Intervals;\n import org.apache.druid.java.util.common.granularity.AllGranularity;\n import org.apache.druid.query.QueryDataSource;\n@@ -42,58 +38,21 @@\n import org.apache.druid.query.dimension.DefaultDimensionSpec;\n import org.apache.druid.query.expression.TestExprMacroTable;\n import org.apache.druid.query.groupby.GroupByQuery;\n-import org.apache.druid.segment.IndexBuilder;\n-import org.apache.druid.segment.QueryableIndex;\n import org.apache.druid.segment.column.ValueType;\n-import org.apache.druid.segment.incremental.IncrementalIndexSchema;\n import org.apache.druid.segment.join.JoinType;\n import org.apache.druid.segment.virtual.ExpressionVirtualColumn;\n-import org.apache.druid.segment.writeout.OffHeapMemorySegmentWriteOutMediumFactory;\n import org.apache.druid.sql.calcite.expression.DruidExpression;\n-import org.apache.druid.timeline.DataSegment;\n-import org.apache.druid.timeline.partition.LinearShardSpec;\n-import org.junit.Before;\n+import org.apache.druid.sql.calcite.util.CalciteTests;\n import org.junit.Test;\n import org.junit.runner.RunWith;\n \n-import java.io.File;\n import java.util.Arrays;\n import java.util.Collections;\n-import java.util.List;\n import java.util.Map;\n \n @RunWith(JUnitParamsRunner.class)\n public class CalciteCorrelatedQueryTest extends BaseCalciteQueryTest\n {\n-  private static final IncrementalIndexSchema INDEX_SCHEMA = new IncrementalIndexSchema.Builder()\n-      .withMetrics(\n-          new CountAggregatorFactory(\"cnt\")\n-      )\n-      .withRollup(false)\n-      .withMinTimestamp(DateTimes.of(\"2020-12-31\").getMillis())\n-      .build();\n-  private static final List<String> DIMENSIONS = ImmutableList.of(\"user\", \"country\", \"city\");\n-\n-  @Before\n-  public void setup() throws Exception\n-  {\n-    final QueryableIndex index1 = IndexBuilder\n-        .create()\n-        .tmpDir(new File(temporaryFolder.newFolder(), \"1\"))\n-        .segmentWriteOutMediumFactory(OffHeapMemorySegmentWriteOutMediumFactory.instance())\n-        .schema(INDEX_SCHEMA)\n-        .rows(getRawRows())\n-        .buildMMappedIndex();\n-    final DataSegment segment = DataSegment.builder()\n-                                           .dataSource(\"visits\")\n-                                           .interval(index1.getDataInterval())\n-                                           .version(\"1\")\n-                                           .shardSpec(new LinearShardSpec(0))\n-                                           .size(0)\n-                                           .build();\n-    walker.add(segment, index1);\n-\n-  }\n \n   @Test\n   @Parameters(source = QueryContextForJoinProvider.class)\n@@ -115,12 +74,12 @@ public void testCorrelatedSubquery(Map<String, Object> queryContext) throws Exce\n             GroupByQuery.builder()\n                         .setDataSource(\n                             join(\n-                                new TableDataSource(\"visits\"),\n+                                new TableDataSource(CalciteTests.USERVISITDATASOURCE),\n                                 new QueryDataSource(\n                                     GroupByQuery.builder()\n                                                 .setDataSource(\n                                                     GroupByQuery.builder()\n-                                                                .setDataSource(\"visits\")\n+                                                                .setDataSource(CalciteTests.USERVISITDATASOURCE)\n                                                                 .setQuerySegmentSpec(querySegmentSpec(Intervals.ETERNITY))\n                                                                 .setVirtualColumns(new ExpressionVirtualColumn(\n                                                                     \"v0\",\n@@ -222,12 +181,12 @@ public void testCorrelatedSubqueryWithLeftFilter(Map<String, Object> queryContex\n             GroupByQuery.builder()\n                         .setDataSource(\n                             join(\n-                                new TableDataSource(\"visits\"),\n+                                new TableDataSource(CalciteTests.USERVISITDATASOURCE),\n                                 new QueryDataSource(\n                                     GroupByQuery.builder()\n                                                 .setDataSource(\n                                                     GroupByQuery.builder()\n-                                                                .setDataSource(\"visits\")\n+                                                                .setDataSource(CalciteTests.USERVISITDATASOURCE)\n                                                                 .setQuerySegmentSpec(querySegmentSpec(Intervals.ETERNITY))\n                                                                 .setVirtualColumns(new ExpressionVirtualColumn(\n                                                                     \"v0\",\n@@ -304,7 +263,7 @@ public void testCorrelatedSubqueryWithLeftFilter_leftDirectAccessDisabled(Map<St\n             GroupByQuery.builder()\n                         .setDataSource(\n                             join(\n-                                new QueryDataSource(newScanQueryBuilder().dataSource(\"visits\")\n+                                new QueryDataSource(newScanQueryBuilder().dataSource(CalciteTests.USERVISITDATASOURCE)\n                                                                          .intervals(querySegmentSpec(Intervals.of(\n                                                                              \"2021-01-01T01:00:00.000Z/2021-01-02T23:59:59.001Z\")))\n                                                                          .filters(selector(\"city\", \"B\", null))\n@@ -314,7 +273,7 @@ public void testCorrelatedSubqueryWithLeftFilter_leftDirectAccessDisabled(Map<St\n                                     GroupByQuery.builder()\n                                                 .setDataSource(\n                                                     GroupByQuery.builder()\n-                                                                .setDataSource(\"visits\")\n+                                                                .setDataSource(CalciteTests.USERVISITDATASOURCE)\n                                                                 .setQuerySegmentSpec(querySegmentSpec(Intervals.ETERNITY))\n                                                                 .setVirtualColumns(new ExpressionVirtualColumn(\n                                                                     \"v0\",\n@@ -390,12 +349,12 @@ public void testCorrelatedSubqueryWithCorrelatedQueryFilter(Map<String, Object>\n             GroupByQuery.builder()\n                         .setDataSource(\n                             join(\n-                                new TableDataSource(\"visits\"),\n+                                new TableDataSource(CalciteTests.USERVISITDATASOURCE),\n                                 new QueryDataSource(\n                                     GroupByQuery.builder()\n                                                 .setDataSource(\n                                                     GroupByQuery.builder()\n-                                                                .setDataSource(\"visits\")\n+                                                                .setDataSource(CalciteTests.USERVISITDATASOURCE)\n                                                                 .setQuerySegmentSpec(querySegmentSpec(Intervals.ETERNITY))\n                                                                 .setVirtualColumns(new ExpressionVirtualColumn(\n                                                                     \"v0\",\n@@ -477,12 +436,12 @@ public void testCorrelatedSubqueryWithCorrelatedQueryFilter_Scan(Map<String, Obj\n             GroupByQuery.builder()\n                         .setDataSource(\n                             join(\n-                                new TableDataSource(\"visits\"),\n+                                new TableDataSource(CalciteTests.USERVISITDATASOURCE),\n                                 new QueryDataSource(\n                                     GroupByQuery.builder()\n                                                 .setDataSource(\n                                                     GroupByQuery.builder()\n-                                                                .setDataSource(\"visits\")\n+                                                                .setDataSource(CalciteTests.USERVISITDATASOURCE)\n                                                                 .setQuerySegmentSpec(querySegmentSpec(Intervals.ETERNITY))\n                                                                 .setVirtualColumns(new ExpressionVirtualColumn(\n                                                                     \"v0\",\n@@ -544,26 +503,4 @@ public void testCorrelatedSubqueryWithCorrelatedQueryFilter_Scan(Map<String, Obj\n     );\n   }\n \n-  private List<InputRow> getRawRows()\n-  {\n-    return ImmutableList.of(\n-        toRow(\"2021-01-01T01:00:00Z\", ImmutableMap.of(\"user\", \"alice\", \"country\", \"canada\", \"city\", \"A\")),\n-        toRow(\"2021-01-01T02:00:00Z\", ImmutableMap.of(\"user\", \"alice\", \"country\", \"canada\", \"city\", \"B\")),\n-        toRow(\"2021-01-01T03:00:00Z\", ImmutableMap.of(\"user\", \"bob\", \"country\", \"canada\", \"city\", \"A\")),\n-        toRow(\"2021-01-01T04:00:00Z\", ImmutableMap.of(\"user\", \"alice\", \"country\", \"India\", \"city\", \"Y\")),\n-        toRow(\"2021-01-02T01:00:00Z\", ImmutableMap.of(\"user\", \"alice\", \"country\", \"canada\", \"city\", \"A\")),\n-        toRow(\"2021-01-02T02:00:00Z\", ImmutableMap.of(\"user\", \"bob\", \"country\", \"canada\", \"city\", \"A\")),\n-        toRow(\"2021-01-02T03:00:00Z\", ImmutableMap.of(\"user\", \"foo\", \"country\", \"canada\", \"city\", \"B\")),\n-        toRow(\"2021-01-02T04:00:00Z\", ImmutableMap.of(\"user\", \"bar\", \"country\", \"canada\", \"city\", \"B\")),\n-        toRow(\"2021-01-02T05:00:00Z\", ImmutableMap.of(\"user\", \"alice\", \"country\", \"India\", \"city\", \"X\")),\n-        toRow(\"2021-01-02T06:00:00Z\", ImmutableMap.of(\"user\", \"bob\", \"country\", \"India\", \"city\", \"X\")),\n-        toRow(\"2021-01-02T07:00:00Z\", ImmutableMap.of(\"user\", \"foo\", \"country\", \"India\", \"city\", \"X\")),\n-        toRow(\"2021-01-03T01:00:00Z\", ImmutableMap.of(\"user\", \"foo\", \"country\", \"USA\", \"city\", \"M\"))\n-    );\n-  }\n-\n-  private MapBasedInputRow toRow(String time, Map<String, Object> event)\n-  {\n-    return new MapBasedInputRow(DateTimes.ISO_DATE_OPTIONAL_TIME.parse(time), DIMENSIONS, event);\n-  }\n }"
  },
  {
    "sha": "4cbd83a706f7407e9ba44e3e334eb212405c5af8",
    "filename": "sql/src/test/java/org/apache/druid/sql/calcite/CalciteQueryTest.java",
    "status": "modified",
    "additions": 73,
    "deletions": 0,
    "changes": 73,
    "blob_url": "https://github.com/apache/druid/blob/4745f52ee8d0f6fac4e8c3efdce194b724469cf6/sql/src/test/java/org/apache/druid/sql/calcite/CalciteQueryTest.java",
    "raw_url": "https://github.com/apache/druid/raw/4745f52ee8d0f6fac4e8c3efdce194b724469cf6/sql/src/test/java/org/apache/druid/sql/calcite/CalciteQueryTest.java",
    "contents_url": "https://api.github.com/repos/apache/druid/contents/sql/src/test/java/org/apache/druid/sql/calcite/CalciteQueryTest.java?ref=4745f52ee8d0f6fac4e8c3efdce194b724469cf6",
    "patch": "@@ -131,6 +131,8 @@\n import java.util.Map;\n import java.util.stream.Collectors;\n \n+import static org.apache.druid.sql.calcite.planner.PlannerConfig.CTX_KEY_USE_GROUPING_SET_FOR_EXACT_DISTINCT;\n+\n @RunWith(JUnitParamsRunner.class)\n public class CalciteQueryTest extends BaseCalciteQueryTest\n {\n@@ -877,6 +879,7 @@ public void testInformationSchemaTables() throws Exception\n             .add(new Object[]{\"druid\", CalciteTests.DATASOURCE3, \"TABLE\", \"NO\", \"NO\"})\n             .add(new Object[]{\"druid\", CalciteTests.SOME_DATASOURCE, \"TABLE\", \"NO\", \"NO\"})\n             .add(new Object[]{\"druid\", CalciteTests.SOMEXDATASOURCE, \"TABLE\", \"NO\", \"NO\"})\n+            .add(new Object[]{\"druid\", CalciteTests.USERVISITDATASOURCE, \"TABLE\", \"NO\", \"NO\"})\n             .add(new Object[]{\"INFORMATION_SCHEMA\", \"COLUMNS\", \"SYSTEM_TABLE\", \"NO\", \"NO\"})\n             .add(new Object[]{\"INFORMATION_SCHEMA\", \"SCHEMATA\", \"SYSTEM_TABLE\", \"NO\", \"NO\"})\n             .add(new Object[]{\"INFORMATION_SCHEMA\", \"TABLES\", \"SYSTEM_TABLE\", \"NO\", \"NO\"})\n@@ -912,6 +915,7 @@ public void testInformationSchemaTables() throws Exception\n             .add(new Object[]{\"druid\", CalciteTests.DATASOURCE3, \"TABLE\", \"NO\", \"NO\"})\n             .add(new Object[]{\"druid\", CalciteTests.SOME_DATASOURCE, \"TABLE\", \"NO\", \"NO\"})\n             .add(new Object[]{\"druid\", CalciteTests.SOMEXDATASOURCE, \"TABLE\", \"NO\", \"NO\"})\n+            .add(new Object[]{\"druid\", CalciteTests.USERVISITDATASOURCE, \"TABLE\", \"NO\", \"NO\"})\n             .add(new Object[]{\"INFORMATION_SCHEMA\", \"COLUMNS\", \"SYSTEM_TABLE\", \"NO\", \"NO\"})\n             .add(new Object[]{\"INFORMATION_SCHEMA\", \"SCHEMATA\", \"SYSTEM_TABLE\", \"NO\", \"NO\"})\n             .add(new Object[]{\"INFORMATION_SCHEMA\", \"TABLES\", \"SYSTEM_TABLE\", \"NO\", \"NO\"})\n@@ -7607,6 +7611,72 @@ public void testExactCountDistinctWithGroupingAndOtherAggregators() throws Excep\n     );\n   }\n \n+  @Test\n+  public void testMultipleExactCountDistinctWithGroupingAndOtherAggregators() throws Exception\n+  {\n+    requireMergeBuffers(4);\n+    testQuery(\n+        PLANNER_CONFIG_NO_HLL.withOverrides(ImmutableMap.of(CTX_KEY_USE_GROUPING_SET_FOR_EXACT_DISTINCT, \"true\")),\n+        \"SELECT FLOOR(__time to day), COUNT(distinct city), COUNT(distinct user) FROM druid.visits GROUP BY 1\",\n+        CalciteTests.REGULAR_USER_AUTH_RESULT,\n+        ImmutableList.of(\n+            GroupByQuery.builder()\n+                        .setDataSource(\n+                            new QueryDataSource(\n+                                GroupByQuery.builder()\n+                                            .setDataSource(CalciteTests.USERVISITDATASOURCE)\n+                                            .setInterval(querySegmentSpec(Filtration.eternity()))\n+                                            .setGranularity(Granularities.ALL)\n+                                            .setVirtualColumns(expressionVirtualColumn(\n+                                                \"v0\",\n+                                                \"timestamp_floor(\\\"__time\\\",'P1D',null,'UTC')\",\n+                                                ValueType.LONG\n+                                            ))\n+                                            .setDimensions(dimensions(\n+                                                new DefaultDimensionSpec(\"v0\", \"d0\", ValueType.LONG),\n+                                                new DefaultDimensionSpec(\"city\", \"d1\"),\n+                                                new DefaultDimensionSpec(\"user\", \"d2\")\n+                                            ))\n+                                            .setAggregatorSpecs(aggregators(new GroupingAggregatorFactory(\n+                                                \"a0\",\n+                                                Arrays.asList(\n+                                                    \"v0\",\n+                                                    \"city\",\n+                                                    \"user\"\n+                                                )\n+                                            )))\n+                                            .setSubtotalsSpec(ImmutableList.of(\n+                                                ImmutableList.of(\"d0\", \"d1\"),\n+                                                ImmutableList.of(\"d0\", \"d2\")\n+                                            ))\n+                                            .setContext(QUERY_CONTEXT_DEFAULT)\n+                                            .build()\n+                            )\n+                        )\n+                        .setInterval(querySegmentSpec(Filtration.eternity()))\n+                        .setGranularity(Granularities.ALL)\n+                        .setDimensions(dimensions(new DefaultDimensionSpec(\"d0\", \"_d0\", ValueType.LONG)))\n+                        .setAggregatorSpecs(aggregators(\n+                            new FilteredAggregatorFactory(\n+                                new CountAggregatorFactory(\"_a0\"),\n+                                and(not(selector(\"d1\", null, null)), selector(\"a0\", \"1\", null))\n+                            ),\n+                            new FilteredAggregatorFactory(\n+                                new CountAggregatorFactory(\"_a1\"),\n+                                and(not(selector(\"d2\", null, null)), selector(\"a0\", \"2\", null))\n+                            )\n+                        ))\n+                        .setContext(QUERY_CONTEXT_DEFAULT)\n+                        .build()\n+        ),\n+        ImmutableList.of(\n+            new Object[]{1609459200000L, 3L, 2L},\n+            new Object[]{1609545600000L, 3L, 4L},\n+            new Object[]{1609632000000L, 1L, 1L}\n+        )\n+    );\n+  }\n+\n   @Test\n   public void testApproxCountDistinct() throws Exception\n   {\n@@ -7758,6 +7828,7 @@ public void testNestedGroupBy() throws Exception\n   @Test\n   public void testDoubleNestedGroupBy() throws Exception\n   {\n+    requireMergeBuffers(3);\n     testQuery(\n         \"SELECT SUM(cnt), COUNT(*) FROM (\\n\"\n         + \"  SELECT dim2, SUM(t1.cnt) cnt FROM (\\n\"\n@@ -12517,6 +12588,8 @@ public void testGroupingSets() throws Exception\n   @Test\n   public void testGroupingAggregatorDifferentOrder() throws Exception\n   {\n+    requireMergeBuffers(3);\n+\n     // Cannot vectorize due to virtual columns.\n     cannotVectorize();\n "
  },
  {
    "sha": "5a78f0f26bb60fc9a0dcfd2bba213c943520e77a",
    "filename": "sql/src/test/java/org/apache/druid/sql/calcite/util/CalciteTests.java",
    "status": "modified",
    "additions": 60,
    "deletions": 0,
    "changes": 60,
    "blob_url": "https://github.com/apache/druid/blob/4745f52ee8d0f6fac4e8c3efdce194b724469cf6/sql/src/test/java/org/apache/druid/sql/calcite/util/CalciteTests.java",
    "raw_url": "https://github.com/apache/druid/raw/4745f52ee8d0f6fac4e8c3efdce194b724469cf6/sql/src/test/java/org/apache/druid/sql/calcite/util/CalciteTests.java",
    "contents_url": "https://api.github.com/repos/apache/druid/contents/sql/src/test/java/org/apache/druid/sql/calcite/util/CalciteTests.java?ref=4745f52ee8d0f6fac4e8c3efdce194b724469cf6",
    "patch": "@@ -35,6 +35,7 @@\n import org.apache.druid.client.DruidServer;\n import org.apache.druid.client.ServerInventoryView;\n import org.apache.druid.data.input.InputRow;\n+import org.apache.druid.data.input.MapBasedInputRow;\n import org.apache.druid.data.input.impl.DimensionSchema;\n import org.apache.druid.data.input.impl.DimensionsSpec;\n import org.apache.druid.data.input.impl.DoubleDimensionSchema;\n@@ -160,6 +161,7 @@\n   public static final String SOME_DATASOURCE = \"some_datasource\";\n   public static final String SOME_DATSOURCE_ESCAPED = \"some\\\\_datasource\";\n   public static final String SOMEXDATASOURCE = \"somexdatasource\";\n+  public static final String USERVISITDATASOURCE = \"visits\";\n   public static final String DRUID_SCHEMA_NAME = \"druid\";\n   public static final String INFORMATION_SCHEMA_NAME = \"INFORMATION_SCHEMA\";\n   public static final String SYSTEM_SCHEMA_NAME = \"sys\";\n@@ -365,6 +367,15 @@ public AuthenticationResult createEscalatedAuthenticationResult()\n       .withRollup(false)\n       .build();\n \n+  private static final List<String> USER_VISIT_DIMS = ImmutableList.of(\"user\", \"country\", \"city\");\n+  private static final IncrementalIndexSchema INDEX_SCHEMA_USER_VISIT = new IncrementalIndexSchema.Builder()\n+      .withMetrics(\n+          new CountAggregatorFactory(\"cnt\")\n+      )\n+      .withRollup(false)\n+      .withMinTimestamp(DateTimes.of(\"2020-12-31\").getMillis())\n+      .build();\n+\n   public static final List<ImmutableMap<String, Object>> RAW_ROWS1 = ImmutableList.of(\n       ImmutableMap.<String, Object>builder()\n           .put(\"t\", \"2000-01-01\")\n@@ -647,6 +658,33 @@ public AuthenticationResult createEscalatedAuthenticationResult()\n       )\n   );\n \n+  private static List<InputRow> USER_VISIT_ROWS = ImmutableList.of(\n+      toRow(\n+          \"2021-01-01T01:00:00Z\",\n+          USER_VISIT_DIMS,\n+          ImmutableMap.of(\"user\", \"alice\", \"country\", \"canada\", \"city\", \"A\")\n+      ),\n+      toRow(\n+          \"2021-01-01T02:00:00Z\",\n+          USER_VISIT_DIMS,\n+          ImmutableMap.of(\"user\", \"alice\", \"country\", \"canada\", \"city\", \"B\")\n+      ),\n+      toRow(\"2021-01-01T03:00:00Z\", USER_VISIT_DIMS, ImmutableMap.of(\"user\", \"bob\", \"country\", \"canada\", \"city\", \"A\")),\n+      toRow(\"2021-01-01T04:00:00Z\", USER_VISIT_DIMS, ImmutableMap.of(\"user\", \"alice\", \"country\", \"India\", \"city\", \"Y\")),\n+      toRow(\n+          \"2021-01-02T01:00:00Z\",\n+          USER_VISIT_DIMS,\n+          ImmutableMap.of(\"user\", \"alice\", \"country\", \"canada\", \"city\", \"A\")\n+      ),\n+      toRow(\"2021-01-02T02:00:00Z\", USER_VISIT_DIMS, ImmutableMap.of(\"user\", \"bob\", \"country\", \"canada\", \"city\", \"A\")),\n+      toRow(\"2021-01-02T03:00:00Z\", USER_VISIT_DIMS, ImmutableMap.of(\"user\", \"foo\", \"country\", \"canada\", \"city\", \"B\")),\n+      toRow(\"2021-01-02T04:00:00Z\", USER_VISIT_DIMS, ImmutableMap.of(\"user\", \"bar\", \"country\", \"canada\", \"city\", \"B\")),\n+      toRow(\"2021-01-02T05:00:00Z\", USER_VISIT_DIMS, ImmutableMap.of(\"user\", \"alice\", \"country\", \"India\", \"city\", \"X\")),\n+      toRow(\"2021-01-02T06:00:00Z\", USER_VISIT_DIMS, ImmutableMap.of(\"user\", \"bob\", \"country\", \"India\", \"city\", \"X\")),\n+      toRow(\"2021-01-02T07:00:00Z\", USER_VISIT_DIMS, ImmutableMap.of(\"user\", \"foo\", \"country\", \"India\", \"city\", \"X\")),\n+      toRow(\"2021-01-03T01:00:00Z\", USER_VISIT_DIMS, ImmutableMap.of(\"user\", \"foo\", \"country\", \"USA\", \"city\", \"M\"))\n+  );\n+\n   private static final InlineDataSource JOINABLE_BACKING_DATA = InlineDataSource.fromIterable(\n       RAW_ROWS1_WITH_NUMERIC_DIMS.stream().map(x -> new Object[]{\n           x.get(\"dim1\"),\n@@ -856,6 +894,14 @@ public static SpecificSegmentsQuerySegmentWalker createMockWalker(\n         .rows(RAW_ROWS1_X)\n         .buildMMappedIndex();\n \n+    final QueryableIndex userVisitIndex = IndexBuilder\n+        .create()\n+        .tmpDir(new File(tmpDir, \"8\"))\n+        .segmentWriteOutMediumFactory(OffHeapMemorySegmentWriteOutMediumFactory.instance())\n+        .schema(INDEX_SCHEMA)\n+        .rows(USER_VISIT_ROWS)\n+        .buildMMappedIndex();\n+\n \n     return new SpecificSegmentsQuerySegmentWalker(\n         conglomerate,\n@@ -943,9 +989,23 @@ public static SpecificSegmentsQuerySegmentWalker createMockWalker(\n                    .size(0)\n                    .build(),\n         indexNumericDims\n+    ).add(\n+        DataSegment.builder()\n+                   .dataSource(USERVISITDATASOURCE)\n+                   .interval(userVisitIndex.getDataInterval())\n+                   .version(\"1\")\n+                   .shardSpec(new LinearShardSpec(0))\n+                   .size(0)\n+                   .build(),\n+        userVisitIndex\n     );\n   }\n \n+  private static MapBasedInputRow toRow(String time, List<String> dimensions, Map<String, Object> event)\n+  {\n+    return new MapBasedInputRow(DateTimes.ISO_DATE_OPTIONAL_TIME.parse(time), dimensions, event);\n+  }\n+\n   public static ExprMacroTable createExprMacroTable()\n   {\n     final List<ExprMacroTable.ExprMacro> exprMacros = new ArrayList<>();"
  }
]
