[
  {
    "sha": "5c5543eb1f68bcd0c75fe9d26aba864734336e08",
    "filename": "CONTRIBUTING.md",
    "status": "modified",
    "additions": 2,
    "deletions": 2,
    "changes": 4,
    "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e65612dfcba6c3ec0d0c25ba3d7a05d784664d83/CONTRIBUTING.md",
    "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e65612dfcba6c3ec0d0c25ba3d7a05d784664d83/CONTRIBUTING.md",
    "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/CONTRIBUTING.md?ref=e65612dfcba6c3ec0d0c25ba3d7a05d784664d83",
    "patch": "@@ -7,9 +7,9 @@ Start by forking the dolphinscheduler GitHub repository, make changes in a branc\n \n There are three branches in the remote repository currently:\n   - `master` : normal delivery branch. After the stable version is released, the code for the stable version branch is merged into the master branch.\n-            \n+\n   - `dev` : daily development branch. The daily development branch, the newly submitted code can pull requests to this branch.\n-  \n+\n   - `x.x.x-release` : the stable release version.\n \n So, you should fork the `dev` branch."
  },
  {
    "sha": "cfb26ef71f2dc3bcefd7ff6b01ce005a2c0bdc5a",
    "filename": "DISCLAIMER",
    "status": "modified",
    "additions": 3,
    "deletions": 3,
    "changes": 6,
    "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e65612dfcba6c3ec0d0c25ba3d7a05d784664d83/DISCLAIMER",
    "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e65612dfcba6c3ec0d0c25ba3d7a05d784664d83/DISCLAIMER",
    "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/DISCLAIMER?ref=e65612dfcba6c3ec0d0c25ba3d7a05d784664d83",
    "patch": "@@ -1,5 +1,5 @@\n Apache DolphinScheduler is an effort undergoing incubation at The Apache Software Foundation (ASF), sponsored by the Apache Incubator.\n-Incubation is required of all newly accepted projects until a further review indicates that the infrastructure, \n-communications, and decision making process have stabilized in a manner consistent with other successful ASF projects. \n-While incubation status is not necessarily a reflection of the completeness or stability of the code, \n+Incubation is required of all newly accepted projects until a further review indicates that the infrastructure,\n+communications, and decision making process have stabilized in a manner consistent with other successful ASF projects.\n+While incubation status is not necessarily a reflection of the completeness or stability of the code,\n it does indicate that the project has yet to be fully endorsed by the ASF."
  },
  {
    "sha": "8e4611d69597588d24170cff6bb8574eb07185ae",
    "filename": "README.md",
    "status": "modified",
    "additions": 1,
    "deletions": 1,
    "changes": 2,
    "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e65612dfcba6c3ec0d0c25ba3d7a05d784664d83/README.md",
    "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e65612dfcba6c3ec0d0c25ba3d7a05d784664d83/README.md",
    "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/README.md?ref=e65612dfcba6c3ec0d0c25ba3d7a05d784664d83",
    "patch": "@@ -15,7 +15,7 @@ Dolphin Scheduler Official Website\n \n ### Design Features:\n \n-DolphinScheduler is a distributed and extensible workflow scheduler platform with powerful DAG visual interfaces, dedicated to solving complex job dependencies in the data pipeline and providing various types of jobs available `out of the box`. \n+DolphinScheduler is a distributed and extensible workflow scheduler platform with powerful DAG visual interfaces, dedicated to solving complex job dependencies in the data pipeline and providing various types of jobs available `out of the box`.\n \n Its main objectives are as follows:\n "
  },
  {
    "sha": "d1ff9503a391b2ea300e8c62bb6eaf0a4ccbb347",
    "filename": "ambari_plugin/README.md",
    "status": "modified",
    "additions": 8,
    "deletions": 8,
    "changes": 16,
    "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e65612dfcba6c3ec0d0c25ba3d7a05d784664d83/ambari_plugin/README.md",
    "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e65612dfcba6c3ec0d0c25ba3d7a05d784664d83/ambari_plugin/README.md",
    "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/ambari_plugin/README.md?ref=e65612dfcba6c3ec0d0c25ba3d7a05d784664d83",
    "patch": "@@ -4,7 +4,7 @@\n \n 1. This document is intended for users with a basic understanding of Ambari\n 2. This document is a description of adding the Dolphin Scheduler service to the installed Ambari service\n-3. This document is based on version 2.5.2 of Ambari \n+3. This document is based on version 2.5.2 of Ambari\n \n ####   Installation preparation\n \n@@ -20,9 +20,9 @@\n       - Copy the prepared RPM packages to each node of the cluster.\n       - Execute with DS installation user: ```rpm -ivh apache-dolphinscheduler-incubating-xxx.noarch.rpm```\n       - Mysql-connector-java packaged using the default POM file will not be included.\n-      - The RPM package was packaged in the project with the installation path of /opt/soft. \n+      - The RPM package was packaged in the project with the installation path of /opt/soft.\n         If you use mysql as the database, you need add it manually.\n-      \n+\n    - Automatic installation with ambari\n       - Each node of the cluster needs to configure the local yum source\n       - Copy the prepared RPM packages to each node local yum source\n@@ -38,7 +38,7 @@\n    -- Create the database for the Dolphin Schedulerï¼šdolphinscheduler\n    CREATE DATABASE dolphinscheduler DEFAULT CHARACTER SET utf8 DEFAULT COLLATE\n    utf8_general_ci;\n-   \n+\n    -- Initialize the user and password for the dolphinscheduler database and assign permissions\n    -- Replace the {user} in the SQL statement below with the user of the dolphinscheduler database\n    GRANT ALL PRIVILEGES ON dolphinscheduler.* TO '{user}'@'%' IDENTIFIED BY '{password}';\n@@ -47,7 +47,7 @@\n    flush privileges;\n    ```\n \n- \n+\n \n #### Ambari Install Dolphin Scheduler\n - **NOTE: You have to install zookeeper first**\n@@ -71,7 +71,7 @@\n 5. System Env Optimization will export some system environment config. Modify according to actual situation\n \n    ![](https://github.com/apache/incubator-dolphinscheduler-website/blob/master/img/ambari-plugin/DS2_AMBARI_020.png)\n-   \n+\n 6. Configure the database information (same as in the initialization database in step 1)\n \n    ![](https://github.com/apache/incubator-dolphinscheduler-website/blob/master/img/ambari-plugin/DS2_AMBARI_005.png)\n@@ -89,8 +89,8 @@\n 9. The interface after successful installation\n \n    ![](https://github.com/apache/incubator-dolphinscheduler-website/blob/master/img/ambari-plugin/DS2_AMBARI_009.png)\n-   \n-   \n+\n+\n \n ------\n "
  },
  {
    "sha": "88fedda42dc06ec4ee5730546b02e9f94b6ae3e7",
    "filename": "ambari_plugin/common-services/DOLPHIN/1.3.0/package/alerts/alert_dolphin_scheduler_status.py",
    "status": "modified",
    "additions": 9,
    "deletions": 9,
    "changes": 18,
    "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e65612dfcba6c3ec0d0c25ba3d7a05d784664d83/ambari_plugin/common-services/DOLPHIN/1.3.0/package/alerts/alert_dolphin_scheduler_status.py",
    "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e65612dfcba6c3ec0d0c25ba3d7a05d784664d83/ambari_plugin/common-services/DOLPHIN/1.3.0/package/alerts/alert_dolphin_scheduler_status.py",
    "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/ambari_plugin/common-services/DOLPHIN/1.3.0/package/alerts/alert_dolphin_scheduler_status.py?ref=e65612dfcba6c3ec0d0c25ba3d7a05d784664d83",
    "patch": "@@ -35,13 +35,13 @@ def get_tokens():\n     \"\"\"\n     Returns a tuple of tokens in the format {{site/property}} that will be used\n     to build the dictionary passed into execute\n-    \n+\n     :rtype tuple\n     \"\"\"\n \n def get_info(url, connection_timeout):\n     response = None\n-    \n+\n     try:\n         response = urllib2.urlopen(url, timeout=connection_timeout)\n         json_data = response.read()\n@@ -57,24 +57,24 @@ def get_info(url, connection_timeout):\n def execute(configurations={}, parameters={}, host_name=None):\n     \"\"\"\n     Returns a tuple containing the result code and a pre-formatted result label\n-    \n+\n     Keyword arguments:\n     configurations : a mapping of configuration key to value\n     parameters : a mapping of script parameter key to value\n     host_name : the name of this host where the alert is running\n-    \n+\n     :type configurations dict\n     :type parameters dict\n     :type host_name str\n     \"\"\"\n-    \n+\n     alert_name = parameters['alertName']\n \n     dolphin_pidfile_dir = \"/opt/soft/run/dolphinscheduler\"\n \n     pid = \"0\"\n-    \n-    \n+\n+\n     from resource_management.core import sudo\n \n     is_running = True\n@@ -89,10 +89,10 @@ def execute(configurations={}, parameters={}, host_name=None):\n         pid_file_path = dolphin_pidfile_dir + \"/logger-server.pid\"\n     elif alert_name == 'DOLPHIN_API':\n         pid_file_path = dolphin_pidfile_dir + \"/api-server.pid\"\n-        \n+\n     if not pid_file_path or not os.path.isfile(pid_file_path):\n         is_running = False\n-        \n+\n     try:\n         pid = int(sudo.read_file(pid_file_path))\n     except:"
  },
  {
    "sha": "88fedda42dc06ec4ee5730546b02e9f94b6ae3e7",
    "filename": "ambari_plugin/common-services/DOLPHIN/1.3.3/package/alerts/alert_dolphin_scheduler_status.py",
    "status": "modified",
    "additions": 9,
    "deletions": 9,
    "changes": 18,
    "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e65612dfcba6c3ec0d0c25ba3d7a05d784664d83/ambari_plugin/common-services/DOLPHIN/1.3.3/package/alerts/alert_dolphin_scheduler_status.py",
    "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e65612dfcba6c3ec0d0c25ba3d7a05d784664d83/ambari_plugin/common-services/DOLPHIN/1.3.3/package/alerts/alert_dolphin_scheduler_status.py",
    "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/ambari_plugin/common-services/DOLPHIN/1.3.3/package/alerts/alert_dolphin_scheduler_status.py?ref=e65612dfcba6c3ec0d0c25ba3d7a05d784664d83",
    "patch": "@@ -35,13 +35,13 @@ def get_tokens():\n     \"\"\"\n     Returns a tuple of tokens in the format {{site/property}} that will be used\n     to build the dictionary passed into execute\n-    \n+\n     :rtype tuple\n     \"\"\"\n \n def get_info(url, connection_timeout):\n     response = None\n-    \n+\n     try:\n         response = urllib2.urlopen(url, timeout=connection_timeout)\n         json_data = response.read()\n@@ -57,24 +57,24 @@ def get_info(url, connection_timeout):\n def execute(configurations={}, parameters={}, host_name=None):\n     \"\"\"\n     Returns a tuple containing the result code and a pre-formatted result label\n-    \n+\n     Keyword arguments:\n     configurations : a mapping of configuration key to value\n     parameters : a mapping of script parameter key to value\n     host_name : the name of this host where the alert is running\n-    \n+\n     :type configurations dict\n     :type parameters dict\n     :type host_name str\n     \"\"\"\n-    \n+\n     alert_name = parameters['alertName']\n \n     dolphin_pidfile_dir = \"/opt/soft/run/dolphinscheduler\"\n \n     pid = \"0\"\n-    \n-    \n+\n+\n     from resource_management.core import sudo\n \n     is_running = True\n@@ -89,10 +89,10 @@ def execute(configurations={}, parameters={}, host_name=None):\n         pid_file_path = dolphin_pidfile_dir + \"/logger-server.pid\"\n     elif alert_name == 'DOLPHIN_API':\n         pid_file_path = dolphin_pidfile_dir + \"/api-server.pid\"\n-        \n+\n     if not pid_file_path or not os.path.isfile(pid_file_path):\n         is_running = False\n-        \n+\n     try:\n         pid = int(sudo.read_file(pid_file_path))\n     except:"
  },
  {
    "sha": "33c7467516e643c2800f1a051166e6f57edf9e24",
    "filename": "dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/dto/resources/visitor/ResourceTreeVisitor.java",
    "status": "modified",
    "additions": 1,
    "deletions": 1,
    "changes": 2,
    "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e65612dfcba6c3ec0d0c25ba3d7a05d784664d83/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/dto/resources/visitor/ResourceTreeVisitor.java",
    "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e65612dfcba6c3ec0d0c25ba3d7a05d784664d83/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/dto/resources/visitor/ResourceTreeVisitor.java",
    "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/dto/resources/visitor/ResourceTreeVisitor.java?ref=e65612dfcba6c3ec0d0c25ba3d7a05d784664d83",
    "patch": "@@ -118,7 +118,7 @@ private static ResourceComponent getResourceComponent(Resource resource) {\n         }else{\n             tempResourceComponent = new FileLeaf();\n         }\n-        \n+\n         tempResourceComponent.setName(resource.getAlias());\n         tempResourceComponent.setFullName(resource.getFullName().replaceFirst(\"/\",\"\"));\n         tempResourceComponent.setId(resource.getId());"
  },
  {
    "sha": "67d649395c7d7cf3ef077579a050fe9600190015",
    "filename": "dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/MonitorService.java",
    "status": "modified",
    "additions": 4,
    "deletions": 4,
    "changes": 8,
    "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e65612dfcba6c3ec0d0c25ba3d7a05d784664d83/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/MonitorService.java",
    "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e65612dfcba6c3ec0d0c25ba3d7a05d784664d83/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/MonitorService.java",
    "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/MonitorService.java?ref=e65612dfcba6c3ec0d0c25ba3d7a05d784664d83",
    "patch": "@@ -35,30 +35,30 @@\n      * @return data base state\n      */\n     Map<String,Object> queryDatabaseState(User loginUser);\n-    \n+\n     /**\n      * query master list\n      *\n      * @param loginUser login user\n      * @return master information list\n      */\n     Map<String,Object> queryMaster(User loginUser);\n-    \n+\n     /**\n      * query zookeeper state\n      *\n      * @param loginUser login user\n      * @return zookeeper information list\n      */\n     Map<String,Object> queryZookeeperState(User loginUser);\n-    \n+\n     /**\n      * query worker list\n      *\n      * @param loginUser login user\n      * @return worker information list\n      */\n     Map<String,Object> queryWorker(User loginUser);\n-    \n+\n     List<Server> getServerListFromZK(boolean isMaster);\n }"
  },
  {
    "sha": "bce1f8c3451b2f818219dc10bfa19b687ede6a18",
    "filename": "dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/DataAnalysisServiceImpl.java",
    "status": "modified",
    "additions": 1,
    "deletions": 1,
    "changes": 2,
    "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e65612dfcba6c3ec0d0c25ba3d7a05d784664d83/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/DataAnalysisServiceImpl.java",
    "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e65612dfcba6c3ec0d0c25ba3d7a05d784664d83/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/DataAnalysisServiceImpl.java",
    "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/DataAnalysisServiceImpl.java?ref=e65612dfcba6c3ec0d0c25ba3d7a05d784664d83",
    "patch": "@@ -274,7 +274,7 @@\n             return result;\n         }\n \n-        //TODO need to add detail data info \n+        //TODO need to add detail data info\n         Map<String, Integer> dataMap = new HashMap<>();\n         dataMap.put(\"taskQueue\", 0);\n         dataMap.put(\"taskKill\", 0);"
  },
  {
    "sha": "4d4b7348a5a40916ab778fde037314450cdafa84",
    "filename": "dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/utils/FourLetterWordMain.java",
    "status": "modified",
    "additions": 1,
    "deletions": 1,
    "changes": 2,
    "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e65612dfcba6c3ec0d0c25ba3d7a05d784664d83/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/utils/FourLetterWordMain.java",
    "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e65612dfcba6c3ec0d0c25ba3d7a05d784664d83/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/utils/FourLetterWordMain.java",
    "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/utils/FourLetterWordMain.java?ref=e65612dfcba6c3ec0d0c25ba3d7a05d784664d83",
    "patch": "@@ -68,7 +68,7 @@ public static String send4LetterWord(String host, int port, String cmd, int time\n         LOG.info(\"connecting to {} {}\", host, port);\n         InetSocketAddress hostaddress= host != null ? new InetSocketAddress(host, port) :\n                 new InetSocketAddress(InetAddress.getByName(null), port);\n-        \n+\n         try (Socket sock = new Socket()) {\n             sock.setSoTimeout(timeout);\n             sock.connect(hostaddress, timeout);"
  },
  {
    "sha": "fc2b4c1f43b023d9d07fe87f0deb73a76cc668f8",
    "filename": "dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/utils/ZooKeeperState.java",
    "status": "modified",
    "additions": 2,
    "deletions": 2,
    "changes": 4,
    "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e65612dfcba6c3ec0d0c25ba3d7a05d784664d83/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/utils/ZooKeeperState.java",
    "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e65612dfcba6c3ec0d0c25ba3d7a05d784664d83/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/utils/ZooKeeperState.java",
    "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/utils/ZooKeeperState.java?ref=e65612dfcba6c3ec0d0c25ba3d7a05d784664d83",
    "patch": "@@ -77,7 +77,7 @@ public void getZookeeperInfo() {\n \t\t\t\t\t\tnodeCount = Integer.parseInt(getStringValueFromLine(line));\n \t\t\t\t\t}\n \t\t\t\t}\n-\t\t\t} \t\n+\t\t\t}\n \t\t}\n \n \t\tString wchsText = cmd(\"wchs\");\n@@ -89,7 +89,7 @@ public void getZookeeperInfo() {\n \t\t\t\t\t\twatches = Integer.parseInt(getStringValueFromLine(line));\n \t\t\t\t\t}\n \t\t\t\t}\n-\t\t\t}\t\n+\t\t\t}\n \t\t}\n \n \t\tString consText = cmd(\"cons\");"
  },
  {
    "sha": "c58e5e3e44ab6b5cd2bdad813d73fb82d1f0bf57",
    "filename": "dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/utils/ZookeeperMonitor.java",
    "status": "modified",
    "additions": 1,
    "deletions": 1,
    "changes": 2,
    "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e65612dfcba6c3ec0d0c25ba3d7a05d784664d83/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/utils/ZookeeperMonitor.java",
    "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e65612dfcba6c3ec0d0c25ba3d7a05d784664d83/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/utils/ZookeeperMonitor.java",
    "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/utils/ZookeeperMonitor.java?ref=e65612dfcba6c3ec0d0c25ba3d7a05d784664d83",
    "patch": "@@ -74,7 +74,7 @@\n \n \t\tif(StringUtils.isNotBlank(zookeeperServers)){\n \t\t\tString[] zookeeperServersArray = zookeeperServers.split(\",\");\n-\t\t\t\n+\n \t\t\tfor (String zookeeperServer : zookeeperServersArray) {\n \t\t\t\tZooKeeperState state = new ZooKeeperState(zookeeperServer);\n \t\t\t\tboolean ok = state.ruok();"
  },
  {
    "sha": "5370453e74837f8dd86b4bd45d4000cd18cf0e9f",
    "filename": "dolphinscheduler-api/src/main/resources/i18n/messages.properties",
    "status": "modified",
    "additions": 56,
    "deletions": 56,
    "changes": 112,
    "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e65612dfcba6c3ec0d0c25ba3d7a05d784664d83/dolphinscheduler-api/src/main/resources/i18n/messages.properties",
    "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e65612dfcba6c3ec0d0c25ba3d7a05d784664d83/dolphinscheduler-api/src/main/resources/i18n/messages.properties",
    "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dolphinscheduler-api/src/main/resources/i18n/messages.properties?ref=e65612dfcba6c3ec0d0c25ba3d7a05d784664d83",
    "patch": "@@ -18,52 +18,52 @@\n QUERY_SCHEDULE_LIST_NOTES=query schedule list\n EXECUTE_PROCESS_TAG=execute process related operation\n PROCESS_INSTANCE_EXECUTOR_TAG=process instance executor related operation\n-RUN_PROCESS_INSTANCE_NOTES=run process instance \n+RUN_PROCESS_INSTANCE_NOTES=run process instance\n START_NODE_LIST=start node listï¼ˆnode nameï¼‰\n TASK_DEPEND_TYPE=task depend type\n COMMAND_TYPE=command type\n RUN_MODE=run mode\n TIMEOUT=timeout\n-EXECUTE_ACTION_TO_PROCESS_INSTANCE_NOTES=execute action to process instance \n+EXECUTE_ACTION_TO_PROCESS_INSTANCE_NOTES=execute action to process instance\n EXECUTE_TYPE=execute type\n-START_CHECK_PROCESS_DEFINITION_NOTES=start check process definition \n-GET_RECEIVER_CC_NOTES=query receiver cc \n+START_CHECK_PROCESS_DEFINITION_NOTES=start check process definition\n+GET_RECEIVER_CC_NOTES=query receiver cc\n DESC=description\n GROUP_NAME=group name\n GROUP_TYPE=group type\n-QUERY_ALERT_GROUP_LIST_NOTES=query alert group list \n-UPDATE_ALERT_GROUP_NOTES=update alert group \n-DELETE_ALERT_GROUP_BY_ID_NOTES=delete alert group by id \n-VERIFY_ALERT_GROUP_NAME_NOTES=verify alert group name, check alert group exist or not \n-GRANT_ALERT_GROUP_NOTES=grant alert group \n+QUERY_ALERT_GROUP_LIST_NOTES=query alert group list\n+UPDATE_ALERT_GROUP_NOTES=update alert group\n+DELETE_ALERT_GROUP_BY_ID_NOTES=delete alert group by id\n+VERIFY_ALERT_GROUP_NAME_NOTES=verify alert group name, check alert group exist or not\n+GRANT_ALERT_GROUP_NOTES=grant alert group\n USER_IDS=user id list\n ALERT_GROUP_TAG=alert group related operation\n ALERT_PLUGIN_INSTANCE_TAG=alert plugin instance related operation\n UPDATE_ALERT_PLUGIN_INSTANCE_NOTES=update alert plugin instance operation\n CREATE_ALERT_PLUGIN_INSTANCE_NOTES=create alert plugin instance operation\n DELETE_ALERT_PLUGIN_INSTANCE_NOTES=delete alert plugin instance operation\n GET_ALERT_PLUGIN_INSTANCE_NOTES=get alert plugin instance operation\n-CREATE_ALERT_GROUP_NOTES=create alert group \n+CREATE_ALERT_GROUP_NOTES=create alert group\n WORKER_GROUP_TAG=worker group related operation\n SAVE_WORKER_GROUP_NOTES=create worker group\n WORKER_GROUP_NAME=worker group name\n WORKER_IP_LIST=worker ip list, eg. 192.168.1.1,192.168.1.2\n QUERY_WORKER_GROUP_PAGING_NOTES=query worker group paging\n-QUERY_WORKER_GROUP_LIST_NOTES=query worker group list \n-DELETE_WORKER_GROUP_BY_ID_NOTES=delete worker group by id \n+QUERY_WORKER_GROUP_LIST_NOTES=query worker group list\n+DELETE_WORKER_GROUP_BY_ID_NOTES=delete worker group by id\n DATA_ANALYSIS_TAG=analysis related operation of task state\n-COUNT_TASK_STATE_NOTES=count task state \n+COUNT_TASK_STATE_NOTES=count task state\n COUNT_PROCESS_INSTANCE_NOTES=count process instance state\n-COUNT_PROCESS_DEFINITION_BY_USER_NOTES=count process definition by user \n-COUNT_COMMAND_STATE_NOTES=count command state \n+COUNT_PROCESS_DEFINITION_BY_USER_NOTES=count process definition by user\n+COUNT_COMMAND_STATE_NOTES=count command state\n COUNT_QUEUE_STATE_NOTES=count the running status of the task in the queue\\\n \n ACCESS_TOKEN_TAG=access token related operation\n MONITOR_TAG=monitor related operation\n MASTER_LIST_NOTES=master server list\n WORKER_LIST_NOTES=worker server list\n-QUERY_DATABASE_STATE_NOTES=query database state \n-QUERY_ZOOKEEPER_STATE_NOTES=QUERY ZOOKEEPER STATE \n+QUERY_DATABASE_STATE_NOTES=query database state\n+QUERY_ZOOKEEPER_STATE_NOTES=QUERY ZOOKEEPER STATE\n TASK_STATE=task instance state\n SOURCE_TABLE=SOURCE TABLE\n DEST_TABLE=dest table\n@@ -78,18 +78,18 @@ DATA_SOURCE_HOST=DATA SOURCE HOST\n DATA_SOURCE_PORT=data source port\n DATABASE_NAME=database name\n QUEUE_TAG=queue related operation\n-QUERY_QUEUE_LIST_NOTES=query queue list \n-QUERY_QUEUE_LIST_PAGING_NOTES=query queue list paging  \n+QUERY_QUEUE_LIST_NOTES=query queue list\n+QUERY_QUEUE_LIST_PAGING_NOTES=query queue list paging\n CREATE_QUEUE_NOTES=create queue\n YARN_QUEUE_NAME=yarn(hadoop) queue name\n QUEUE_ID=queue id\n TENANT_DESC=tenant desc\n-QUERY_TENANT_LIST_PAGING_NOTES=query tenant list paging \n-QUERY_TENANT_LIST_NOTES=query tenant list \n-UPDATE_TENANT_NOTES=update tenant \n-DELETE_TENANT_NOTES=delete tenant \n+QUERY_TENANT_LIST_PAGING_NOTES=query tenant list paging\n+QUERY_TENANT_LIST_NOTES=query tenant list\n+UPDATE_TENANT_NOTES=update tenant\n+DELETE_TENANT_NOTES=delete tenant\n RESOURCES_TAG=resource center related operation\n-CREATE_RESOURCE_NOTES=create resource \n+CREATE_RESOURCE_NOTES=create resource\n RESOURCE_TYPE=resource file type\n RESOURCE_NAME=resource name\n RESOURCE_DESC=resource file desc\n@@ -98,29 +98,29 @@ RESOURCE_ID=resource id\n QUERY_RESOURCE_LIST_NOTES=query resource list\n DELETE_RESOURCE_BY_ID_NOTES=delete resource by id\n VIEW_RESOURCE_BY_ID_NOTES=view resource by id\n-ONLINE_CREATE_RESOURCE_NOTES=online create resource \n+ONLINE_CREATE_RESOURCE_NOTES=online create resource\n SUFFIX=resource file suffix\n CONTENT=resource file content\n UPDATE_RESOURCE_NOTES=edit resource file online\n DOWNLOAD_RESOURCE_NOTES=download resource file\n-CREATE_UDF_FUNCTION_NOTES=create udf function \n+CREATE_UDF_FUNCTION_NOTES=create udf function\n UDF_TYPE=UDF type\n FUNC_NAME=function name\n CLASS_NAME=package and class name\n ARG_TYPES=arguments\n UDF_DESC=udf desc\n-VIEW_UDF_FUNCTION_NOTES=view udf function \n-UPDATE_UDF_FUNCTION_NOTES=update udf function \n-QUERY_UDF_FUNCTION_LIST_PAGING_NOTES=query udf function list paging \n-VERIFY_UDF_FUNCTION_NAME_NOTES=verify udf function name \n-DELETE_UDF_FUNCTION_NOTES=delete udf function \n-AUTHORIZED_FILE_NOTES=authorized file \n-UNAUTHORIZED_FILE_NOTES=unauthorized file \n-AUTHORIZED_UDF_FUNC_NOTES=authorized udf func \n-UNAUTHORIZED_UDF_FUNC_NOTES=unauthorized udf func \n-VERIFY_QUEUE_NOTES=verify queue \n+VIEW_UDF_FUNCTION_NOTES=view udf function\n+UPDATE_UDF_FUNCTION_NOTES=update udf function\n+QUERY_UDF_FUNCTION_LIST_PAGING_NOTES=query udf function list paging\n+VERIFY_UDF_FUNCTION_NAME_NOTES=verify udf function name\n+DELETE_UDF_FUNCTION_NOTES=delete udf function\n+AUTHORIZED_FILE_NOTES=authorized file\n+UNAUTHORIZED_FILE_NOTES=unauthorized file\n+AUTHORIZED_UDF_FUNC_NOTES=authorized udf func\n+UNAUTHORIZED_UDF_FUNC_NOTES=unauthorized udf func\n+VERIFY_QUEUE_NOTES=verify queue\n TENANT_TAG=tenant related operation\n-CREATE_TENANT_NOTES=create tenant \n+CREATE_TENANT_NOTES=create tenant\n TENANT_CODE=os tenant code\n QUEUE_NAME=queue name\n PASSWORD=password\n@@ -130,18 +130,18 @@ DATA_SOURCE_KERBEROS_KRB5_CONF=the kerberos authentication parameter java.securi\n DATA_SOURCE_KERBEROS_KEYTAB_USERNAME=the kerberos authentication parameter login.user.keytab.username\n DATA_SOURCE_KERBEROS_KEYTAB_PATH=the kerberos authentication parameter login.user.keytab.path\n PROJECT_TAG=project related operation\n-CREATE_PROJECT_NOTES=create project \n+CREATE_PROJECT_NOTES=create project\n PROJECT_DESC=project description\n-UPDATE_PROJECT_NOTES=update project \n+UPDATE_PROJECT_NOTES=update project\n PROJECT_ID=project id\n QUERY_PROJECT_BY_ID_NOTES=query project info by project id\n-QUERY_PROJECT_LIST_PAGING_NOTES=QUERY PROJECT LIST PAGING \n-DELETE_PROJECT_BY_ID_NOTES=delete project by id \n+QUERY_PROJECT_LIST_PAGING_NOTES=QUERY PROJECT LIST PAGING\n+DELETE_PROJECT_BY_ID_NOTES=delete project by id\n QUERY_UNAUTHORIZED_PROJECT_NOTES=query unauthorized project\n QUERY_ALL_PROJECT_LIST_NOTES=query all project list\n QUERY_AUTHORIZED_PROJECT_NOTES=query authorized project\n TASK_RECORD_TAG=task record related operation\n-QUERY_TASK_RECORD_LIST_PAGING_NOTES=query task record list paging \n+QUERY_TASK_RECORD_LIST_PAGING_NOTES=query task record list paging\n CREATE_TOKEN_NOTES=create token ï¼Œnote: please login first\n QUERY_ACCESS_TOKEN_LIST_NOTES=query access token list paging\n SCHEDULE=schedule\n@@ -152,11 +152,11 @@ RECEIVERS=receivers\n RECEIVERS_CC=receivers cc\n WORKER_GROUP_ID=worker server group id\n PROCESS_INSTANCE_PRIORITY=process instance priority\n-UPDATE_SCHEDULE_NOTES=update schedule \n+UPDATE_SCHEDULE_NOTES=update schedule\n SCHEDULE_ID=schedule id\n ONLINE_SCHEDULE_NOTES=online schedule\n-OFFLINE_SCHEDULE_NOTES=offline schedule \n-QUERY_SCHEDULE_NOTES=query schedule \n+OFFLINE_SCHEDULE_NOTES=offline schedule\n+QUERY_SCHEDULE_NOTES=query schedule\n QUERY_SCHEDULE_LIST_PAGING_NOTES=query schedule list paging\n LOGIN_TAG=User login related operations\n USER_NAME=user name\n@@ -191,7 +191,7 @@ PROCESS_INSTANCE_JSON=process instance info(json format)\n SCHEDULE_TIME=schedule time\n SYNC_DEFINE=update the information of the process instance to the process definition\\\n \n-RECOVERY_PROCESS_INSTANCE_FLAG=whether to recovery process instance \n+RECOVERY_PROCESS_INSTANCE_FLAG=whether to recovery process instance\n SEARCH_VAL=search val\n USER_ID=user id\n PAGE_SIZE=page size\n@@ -206,37 +206,37 @@ QUERY_PROCESS_INSTANCE_BY_ID_NOTES=query process instance by process instance id\n DELETE_PROCESS_INSTANCE_BY_ID_NOTES=delete process instance by process instance id\n TASK_ID=task instance id\n SKIP_LINE_NUM=skip line num\n-QUERY_TASK_INSTANCE_LOG_NOTES=query task instance log \n+QUERY_TASK_INSTANCE_LOG_NOTES=query task instance log\n DOWNLOAD_TASK_INSTANCE_LOG_NOTES=download task instance log\n USERS_TAG=users related operation\n SCHEDULER_TAG=scheduler related operation\n-CREATE_SCHEDULE_NOTES=create schedule \n+CREATE_SCHEDULE_NOTES=create schedule\n CREATE_USER_NOTES=create user\n TENANT_ID=tenant id\n QUEUE=queue\n EMAIL=email\n PHONE=phone\n-QUERY_USER_LIST_NOTES=query user list \n+QUERY_USER_LIST_NOTES=query user list\n UPDATE_USER_NOTES=update user\n DELETE_USER_BY_ID_NOTES=delete user by id\n-GRANT_PROJECT_NOTES=GRANT PROJECT \n+GRANT_PROJECT_NOTES=GRANT PROJECT\n PROJECT_IDS=project ids(string format, multiple projects separated by \",\")\n GRANT_RESOURCE_NOTES=grant resource file\n RESOURCE_IDS=resource ids(string format, multiple resources separated by \",\")\n-GET_USER_INFO_NOTES=get user info \n+GET_USER_INFO_NOTES=get user info\n LIST_USER_NOTES=list user\n VERIFY_USER_NAME_NOTES=verify user name\n UNAUTHORIZED_USER_NOTES=cancel authorization\n ALERT_GROUP_ID=alert group id\n AUTHORIZED_USER_NOTES=authorized user\n GRANT_UDF_FUNC_NOTES=grant udf function\n UDF_IDS=udf ids(string format, multiple udf functions separated by \",\")\n-GRANT_DATASOURCE_NOTES=grant datasource \n+GRANT_DATASOURCE_NOTES=grant datasource\n DATASOURCE_IDS=datasource ids(string format, multiple datasources separated by \",\")\n QUERY_SUBPROCESS_INSTANCE_BY_TASK_ID_NOTES=query subprocess instance by task instance id\n QUERY_PARENT_PROCESS_INSTANCE_BY_SUB_PROCESS_INSTANCE_ID_NOTES=query parent process instance info by sub process instance id\n QUERY_PROCESS_INSTANCE_GLOBAL_VARIABLES_AND_LOCAL_VARIABLES_NOTES=query process instance global variables and local variables\n-VIEW_GANTT_NOTES=view gantt \n+VIEW_GANTT_NOTES=view gantt\n SUB_PROCESS_INSTANCE_ID=sub process instance id\n TASK_NAME=task instance name\n TASK_INSTANCE_TAG=task instance related operation\n@@ -252,9 +252,9 @@ DATA_SOURCE_ID=DATA SOURCE ID\n QUERY_DATA_SOURCE_NOTES=query data source by id\n QUERY_DATA_SOURCE_LIST_BY_TYPE_NOTES=query data source list by database type\n QUERY_DATA_SOURCE_LIST_PAGING_NOTES=query data source list paging\n-CONNECT_DATA_SOURCE_NOTES=CONNECT DATA SOURCE \n-CONNECT_DATA_SOURCE_TEST_NOTES=connect data source test \n-DELETE_DATA_SOURCE_NOTES=delete data source \n+CONNECT_DATA_SOURCE_NOTES=CONNECT DATA SOURCE\n+CONNECT_DATA_SOURCE_TEST_NOTES=connect data source test\n+DELETE_DATA_SOURCE_NOTES=delete data source\n VERIFY_DATA_SOURCE_NOTES=verify data source\n UNAUTHORIZED_DATA_SOURCE_NOTES=unauthorized data source\n AUTHORIZED_DATA_SOURCE_NOTES=authorized data source"
  },
  {
    "sha": "f86d8c3146028a72bdd6edcde3c0e3cbfab2823a",
    "filename": "dolphinscheduler-api/src/main/resources/i18n/messages_en_US.properties",
    "status": "modified",
    "additions": 56,
    "deletions": 56,
    "changes": 112,
    "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e65612dfcba6c3ec0d0c25ba3d7a05d784664d83/dolphinscheduler-api/src/main/resources/i18n/messages_en_US.properties",
    "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e65612dfcba6c3ec0d0c25ba3d7a05d784664d83/dolphinscheduler-api/src/main/resources/i18n/messages_en_US.properties",
    "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dolphinscheduler-api/src/main/resources/i18n/messages_en_US.properties?ref=e65612dfcba6c3ec0d0c25ba3d7a05d784664d83",
    "patch": "@@ -18,52 +18,52 @@\n QUERY_SCHEDULE_LIST_NOTES=query schedule list\n EXECUTE_PROCESS_TAG=execute process related operation\n PROCESS_INSTANCE_EXECUTOR_TAG=process instance executor related operation\n-RUN_PROCESS_INSTANCE_NOTES=run process instance \n+RUN_PROCESS_INSTANCE_NOTES=run process instance\n START_NODE_LIST=start node listï¼ˆnode nameï¼‰\n TASK_DEPEND_TYPE=task depend type\n COMMAND_TYPE=command type\n RUN_MODE=run mode\n TIMEOUT=timeout\n-EXECUTE_ACTION_TO_PROCESS_INSTANCE_NOTES=execute action to process instance \n+EXECUTE_ACTION_TO_PROCESS_INSTANCE_NOTES=execute action to process instance\n EXECUTE_TYPE=execute type\n-START_CHECK_PROCESS_DEFINITION_NOTES=start check process definition \n-GET_RECEIVER_CC_NOTES=query receiver cc \n+START_CHECK_PROCESS_DEFINITION_NOTES=start check process definition\n+GET_RECEIVER_CC_NOTES=query receiver cc\n DESC=description\n GROUP_NAME=group name\n GROUP_TYPE=group type\n-QUERY_ALERT_GROUP_LIST_NOTES=query alert group list \n-UPDATE_ALERT_GROUP_NOTES=update alert group \n-DELETE_ALERT_GROUP_BY_ID_NOTES=delete alert group by id \n-VERIFY_ALERT_GROUP_NAME_NOTES=verify alert group name, check alert group exist or not \n-GRANT_ALERT_GROUP_NOTES=grant alert group \n+QUERY_ALERT_GROUP_LIST_NOTES=query alert group list\n+UPDATE_ALERT_GROUP_NOTES=update alert group\n+DELETE_ALERT_GROUP_BY_ID_NOTES=delete alert group by id\n+VERIFY_ALERT_GROUP_NAME_NOTES=verify alert group name, check alert group exist or not\n+GRANT_ALERT_GROUP_NOTES=grant alert group\n USER_IDS=user id list\n ALERT_GROUP_TAG=alert group related operation\n ALERT_PLUGIN_INSTANCE_TAG=alert plugin instance related operation\n UPDATE_ALERT_PLUGIN_INSTANCE_NOTES=update alert plugin instance operation\n CREATE_ALERT_PLUGIN_INSTANCE_NOTES=create alert plugin instance operation\n DELETE_ALERT_PLUGIN_INSTANCE_NOTES=delete alert plugin instance operation\n GET_ALERT_PLUGIN_INSTANCE_NOTES=get alert plugin instance operation\n-CREATE_ALERT_GROUP_NOTES=create alert group \n+CREATE_ALERT_GROUP_NOTES=create alert group\n WORKER_GROUP_TAG=worker group related operation\n SAVE_WORKER_GROUP_NOTES=create worker group\n WORKER_GROUP_NAME=worker group name\n WORKER_IP_LIST=worker ip list, eg. 192.168.1.1,192.168.1.2\n QUERY_WORKER_GROUP_PAGING_NOTES=query worker group paging\n-QUERY_WORKER_GROUP_LIST_NOTES=query worker group list \n-DELETE_WORKER_GROUP_BY_ID_NOTES=delete worker group by id \n+QUERY_WORKER_GROUP_LIST_NOTES=query worker group list\n+DELETE_WORKER_GROUP_BY_ID_NOTES=delete worker group by id\n DATA_ANALYSIS_TAG=analysis related operation of task state\n-COUNT_TASK_STATE_NOTES=count task state \n+COUNT_TASK_STATE_NOTES=count task state\n COUNT_PROCESS_INSTANCE_NOTES=count process instance state\n-COUNT_PROCESS_DEFINITION_BY_USER_NOTES=count process definition by user \n-COUNT_COMMAND_STATE_NOTES=count command state \n+COUNT_PROCESS_DEFINITION_BY_USER_NOTES=count process definition by user\n+COUNT_COMMAND_STATE_NOTES=count command state\n COUNT_QUEUE_STATE_NOTES=count the running status of the task in the queue\\\n \n ACCESS_TOKEN_TAG=access token related operation\n MONITOR_TAG=monitor related operation\n MASTER_LIST_NOTES=master server list\n WORKER_LIST_NOTES=worker server list\n-QUERY_DATABASE_STATE_NOTES=query database state \n-QUERY_ZOOKEEPER_STATE_NOTES=QUERY ZOOKEEPER STATE \n+QUERY_DATABASE_STATE_NOTES=query database state\n+QUERY_ZOOKEEPER_STATE_NOTES=QUERY ZOOKEEPER STATE\n TASK_STATE=task instance state\n SOURCE_TABLE=SOURCE TABLE\n DEST_TABLE=dest table\n@@ -78,18 +78,18 @@ DATA_SOURCE_HOST=DATA SOURCE HOST\n DATA_SOURCE_PORT=data source port\n DATABASE_NAME=database name\n QUEUE_TAG=queue related operation\n-QUERY_QUEUE_LIST_NOTES=query queue list \n-QUERY_QUEUE_LIST_PAGING_NOTES=query queue list paging  \n+QUERY_QUEUE_LIST_NOTES=query queue list\n+QUERY_QUEUE_LIST_PAGING_NOTES=query queue list paging\n CREATE_QUEUE_NOTES=create queue\n YARN_QUEUE_NAME=yarn(hadoop) queue name\n QUEUE_ID=queue id\n TENANT_DESC=tenant desc\n-QUERY_TENANT_LIST_PAGING_NOTES=query tenant list paging \n-QUERY_TENANT_LIST_NOTES=query tenant list \n-UPDATE_TENANT_NOTES=update tenant \n-DELETE_TENANT_NOTES=delete tenant \n+QUERY_TENANT_LIST_PAGING_NOTES=query tenant list paging\n+QUERY_TENANT_LIST_NOTES=query tenant list\n+UPDATE_TENANT_NOTES=update tenant\n+DELETE_TENANT_NOTES=delete tenant\n RESOURCES_TAG=resource center related operation\n-CREATE_RESOURCE_NOTES=create resource \n+CREATE_RESOURCE_NOTES=create resource\n RESOURCE_TYPE=resource file type\n RESOURCE_NAME=resource name\n RESOURCE_DESC=resource file desc\n@@ -98,29 +98,29 @@ RESOURCE_ID=resource id\n QUERY_RESOURCE_LIST_NOTES=query resource list\n DELETE_RESOURCE_BY_ID_NOTES=delete resource by id\n VIEW_RESOURCE_BY_ID_NOTES=view resource by id\n-ONLINE_CREATE_RESOURCE_NOTES=online create resource \n+ONLINE_CREATE_RESOURCE_NOTES=online create resource\n SUFFIX=resource file suffix\n CONTENT=resource file content\n UPDATE_RESOURCE_NOTES=edit resource file online\n DOWNLOAD_RESOURCE_NOTES=download resource file\n-CREATE_UDF_FUNCTION_NOTES=create udf function \n+CREATE_UDF_FUNCTION_NOTES=create udf function\n UDF_TYPE=UDF type\n FUNC_NAME=function name\n CLASS_NAME=package and class name\n ARG_TYPES=arguments\n UDF_DESC=udf desc\n-VIEW_UDF_FUNCTION_NOTES=view udf function \n-UPDATE_UDF_FUNCTION_NOTES=update udf function \n-QUERY_UDF_FUNCTION_LIST_PAGING_NOTES=query udf function list paging \n-VERIFY_UDF_FUNCTION_NAME_NOTES=verify udf function name \n-DELETE_UDF_FUNCTION_NOTES=delete udf function \n-AUTHORIZED_FILE_NOTES=authorized file \n-UNAUTHORIZED_FILE_NOTES=unauthorized file \n-AUTHORIZED_UDF_FUNC_NOTES=authorized udf func \n-UNAUTHORIZED_UDF_FUNC_NOTES=unauthorized udf func \n-VERIFY_QUEUE_NOTES=verify queue \n+VIEW_UDF_FUNCTION_NOTES=view udf function\n+UPDATE_UDF_FUNCTION_NOTES=update udf function\n+QUERY_UDF_FUNCTION_LIST_PAGING_NOTES=query udf function list paging\n+VERIFY_UDF_FUNCTION_NAME_NOTES=verify udf function name\n+DELETE_UDF_FUNCTION_NOTES=delete udf function\n+AUTHORIZED_FILE_NOTES=authorized file\n+UNAUTHORIZED_FILE_NOTES=unauthorized file\n+AUTHORIZED_UDF_FUNC_NOTES=authorized udf func\n+UNAUTHORIZED_UDF_FUNC_NOTES=unauthorized udf func\n+VERIFY_QUEUE_NOTES=verify queue\n TENANT_TAG=tenant related operation\n-CREATE_TENANT_NOTES=create tenant \n+CREATE_TENANT_NOTES=create tenant\n TENANT_CODE=os tenant code\n QUEUE_NAME=queue name\n PASSWORD=password\n@@ -130,18 +130,18 @@ DATA_SOURCE_KERBEROS_KRB5_CONF=the kerberos authentication parameter java.securi\n DATA_SOURCE_KERBEROS_KEYTAB_USERNAME=the kerberos authentication parameter login.user.keytab.username\n DATA_SOURCE_KERBEROS_KEYTAB_PATH=the kerberos authentication parameter login.user.keytab.path\n PROJECT_TAG=project related operation\n-CREATE_PROJECT_NOTES=create project \n+CREATE_PROJECT_NOTES=create project\n PROJECT_DESC=project description\n-UPDATE_PROJECT_NOTES=update project \n+UPDATE_PROJECT_NOTES=update project\n PROJECT_ID=project id\n QUERY_PROJECT_BY_ID_NOTES=query project info by project id\n-QUERY_PROJECT_LIST_PAGING_NOTES=QUERY PROJECT LIST PAGING \n+QUERY_PROJECT_LIST_PAGING_NOTES=QUERY PROJECT LIST PAGING\n QUERY_ALL_PROJECT_LIST_NOTES=query all project list\n-DELETE_PROJECT_BY_ID_NOTES=delete project by id \n+DELETE_PROJECT_BY_ID_NOTES=delete project by id\n QUERY_UNAUTHORIZED_PROJECT_NOTES=query unauthorized project\n QUERY_AUTHORIZED_PROJECT_NOTES=query authorized project\n TASK_RECORD_TAG=task record related operation\n-QUERY_TASK_RECORD_LIST_PAGING_NOTES=query task record list paging \n+QUERY_TASK_RECORD_LIST_PAGING_NOTES=query task record list paging\n CREATE_TOKEN_NOTES=create token ï¼Œnote: please login first\n QUERY_ACCESS_TOKEN_LIST_NOTES=query access token list paging\n SCHEDULE=schedule\n@@ -152,11 +152,11 @@ RECEIVERS=receivers\n RECEIVERS_CC=receivers cc\n WORKER_GROUP_ID=worker server group id\n PROCESS_INSTANCE_PRIORITY=process instance priority\n-UPDATE_SCHEDULE_NOTES=update schedule \n+UPDATE_SCHEDULE_NOTES=update schedule\n SCHEDULE_ID=schedule id\n ONLINE_SCHEDULE_NOTES=online schedule\n-OFFLINE_SCHEDULE_NOTES=offline schedule \n-QUERY_SCHEDULE_NOTES=query schedule \n+OFFLINE_SCHEDULE_NOTES=offline schedule\n+QUERY_SCHEDULE_NOTES=query schedule\n QUERY_SCHEDULE_LIST_PAGING_NOTES=query schedule list paging\n LOGIN_TAG=User login related operations\n USER_NAME=user name\n@@ -190,7 +190,7 @@ PROCESS_INSTANCE_JSON=process instance info(json format)\n SCHEDULE_TIME=schedule time\n SYNC_DEFINE=update the information of the process instance to the process definition\\\n \n-RECOVERY_PROCESS_INSTANCE_FLAG=whether to recovery process instance \n+RECOVERY_PROCESS_INSTANCE_FLAG=whether to recovery process instance\n SEARCH_VAL=search val\n USER_ID=user id\n PAGE_SIZE=page size\n@@ -205,37 +205,37 @@ QUERY_PROCESS_INSTANCE_BY_ID_NOTES=query process instance by process instance id\n DELETE_PROCESS_INSTANCE_BY_ID_NOTES=delete process instance by process instance id\n TASK_ID=task instance id\n SKIP_LINE_NUM=skip line num\n-QUERY_TASK_INSTANCE_LOG_NOTES=query task instance log \n+QUERY_TASK_INSTANCE_LOG_NOTES=query task instance log\n DOWNLOAD_TASK_INSTANCE_LOG_NOTES=download task instance log\n USERS_TAG=users related operation\n SCHEDULER_TAG=scheduler related operation\n-CREATE_SCHEDULE_NOTES=create schedule \n+CREATE_SCHEDULE_NOTES=create schedule\n CREATE_USER_NOTES=create user\n TENANT_ID=tenant id\n QUEUE=queue\n EMAIL=email\n PHONE=phone\n-QUERY_USER_LIST_NOTES=query user list \n+QUERY_USER_LIST_NOTES=query user list\n UPDATE_USER_NOTES=update user\n DELETE_USER_BY_ID_NOTES=delete user by id\n-GRANT_PROJECT_NOTES=GRANT PROJECT \n+GRANT_PROJECT_NOTES=GRANT PROJECT\n PROJECT_IDS=project ids(string format, multiple projects separated by \",\")\n GRANT_RESOURCE_NOTES=grant resource file\n RESOURCE_IDS=resource ids(string format, multiple resources separated by \",\")\n-GET_USER_INFO_NOTES=get user info \n+GET_USER_INFO_NOTES=get user info\n LIST_USER_NOTES=list user\n VERIFY_USER_NAME_NOTES=verify user name\n UNAUTHORIZED_USER_NOTES=cancel authorization\n ALERT_GROUP_ID=alert group id\n AUTHORIZED_USER_NOTES=authorized user\n GRANT_UDF_FUNC_NOTES=grant udf function\n UDF_IDS=udf ids(string format, multiple udf functions separated by \",\")\n-GRANT_DATASOURCE_NOTES=grant datasource \n+GRANT_DATASOURCE_NOTES=grant datasource\n DATASOURCE_IDS=datasource ids(string format, multiple datasources separated by \",\")\n QUERY_SUBPROCESS_INSTANCE_BY_TASK_ID_NOTES=query subprocess instance by task instance id\n QUERY_PARENT_PROCESS_INSTANCE_BY_SUB_PROCESS_INSTANCE_ID_NOTES=query parent process instance info by sub process instance id\n QUERY_PROCESS_INSTANCE_GLOBAL_VARIABLES_AND_LOCAL_VARIABLES_NOTES=query process instance global variables and local variables\n-VIEW_GANTT_NOTES=view gantt \n+VIEW_GANTT_NOTES=view gantt\n SUB_PROCESS_INSTANCE_ID=sub process instance id\n TASK_NAME=task instance name\n TASK_INSTANCE_TAG=task instance related operation\n@@ -251,9 +251,9 @@ DATA_SOURCE_ID=DATA SOURCE ID\n QUERY_DATA_SOURCE_NOTES=query data source by id\n QUERY_DATA_SOURCE_LIST_BY_TYPE_NOTES=query data source list by database type\n QUERY_DATA_SOURCE_LIST_PAGING_NOTES=query data source list paging\n-CONNECT_DATA_SOURCE_NOTES=CONNECT DATA SOURCE \n-CONNECT_DATA_SOURCE_TEST_NOTES=connect data source test \n-DELETE_DATA_SOURCE_NOTES=delete data source \n+CONNECT_DATA_SOURCE_NOTES=CONNECT DATA SOURCE\n+CONNECT_DATA_SOURCE_TEST_NOTES=connect data source test\n+DELETE_DATA_SOURCE_NOTES=delete data source\n VERIFY_DATA_SOURCE_NOTES=verify data source\n UNAUTHORIZED_DATA_SOURCE_NOTES=unauthorized data source\n AUTHORIZED_DATA_SOURCE_NOTES=authorized data source"
  },
  {
    "sha": "b2b973b57a31d83fee981d317abdd53421642810",
    "filename": "dolphinscheduler-api/src/test/java/org/apache/dolphinscheduler/api/service/ExecutorService2Test.java",
    "status": "modified",
    "additions": 1,
    "deletions": 1,
    "changes": 2,
    "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e65612dfcba6c3ec0d0c25ba3d7a05d784664d83/dolphinscheduler-api/src/test/java/org/apache/dolphinscheduler/api/service/ExecutorService2Test.java",
    "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e65612dfcba6c3ec0d0c25ba3d7a05d784664d83/dolphinscheduler-api/src/test/java/org/apache/dolphinscheduler/api/service/ExecutorService2Test.java",
    "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dolphinscheduler-api/src/test/java/org/apache/dolphinscheduler/api/service/ExecutorService2Test.java?ref=e65612dfcba6c3ec0d0c25ba3d7a05d784664d83",
    "patch": "@@ -264,7 +264,7 @@ public void testNoMsterServers() throws ParseException {\n     @Test\n     public void testExecuteRepeatRunning() throws Exception {\n         Mockito.when(processService.verifyIsNeedCreateCommand(any(Command.class))).thenReturn(true);\n-        \n+\n         Map<String, Object> result = executorService.execute(loginUser, projectName, processInstanceId, ExecuteType.REPEAT_RUNNING);\n         Assert.assertEquals(Status.SUCCESS, result.get(Constants.STATUS));\n     }"
  },
  {
    "sha": "3d5446d08a9d96e38d8da567c1ae9450dba49f10",
    "filename": "dolphinscheduler-api/src/test/java/org/apache/dolphinscheduler/api/utils/FourLetterWordMainTest.java",
    "status": "modified",
    "additions": 7,
    "deletions": 7,
    "changes": 14,
    "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e65612dfcba6c3ec0d0c25ba3d7a05d784664d83/dolphinscheduler-api/src/test/java/org/apache/dolphinscheduler/api/utils/FourLetterWordMainTest.java",
    "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e65612dfcba6c3ec0d0c25ba3d7a05d784664d83/dolphinscheduler-api/src/test/java/org/apache/dolphinscheduler/api/utils/FourLetterWordMainTest.java",
    "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dolphinscheduler-api/src/test/java/org/apache/dolphinscheduler/api/utils/FourLetterWordMainTest.java?ref=e65612dfcba6c3ec0d0c25ba3d7a05d784664d83",
    "patch": "@@ -46,7 +46,7 @@\n @PrepareForTest({FourLetterWordMain.class, Socket.class})\n public class FourLetterWordMainTest {\n \n-    private static final Logger logger = \n+    private static final Logger logger =\n             LoggerFactory.getLogger(FourLetterWordMainTest.class);\n     private static final String NEW_LINE = \"\\n\";\n \n@@ -123,7 +123,7 @@ public void testNullCmd() {\n         } catch (Exception e) {\n             testResult = e.getMessage();\n         }\n-        \n+\n         logger.info(\"testNullCmd result: \" + testResult);\n         assertEquals(\"cmd must not be null\", testResult);\n     }\n@@ -174,7 +174,7 @@ public void testSocketTimeOut() {\n         } catch (Exception e) {\n             testResult = e.getMessage();\n         }\n-        \n+\n         logger.info(\"testSocketTimeOut result: \" + testResult);\n         assertEquals(\n                 \"Exception while executing four letter word: \" + cmd,\n@@ -184,7 +184,7 @@ public void testSocketTimeOut() {\n \n     /**\n      * Test FourLetterWordMain.send4LetterWord() with input cmd and output\n-     * string. \n+     * string.\n      * @param cmd\n      * @param expectedStr\n      */\n@@ -193,7 +193,7 @@ public void testSend4LetterWord(String cmd, String expectedStr) {\n             final byte[] strBytes = cmd.getBytes();\n             byteArrayOutputStream = new ByteArrayOutputStream(strBytes.length);\n             byteArrayOutputStream.write(strBytes, 0, strBytes.length);\n-            \n+\n             inputStream = new ByteArrayInputStream(expectedStr.getBytes());\n \n             when(socket.getOutputStream())\n@@ -204,8 +204,8 @@ public void testSend4LetterWord(String cmd, String expectedStr) {\n                     .send4LetterWord(localHost, zkPort, cmd);\n             logger.info(\n                     \"testSend4LetterWord: \" +\n-                    \"cmd: \" + cmd + \n-                    \", expectedStr: \" + expectedStr + \n+                    \"cmd: \" + cmd +\n+                    \", expectedStr: \" + expectedStr +\n                     \", result: \" + result + \".\"\n             );\n             Assert.assertEquals(expectedStr, result);"
  },
  {
    "sha": "08a0ba483e3801806cd5d4edd303c48dba549d88",
    "filename": "dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/shell/AbstractShell.java",
    "status": "modified",
    "additions": 29,
    "deletions": 29,
    "changes": 58,
    "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e65612dfcba6c3ec0d0c25ba3d7a05d784664d83/dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/shell/AbstractShell.java",
    "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e65612dfcba6c3ec0d0c25ba3d7a05d784664d83/dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/shell/AbstractShell.java",
    "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/shell/AbstractShell.java?ref=e65612dfcba6c3ec0d0c25ba3d7a05d784664d83",
    "patch": "@@ -31,17 +31,17 @@\n import org.slf4j.LoggerFactory;\n \n \n-/** \n+/**\n  * A base class for running a Unix command.\n- * \n+ *\n  * <code>AbstractShell</code> can be used to run unix commands like <code>du</code> or\n- * <code>df</code>. It also offers facilities to gate commands by \n+ * <code>df</code>. It also offers facilities to gate commands by\n  * time-intervals.\n  */\n public abstract class AbstractShell {\n-  \n+\n   private static final Logger logger = LoggerFactory.getLogger(AbstractShell.class);\n-  \n+\n \n \n   /**\n@@ -79,13 +79,13 @@\n    * If or not script finished executing\n    */\n   private AtomicBoolean completed;\n-  \n+\n   public AbstractShell() {\n     this(0L);\n   }\n-  \n+\n   /**\n-   * @param interval the minimum duration to wait before re-executing the \n+   * @param interval the minimum duration to wait before re-executing the\n    *        command.\n    */\n   public AbstractShell(long interval ) {\n@@ -94,7 +94,7 @@ public AbstractShell(long interval ) {\n   }\n \n \n-  \n+\n   /**\n    * set the environment for the command\n    * @param env Mapping of environment variables\n@@ -124,7 +124,7 @@ protected void run() throws IOException {\n     runCommand();\n   }\n \n-  \n+\n   /**\n    * Run a command   actual work\n    */\n@@ -134,14 +134,14 @@ private void runCommand() throws IOException {\n     ShellTimeoutTimerTask timeoutTimerTask = null;\n     timedOut = new AtomicBoolean(false);\n     completed = new AtomicBoolean(false);\n-    \n+\n     if (environment != null) {\n       builder.environment().putAll(this.environment);\n     }\n     if (dir != null) {\n       builder.directory(this.dir);\n     }\n-    \n+\n     process = builder.start();\n     ProcessContainer.putProcess(process);\n \n@@ -152,14 +152,14 @@ private void runCommand() throws IOException {\n       //One time scheduling.\n       timeOutTimer.schedule(timeoutTimerTask, timeOutInterval);\n     }\n-    final BufferedReader errReader = \n+    final BufferedReader errReader =\n             new BufferedReader(\n                     new InputStreamReader(process.getErrorStream()));\n     BufferedReader inReader =\n             new BufferedReader(\n                     new InputStreamReader(process.getInputStream()));\n     final StringBuilder errMsg = new StringBuilder();\n-    \n+\n     // read error and input streams as this would free up the buffers\n     // free the error stream buffer\n     Thread errThread = new Thread() {\n@@ -239,7 +239,7 @@ public void run() {\n    * @return an array containing the command name and its parameters\n    */\n   protected abstract String[] getExecString();\n-  \n+\n   /**\n    * Parse the execution result\n    * @param lines lines\n@@ -256,7 +256,7 @@ public Process getProcess() {\n     return process;\n   }\n \n-  /** get the exit code \n+  /** get the exit code\n    * @return the exit code of the process\n    */\n   public int getExitCode() {\n@@ -265,12 +265,12 @@ public int getExitCode() {\n \n   /**\n    * Set if the command has timed out.\n-   * \n+   *\n    */\n   private void setTimedOut() {\n     this.timedOut.set(true);\n   }\n-  \n+\n \n \n   /**\n@@ -291,7 +291,7 @@ public void run() {\n         p.exitValue();\n       } catch (Exception e) {\n         //Process has not terminated.\n-        //So check if it has completed \n+        //So check if it has completed\n         //if not just destroy it.\n         if (p != null && !shell.completed.get()) {\n           shell.setTimedOut();\n@@ -300,23 +300,23 @@ public void run() {\n       }\n     }\n   }\n-  \n+\n   /**\n    * This is an IOException with exit code added.\n    */\n   public static class ExitCodeException extends IOException {\n     int exitCode;\n-    \n+\n     public ExitCodeException(int exitCode, String message) {\n       super(message);\n       this.exitCode = exitCode;\n     }\n-    \n+\n     public int getExitCode() {\n       return exitCode;\n     }\n   }\n-  \n+\n   /**\n    * process manage container\n    *\n@@ -329,29 +329,29 @@ private ProcessContainer(){\n \t  public static final ProcessContainer getInstance(){\n \t\treturn container;\n \t  }\n-\t  \n+\n \t  public static void putProcess(Process process){\n \t\t  getInstance().put(process.hashCode(), process);\n \t  }\n \t  public static int processSize(){\n \t\t  return getInstance().size();\n \t  }\n-\t  \n+\n \t  public static void removeProcess(Process process){\n \t\t  getInstance().remove(process.hashCode());\n \t  }\n-\t  \n+\n \t  public static void destroyAllProcess(){\n \t\t  Set<Entry<Integer, Process>> set = getInstance().entrySet();\n \t\t  for (Entry<Integer, Process> entry : set) {\n-\t\t\ttry{  \n+\t\t\ttry{\n \t\t\t  entry.getValue().destroy();\n \t\t  \t} catch (Exception e) {\n \t\t  \t\tlogger.error(\"Destroy All Processes error\", e);\n \t\t  \t}\n \t\t  }\n-\t\t  \n+\n \t\t  logger.info(\"close \" + set.size() + \" executing process tasks\");\n \t  }\n-  }\t  \n+  }\n }"
  },
  {
    "sha": "b7a6a194bc1ff4d57c929b2a112f5165eb4c88d1",
    "filename": "dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/thread/Stopper.java",
    "status": "modified",
    "additions": 3,
    "deletions": 3,
    "changes": 6,
    "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e65612dfcba6c3ec0d0c25ba3d7a05d784664d83/dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/thread/Stopper.java",
    "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e65612dfcba6c3ec0d0c25ba3d7a05d784664d83/dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/thread/Stopper.java",
    "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/thread/Stopper.java?ref=e65612dfcba6c3ec0d0c25ba3d7a05d784664d83",
    "patch": "@@ -24,15 +24,15 @@\n public class Stopper {\n \n \tprivate static AtomicBoolean signal = new AtomicBoolean(false);\n-\t\n+\n \tpublic static final boolean isStopped(){\n \t\treturn signal.get();\n \t}\n-\t\n+\n \tpublic static final boolean isRunning(){\n \t\treturn !signal.get();\n \t}\n-\t\n+\n \tpublic static final void stop(){\n \t\tsignal.set(true);\n \t}"
  },
  {
    "sha": "33c8d599a50ac320048b39048ba5d13de02284fc",
    "filename": "dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/utils/ScriptRunner.java",
    "status": "modified",
    "additions": 5,
    "deletions": 5,
    "changes": 10,
    "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e65612dfcba6c3ec0d0c25ba3d7a05d784664d83/dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/utils/ScriptRunner.java",
    "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e65612dfcba6c3ec0d0c25ba3d7a05d784664d83/dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/utils/ScriptRunner.java",
    "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/utils/ScriptRunner.java?ref=e65612dfcba6c3ec0d0c25ba3d7a05d784664d83",
    "patch": "@@ -160,12 +160,12 @@ private void runScript(Connection conn, Reader reader) throws IOException, SQLEx\n                                     logger.info(\"\");\n                                 }\n                             }\n-                        }   \n+                        }\n                     } catch (SQLException e) {\n                         logger.error(\"SQLException\", e);\n                         throw e;\n                     }\n-                    \n+\n \t\t\t\t\tcommand = null;\n \t\t\t\t\tThread.yield();\n \t\t\t\t} else {\n@@ -213,7 +213,7 @@ private void runScript(Connection conn, Reader reader , String dbName) throws IO\n \t\t\t\t\tcommand.append(\" \");\n \t\t\t\t\tsql = command.toString().replaceAll(\"\\\\{\\\\{APPDB\\\\}\\\\}\", dbName);\n                     logger.info(\"sql : {}\", sql);\n-                    \n+\n                     try (Statement statement = conn.createStatement()) {\n                         statement.execute(sql);\n                         try (ResultSet rs = statement.getResultSet()) {\n@@ -233,7 +233,7 @@ private void runScript(Connection conn, Reader reader , String dbName) throws IO\n                                     logger.info(\"\");\n                                 }\n                             }\n-                        }   \n+                        }\n                     } catch (SQLException e) {\n                         logger.error(\"SQLException\", e);\n                         throw e;\n@@ -259,5 +259,5 @@ private void runScript(Connection conn, Reader reader , String dbName) throws IO\n \tprivate String getDelimiter() {\n \t\treturn delimiter;\n \t}\n-\t\n+\n }\n\\ No newline at end of file"
  },
  {
    "sha": "e3a3fc1043b000861dcbc7d1ba130538168919c8",
    "filename": "dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/utils/VarPoolUtils.java",
    "status": "modified",
    "additions": 1,
    "deletions": 1,
    "changes": 2,
    "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e65612dfcba6c3ec0d0c25ba3d7a05d784664d83/dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/utils/VarPoolUtils.java",
    "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e65612dfcba6c3ec0d0c25ba3d7a05d784664d83/dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/utils/VarPoolUtils.java",
    "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/utils/VarPoolUtils.java?ref=e65612dfcba6c3ec0d0c25ba3d7a05d784664d83",
    "patch": "@@ -107,4 +107,4 @@ public static String convertPythonScriptPlaceholders(String rawScript) throws St\n         }\n         return rawScript;\n     }\n-} \n\\ No newline at end of file\n+}\n\\ No newline at end of file"
  },
  {
    "sha": "27fcee032040ab6f62a3f90ffab381b747b6734a",
    "filename": "dolphinscheduler-common/src/test/java/org/apache/dolphinscheduler/common/task/EntityTestUtils.java",
    "status": "modified",
    "additions": 2,
    "deletions": 2,
    "changes": 4,
    "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e65612dfcba6c3ec0d0c25ba3d7a05d784664d83/dolphinscheduler-common/src/test/java/org/apache/dolphinscheduler/common/task/EntityTestUtils.java",
    "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e65612dfcba6c3ec0d0c25ba3d7a05d784664d83/dolphinscheduler-common/src/test/java/org/apache/dolphinscheduler/common/task/EntityTestUtils.java",
    "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dolphinscheduler-common/src/test/java/org/apache/dolphinscheduler/common/task/EntityTestUtils.java?ref=e65612dfcba6c3ec0d0c25ba3d7a05d784664d83",
    "patch": "@@ -27,7 +27,7 @@\n public class EntityTestUtils {\n \n     private static final Map<String, Object> OBJECT_MAP = new HashMap<>();\n- \n+\n     private static final String SKIP_METHOD = \"getClass,notify,notifyAll,wait,equals,hashCode,clone\";\n \n     static {\n@@ -41,7 +41,7 @@\n         OBJECT_MAP.put(\"java.util.Map\", new HashMap());\n         OBJECT_MAP.put(\"boolean\", true);\n     }\n-    \n+\n     public static void run(List<Class> classList)\n             throws IllegalAccessException, InvocationTargetException, InstantiationException {\n         for (Class temp : classList) {"
  },
  {
    "sha": "20ac2b2beceedb252f3ac910b3f20577c25e68d5",
    "filename": "dolphinscheduler-common/src/test/java/org/apache/dolphinscheduler/common/utils/VarPoolUtilsTest.java",
    "status": "modified",
    "additions": 2,
    "deletions": 2,
    "changes": 4,
    "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e65612dfcba6c3ec0d0c25ba3d7a05d784664d83/dolphinscheduler-common/src/test/java/org/apache/dolphinscheduler/common/utils/VarPoolUtilsTest.java",
    "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e65612dfcba6c3ec0d0c25ba3d7a05d784664d83/dolphinscheduler-common/src/test/java/org/apache/dolphinscheduler/common/utils/VarPoolUtilsTest.java",
    "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dolphinscheduler-common/src/test/java/org/apache/dolphinscheduler/common/utils/VarPoolUtilsTest.java?ref=e65612dfcba6c3ec0d0c25ba3d7a05d784664d83",
    "patch": "@@ -29,7 +29,7 @@\n import org.slf4j.LoggerFactory;\n \n public class VarPoolUtilsTest {\n-    \n+\n     private static final Logger logger = LoggerFactory.getLogger(VarPoolUtilsTest.class);\n \n     @Test\n@@ -41,7 +41,7 @@ public void testConvertVarPoolToMap() throws Exception {\n         Assert.assertEquals((String)propToValue.get(\"p2\"), \"69\");\n         logger.info(propToValue.toString());\n     }\n-    \n+\n     @Test\n     public void testConvertPythonScriptPlaceholders() throws Exception {\n         String rawScript = \"print(${p1});\\n${setShareVar(${p1},3)};\\n${setShareVar(${p2},4)};\";"
  },
  {
    "sha": "72d9348af4ea423089be6178bcdc0137c46a5e55",
    "filename": "dolphinscheduler-dao/src/main/java/org/apache/dolphinscheduler/dao/entity/TaskInstance.java",
    "status": "modified",
    "additions": 2,
    "deletions": 2,
    "changes": 4,
    "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e65612dfcba6c3ec0d0c25ba3d7a05d784664d83/dolphinscheduler-dao/src/main/java/org/apache/dolphinscheduler/dao/entity/TaskInstance.java",
    "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e65612dfcba6c3ec0d0c25ba3d7a05d784664d83/dolphinscheduler-dao/src/main/java/org/apache/dolphinscheduler/dao/entity/TaskInstance.java",
    "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dolphinscheduler-dao/src/main/java/org/apache/dolphinscheduler/dao/entity/TaskInstance.java?ref=e65612dfcba6c3ec0d0c25ba3d7a05d784664d83",
    "patch": "@@ -216,7 +216,7 @@\n      * varPool string\n      */\n     private String varPool;\n-    \n+\n     /**\n      * executor name\n      */\n@@ -245,7 +245,7 @@ public String getVarPool() {\n     public void setVarPool(String varPool) {\n         this.varPool = varPool;\n     }\n-    \n+\n     public ProcessInstance getProcessInstance() {\n         return processInstance;\n     }"
  },
  {
    "sha": "cbd3bc26e693d90a15667c5cd5c3bec5d357f324",
    "filename": "dolphinscheduler-dao/src/main/java/org/apache/dolphinscheduler/dao/upgrade/shell/InitDolphinScheduler.java",
    "status": "modified",
    "additions": 1,
    "deletions": 1,
    "changes": 2,
    "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e65612dfcba6c3ec0d0c25ba3d7a05d784664d83/dolphinscheduler-dao/src/main/java/org/apache/dolphinscheduler/dao/upgrade/shell/InitDolphinScheduler.java",
    "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e65612dfcba6c3ec0d0c25ba3d7a05d784664d83/dolphinscheduler-dao/src/main/java/org/apache/dolphinscheduler/dao/upgrade/shell/InitDolphinScheduler.java",
    "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dolphinscheduler-dao/src/main/java/org/apache/dolphinscheduler/dao/upgrade/shell/InitDolphinScheduler.java?ref=e65612dfcba6c3ec0d0c25ba3d7a05d784664d83",
    "patch": "@@ -37,6 +37,6 @@ public static void main(String[] args) {\n \t\tDolphinSchedulerManager dolphinSchedulerManager = new DolphinSchedulerManager();\n \t\tdolphinSchedulerManager.initDolphinScheduler();\n \t\tlogger.info(\"init DolphinScheduler finished\");\n-\t\t\n+\n \t}\n }"
  },
  {
    "sha": "7e2dfcf0b59b31351246503f03e9c42f6075ced1",
    "filename": "dolphinscheduler-dao/src/main/java/org/apache/dolphinscheduler/dao/upgrade/shell/UpgradeDolphinScheduler.java",
    "status": "modified",
    "additions": 3,
    "deletions": 3,
    "changes": 6,
    "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e65612dfcba6c3ec0d0c25ba3d7a05d784664d83/dolphinscheduler-dao/src/main/java/org/apache/dolphinscheduler/dao/upgrade/shell/UpgradeDolphinScheduler.java",
    "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e65612dfcba6c3ec0d0c25ba3d7a05d784664d83/dolphinscheduler-dao/src/main/java/org/apache/dolphinscheduler/dao/upgrade/shell/UpgradeDolphinScheduler.java",
    "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dolphinscheduler-dao/src/main/java/org/apache/dolphinscheduler/dao/upgrade/shell/UpgradeDolphinScheduler.java?ref=e65612dfcba6c3ec0d0c25ba3d7a05d784664d83",
    "patch": "@@ -41,7 +41,7 @@ public static void main(String[] args) {\n \t\t\tthrow new RuntimeException(e);\n \t\t}\n \t}\n-\t\n-\t\n-\t\n+\n+\n+\n }"
  },
  {
    "sha": "290c254f796f9ab1ffb28734ec7f89b631a2693c",
    "filename": "dolphinscheduler-dao/src/main/java/org/apache/dolphinscheduler/dao/utils/PostgrePerformance.java",
    "status": "modified",
    "additions": 1,
    "deletions": 1,
    "changes": 2,
    "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e65612dfcba6c3ec0d0c25ba3d7a05d784664d83/dolphinscheduler-dao/src/main/java/org/apache/dolphinscheduler/dao/utils/PostgrePerformance.java",
    "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e65612dfcba6c3ec0d0c25ba3d7a05d784664d83/dolphinscheduler-dao/src/main/java/org/apache/dolphinscheduler/dao/utils/PostgrePerformance.java",
    "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dolphinscheduler-dao/src/main/java/org/apache/dolphinscheduler/dao/utils/PostgrePerformance.java?ref=e65612dfcba6c3ec0d0c25ba3d7a05d784664d83",
    "patch": "@@ -49,7 +49,7 @@ public MonitorRecord getMonitorRecord(Connection conn) {\n         Statement pstmt= null;\n         try{\n             pstmt = conn.createStatement();\n-            \n+\n             try (ResultSet rs1 = pstmt.executeQuery(\"select count(*) from pg_stat_activity;\")) {\n                 if(rs1.next()){\n                     monitorRecord.setThreadsConnections(rs1.getInt(\"count\"));"
  },
  {
    "sha": "e9993cd93a6cf9acebb7e7a22183a56939d481bf",
    "filename": "dolphinscheduler-dao/src/test/java/org/apache/dolphinscheduler/dao/datasource/OracleDataSourceTest.java",
    "status": "modified",
    "additions": 1,
    "deletions": 1,
    "changes": 2,
    "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e65612dfcba6c3ec0d0c25ba3d7a05d784664d83/dolphinscheduler-dao/src/test/java/org/apache/dolphinscheduler/dao/datasource/OracleDataSourceTest.java",
    "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e65612dfcba6c3ec0d0c25ba3d7a05d784664d83/dolphinscheduler-dao/src/test/java/org/apache/dolphinscheduler/dao/datasource/OracleDataSourceTest.java",
    "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dolphinscheduler-dao/src/test/java/org/apache/dolphinscheduler/dao/datasource/OracleDataSourceTest.java?ref=e65612dfcba6c3ec0d0c25ba3d7a05d784664d83",
    "patch": "@@ -71,4 +71,4 @@ public void testAppendDatabase() {\n         oracleDataSource2.appendDatabase(jdbcUrl2);\n         Assert.assertEquals(\"jdbc:oracle:thin:@127.0.0.1:1521:orcl\", jdbcUrl2.toString());\n     }\n-} \n\\ No newline at end of file\n+}\n\\ No newline at end of file"
  },
  {
    "sha": "27c1de081c2b0e1216c10c05d4ec95c0482ebb37",
    "filename": "dolphinscheduler-dao/src/test/java/org/apache/dolphinscheduler/dao/entity/UdfFuncTest.java",
    "status": "modified",
    "additions": 1,
    "deletions": 1,
    "changes": 2,
    "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e65612dfcba6c3ec0d0c25ba3d7a05d784664d83/dolphinscheduler-dao/src/test/java/org/apache/dolphinscheduler/dao/entity/UdfFuncTest.java",
    "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e65612dfcba6c3ec0d0c25ba3d7a05d784664d83/dolphinscheduler-dao/src/test/java/org/apache/dolphinscheduler/dao/entity/UdfFuncTest.java",
    "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dolphinscheduler-dao/src/test/java/org/apache/dolphinscheduler/dao/entity/UdfFuncTest.java?ref=e65612dfcba6c3ec0d0c25ba3d7a05d784664d83",
    "patch": "@@ -29,7 +29,7 @@\n    */\n   @Test\n   public void testUdfFuncToString() {\n-    \n+\n     UdfFunc udfFunc = new UdfFunc();\n     udfFunc.setResourceName(\"dolphin_resource_update\");\n     udfFunc.setResourceId(2);"
  },
  {
    "sha": "e70917c642fc72465c9a2054f054c50e220a0a52",
    "filename": "dolphinscheduler-dist/release-docs/NOTICE",
    "status": "modified",
    "additions": 5,
    "deletions": 5,
    "changes": 10,
    "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e65612dfcba6c3ec0d0c25ba3d7a05d784664d83/dolphinscheduler-dist/release-docs/NOTICE",
    "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e65612dfcba6c3ec0d0c25ba3d7a05d784664d83/dolphinscheduler-dist/release-docs/NOTICE",
    "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dolphinscheduler-dist/release-docs/NOTICE?ref=e65612dfcba6c3ec0d0c25ba3d7a05d784664d83",
    "patch": "@@ -481,8 +481,8 @@ This product includes software developed at\n The Apache Software Foundation (http://www.apache.org/).\n \n =========================================================================\n-    NOTICE file corresponding to section 4(d) of the Apache License,   \n-    Version 2.0, in this case for the Apache Xerces Java distribution. \n+    NOTICE file corresponding to section 4(d) of the Apache License,\n+    Version 2.0, in this case for the Apache Xerces Java distribution.\n =========================================================================\n \n    Apache Xerces Java\n@@ -546,7 +546,7 @@ Spring Framework\n    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n    See the License for the specific language governing permissions and\n    limitations under the License.\n-   \n+\n ========================================================================\n \n \n@@ -596,7 +596,7 @@ with the following copyright notice:\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n-  \n+\n ========================================================================\n \n \n@@ -625,7 +625,7 @@ This product contains the Piccolo XML Parser for Java\n This product contains the chunks_parse_cmds.tbl file from the vsdump program.\n Copyright (C) 2006-2007 Valek Filippov (frob@df.ru)\n \n-This product contains parts of the eID Applet project \n+This product contains parts of the eID Applet project\n <http://eid-applet.googlecode.com> and <https://github.com/e-Contract/eid-applet>.\n Copyright (c) 2009-2014\n FedICT (federal ICT department of Belgium), e-Contract.be BVBA (https://www.e-contract.be),"
  },
  {
    "sha": "5363861d826f19999ffa28493a61cd1640031b8b",
    "filename": "dolphinscheduler-dist/release-docs/licenses/LICENSE-commons-math3.txt",
    "status": "modified",
    "additions": 29,
    "deletions": 29,
    "changes": 58,
    "blob_url": "https://github.com/apache/incubator-dolphinscheduler/blob/e65612dfcba6c3ec0d0c25ba3d7a05d784664d83/dolphinscheduler-dist/release-docs/licenses/LICENSE-commons-math3.txt",
    "raw_url": "https://github.com/apache/incubator-dolphinscheduler/raw/e65612dfcba6c3ec0d0c25ba3d7a05d784664d83/dolphinscheduler-dist/release-docs/licenses/LICENSE-commons-math3.txt",
    "contents_url": "https://api.github.com/repos/apache/incubator-dolphinscheduler/contents/dolphinscheduler-dist/release-docs/licenses/LICENSE-commons-math3.txt?ref=e65612dfcba6c3ec0d0c25ba3d7a05d784664d83",
    "patch": "@@ -202,7 +202,7 @@\n    limitations under the License.\n \n \n-APACHE COMMONS MATH DERIVATIVE WORKS: \n+APACHE COMMONS MATH DERIVATIVE WORKS:\n \n The Apache commons-math library includes a number of subcomponents\n whose implementation is derived from original sources written\n@@ -212,7 +212,7 @@ are reproduced below.\n ===============================================================================\n For the lmder, lmpar and qrsolv Fortran routine from minpack and translated in\n the LevenbergMarquardtOptimizer class in package\n-org.apache.commons.math3.optimization.general \n+org.apache.commons.math3.optimization.general\n Original source copyright and license statement:\n \n Minpack Copyright Notice (1999) University of Chicago.  All rights reserved\n@@ -275,27 +275,27 @@ in package org.apache.commons.math3.ode.nonstiff:\n \n Copyright (c) 2004, Ernst Hairer\n \n-Redistribution and use in source and binary forms, with or without \n-modification, are permitted provided that the following conditions are \n+Redistribution and use in source and binary forms, with or without\n+modification, are permitted provided that the following conditions are\n met:\n \n-- Redistributions of source code must retain the above copyright \n+- Redistributions of source code must retain the above copyright\n notice, this list of conditions and the following disclaimer.\n \n-- Redistributions in binary form must reproduce the above copyright \n-notice, this list of conditions and the following disclaimer in the \n+- Redistributions in binary form must reproduce the above copyright\n+notice, this list of conditions and the following disclaimer in the\n documentation and/or other materials provided with the distribution.\n \n-THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS \n-IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED \n-TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A \n-PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE REGENTS OR \n-CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, \n-EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, \n-PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR \n-PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF \n-LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING \n-NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS \n+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS\n+IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED\n+TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A\n+PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE REGENTS OR\n+CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,\n+EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,\n+PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR\n+PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF\n+LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING\n+NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\n SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n ===============================================================================\n \n@@ -316,36 +316,36 @@ modification, are permitted provided that the following conditions are\n met:\n \n - Redistributions of source code must retain the above copyright\n-  notice, this list of conditions and the following disclaimer. \n-  \n+  notice, this list of conditions and the following disclaimer.\n+\n - Redistributions in binary form must reproduce the above copyright\n   notice, this list of conditions and the following disclaimer listed\n   in this license in the documentation and/or other materials\n   provided with the distribution.\n-  \n+\n - Neither the name of the copyright holders nor the names of its\n   contributors may be used to endorse or promote products derived from\n   this software without specific prior written permission.\n-  \n+\n THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n-\"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT  \n+\"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\n LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\n-A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT \n+A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\n OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\n LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n-THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT  \n+THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n-OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. \n+OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n ===============================================================================\n \n Copyright and license statement for the original Mersenne twister C\n-routines translated in MersenneTwister class in package \n+routines translated in MersenneTwister class in package\n org.apache.commons.math3.random:\n \n    Copyright (C) 1997 - 2002, Makoto Matsumoto and Takuji Nishimura,\n-   All rights reserved.                          \n+   All rights reserved.\n \n    Redistribution and use in source and binary forms, with or without\n    modification, are permitted provided that the following conditions\n@@ -358,8 +358,8 @@ org.apache.commons.math3.random:\n         notice, this list of conditions and the following disclaimer in the\n         documentation and/or other materials provided with the distribution.\n \n-     3. The names of its contributors may not be used to endorse or promote \n-        products derived from this software without specific prior written \n+     3. The names of its contributors may not be used to endorse or promote\n+        products derived from this software without specific prior written\n         permission.\n \n    THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS"
  }
]
