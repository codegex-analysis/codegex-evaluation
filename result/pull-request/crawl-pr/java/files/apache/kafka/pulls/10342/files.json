[
  {
    "sha": "f375fb0f6e0173ed7c492a43f178ba41150ad90e",
    "filename": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java",
    "status": "modified",
    "additions": 9,
    "deletions": 1,
    "changes": 10,
    "blob_url": "https://github.com/apache/kafka/blob/518a1c894fc44f2cd0ba0e152ecd516c539ba780/streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java",
    "raw_url": "https://github.com/apache/kafka/raw/518a1c894fc44f2cd0ba0e152ecd516c539ba780/streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java",
    "contents_url": "https://api.github.com/repos/apache/kafka/contents/streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java?ref=518a1c894fc44f2cd0ba0e152ecd516c539ba780",
    "patch": "@@ -61,6 +61,7 @@\n import org.apache.kafka.streams.processor.internals.ProcessorTopology;\n import org.apache.kafka.streams.processor.internals.StateDirectory;\n import org.apache.kafka.streams.processor.internals.StreamThread;\n+import org.apache.kafka.streams.processor.internals.StreamThread.State;\n import org.apache.kafka.streams.processor.internals.StreamsMetadataState;\n import org.apache.kafka.streams.processor.internals.Task;\n import org.apache.kafka.streams.processor.internals.ThreadStateTransitionValidator;\n@@ -1227,7 +1228,14 @@ public synchronized void start() throws IllegalStateException, StreamsException\n             stateDirCleaner.scheduleAtFixedRate(() -> {\n                 // we do not use lock here since we only read on the value and act on it\n                 if (state == State.RUNNING) {\n-                    stateDirectory.cleanRemovedTasks(cleanupDelay);\n+                    // Pass in the thread names so the cleanup thread can check for orphaned task directories\n+                    final Set<String> nonDeadStreamThreadNames = new HashSet<>();\n+                    processStreamThread(thread -> {\n+                        if (thread.state() != StreamThread.State.DEAD) {\n+                            nonDeadStreamThreadNames.add(thread.getName());\n+                        }\n+                    });\n+                    stateDirectory.cleanRemovedTasks(cleanupDelay, nonDeadStreamThreadNames);\n                 }\n             }, cleanupDelay, cleanupDelay, TimeUnit.MILLISECONDS);\n "
  },
  {
    "sha": "2b75d8ddcb5795c8606463cbdf202870c84131b6",
    "filename": "streams/src/main/java/org/apache/kafka/streams/processor/internals/ProcessorStateManager.java",
    "status": "modified",
    "additions": 1,
    "deletions": 1,
    "changes": 2,
    "blob_url": "https://github.com/apache/kafka/blob/518a1c894fc44f2cd0ba0e152ecd516c539ba780/streams/src/main/java/org/apache/kafka/streams/processor/internals/ProcessorStateManager.java",
    "raw_url": "https://github.com/apache/kafka/raw/518a1c894fc44f2cd0ba0e152ecd516c539ba780/streams/src/main/java/org/apache/kafka/streams/processor/internals/ProcessorStateManager.java",
    "contents_url": "https://api.github.com/repos/apache/kafka/contents/streams/src/main/java/org/apache/kafka/streams/processor/internals/ProcessorStateManager.java?ref=518a1c894fc44f2cd0ba0e152ecd516c539ba780",
    "patch": "@@ -186,7 +186,7 @@ public ProcessorStateManager(final TaskId taskId,\n         this.changelogReader = changelogReader;\n         this.sourcePartitions = sourcePartitions;\n \n-        this.baseDir = stateDirectory.directoryForTask(taskId);\n+        this.baseDir = stateDirectory.getOrCreateDirectoryForTask(taskId);\n         this.checkpointFile = new OffsetCheckpoint(stateDirectory.checkpointFileFor(taskId));\n \n         log.debug(\"Created state store manager for task {}\", taskId);"
  },
  {
    "sha": "55bda907ebb6d4b3204ee100d1fb52b5a0b3421e",
    "filename": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StateDirectory.java",
    "status": "modified",
    "additions": 45,
    "deletions": 89,
    "changes": 134,
    "blob_url": "https://github.com/apache/kafka/blob/518a1c894fc44f2cd0ba0e152ecd516c539ba780/streams/src/main/java/org/apache/kafka/streams/processor/internals/StateDirectory.java",
    "raw_url": "https://github.com/apache/kafka/raw/518a1c894fc44f2cd0ba0e152ecd516c539ba780/streams/src/main/java/org/apache/kafka/streams/processor/internals/StateDirectory.java",
    "contents_url": "https://api.github.com/repos/apache/kafka/contents/streams/src/main/java/org/apache/kafka/streams/processor/internals/StateDirectory.java?ref=518a1c894fc44f2cd0ba0e152ecd516c539ba780",
    "patch": "@@ -85,25 +85,14 @@ public StateDirectoryProcessFile() {\n     private final File stateDir;\n     private final boolean hasPersistentStores;\n \n-    private final HashMap<TaskId, FileChannel> channels = new HashMap<>();\n-    private final HashMap<TaskId, LockAndOwner> locks = new HashMap<>();\n+    private final HashMap<TaskId, String> lockedTasksToStreamThreadOwner = new HashMap<>();\n \n     private FileChannel stateDirLockChannel;\n     private FileLock stateDirLock;\n \n     private FileChannel globalStateChannel;\n     private FileLock globalStateLock;\n \n-    private static class LockAndOwner {\n-        final FileLock lock;\n-        final String owningThread;\n-\n-        LockAndOwner(final String owningThread, final FileLock lock) {\n-            this.owningThread = owningThread;\n-            this.lock = lock;\n-        }\n-    }\n-\n     /**\n      * Ensures that the state base directory as well as the application's sub-directory are created.\n      *\n@@ -224,7 +213,7 @@ public UUID initializeProcessId() {\n      * @return directory for the {@link TaskId}\n      * @throws ProcessorStateException if the task directory does not exists and could not be created\n      */\n-    public File directoryForTask(final TaskId taskId) {\n+    public File getOrCreateDirectoryForTask(final TaskId taskId) {\n         final File taskDir = new File(stateDir, taskId.toString());\n         if (hasPersistentStores && !taskDir.exists()) {\n             synchronized (taskDirCreationLock) {\n@@ -245,14 +234,14 @@ public File directoryForTask(final TaskId taskId) {\n      * @return The File handle for the checkpoint in the given task's directory\n      */\n     File checkpointFileFor(final TaskId taskId) {\n-        return new File(directoryForTask(taskId), StateManagerUtil.CHECKPOINT_FILE_NAME);\n+        return new File(getOrCreateDirectoryForTask(taskId), StateManagerUtil.CHECKPOINT_FILE_NAME);\n     }\n \n     /**\n      * Decide if the directory of the task is empty or not\n      */\n     boolean directoryForTaskIsEmpty(final TaskId taskId) {\n-        final File taskDir = directoryForTask(taskId);\n+        final File taskDir = getOrCreateDirectoryForTask(taskId);\n \n         return taskDirEmpty(taskDir);\n     }\n@@ -288,50 +277,31 @@ private String logPrefix() {\n      * Get the lock for the {@link TaskId}s directory if it is available\n      * @param taskId task id\n      * @return true if successful\n-     * @throws IOException if the file cannot be created or file handle cannot be grabbed, should be considered as fatal\n      */\n-    synchronized boolean lock(final TaskId taskId) throws IOException {\n+    synchronized boolean lock(final TaskId taskId) {\n         if (!hasPersistentStores) {\n             return true;\n         }\n \n-        final File lockFile;\n-        // we already have the lock so bail out here\n-        final LockAndOwner lockAndOwner = locks.get(taskId);\n-        if (lockAndOwner != null && lockAndOwner.owningThread.equals(Thread.currentThread().getName())) {\n-            log.trace(\"{} Found cached state dir lock for task {}\", logPrefix(), taskId);\n+        final String lockOwner = lockedTasksToStreamThreadOwner.get(taskId);\n+        if (lockOwner != null) {\n+            if (lockOwner.equals(Thread.currentThread().getName())) {\n+                log.trace(\"{} Found cached state dir lock for task {}\", logPrefix(), taskId);\n+                // we already own the lock\n+                return true;\n+            } else {\n+                // another thread owns the lock\n+                return false;\n+            }\n+        } else if (!stateDir.exists()) {\n+            log.error(\"Tried to lock task directory for {} but the state directory does not exist\", taskId);\n+            throw new IllegalStateException(\"The state directory has been deleted\");\n+        } else {\n+            lockedTasksToStreamThreadOwner.put(taskId, Thread.currentThread().getName());\n+            // make sure the task directory actually exists, and create it if not\n+            getOrCreateDirectoryForTask(taskId);\n             return true;\n-        } else if (lockAndOwner != null) {\n-            // another thread owns the lock\n-            return false;\n-        }\n-\n-        try {\n-            lockFile = new File(directoryForTask(taskId), LOCK_FILE_NAME);\n-        } catch (final ProcessorStateException e) {\n-            // directoryForTask could be throwing an exception if another thread\n-            // has concurrently deleted the directory\n-            return false;\n-        }\n-\n-        final FileChannel channel;\n-\n-        try {\n-            channel = getOrCreateFileChannel(taskId, lockFile.toPath());\n-        } catch (final NoSuchFileException e) {\n-            // FileChannel.open(..) could throw NoSuchFileException when there is another thread\n-            // concurrently deleting the parent directory (i.e. the directory of the taskId) of the lock\n-            // file, in this case we will return immediately indicating locking failed.\n-            return false;\n-        }\n-\n-        final FileLock lock = tryLock(channel);\n-        if (lock != null) {\n-            locks.put(taskId, new LockAndOwner(Thread.currentThread().getName(), lock));\n-\n-            log.debug(\"{} Acquired state dir lock for task {}\", logPrefix(), taskId);\n         }\n-        return lock != null;\n     }\n \n     synchronized boolean lockGlobalState() throws IOException {\n@@ -382,17 +352,11 @@ synchronized void unlockGlobalState() throws IOException {\n     /**\n      * Unlock the state directory for the given {@link TaskId}.\n      */\n-    synchronized void unlock(final TaskId taskId) throws IOException {\n-        final LockAndOwner lockAndOwner = locks.get(taskId);\n-        if (lockAndOwner != null && lockAndOwner.owningThread.equals(Thread.currentThread().getName())) {\n-            locks.remove(taskId);\n-            lockAndOwner.lock.release();\n+    synchronized void unlock(final TaskId taskId) {\n+        final String lockOwner = lockedTasksToStreamThreadOwner.get(taskId);\n+        if (lockOwner != null && lockOwner.equals(Thread.currentThread().getName())) {\n+            lockedTasksToStreamThreadOwner.remove(taskId);\n             log.debug(\"{} Released state dir lock for task {}\", logPrefix(), taskId);\n-\n-            final FileChannel fileChannel = channels.remove(taskId);\n-            if (fileChannel != null) {\n-                fileChannel.close();\n-            }\n         }\n     }\n \n@@ -410,8 +374,8 @@ public void close() {\n             }\n \n             // all threads should be stopped and cleaned up by now, so none should remain holding a lock\n-            if (locks.isEmpty()) {\n-                log.error(\"Some task directories still locked while closing state, this indicates unclean shutdown: {}\", locks);\n+            if (lockedTasksToStreamThreadOwner.isEmpty()) {\n+                log.error(\"Some task directories still locked while closing state, this indicates unclean shutdown: {}\", lockedTasksToStreamThreadOwner);\n             }\n             if (globalStateLock != null) {\n                 log.error(\"Global state lock is present while closing the state, this indicates unclean shutdown\");\n@@ -444,22 +408,30 @@ public synchronized void clean() {\n      * Remove the directories for any {@link TaskId}s that are no-longer\n      * owned by this {@link StreamThread} and aren't locked by either\n      * another process or another {@link StreamThread}\n-     * @param cleanupDelayMs only remove directories if they haven't been modified for at least\n-     *                       this amount of time (milliseconds)\n+     * @param cleanupDelayMs        only remove directories if they haven't been modified for at least\n+     *                              this amount of time (milliseconds)\n+     * @param currentThreadNames    the names of all non-DEAD stream threads so we can clean up any\n+     *                              orphaned task directories\n      */\n-    public synchronized void cleanRemovedTasks(final long cleanupDelayMs) {\n+    public synchronized void cleanRemovedTasks(final long cleanupDelayMs, final Set<String> currentThreadNames) {\n         try {\n-            cleanRemovedTasksCalledByCleanerThread(cleanupDelayMs);\n+            cleanRemovedTasksCalledByCleanerThread(cleanupDelayMs, currentThreadNames);\n         } catch (final Exception cannotHappen) {\n             throw new IllegalStateException(\"Should have swallowed exception.\", cannotHappen);\n         }\n     }\n \n-    private void cleanRemovedTasksCalledByCleanerThread(final long cleanupDelayMs) {\n+    private void cleanRemovedTasksCalledByCleanerThread(final long cleanupDelayMs, final Set<String> currentThreadNames) {\n         for (final File taskDir : listNonEmptyTaskDirectories()) {\n             final String dirName = taskDir.getName();\n             final TaskId id = TaskId.parse(dirName);\n-            if (!locks.containsKey(id)) {\n+\n+            final String owningThread = lockedTasksToStreamThreadOwner.get(id);\n+            if (owningThread != null && !currentThreadNames.contains(owningThread)) {\n+                log.warn(\"Deleting lock for task directory {} since the thread owning the lock is gone: {}\", id, owningThread);\n+                lockedTasksToStreamThreadOwner.remove(id);\n+            }\n+            if (!lockedTasksToStreamThreadOwner.containsKey(id)) {\n                 try {\n                     if (lock(id)) {\n                         final long now = time.milliseconds();\n@@ -470,22 +442,14 @@ private void cleanRemovedTasksCalledByCleanerThread(final long cleanupDelayMs) {\n                             Utils.delete(taskDir, Collections.singletonList(new File(taskDir, LOCK_FILE_NAME)));\n                         }\n                     }\n-                } catch (final OverlappingFileLockException | IOException exception) {\n+                } catch (final IOException exception) {\n                     log.warn(\n                         String.format(\"%s Swallowed the following exception during deletion of obsolete state directory %s for task %s:\",\n                             logPrefix(), dirName, id),\n                         exception\n                     );\n                 } finally {\n-                    try {\n-                        unlock(id);\n-                    } catch (final IOException exception) {\n-                        log.warn(\n-                            String.format(\"%s Swallowed the following exception during unlocking after deletion of obsolete \" +\n-                                \"state directory %s for task %s:\", logPrefix(), dirName, id),\n-                            exception\n-                        );\n-                    }\n+                    unlock(id);\n                 }\n             }\n         }\n@@ -496,7 +460,7 @@ private void cleanRemovedTasksCalledByUser() throws Exception {\n         for (final File taskDir : listAllTaskDirectories()) {\n             final String dirName = taskDir.getName();\n             final TaskId id = TaskId.parse(dirName);\n-            if (!locks.containsKey(id)) {\n+            if (!lockedTasksToStreamThreadOwner.containsKey(id)) {\n                 try {\n                     if (lock(id)) {\n                         log.info(\"{} Deleting state directory {} for task {} as user calling cleanup.\",\n@@ -575,14 +539,6 @@ private void cleanRemovedTasksCalledByUser() throws Exception {\n         return taskDirectories == null ? new File[0] : taskDirectories;\n     }\n \n-    private FileChannel getOrCreateFileChannel(final TaskId taskId,\n-                                               final Path lockPath) throws IOException {\n-        if (!channels.containsKey(taskId)) {\n-            channels.put(taskId, FileChannel.open(lockPath, StandardOpenOption.CREATE, StandardOpenOption.WRITE));\n-        }\n-        return channels.get(taskId);\n-    }\n-\n     private FileLock tryLock(final FileChannel channel) throws IOException {\n         try {\n             return channel.tryLock();"
  },
  {
    "sha": "64bec567f0497fae3fdf144f3efafb01fa184cc8",
    "filename": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StateManagerUtil.java",
    "status": "modified",
    "additions": 2,
    "deletions": 9,
    "changes": 11,
    "blob_url": "https://github.com/apache/kafka/blob/518a1c894fc44f2cd0ba0e152ecd516c539ba780/streams/src/main/java/org/apache/kafka/streams/processor/internals/StateManagerUtil.java",
    "raw_url": "https://github.com/apache/kafka/raw/518a1c894fc44f2cd0ba0e152ecd516c539ba780/streams/src/main/java/org/apache/kafka/streams/processor/internals/StateManagerUtil.java",
    "contents_url": "https://api.github.com/repos/apache/kafka/contents/streams/src/main/java/org/apache/kafka/streams/processor/internals/StateManagerUtil.java?ref=518a1c894fc44f2cd0ba0e152ecd516c539ba780",
    "patch": "@@ -86,15 +86,8 @@ static void registerStateStores(final Logger log,\n         }\n \n         final TaskId id = stateMgr.taskId();\n-        try {\n-            if (!stateDirectory.lock(id)) {\n-                throw new LockException(String.format(\"%sFailed to lock the state directory for task %s\", logPrefix, id));\n-            }\n-        } catch (final IOException e) {\n-            throw new StreamsException(\n-                String.format(\"%sFatal error while trying to lock the state directory for task %s\", logPrefix, id),\n-                e\n-            );\n+        if (!stateDirectory.lock(id)) {\n+            throw new LockException(String.format(\"%sFailed to lock the state directory for task %s\", logPrefix, id));\n         }\n         log.debug(\"Acquired state directory lock\");\n "
  },
  {
    "sha": "25596ed3cb81a0496f9e5d8640b93d1b4463e7eb",
    "filename": "streams/src/main/java/org/apache/kafka/streams/processor/internals/TaskManager.java",
    "status": "modified",
    "additions": 6,
    "deletions": 17,
    "changes": 23,
    "blob_url": "https://github.com/apache/kafka/blob/518a1c894fc44f2cd0ba0e152ecd516c539ba780/streams/src/main/java/org/apache/kafka/streams/processor/internals/TaskManager.java",
    "raw_url": "https://github.com/apache/kafka/raw/518a1c894fc44f2cd0ba0e152ecd516c539ba780/streams/src/main/java/org/apache/kafka/streams/processor/internals/TaskManager.java",
    "contents_url": "https://api.github.com/repos/apache/kafka/contents/streams/src/main/java/org/apache/kafka/streams/processor/internals/TaskManager.java?ref=518a1c894fc44f2cd0ba0e152ecd516c539ba780",
    "patch": "@@ -658,16 +658,11 @@ private void tryToLockAllNonEmptyTaskDirectories() {\n         for (final File dir : stateDirectory.listNonEmptyTaskDirectories()) {\n             try {\n                 final TaskId id = TaskId.parse(dir.getName());\n-                try {\n-                    if (stateDirectory.lock(id)) {\n-                        lockedTaskDirectories.add(id);\n-                        if (!tasks.owned(id)) {\n-                            log.debug(\"Temporarily locked unassigned task {} for the upcoming rebalance\", id);\n-                        }\n+                if (stateDirectory.lock(id)) {\n+                    lockedTaskDirectories.add(id);\n+                    if (!tasks.owned(id)) {\n+                        log.debug(\"Temporarily locked unassigned task {} for the upcoming rebalance\", id);\n                     }\n-                } catch (final IOException e) {\n-                    // if for any reason we can't lock this task dir, just move on\n-                    log.warn(String.format(\"Exception caught while attempting to lock task %s:\", id), e);\n                 }\n             } catch (final TaskIdFormatException e) {\n                 // ignore any unknown files that sit in the same directory\n@@ -686,14 +681,8 @@ private void releaseLockedUnassignedTaskDirectories() {\n         while (taskIdIterator.hasNext()) {\n             final TaskId id = taskIdIterator.next();\n             if (!tasks.owned(id)) {\n-                try {\n-                    stateDirectory.unlock(id);\n-                    taskIdIterator.remove();\n-                } catch (final IOException e) {\n-                    log.error(String.format(\"Caught the following exception while trying to unlock task %s\", id), e);\n-                    firstException.compareAndSet(null,\n-                        new StreamsException(String.format(\"Failed to unlock task directory %s\", id), e));\n-                }\n+                stateDirectory.unlock(id);\n+                taskIdIterator.remove();\n             }\n         }\n "
  },
  {
    "sha": "f9cfc0a7fd8cdf4d05133b49daaf7194bc834ba7",
    "filename": "streams/src/test/java/org/apache/kafka/streams/integration/RestoreIntegrationTest.java",
    "status": "modified",
    "additions": 4,
    "deletions": 4,
    "changes": 8,
    "blob_url": "https://github.com/apache/kafka/blob/518a1c894fc44f2cd0ba0e152ecd516c539ba780/streams/src/test/java/org/apache/kafka/streams/integration/RestoreIntegrationTest.java",
    "raw_url": "https://github.com/apache/kafka/raw/518a1c894fc44f2cd0ba0e152ecd516c539ba780/streams/src/test/java/org/apache/kafka/streams/integration/RestoreIntegrationTest.java",
    "contents_url": "https://api.github.com/repos/apache/kafka/contents/streams/src/test/java/org/apache/kafka/streams/integration/RestoreIntegrationTest.java?ref=518a1c894fc44f2cd0ba0e152ecd516c539ba780",
    "patch": "@@ -143,9 +143,9 @@ public void shouldRestoreStateFromSourceTopic() throws Exception {\n \n         final StateDirectory stateDirectory = new StateDirectory(new StreamsConfig(props), new MockTime(), true);\n         // note here the checkpointed offset is the last processed record's offset, so without control message we should write this offset - 1\n-        new OffsetCheckpoint(new File(stateDirectory.directoryForTask(new TaskId(0, 0)), \".checkpoint\"))\n+        new OffsetCheckpoint(new File(stateDirectory.getOrCreateDirectoryForTask(new TaskId(0, 0)), \".checkpoint\"))\n                 .write(Collections.singletonMap(new TopicPartition(inputStream, 0), (long) offsetCheckpointed - 1));\n-        new OffsetCheckpoint(new File(stateDirectory.directoryForTask(new TaskId(0, 1)), \".checkpoint\"))\n+        new OffsetCheckpoint(new File(stateDirectory.getOrCreateDirectoryForTask(new TaskId(0, 1)), \".checkpoint\"))\n                 .write(Collections.singletonMap(new TopicPartition(inputStream, 1), (long) offsetCheckpointed - 1));\n \n         final CountDownLatch startupLatch = new CountDownLatch(1);\n@@ -209,9 +209,9 @@ public void shouldRestoreStateFromChangelogTopic() throws Exception {\n \n         final StateDirectory stateDirectory = new StateDirectory(new StreamsConfig(props), new MockTime(), true);\n         // note here the checkpointed offset is the last processed record's offset, so without control message we should write this offset - 1\n-        new OffsetCheckpoint(new File(stateDirectory.directoryForTask(new TaskId(0, 0)), \".checkpoint\"))\n+        new OffsetCheckpoint(new File(stateDirectory.getOrCreateDirectoryForTask(new TaskId(0, 0)), \".checkpoint\"))\n                 .write(Collections.singletonMap(new TopicPartition(changelog, 0), (long) offsetCheckpointed - 1));\n-        new OffsetCheckpoint(new File(stateDirectory.directoryForTask(new TaskId(0, 1)), \".checkpoint\"))\n+        new OffsetCheckpoint(new File(stateDirectory.getOrCreateDirectoryForTask(new TaskId(0, 1)), \".checkpoint\"))\n                 .write(Collections.singletonMap(new TopicPartition(changelog, 1), (long) offsetCheckpointed - 1));\n \n         final CountDownLatch startupLatch = new CountDownLatch(1);"
  },
  {
    "sha": "80ba85ed5400830a8f1ec7406e9e983afcde6de5",
    "filename": "streams/src/test/java/org/apache/kafka/streams/integration/StandbyTaskEOSIntegrationTest.java",
    "status": "modified",
    "additions": 2,
    "deletions": 2,
    "changes": 4,
    "blob_url": "https://github.com/apache/kafka/blob/518a1c894fc44f2cd0ba0e152ecd516c539ba780/streams/src/test/java/org/apache/kafka/streams/integration/StandbyTaskEOSIntegrationTest.java",
    "raw_url": "https://github.com/apache/kafka/raw/518a1c894fc44f2cd0ba0e152ecd516c539ba780/streams/src/test/java/org/apache/kafka/streams/integration/StandbyTaskEOSIntegrationTest.java",
    "contents_url": "https://api.github.com/repos/apache/kafka/contents/streams/src/test/java/org/apache/kafka/streams/integration/StandbyTaskEOSIntegrationTest.java?ref=518a1c894fc44f2cd0ba0e152ecd516c539ba780",
    "patch": "@@ -177,10 +177,10 @@ private KafkaStreams buildStreamWithDirtyStateDir(final String stateDirPath,\n         final StateDirectory stateDirectory = new StateDirectory(\n             new StreamsConfig(props), new MockTime(), true);\n \n-        new OffsetCheckpoint(new File(stateDirectory.directoryForTask(taskId), \".checkpoint\"))\n+        new OffsetCheckpoint(new File(stateDirectory.getOrCreateDirectoryForTask(taskId), \".checkpoint\"))\n             .write(Collections.singletonMap(new TopicPartition(\"unknown-topic\", 0), 5L));\n \n-        assertTrue(new File(stateDirectory.directoryForTask(taskId),\n+        assertTrue(new File(stateDirectory.getOrCreateDirectoryForTask(taskId),\n                             \"rocksdb/KSTREAM-AGGREGATE-STATE-STORE-0000000001\").mkdirs());\n \n         builder.stream(inputTopic,"
  },
  {
    "sha": "3541c10cae2c4a9d4e1949e4e3c321d192f12acd",
    "filename": "streams/src/test/java/org/apache/kafka/streams/processor/internals/ActiveTaskCreatorTest.java",
    "status": "modified",
    "additions": 2,
    "deletions": 2,
    "changes": 4,
    "blob_url": "https://github.com/apache/kafka/blob/518a1c894fc44f2cd0ba0e152ecd516c539ba780/streams/src/test/java/org/apache/kafka/streams/processor/internals/ActiveTaskCreatorTest.java",
    "raw_url": "https://github.com/apache/kafka/raw/518a1c894fc44f2cd0ba0e152ecd516c539ba780/streams/src/test/java/org/apache/kafka/streams/processor/internals/ActiveTaskCreatorTest.java",
    "contents_url": "https://api.github.com/repos/apache/kafka/contents/streams/src/test/java/org/apache/kafka/streams/processor/internals/ActiveTaskCreatorTest.java?ref=518a1c894fc44f2cd0ba0e152ecd516c539ba780",
    "patch": "@@ -442,9 +442,9 @@ private void createTasks() {\n \n         reset(builder, stateDirectory);\n         expect(builder.buildSubtopology(0)).andReturn(topology).anyTimes();\n-        expect(stateDirectory.directoryForTask(task00)).andReturn(mock(File.class));\n+        expect(stateDirectory.getOrCreateDirectoryForTask(task00)).andReturn(mock(File.class));\n         expect(stateDirectory.checkpointFileFor(task00)).andReturn(mock(File.class));\n-        expect(stateDirectory.directoryForTask(task01)).andReturn(mock(File.class));\n+        expect(stateDirectory.getOrCreateDirectoryForTask(task01)).andReturn(mock(File.class));\n         expect(stateDirectory.checkpointFileFor(task01)).andReturn(mock(File.class));\n         expect(topology.storeToChangelogTopic()).andReturn(Collections.emptyMap()).anyTimes();\n         expect(topology.source(\"topic\")).andReturn(sourceNode).anyTimes();"
  },
  {
    "sha": "cf6c61a9a17f8f1dc6e0f09ac684e1a9dbf2cfa3",
    "filename": "streams/src/test/java/org/apache/kafka/streams/processor/internals/ProcessorStateManagerTest.java",
    "status": "modified",
    "additions": 2,
    "deletions": 2,
    "changes": 4,
    "blob_url": "https://github.com/apache/kafka/blob/518a1c894fc44f2cd0ba0e152ecd516c539ba780/streams/src/test/java/org/apache/kafka/streams/processor/internals/ProcessorStateManagerTest.java",
    "raw_url": "https://github.com/apache/kafka/raw/518a1c894fc44f2cd0ba0e152ecd516c539ba780/streams/src/test/java/org/apache/kafka/streams/processor/internals/ProcessorStateManagerTest.java",
    "contents_url": "https://api.github.com/repos/apache/kafka/contents/streams/src/test/java/org/apache/kafka/streams/processor/internals/ProcessorStateManagerTest.java?ref=518a1c894fc44f2cd0ba0e152ecd516c539ba780",
    "patch": "@@ -135,7 +135,7 @@ public void setup() {\n                 put(StreamsConfig.STATE_DIR_CONFIG, baseDir.getPath());\n             }\n         }), new MockTime(), true);\n-        checkpointFile = new File(stateDirectory.directoryForTask(taskId), CHECKPOINT_FILE_NAME);\n+        checkpointFile = new File(stateDirectory.getOrCreateDirectoryForTask(taskId), CHECKPOINT_FILE_NAME);\n         checkpoint = new OffsetCheckpoint(checkpointFile);\n \n         expect(storeMetadata.changelogPartition()).andReturn(persistentStorePartition).anyTimes();\n@@ -163,7 +163,7 @@ public void shouldReturnDefaultChangelogTopicName() {\n     @Test\n     public void shouldReturnBaseDir() {\n         final ProcessorStateManager stateMgr = getStateManager(Task.TaskType.ACTIVE);\n-        assertEquals(stateDirectory.directoryForTask(taskId), stateMgr.baseDir());\n+        assertEquals(stateDirectory.getOrCreateDirectoryForTask(taskId), stateMgr.baseDir());\n     }\n \n     // except this test for all other tests active / standby state managers acts the same, so"
  },
  {
    "sha": "d3272a724f446075322d9679857dd07fae9f4693",
    "filename": "streams/src/test/java/org/apache/kafka/streams/processor/internals/StateDirectoryTest.java",
    "status": "modified",
    "additions": 38,
    "deletions": 81,
    "changes": 119,
    "blob_url": "https://github.com/apache/kafka/blob/518a1c894fc44f2cd0ba0e152ecd516c539ba780/streams/src/test/java/org/apache/kafka/streams/processor/internals/StateDirectoryTest.java",
    "raw_url": "https://github.com/apache/kafka/raw/518a1c894fc44f2cd0ba0e152ecd516c539ba780/streams/src/test/java/org/apache/kafka/streams/processor/internals/StateDirectoryTest.java",
    "contents_url": "https://api.github.com/repos/apache/kafka/contents/streams/src/test/java/org/apache/kafka/streams/processor/internals/StateDirectoryTest.java?ref=518a1c894fc44f2cd0ba0e152ecd516c539ba780",
    "patch": "@@ -152,33 +152,15 @@ private void assertPermissions(final File file) {\n     @Test\n     public void shouldCreateTaskStateDirectory() {\n         final TaskId taskId = new TaskId(0, 0);\n-        final File taskDirectory = directory.directoryForTask(taskId);\n+        final File taskDirectory = directory.getOrCreateDirectoryForTask(taskId);\n         assertTrue(taskDirectory.exists());\n         assertTrue(taskDirectory.isDirectory());\n     }\n \n     @Test\n-    public void shouldLockTaskStateDirectory() throws IOException {\n+    public void shouldBeTrueIfAlreadyHoldsLock() {\n         final TaskId taskId = new TaskId(0, 0);\n-        final File taskDirectory = directory.directoryForTask(taskId);\n-\n-        directory.lock(taskId);\n-\n-        try (\n-            final FileChannel channel = FileChannel.open(\n-                new File(taskDirectory, LOCK_FILE_NAME).toPath(),\n-                StandardOpenOption.CREATE, StandardOpenOption.WRITE)\n-        ) {\n-            assertThrows(OverlappingFileLockException.class, channel::tryLock);\n-        } finally {\n-            directory.unlock(taskId);\n-        }\n-    }\n-\n-    @Test\n-    public void shouldBeTrueIfAlreadyHoldsLock() throws IOException {\n-        final TaskId taskId = new TaskId(0, 0);\n-        directory.directoryForTask(taskId);\n+        directory.getOrCreateDirectoryForTask(taskId);\n         directory.lock(taskId);\n         try {\n             assertTrue(directory.lock(taskId));\n@@ -188,7 +170,7 @@ public void shouldBeTrueIfAlreadyHoldsLock() throws IOException {\n     }\n \n     @Test\n-    public void shouldBeAbleToUnlockEvenWithoutLocking() throws IOException {\n+    public void shouldBeAbleToUnlockEvenWithoutLocking() {\n         final TaskId taskId = new TaskId(0, 0);\n         directory.unlock(taskId);\n     }\n@@ -205,14 +187,14 @@ public void shouldReportDirectoryEmpty() throws IOException {\n         assertTrue(directory.directoryForTaskIsEmpty(taskId));\n \n         // after writing checkpoint, it should still be empty\n-        final OffsetCheckpoint checkpointFile = new OffsetCheckpoint(new File(directory.directoryForTask(taskId), CHECKPOINT_FILE_NAME));\n+        final OffsetCheckpoint checkpointFile = new OffsetCheckpoint(new File(directory.getOrCreateDirectoryForTask(taskId), CHECKPOINT_FILE_NAME));\n         assertTrue(directory.directoryForTaskIsEmpty(taskId));\n \n         checkpointFile.write(Collections.singletonMap(new TopicPartition(\"topic\", 0), 0L));\n         assertTrue(directory.directoryForTaskIsEmpty(taskId));\n \n         // if some store dir is created, it should not be empty\n-        final File dbDir = new File(new File(directory.directoryForTask(taskId), \"db\"), \"store1\");\n+        final File dbDir = new File(new File(directory.getOrCreateDirectoryForTask(taskId), \"db\"), \"store1\");\n \n         Files.createDirectories(dbDir.getParentFile().toPath());\n         Files.createDirectories(dbDir.getAbsoluteFile().toPath());\n@@ -233,49 +215,32 @@ public void shouldThrowProcessorStateException() throws IOException {\n \n         Utils.delete(stateDir);\n \n-        assertThrows(ProcessorStateException.class, () -> directory.directoryForTask(taskId));\n+        assertThrows(ProcessorStateException.class, () -> directory.getOrCreateDirectoryForTask(taskId));\n     }\n \n     @Test\n-    public void shouldNotLockDeletedDirectory() throws IOException {\n+    public void shouldNotThrowIfStateDirectoryHasBeenDeleted() throws IOException {\n         final TaskId taskId = new TaskId(0, 0);\n \n         Utils.delete(stateDir);\n-        assertFalse(directory.lock(taskId));\n+        assertThrows(IllegalStateException.class, () -> directory.lock(taskId));\n     }\n-    \n+\n     @Test\n-    public void shouldLockMultipleTaskDirectories() throws IOException {\n+    public void shouldLockMultipleTaskDirectories() {\n         final TaskId taskId = new TaskId(0, 0);\n-        final File task1Dir = directory.directoryForTask(taskId);\n         final TaskId taskId2 = new TaskId(1, 0);\n-        final File task2Dir = directory.directoryForTask(taskId2);\n-\n \n-        try (\n-            final FileChannel channel1 = FileChannel.open(\n-                new File(task1Dir, LOCK_FILE_NAME).toPath(),\n-                StandardOpenOption.CREATE,\n-                StandardOpenOption.WRITE);\n-            final FileChannel channel2 = FileChannel.open(new File(task2Dir, LOCK_FILE_NAME).toPath(),\n-                StandardOpenOption.CREATE,\n-                StandardOpenOption.WRITE)\n-        ) {\n-            directory.lock(taskId);\n-            directory.lock(taskId2);\n-\n-            assertThrows(OverlappingFileLockException.class, channel1::tryLock);\n-            assertThrows(OverlappingFileLockException.class, channel2::tryLock);\n-        } finally {\n-            directory.unlock(taskId);\n-            directory.unlock(taskId2);\n-        }\n+        assertThat(directory.lock(taskId), is(true));\n+        assertThat(directory.lock(taskId2), is(true));\n+        directory.unlock(taskId);\n+        directory.unlock(taskId2);\n     }\n \n     @Test\n     public void shouldReleaseTaskStateDirectoryLock() throws IOException {\n         final TaskId taskId = new TaskId(0, 0);\n-        final File taskDirectory = directory.directoryForTask(taskId);\n+        final File taskDirectory = directory.getOrCreateDirectoryForTask(taskId);\n \n         directory.lock(taskId);\n         directory.unlock(taskId);\n@@ -291,14 +256,14 @@ public void shouldReleaseTaskStateDirectoryLock() throws IOException {\n     }\n \n     @Test\n-    public void shouldCleanUpTaskStateDirectoriesThatAreNotCurrentlyLocked() throws IOException {\n+    public void shouldCleanUpTaskStateDirectoriesThatAreNotCurrentlyLocked() {\n         final TaskId task0 = new TaskId(0, 0);\n         final TaskId task1 = new TaskId(1, 0);\n         final TaskId task2 = new TaskId(2, 0);\n         try {\n-            assertTrue(new File(directory.directoryForTask(task0), \"store\").mkdir());\n-            assertTrue(new File(directory.directoryForTask(task1), \"store\").mkdir());\n-            assertTrue(new File(directory.directoryForTask(task2), \"store\").mkdir());\n+            assertTrue(new File(directory.getOrCreateDirectoryForTask(task0), \"store\").mkdir());\n+            assertTrue(new File(directory.getOrCreateDirectoryForTask(task1), \"store\").mkdir());\n+            assertTrue(new File(directory.getOrCreateDirectoryForTask(task2), \"store\").mkdir());\n \n             directory.lock(task0);\n             directory.lock(task1);\n@@ -316,7 +281,7 @@ public void shouldCleanUpTaskStateDirectoriesThatAreNotCurrentlyLocked() throws\n             assertEquals(mkSet(dir0, dir1, dir2), files);\n \n             time.sleep(5000);\n-            directory.cleanRemovedTasks(0);\n+            directory.cleanRemovedTasks(0, Collections.singleton(Thread.currentThread().getName()));\n \n             files = Arrays.stream(\n                 Objects.requireNonNull(directory.listAllTaskDirectories())).collect(Collectors.toSet());\n@@ -333,32 +298,32 @@ public void shouldCleanUpTaskStateDirectoriesThatAreNotCurrentlyLocked() throws\n \n     @Test\n     public void shouldCleanupStateDirectoriesWhenLastModifiedIsLessThanNowMinusCleanupDelay() {\n-        final File dir = directory.directoryForTask(new TaskId(2, 0));\n+        final File dir = directory.getOrCreateDirectoryForTask(new TaskId(2, 0));\n         assertTrue(new File(dir, \"store\").mkdir());\n \n         final int cleanupDelayMs = 60000;\n-        directory.cleanRemovedTasks(cleanupDelayMs);\n+        directory.cleanRemovedTasks(cleanupDelayMs, Collections.emptySet());\n         assertTrue(dir.exists());\n         assertEquals(1, directory.listAllTaskDirectories().length);\n         assertEquals(1, directory.listNonEmptyTaskDirectories().length);\n \n         time.sleep(cleanupDelayMs + 1000);\n-        directory.cleanRemovedTasks(cleanupDelayMs);\n+        directory.cleanRemovedTasks(cleanupDelayMs, Collections.emptySet());\n         assertTrue(dir.exists());\n         assertEquals(1, directory.listAllTaskDirectories().length);\n         assertEquals(0, directory.listNonEmptyTaskDirectories().length);\n     }\n \n     @Test\n     public void shouldCleanupObsoleteStateDirectoriesOnlyOnce() {\n-        final File dir = directory.directoryForTask(new TaskId(2, 0));\n+        final File dir = directory.getOrCreateDirectoryForTask(new TaskId(2, 0));\n         assertTrue(new File(dir, \"store\").mkdir());\n         assertEquals(1, directory.listAllTaskDirectories().length);\n         assertEquals(1, directory.listNonEmptyTaskDirectories().length);\n \n         try (final LogCaptureAppender appender = LogCaptureAppender.createAndRegister(StateDirectory.class)) {\n             time.sleep(5000);\n-            directory.cleanRemovedTasks(0);\n+            directory.cleanRemovedTasks(0, Collections.emptySet());\n             assertTrue(dir.exists());\n             assertEquals(1, directory.listAllTaskDirectories().length);\n             assertEquals(0, directory.listNonEmptyTaskDirectories().length);\n@@ -370,7 +335,7 @@ public void shouldCleanupObsoleteStateDirectoriesOnlyOnce() {\n \n         try (final LogCaptureAppender appender = LogCaptureAppender.createAndRegister(StateDirectory.class)) {\n             time.sleep(5000);\n-            directory.cleanRemovedTasks(0);\n+            directory.cleanRemovedTasks(0, Collections.emptySet());\n             assertTrue(dir.exists());\n             assertEquals(1, directory.listAllTaskDirectories().length);\n             assertEquals(0, directory.listNonEmptyTaskDirectories().length);\n@@ -384,7 +349,7 @@ public void shouldCleanupObsoleteStateDirectoriesOnlyOnce() {\n     @Test\n     public void shouldNotRemoveNonTaskDirectoriesAndFiles() {\n         final File otherDir = TestUtils.tempDirectory(stateDir.toPath(), \"foo\");\n-        directory.cleanRemovedTasks(0);\n+        directory.cleanRemovedTasks(0, Collections.emptySet());\n         assertTrue(otherDir.exists());\n     }\n \n@@ -426,8 +391,8 @@ public void shouldReturnEmptyArrayIfListFilesReturnsNull() throws IOException {\n     @Test\n     public void shouldOnlyListNonEmptyTaskDirectories() throws IOException {\n         TestUtils.tempDirectory(stateDir.toPath(), \"foo\");\n-        final File taskDir1 = directory.directoryForTask(new TaskId(0, 0));\n-        final File taskDir2 = directory.directoryForTask(new TaskId(0, 1));\n+        final File taskDir1 = directory.getOrCreateDirectoryForTask(new TaskId(0, 0));\n+        final File taskDir2 = directory.getOrCreateDirectoryForTask(new TaskId(0, 1));\n \n         final File storeDir = new File(taskDir1, \"store\");\n         assertTrue(storeDir.mkdir());\n@@ -458,7 +423,7 @@ public void shouldCreateDirectoriesIfParentDoesntExist() {\n                 }\n             }),\n             time, true);\n-        final File taskDir = stateDirectory.directoryForTask(new TaskId(0, 0));\n+        final File taskDir = stateDirectory.getOrCreateDirectoryForTask(new TaskId(0, 0));\n         assertTrue(stateDir.exists());\n         assertTrue(taskDir.exists());\n     }\n@@ -497,17 +462,9 @@ public void shouldUnlockGlobalStateDirectory() throws IOException {\n     @Test\n     public void shouldNotLockStateDirLockedByAnotherThread() throws Exception {\n         final TaskId taskId = new TaskId(0, 0);\n-        final AtomicReference<IOException> exceptionOnThread = new AtomicReference<>();\n-        final Thread thread = new Thread(() -> {\n-            try {\n-                directory.lock(taskId);\n-            } catch (final IOException e) {\n-                exceptionOnThread.set(e);\n-            }\n-        });\n+        final Thread thread = new Thread(() -> directory.lock(taskId));\n         thread.start();\n         thread.join(30000);\n-        assertNull(\"should not have had an exception during locking on other thread\", exceptionOnThread.get());\n         assertFalse(directory.lock(taskId));\n     }\n \n@@ -544,7 +501,7 @@ public void shouldNotUnLockStateDirLockedByAnotherThread() throws Exception {\n     @Test\n     public void shouldCleanupAllTaskDirectoriesIncludingGlobalOne() {\n         final TaskId id = new TaskId(1, 0);\n-        directory.directoryForTask(id);\n+        directory.getOrCreateDirectoryForTask(id);\n         directory.globalStateDir();\n \n         final File dir0 = new File(appDir, id.toString());\n@@ -573,7 +530,7 @@ public void shouldNotCreateBaseDirectory() throws IOException {\n     public void shouldNotCreateTaskStateDirectory() throws IOException {\n         initializeStateDirectory(false);\n         final TaskId taskId = new TaskId(0, 0);\n-        final File taskDirectory = directory.directoryForTask(taskId);\n+        final File taskDirectory = directory.getOrCreateDirectoryForTask(taskId);\n         assertFalse(taskDirectory.exists());\n     }\n \n@@ -622,7 +579,7 @@ public void shouldNotFailWhenCreatingTaskDirectoryInParallel() throws Exception\n     @Test\n     public void shouldLogManualUserCallMessage() {\n         final TaskId taskId = new TaskId(0, 0);\n-        final File taskDirectory = directory.directoryForTask(taskId);\n+        final File taskDirectory = directory.getOrCreateDirectoryForTask(taskId);\n         final File testFile = new File(taskDirectory, \"testFile\");\n         assertThat(testFile.mkdir(), is(true));\n         assertThat(directory.directoryForTaskIsEmpty(taskId), is(false));\n@@ -639,15 +596,15 @@ public void shouldLogManualUserCallMessage() {\n     @Test\n     public void shouldLogStateDirCleanerMessage() {\n         final TaskId taskId = new TaskId(0, 0);\n-        final File taskDirectory = directory.directoryForTask(taskId);\n+        final File taskDirectory = directory.getOrCreateDirectoryForTask(taskId);\n         final File testFile = new File(taskDirectory, \"testFile\");\n         assertThat(testFile.mkdir(), is(true));\n         assertThat(directory.directoryForTaskIsEmpty(taskId), is(false));\n \n         try (final LogCaptureAppender appender = LogCaptureAppender.createAndRegister(StateDirectory.class)) {\n             final long cleanupDelayMs = 0;\n             time.sleep(5000);\n-            directory.cleanRemovedTasks(cleanupDelayMs);\n+            directory.cleanRemovedTasks(cleanupDelayMs, Collections.emptySet());\n             assertThat(appender.getMessages(), hasItem(endsWith(\"ms has elapsed (cleanup delay is \" + cleanupDelayMs + \"ms).\")));\n         }\n     }\n@@ -758,7 +715,7 @@ private CreateTaskDirRunner(final StateDirectory directory,\n         @Override\n         public void run() {\n             try {\n-                taskDirectory = directory.directoryForTask(taskId);\n+                taskDirectory = directory.getOrCreateDirectoryForTask(taskId);\n             } catch (final ProcessorStateException error) {\n                 passed.set(false);\n             }"
  },
  {
    "sha": "bc7fb14ba7da724d8e769279b914a10820cb4c6b",
    "filename": "streams/src/test/java/org/apache/kafka/streams/processor/internals/StateManagerUtilTest.java",
    "status": "modified",
    "additions": 9,
    "deletions": 61,
    "changes": 70,
    "blob_url": "https://github.com/apache/kafka/blob/518a1c894fc44f2cd0ba0e152ecd516c539ba780/streams/src/test/java/org/apache/kafka/streams/processor/internals/StateManagerUtilTest.java",
    "raw_url": "https://github.com/apache/kafka/raw/518a1c894fc44f2cd0ba0e152ecd516c539ba780/streams/src/test/java/org/apache/kafka/streams/processor/internals/StateManagerUtilTest.java",
    "contents_url": "https://api.github.com/repos/apache/kafka/contents/streams/src/test/java/org/apache/kafka/streams/processor/internals/StateManagerUtilTest.java?ref=518a1c894fc44f2cd0ba0e152ecd516c539ba780",
    "patch": "@@ -21,7 +21,6 @@\n import org.apache.kafka.common.utils.Utils;\n import org.apache.kafka.streams.errors.LockException;\n import org.apache.kafka.streams.errors.ProcessorStateException;\n-import org.apache.kafka.streams.errors.StreamsException;\n import org.apache.kafka.streams.processor.StateStore;\n import org.apache.kafka.streams.processor.TaskId;\n import org.apache.kafka.streams.processor.internals.Task.TaskType;\n@@ -97,7 +96,7 @@ public void testRegisterStateStoreWhenTopologyEmpty() {\n     }\n \n     @Test\n-    public void testRegisterStateStoreFailToLockStateDirectory() throws IOException {\n+    public void testRegisterStateStoreFailToLockStateDirectory() {\n         expect(topology.stateStores()).andReturn(singletonList(new MockKeyValueStore(\"store\", false)));\n \n         expect(stateManager.taskId()).andReturn(taskId);\n@@ -117,30 +116,7 @@ public void testRegisterStateStoreFailToLockStateDirectory() throws IOException\n     }\n \n     @Test\n-    public void testRegisterStateStoreLockThrowIOExceptionWrappedAsStreamException() throws IOException {\n-        expect(topology.stateStores()).andReturn(singletonList(new MockKeyValueStore(\"store\", false)));\n-\n-        expect(stateManager.taskId()).andReturn(taskId);\n-\n-        expect(stateDirectory.lock(taskId)).andThrow(new IOException(\"Fail to lock state dir\"));\n-\n-        ctrl.checkOrder(true);\n-        ctrl.replay();\n-\n-        final StreamsException thrown = assertThrows(StreamsException.class,\n-            () -> StateManagerUtil.registerStateStores(logger, \"logPrefix:\",\n-                topology, stateManager, stateDirectory, processorContext));\n-\n-        assertEquals(\"logPrefix:Fatal error while trying to \" +\n-            \"lock the state directory for task 0_0\", thrown.getMessage());\n-        assertEquals(IOException.class, thrown.getCause().getClass());\n-        assertEquals(\"Fail to lock state dir\", thrown.getCause().getMessage());\n-\n-        ctrl.verify();\n-    }\n-\n-    @Test\n-    public void testRegisterStateStores() throws IOException {\n+    public void testRegisterStateStores() {\n         final MockKeyValueStore store1 = new MockKeyValueStore(\"store1\", false);\n         final MockKeyValueStore store2 = new MockKeyValueStore(\"store2\", false);\n         final List<StateStore> stateStores = Arrays.asList(store1, store2);\n@@ -169,7 +145,7 @@ public void testRegisterStateStores() throws IOException {\n     }\n \n     @Test\n-    public void testCloseStateManagerClean() throws IOException {\n+    public void testCloseStateManagerClean() {\n         expect(stateManager.taskId()).andReturn(taskId);\n \n         expect(stateDirectory.lock(taskId)).andReturn(true);\n@@ -190,31 +166,7 @@ public void testCloseStateManagerClean() throws IOException {\n     }\n \n     @Test\n-    public void testCloseStateManagerThrowsExceptionWhenClean() throws IOException {\n-        expect(stateManager.taskId()).andReturn(taskId);\n-\n-        expect(stateDirectory.lock(taskId)).andReturn(true);\n-\n-        stateManager.close();\n-        expectLastCall();\n-\n-        stateDirectory.unlock(taskId);\n-        expectLastCall().andThrow(new IOException(\"Timeout\"));\n-\n-        ctrl.checkOrder(true);\n-        ctrl.replay();\n-\n-        final ProcessorStateException thrown = assertThrows(\n-            ProcessorStateException.class, () -> StateManagerUtil.closeStateManager(logger,\n-            \"logPrefix:\", true, false, stateManager, stateDirectory, TaskType.ACTIVE));\n-\n-        assertEquals(IOException.class, thrown.getCause().getClass());\n-\n-        ctrl.verify();\n-    }\n-\n-    @Test\n-    public void testCloseStateManagerOnlyThrowsFirstExceptionWhenClean() throws IOException {\n+    public void testCloseStateManagerThrowsExceptionWhenClean() {\n         expect(stateManager.taskId()).andReturn(taskId);\n \n         expect(stateDirectory.lock(taskId)).andReturn(true);\n@@ -224,7 +176,6 @@ public void testCloseStateManagerOnlyThrowsFirstExceptionWhenClean() throws IOEx\n \n         // The unlock logic should still be executed.\n         stateDirectory.unlock(taskId);\n-        expectLastCall().andThrow(new IOException(\"Timeout\"));\n \n         ctrl.checkOrder(true);\n         ctrl.replay();\n@@ -240,32 +191,29 @@ public void testCloseStateManagerOnlyThrowsFirstExceptionWhenClean() throws IOEx\n     }\n \n     @Test\n-    public void testCloseStateManagerThrowsExceptionWhenDirty() throws IOException {\n+    public void testCloseStateManagerThrowsExceptionWhenDirty() {\n         expect(stateManager.taskId()).andReturn(taskId);\n \n         expect(stateDirectory.lock(taskId)).andReturn(true);\n \n         stateManager.close();\n-        expectLastCall();\n+        expectLastCall().andThrow(new ProcessorStateException(\"state manager failed to close\"));\n \n         stateDirectory.unlock(taskId);\n-        expectLastCall().andThrow(new IOException(\"Timeout\"));\n \n         ctrl.checkOrder(true);\n         ctrl.replay();\n \n-        final ProcessorStateException thrown = assertThrows(\n+        assertThrows(\n             ProcessorStateException.class,\n             () -> StateManagerUtil.closeStateManager(\n                 logger, \"logPrefix:\", false, false, stateManager, stateDirectory, TaskType.ACTIVE));\n \n-        assertEquals(IOException.class, thrown.getCause().getClass());\n-\n         ctrl.verify();\n     }\n \n     @Test\n-    public void testCloseStateManagerWithStateStoreWipeOut() throws IOException {\n+    public void testCloseStateManagerWithStateStoreWipeOut() {\n         expect(stateManager.taskId()).andReturn(taskId);\n         expect(stateDirectory.lock(taskId)).andReturn(true);\n \n@@ -350,7 +298,7 @@ public void testCloseStateManagerWithStateStoreWipeOutRethrowWrappedIOException(\n     }\n \n     @Test\n-    public void shouldNotCloseStateManagerIfUnableToLockTaskDirectory() throws IOException {\n+    public void shouldNotCloseStateManagerIfUnableToLockTaskDirectory() {\n         expect(stateManager.taskId()).andReturn(taskId);\n \n         expect(stateDirectory.lock(taskId)).andReturn(false);"
  },
  {
    "sha": "007801361fb95f98ca6285d02602a581e2bc60ce",
    "filename": "streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamTaskTest.java",
    "status": "modified",
    "additions": 1,
    "deletions": 1,
    "changes": 2,
    "blob_url": "https://github.com/apache/kafka/blob/518a1c894fc44f2cd0ba0e152ecd516c539ba780/streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamTaskTest.java",
    "raw_url": "https://github.com/apache/kafka/raw/518a1c894fc44f2cd0ba0e152ecd516c539ba780/streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamTaskTest.java",
    "contents_url": "https://api.github.com/repos/apache/kafka/contents/streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamTaskTest.java?ref=518a1c894fc44f2cd0ba0e152ecd516c539ba780",
    "patch": "@@ -1434,7 +1434,7 @@ public void shouldNotCheckpointOffsetsOnCommitIfEosIsEnabled() {\n         task.prepareCommit();\n         task.postCommit(false);\n         final File checkpointFile = new File(\n-            stateDirectory.directoryForTask(taskId),\n+            stateDirectory.getOrCreateDirectoryForTask(taskId),\n             StateManagerUtil.CHECKPOINT_FILE_NAME\n         );\n "
  },
  {
    "sha": "765e8a6d4018e44ed53524215cfe7ba73a0f3c55",
    "filename": "streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamThreadTest.java",
    "status": "modified",
    "additions": 1,
    "deletions": 1,
    "changes": 2,
    "blob_url": "https://github.com/apache/kafka/blob/518a1c894fc44f2cd0ba0e152ecd516c539ba780/streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamThreadTest.java",
    "raw_url": "https://github.com/apache/kafka/raw/518a1c894fc44f2cd0ba0e152ecd516c539ba780/streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamThreadTest.java",
    "contents_url": "https://api.github.com/repos/apache/kafka/contents/streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamThreadTest.java?ref=518a1c894fc44f2cd0ba0e152ecd516c539ba780",
    "patch": "@@ -1726,7 +1726,7 @@ public void shouldUpdateStandbyTask() throws Exception {\n         restoreConsumer.updateEndOffsets(Collections.singletonMap(partition2, 10L));\n         restoreConsumer.updateBeginningOffsets(Collections.singletonMap(partition2, 0L));\n         final OffsetCheckpoint checkpoint\n-            = new OffsetCheckpoint(new File(stateDirectory.directoryForTask(task3), CHECKPOINT_FILE_NAME));\n+            = new OffsetCheckpoint(new File(stateDirectory.getOrCreateDirectoryForTask(task3), CHECKPOINT_FILE_NAME));\n         checkpoint.write(Collections.singletonMap(partition2, 5L));\n \n         thread.setState(StreamThread.State.STARTING);"
  }
]
