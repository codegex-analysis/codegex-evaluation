[
  {
    "sha": "b047deed4335ba3e824f41480f35a75ba31ed2c2",
    "filename": "connect/mirror/src/main/java/org/apache/kafka/connect/mirror/MirrorConnectorConfig.java",
    "status": "modified",
    "additions": 60,
    "deletions": 1,
    "changes": 61,
    "blob_url": "https://github.com/apache/kafka/blob/fdeea7fedd55e51bf0ff6182fc656b7d8c5d173d/connect/mirror/src/main/java/org/apache/kafka/connect/mirror/MirrorConnectorConfig.java",
    "raw_url": "https://github.com/apache/kafka/raw/fdeea7fedd55e51bf0ff6182fc656b7d8c5d173d/connect/mirror/src/main/java/org/apache/kafka/connect/mirror/MirrorConnectorConfig.java",
    "contents_url": "https://api.github.com/repos/apache/kafka/contents/connect/mirror/src/main/java/org/apache/kafka/connect/mirror/MirrorConnectorConfig.java?ref=fdeea7fedd55e51bf0ff6182fc656b7d8c5d173d",
    "patch": "@@ -18,6 +18,7 @@\n \n import org.apache.kafka.common.config.AbstractConfig;\n import org.apache.kafka.common.config.ConfigDef;\n+import org.apache.kafka.common.config.ConfigDef.ValidString;\n import org.apache.kafka.common.TopicPartition;\n import org.apache.kafka.common.metrics.KafkaMetricsContext;\n import org.apache.kafka.common.metrics.MetricsReporter;\n@@ -33,6 +34,7 @@\n import java.util.HashMap;\n import java.util.List;\n import java.util.stream.Collectors;\n+\n import java.time.Duration;\n \n /** Shared config properties used by MirrorSourceConnector, MirrorCheckpointConnector, and MirrorHeartbeatConnector.\n@@ -77,6 +79,7 @@\n     public static final String ENABLED = \"enabled\";\n     private static final String ENABLED_DOC = \"Whether to replicate source->target.\";\n     public static final String SOURCE_CLUSTER_ALIAS = \"source.cluster.alias\";\n+    public static final String SOURCE_CLUSTER_ALIAS_DEFAULT = \"source\";\n     private static final String SOURCE_CLUSTER_ALIAS_DOC = \"Alias of source cluster\";\n     public static final String TARGET_CLUSTER_ALIAS = \"target.cluster.alias\";\n     public static final String TARGET_CLUSTER_ALIAS_DEFAULT = \"target\";\n@@ -202,6 +205,10 @@\n     private static final String OFFSET_LAG_MAX_DOC = \"How out-of-sync a remote partition can be before it is resynced.\";\n     public static final long OFFSET_LAG_MAX_DEFAULT = 100L;\n \n+    private static final String OFFSET_SYNCS_TOPIC_LOCATION = \"offset-syncs.topic.location\";\n+    private static final Object OFFSET_SYNCS_TOPIC_LOCATION_DEFAULT = SOURCE_CLUSTER_ALIAS_DEFAULT;\n+    private static final String OFFSET_SYNCS_TOPIC_LOCATION_DOC = \"The location of the offset-syncs topic.\";\n+\n     protected static final String SOURCE_CLUSTER_PREFIX = MirrorMakerConfig.SOURCE_CLUSTER_PREFIX;\n     protected static final String TARGET_CLUSTER_PREFIX = MirrorMakerConfig.TARGET_CLUSTER_PREFIX;\n     protected static final String SOURCE_PREFIX = MirrorMakerConfig.SOURCE_PREFIX;\n@@ -281,6 +288,26 @@ Duration adminTimeout() {\n         return props;\n     }\n \n+    Map<String, Object> targetProducerConfig() {\n+        Map<String, Object> props = new HashMap<>();\n+        props.putAll(originalsWithPrefix(TARGET_CLUSTER_PREFIX));\n+        props.keySet().retainAll(MirrorClientConfig.CLIENT_CONFIG_DEF.names());\n+        props.putAll(originalsWithPrefix(PRODUCER_CLIENT_PREFIX));\n+        props.putAll(originalsWithPrefix(TARGET_PREFIX + PRODUCER_CLIENT_PREFIX));\n+        return props;\n+    }\n+\n+    Map<String, Object> targetConsumerConfig() {\n+        Map<String, Object> props = new HashMap<>();\n+        props.putAll(originalsWithPrefix(TARGET_CLUSTER_PREFIX));\n+        props.keySet().retainAll(MirrorClientConfig.CLIENT_CONFIG_DEF.names());\n+        props.putAll(originalsWithPrefix(CONSUMER_CLIENT_PREFIX));\n+        props.putAll(originalsWithPrefix(TARGET_PREFIX + CONSUMER_CLIENT_PREFIX));\n+        props.put(ENABLE_AUTO_COMMIT_CONFIG, \"false\");\n+        props.putIfAbsent(AUTO_OFFSET_RESET_CONFIG, \"earliest\");\n+        return props;\n+    }\n+\n     Map<String, Object> sourceAdminConfig() {\n         Map<String, Object> props = new HashMap<>();\n         props.putAll(originalsWithPrefix(SOURCE_CLUSTER_PREFIX));\n@@ -314,8 +341,33 @@ String targetClusterAlias() {\n     }\n \n     String offsetSyncsTopic() {\n+        String otherClusterAlias = SOURCE_CLUSTER_ALIAS_DEFAULT.equals(offsetSyncsTopicLocation())\n+                ? targetClusterAlias()\n+                : sourceClusterAlias();\n         // \".internal\" suffix ensures this doesn't get replicated\n-        return \"mm2-offset-syncs.\" + targetClusterAlias() + \".internal\";\n+        return \"mm2-offset-syncs.\" + otherClusterAlias + \".internal\";\n+    }\n+\n+    String offsetSyncsTopicLocation() {\n+        return getString(OFFSET_SYNCS_TOPIC_LOCATION);\n+    }\n+\n+    Map<String, Object> offsetSyncsTopicAdminConfig() {\n+        return SOURCE_CLUSTER_ALIAS_DEFAULT.equals(offsetSyncsTopicLocation())\n+                ? sourceAdminConfig()\n+                : targetAdminConfig();\n+    }\n+\n+    Map<String, Object> offsetSyncsTopicProducerConfig() {\n+        return SOURCE_CLUSTER_ALIAS_DEFAULT.equals(offsetSyncsTopicLocation())\n+                ? sourceProducerConfig()\n+                : targetProducerConfig();\n+    }\n+\n+    Map<String, Object> offsetSyncsTopicConsumerConfig() {\n+        return SOURCE_CLUSTER_ALIAS_DEFAULT.equals(offsetSyncsTopicLocation())\n+                ? sourceConsumerConfig()\n+                : targetConsumerConfig();\n     }\n \n     String heartbeatsTopic() {\n@@ -654,6 +706,13 @@ Duration syncGroupOffsetsInterval() {\n                     OFFSET_LAG_MAX_DEFAULT,\n                     ConfigDef.Importance.LOW,\n                     OFFSET_LAG_MAX_DOC)\n+            .define(\n+                    OFFSET_SYNCS_TOPIC_LOCATION,\n+                    ConfigDef.Type.STRING,\n+                    OFFSET_SYNCS_TOPIC_LOCATION_DEFAULT,\n+                    ValidString.in(SOURCE_CLUSTER_ALIAS_DEFAULT, TARGET_CLUSTER_ALIAS_DEFAULT),\n+                    ConfigDef.Importance.LOW,\n+                    OFFSET_SYNCS_TOPIC_LOCATION_DOC)\n             .define(\n                     CommonClientConfigs.METRIC_REPORTER_CLASSES_CONFIG,\n                     ConfigDef.Type.LIST,"
  },
  {
    "sha": "0d490ab532efbc2e531355823cd6acbd2fd94718",
    "filename": "connect/mirror/src/main/java/org/apache/kafka/connect/mirror/MirrorMakerConfig.java",
    "status": "modified",
    "additions": 3,
    "deletions": 0,
    "changes": 3,
    "blob_url": "https://github.com/apache/kafka/blob/fdeea7fedd55e51bf0ff6182fc656b7d8c5d173d/connect/mirror/src/main/java/org/apache/kafka/connect/mirror/MirrorMakerConfig.java",
    "raw_url": "https://github.com/apache/kafka/raw/fdeea7fedd55e51bf0ff6182fc656b7d8c5d173d/connect/mirror/src/main/java/org/apache/kafka/connect/mirror/MirrorMakerConfig.java",
    "contents_url": "https://api.github.com/repos/apache/kafka/contents/connect/mirror/src/main/java/org/apache/kafka/connect/mirror/MirrorMakerConfig.java?ref=fdeea7fedd55e51bf0ff6182fc656b7d8c5d173d",
    "patch": "@@ -220,6 +220,9 @@ public MirrorClientConfig clientConfig(String cluster) {\n         props.putIfAbsent(TARGET_CLUSTER_ALIAS, sourceAndTarget.target());\n \n         // override with connector-level properties\n+        Map<String, String> p = stringsWithPrefixStripped(sourceAndTarget.source() + \"->\"\n+                + sourceAndTarget.target() + \".\");\n+        System.out.println(p);\n         props.putAll(stringsWithPrefixStripped(sourceAndTarget.source() + \"->\"\n             + sourceAndTarget.target() + \".\"));\n "
  },
  {
    "sha": "4d3b9ec7fb53850a7ff32b4e5f62ef00c6c3e422",
    "filename": "connect/mirror/src/main/java/org/apache/kafka/connect/mirror/MirrorSourceConnector.java",
    "status": "modified",
    "additions": 1,
    "deletions": 1,
    "changes": 2,
    "blob_url": "https://github.com/apache/kafka/blob/fdeea7fedd55e51bf0ff6182fc656b7d8c5d173d/connect/mirror/src/main/java/org/apache/kafka/connect/mirror/MirrorSourceConnector.java",
    "raw_url": "https://github.com/apache/kafka/raw/fdeea7fedd55e51bf0ff6182fc656b7d8c5d173d/connect/mirror/src/main/java/org/apache/kafka/connect/mirror/MirrorSourceConnector.java",
    "contents_url": "https://api.github.com/repos/apache/kafka/contents/connect/mirror/src/main/java/org/apache/kafka/connect/mirror/MirrorSourceConnector.java?ref=fdeea7fedd55e51bf0ff6182fc656b7d8c5d173d",
    "patch": "@@ -303,7 +303,7 @@ private void syncTopicConfigs()\n     }\n \n     private void createOffsetSyncsTopic() {\n-        MirrorUtils.createSinglePartitionCompactedTopic(config.offsetSyncsTopic(), config.offsetSyncsTopicReplicationFactor(), config.sourceAdminConfig());\n+        MirrorUtils.createSinglePartitionCompactedTopic(config.offsetSyncsTopic(), config.offsetSyncsTopicReplicationFactor(), config.offsetSyncsTopicAdminConfig());\n     }\n \n     // visible for testing"
  },
  {
    "sha": "548ba0fd7d9601fb100e176c7bd9bd1e579e43e0",
    "filename": "connect/mirror/src/main/java/org/apache/kafka/connect/mirror/MirrorSourceTask.java",
    "status": "modified",
    "additions": 1,
    "deletions": 1,
    "changes": 2,
    "blob_url": "https://github.com/apache/kafka/blob/fdeea7fedd55e51bf0ff6182fc656b7d8c5d173d/connect/mirror/src/main/java/org/apache/kafka/connect/mirror/MirrorSourceTask.java",
    "raw_url": "https://github.com/apache/kafka/raw/fdeea7fedd55e51bf0ff6182fc656b7d8c5d173d/connect/mirror/src/main/java/org/apache/kafka/connect/mirror/MirrorSourceTask.java",
    "contents_url": "https://api.github.com/repos/apache/kafka/contents/connect/mirror/src/main/java/org/apache/kafka/connect/mirror/MirrorSourceTask.java?ref=fdeea7fedd55e51bf0ff6182fc656b7d8c5d173d",
    "patch": "@@ -87,7 +87,7 @@ public void start(Map<String, String> props) {\n         partitionStates = new HashMap<>();\n         offsetSyncsTopic = config.offsetSyncsTopic();\n         consumer = MirrorUtils.newConsumer(config.sourceConsumerConfig());\n-        offsetProducer = MirrorUtils.newProducer(config.sourceProducerConfig());\n+        offsetProducer = MirrorUtils.newProducer(config.offsetSyncsTopicProducerConfig());\n         Set<TopicPartition> taskTopicPartitions = config.taskTopicPartitions();\n         Map<TopicPartition, Long> topicPartitionOffsets = loadOffsets(taskTopicPartitions);\n         consumer.assign(topicPartitionOffsets.keySet());"
  },
  {
    "sha": "600dda46f3166ac0d920123c3239c2025242cfa8",
    "filename": "connect/mirror/src/main/java/org/apache/kafka/connect/mirror/OffsetSyncStore.java",
    "status": "modified",
    "additions": 1,
    "deletions": 1,
    "changes": 2,
    "blob_url": "https://github.com/apache/kafka/blob/fdeea7fedd55e51bf0ff6182fc656b7d8c5d173d/connect/mirror/src/main/java/org/apache/kafka/connect/mirror/OffsetSyncStore.java",
    "raw_url": "https://github.com/apache/kafka/raw/fdeea7fedd55e51bf0ff6182fc656b7d8c5d173d/connect/mirror/src/main/java/org/apache/kafka/connect/mirror/OffsetSyncStore.java",
    "contents_url": "https://api.github.com/repos/apache/kafka/contents/connect/mirror/src/main/java/org/apache/kafka/connect/mirror/OffsetSyncStore.java?ref=fdeea7fedd55e51bf0ff6182fc656b7d8c5d173d",
    "patch": "@@ -35,7 +35,7 @@\n     private TopicPartition offsetSyncTopicPartition;\n \n     OffsetSyncStore(MirrorConnectorConfig config) {\n-        consumer = new KafkaConsumer<>(config.sourceConsumerConfig(),\n+        consumer = new KafkaConsumer<>(config.offsetSyncsTopicConsumerConfig(),\n             new ByteArrayDeserializer(), new ByteArrayDeserializer());\n         offsetSyncTopicPartition = new TopicPartition(config.offsetSyncsTopic(), 0);\n         consumer.assign(Collections.singleton(offsetSyncTopicPartition));"
  },
  {
    "sha": "64a2c2a8372a71f3ef605fc072350f96eb1d089a",
    "filename": "connect/mirror/src/test/java/org/apache/kafka/connect/mirror/MirrorConnectorConfigTest.java",
    "status": "modified",
    "additions": 65,
    "deletions": 0,
    "changes": 65,
    "blob_url": "https://github.com/apache/kafka/blob/fdeea7fedd55e51bf0ff6182fc656b7d8c5d173d/connect/mirror/src/test/java/org/apache/kafka/connect/mirror/MirrorConnectorConfigTest.java",
    "raw_url": "https://github.com/apache/kafka/raw/fdeea7fedd55e51bf0ff6182fc656b7d8c5d173d/connect/mirror/src/test/java/org/apache/kafka/connect/mirror/MirrorConnectorConfigTest.java",
    "contents_url": "https://api.github.com/repos/apache/kafka/contents/connect/mirror/src/test/java/org/apache/kafka/connect/mirror/MirrorConnectorConfigTest.java?ref=fdeea7fedd55e51bf0ff6182fc656b7d8c5d173d",
    "patch": "@@ -18,6 +18,7 @@\n \n import org.apache.kafka.common.TopicPartition;\n import org.apache.kafka.common.config.ConfigDef;\n+import org.apache.kafka.common.config.ConfigException;\n import org.junit.jupiter.api.Test;\n \n import java.util.Arrays;\n@@ -30,6 +31,7 @@\n import static org.apache.kafka.connect.mirror.TestUtils.makeProps;\n import static org.junit.jupiter.api.Assertions.assertTrue;\n import static org.junit.jupiter.api.Assertions.assertFalse;\n+import static org.junit.jupiter.api.Assertions.fail;\n import static org.junit.jupiter.api.Assertions.assertEquals;\n \n public class MirrorConnectorConfigTest {\n@@ -246,4 +248,67 @@ public void testTargetAdminConfigWithSourcePrefix() {\n         assertEquals(expectedAdminProps, connectorAdminProps);\n     }\n \n+    @Test\n+    public void testOffsetSyncsTopic() {\n+        // Invalid location\n+        Map<String, String> connectorProps = makeProps(\"offset-syncs.topic.location\", \"something\");\n+        try {\n+            new MirrorConnectorConfig(connectorProps);\n+            fail(\"Should have thrown ConfigException\");\n+        } catch (ConfigException exc) { } // expected\n+\n+        connectorProps.put(\"offset-syncs.topic.location\", \"source\");\n+        MirrorConnectorConfig config = new MirrorConnectorConfig(connectorProps);\n+        assertEquals(\"mm2-offset-syncs.target2.internal\", config.offsetSyncsTopic());\n+        connectorProps.put(\"offset-syncs.topic.location\", \"target\");\n+        config = new MirrorConnectorConfig(connectorProps);\n+        assertEquals(\"mm2-offset-syncs.source1.internal\", config.offsetSyncsTopic());\n+        // Default to source\n+        connectorProps.remove(\"offset-syncs.topic.location\");\n+        config = new MirrorConnectorConfig(connectorProps);\n+        assertEquals(\"mm2-offset-syncs.target2.internal\", config.offsetSyncsTopic());\n+    }\n+\n+    @Test\n+    public void testConsumerConfigsForOffsetSyncsTopic() {\n+        Map<String, String> connectorProps = makeProps(\n+                \"source.max.partition.fetch.bytes\", \"1\",\n+                \"target.heartbeat.interval.ms\", \"1\",\n+                \"consumer.max.poll.interval.ms\", \"1\",\n+                \"fetch.min.bytes\", \"1\"\n+        );\n+        MirrorConnectorConfig config = new MirrorConnectorConfig(connectorProps);\n+        assertEquals(config.sourceConsumerConfig(), config.offsetSyncsTopicConsumerConfig());\n+        connectorProps.put(\"offset-syncs.topic.location\", \"target\");\n+        assertEquals(config.targetConsumerConfig(), config.offsetSyncsTopicConsumerConfig());\n+    }\n+\n+    @Test\n+    public void testProducerConfigsForOffsetSyncsTopic() {\n+        Map<String, String> connectorProps = makeProps(\n+                \"source.batch.size\", \"1\",\n+                \"target.acks\", \"1\",\n+                \"producer.max.poll.interval.ms\", \"1\",\n+                \"fetch.min.bytes\", \"1\"\n+        );\n+        MirrorConnectorConfig config = new MirrorConnectorConfig(connectorProps);\n+        assertEquals(config.sourceProducerConfig(), config.offsetSyncsTopicProducerConfig());\n+        connectorProps.put(\"offset-syncs.topic.location\", \"target\");\n+        assertEquals(config.targetProducerConfig(), config.offsetSyncsTopicProducerConfig());\n+    }\n+\n+    @Test\n+    public void testAdminConfigsForOffsetSyncsTopic() {\n+        Map<String, String> connectorProps = makeProps(\n+                \"source.request.timeout.ms\", \"1\",\n+                \"target.send.buffer.bytes\", \"1\",\n+                \"admin.reconnect.backoff.max.ms\", \"1\",\n+                \"retries\", \"123\"\n+        );\n+        MirrorConnectorConfig config = new MirrorConnectorConfig(connectorProps);\n+        assertEquals(config.sourceAdminConfig(), config.offsetSyncsTopicAdminConfig());\n+        connectorProps.put(\"offset-syncs.topic.location\", \"target\");\n+        assertEquals(config.targetAdminConfig(), config.offsetSyncsTopicAdminConfig());\n+    }\n+\n }"
  },
  {
    "sha": "85ab18f3331563a40c5929cc465eea6a7aedee68",
    "filename": "connect/mirror/src/test/java/org/apache/kafka/connect/mirror/MirrorSourceConnectorTest.java",
    "status": "modified",
    "additions": 1,
    "deletions": 1,
    "changes": 2,
    "blob_url": "https://github.com/apache/kafka/blob/fdeea7fedd55e51bf0ff6182fc656b7d8c5d173d/connect/mirror/src/test/java/org/apache/kafka/connect/mirror/MirrorSourceConnectorTest.java",
    "raw_url": "https://github.com/apache/kafka/raw/fdeea7fedd55e51bf0ff6182fc656b7d8c5d173d/connect/mirror/src/test/java/org/apache/kafka/connect/mirror/MirrorSourceConnectorTest.java",
    "contents_url": "https://api.github.com/repos/apache/kafka/contents/connect/mirror/src/test/java/org/apache/kafka/connect/mirror/MirrorSourceConnectorTest.java?ref=fdeea7fedd55e51bf0ff6182fc656b7d8c5d173d",
    "patch": "@@ -234,6 +234,6 @@ public void testRefreshTopicPartitionsTopicOnTargetFirst() throws Exception {\n         // when partitions are added to the source cluster, reconfiguration is triggered\n         connector.refreshTopicPartitions();\n         verify(connector, times(1)).computeAndCreateTopicPartitions();\n-\n     }\n+\n }"
  },
  {
    "sha": "e7c23c152d8d376d9dd39775440fcb54f5067487",
    "filename": "connect/mirror/src/test/java/org/apache/kafka/connect/mirror/integration/MirrorConnectorsIntegrationBaseTest.java",
    "status": "modified",
    "additions": 53,
    "deletions": 1,
    "changes": 54,
    "blob_url": "https://github.com/apache/kafka/blob/fdeea7fedd55e51bf0ff6182fc656b7d8c5d173d/connect/mirror/src/test/java/org/apache/kafka/connect/mirror/integration/MirrorConnectorsIntegrationBaseTest.java",
    "raw_url": "https://github.com/apache/kafka/raw/fdeea7fedd55e51bf0ff6182fc656b7d8c5d173d/connect/mirror/src/test/java/org/apache/kafka/connect/mirror/integration/MirrorConnectorsIntegrationBaseTest.java",
    "contents_url": "https://api.github.com/repos/apache/kafka/contents/connect/mirror/src/test/java/org/apache/kafka/connect/mirror/integration/MirrorConnectorsIntegrationBaseTest.java?ref=fdeea7fedd55e51bf0ff6182fc656b7d8c5d173d",
    "patch": "@@ -20,6 +20,7 @@\n import org.apache.kafka.clients.admin.Config;\n import org.apache.kafka.clients.admin.DescribeConfigsResult;\n import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerRecord;\n import org.apache.kafka.clients.consumer.ConsumerRecords;\n import org.apache.kafka.clients.consumer.OffsetAndMetadata;\n import org.apache.kafka.common.config.ConfigResource;\n@@ -32,6 +33,7 @@\n import org.apache.kafka.connect.mirror.MirrorMakerConfig;\n import org.apache.kafka.connect.mirror.MirrorSourceConnector;\n import org.apache.kafka.connect.mirror.SourceAndTarget;\n+import org.apache.kafka.connect.mirror.Checkpoint;\n import org.apache.kafka.connect.mirror.MirrorCheckpointConnector;\n import org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster;\n import org.apache.kafka.connect.util.clusters.EmbeddedKafkaCluster;\n@@ -47,6 +49,7 @@\n import java.util.HashMap;\n import java.util.Map;\n import java.util.Properties;\n+import java.util.Set;\n import java.util.concurrent.TimeUnit;\n import java.util.concurrent.atomic.AtomicInteger;\n \n@@ -435,7 +438,41 @@ public void testOneWayReplicationWithAutoOffsetSync() throws InterruptedExceptio\n         assertEquals(0, records.count(), \"consumer record size is not zero\");\n         backupConsumer.close();\n     }\n-    \n+\n+    @Test\n+    public void testOffsetSyncsTopicsOnTarget() throws Exception {\n+        // move offset-syncs topics to target\n+        mm2Props.put(PRIMARY_CLUSTER_ALIAS + \"->\" + BACKUP_CLUSTER_ALIAS + \".offset-syncs.topic.location\", \"target\");\n+        // one way replication from primary to backup\n+        mm2Props.put(BACKUP_CLUSTER_ALIAS + \"->\" + PRIMARY_CLUSTER_ALIAS + \".enabled\", \"false\");\n+\n+        mm2Config = new MirrorMakerConfig(mm2Props);\n+\n+        waitUntilMirrorMakerIsRunning(backup, CONNECTOR_LIST, mm2Config, PRIMARY_CLUSTER_ALIAS, BACKUP_CLUSTER_ALIAS);\n+\n+        // Ensure the offset syncs topic is created in the target cluster\n+        waitForTopicCreated(backup.kafka(), \"mm2-offset-syncs.\" + PRIMARY_CLUSTER_ALIAS + \".internal\");\n+\n+        produceMessages(primary, \"test-topic-1\");\n+\n+        // Check offsets are pushed to the checkpoint topic\n+        Consumer<byte[], byte[]> backupConsumer = backup.kafka().createConsumerAndSubscribeTo(Collections.singletonMap(\n+                \"auto.offset.reset\", \"earliest\"), PRIMARY_CLUSTER_ALIAS + \".checkpoints.internal\");\n+        waitForCondition(() -> {\n+            ConsumerRecords<byte[], byte[]> records = backupConsumer.poll(Duration.ofSeconds(1L));\n+            for (ConsumerRecord<byte[], byte[]> record : records) {\n+                Checkpoint checkpoint = Checkpoint.deserializeRecord(record);\n+                System.out.println(checkpoint);\n+                if ((PRIMARY_CLUSTER_ALIAS + \".test-topic-1\").equals(checkpoint.topicPartition().topic())) {\n+                    return true;\n+                }\n+            }\n+            return false;\n+        }, 30_000,\n+            \"Unable to find checkpoints for \" + PRIMARY_CLUSTER_ALIAS + \"test-topic-1\"\n+        );\n+    }\n+\n     /*\n      * launch the connectors on kafka connect cluster and check if they are running\n      */\n@@ -593,4 +630,19 @@ private void warmUpConsumer(Map<String, Object> consumerProps) throws Interrupte\n         dummyConsumer.commitSync();\n         dummyConsumer.close();\n     }\n+\n+    /*\n+     * wait for the topic created on the cluster\n+     */\n+    private static void waitForTopicCreated(EmbeddedKafkaCluster cluster, String topicName) throws InterruptedException {\n+        try (final Admin adminClient = cluster.createAdminClient()) {\n+            waitForCondition(() -> {\n+                Set<String> topics = adminClient.listTopics().names().get();\n+                System.out.println(topics);\n+                return topics.contains(topicName);\n+            }, OFFSET_SYNC_DURATION_MS,\n+                \"Topic: \" + topicName + \" didn't get created in the cluster\"\n+            );\n+        }\n+    }\n }"
  }
]
