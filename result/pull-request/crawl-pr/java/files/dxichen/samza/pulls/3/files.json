[
  {
    "sha": "fea025702c6162eff800ca2887536d3c8175ea5b",
    "filename": "samza-api/src/main/java/org/apache/samza/checkpoint/BlobStoreCheckpointMarker.java",
    "status": "added",
    "additions": 93,
    "deletions": 0,
    "changes": 93,
    "blob_url": "https://github.com/dxichen/samza/blob/f010e3429c1b8670cd4fa5d7b13b8f75b3462c7b/samza-api/src/main/java/org/apache/samza/checkpoint/BlobStoreCheckpointMarker.java",
    "raw_url": "https://github.com/dxichen/samza/raw/f010e3429c1b8670cd4fa5d7b13b8f75b3462c7b/samza-api/src/main/java/org/apache/samza/checkpoint/BlobStoreCheckpointMarker.java",
    "contents_url": "https://api.github.com/repos/dxichen/samza/contents/samza-api/src/main/java/org/apache/samza/checkpoint/BlobStoreCheckpointMarker.java?ref=f010e3429c1b8670cd4fa5d7b13b8f75b3462c7b",
    "patch": "@@ -0,0 +1,93 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.samza.checkpoint;\n+\n+import java.util.Objects;\n+import org.apache.commons.lang3.StringUtils;\n+import org.apache.samza.SamzaException;\n+\n+\n+public class BlobStoreCheckpointMarker implements StateCheckpointMarker {\n+  public static final String SEPARATOR = \";\";\n+  // backwards compatibility for this unstable api\n+  private static final short PROTOCOL_VERSION = 1;\n+\n+  // blob store location id obtained after upload\n+  private final String blobId;\n+  // timestamp of when the upload was completed\n+  private final long createdMillis;\n+\n+  public BlobStoreCheckpointMarker(String blobId, long createdMillis) {\n+    this.blobId = blobId;\n+    this.createdMillis = createdMillis;\n+  }\n+\n+  public String getBlobId() {\n+    return blobId;\n+  }\n+\n+  public long getCreatedMillis() {\n+    return createdMillis;\n+  }\n+\n+  public short getProtocolVersion() {\n+    return PROTOCOL_VERSION;\n+  }\n+\n+  public static BlobStoreCheckpointMarker fromString(String message) {\n+    if (StringUtils.isBlank(message)) {\n+      throw new IllegalArgumentException(\"Invalid remote store checkpoint message: \" + message);\n+    }\n+    String[] parts = message.split(SEPARATOR);\n+    if (parts.length != 3) {\n+      throw new IllegalArgumentException(\"Invalid RemoteStore Metadata offset: \" + message);\n+    }\n+    if (Short.parseShort(parts[2]) != PROTOCOL_VERSION) {\n+      throw new IllegalArgumentException(\"Using different protocol versions fore BlobStoreCheckpointMarker, expected \"\n+          + PROTOCOL_VERSION + \", got \" +  parts[2]);\n+    }\n+    return new BlobStoreCheckpointMarker(parts[0], Long.parseLong(parts[1]));\n+  }\n+\n+  @Override\n+  public String toString() {\n+    return String.format(\"%s%s%s%s%s\", blobId, SEPARATOR, createdMillis, SEPARATOR, PROTOCOL_VERSION);\n+  }\n+\n+  @Override\n+  public boolean equals(Object o) {\n+    if (this == o) return true;\n+    if (o == null || getClass() != o.getClass()) return false;\n+    BlobStoreCheckpointMarker that = (BlobStoreCheckpointMarker) o;\n+    return Objects.equals(blobId, that.blobId) &&\n+        Objects.equals(createdMillis, that.createdMillis) &&\n+        Objects.equals(PROTOCOL_VERSION, that.getProtocolVersion());\n+  }\n+\n+  @Override\n+  public int hashCode() {\n+    return Objects.hash(blobId, createdMillis, PROTOCOL_VERSION);\n+  }\n+\n+  @Override\n+  public String getFactoryName() {\n+    throw new SamzaException(\"getFactoryName is not supported for BlobStoreCheckpointMarker\");\n+  }\n+}"
  },
  {
    "sha": "9793b0508e11fc13c2baf29dfe2aa1f42b9e49b3",
    "filename": "samza-api/src/main/java/org/apache/samza/checkpoint/Checkpoint.java",
    "status": "modified",
    "additions": 2,
    "deletions": 50,
    "changes": 52,
    "blob_url": "https://github.com/dxichen/samza/blob/f010e3429c1b8670cd4fa5d7b13b8f75b3462c7b/samza-api/src/main/java/org/apache/samza/checkpoint/Checkpoint.java",
    "raw_url": "https://github.com/dxichen/samza/raw/f010e3429c1b8670cd4fa5d7b13b8f75b3462c7b/samza-api/src/main/java/org/apache/samza/checkpoint/Checkpoint.java",
    "contents_url": "https://api.github.com/repos/dxichen/samza/contents/samza-api/src/main/java/org/apache/samza/checkpoint/Checkpoint.java?ref=f010e3429c1b8670cd4fa5d7b13b8f75b3462c7b",
    "patch": "@@ -19,54 +19,6 @@\n \n package org.apache.samza.checkpoint;\n \n-import org.apache.samza.system.SystemStreamPartition;\n-\n-import java.util.Collections;\n-import java.util.Map;\n-\n-/**\n- * A checkpoint is a mapping of all the streams a job is consuming and the most recent current offset for each.\n- * It is used to restore a {@link org.apache.samza.task.StreamTask}, either as part of a job restart or as part\n- * of restarting a failed container within a running job.\n- */\n-public class Checkpoint {\n-  private final Map<SystemStreamPartition, String> offsets;\n-\n-  /**\n-   * Constructs a new checkpoint based off a map of Samza stream offsets.\n-   * @param offsets Map of Samza streams to their current offset.\n-   */\n-  public Checkpoint(Map<SystemStreamPartition, String> offsets) {\n-    this.offsets = offsets;\n-  }\n-\n-  /**\n-   * Gets a unmodifiable view of the current Samza stream offsets.\n-   * @return A unmodifiable view of a Map of Samza streams to their recorded offsets.\n-   */\n-  public Map<SystemStreamPartition, String> getOffsets() {\n-    return Collections.unmodifiableMap(offsets);\n-  }\n-\n-  @Override\n-  public boolean equals(Object o) {\n-    if (this == o) return true;\n-    if (!(o instanceof Checkpoint)) return false;\n-\n-    Checkpoint that = (Checkpoint) o;\n-\n-    if (offsets != null ? !offsets.equals(that.offsets) : that.offsets != null) return false;\n-\n-    return true;\n-  }\n-\n-  @Override\n-  public int hashCode() {\n-    return offsets != null ? offsets.hashCode() : 0;\n-  }\n-\n-  @Override\n-  public String toString() {\n-    return \"Checkpoint [offsets=\" + offsets + \"]\";\n-  }\n+public interface Checkpoint {\n+  short getVersion();\n }"
  },
  {
    "sha": "eac126e06a2c8a7f1c8a7eccb2e3eb27e9a07a57",
    "filename": "samza-api/src/main/java/org/apache/samza/checkpoint/CheckpointId.java",
    "status": "modified",
    "additions": 9,
    "deletions": 1,
    "changes": 10,
    "blob_url": "https://github.com/dxichen/samza/blob/f010e3429c1b8670cd4fa5d7b13b8f75b3462c7b/samza-api/src/main/java/org/apache/samza/checkpoint/CheckpointId.java",
    "raw_url": "https://github.com/dxichen/samza/raw/f010e3429c1b8670cd4fa5d7b13b8f75b3462c7b/samza-api/src/main/java/org/apache/samza/checkpoint/CheckpointId.java",
    "contents_url": "https://api.github.com/repos/dxichen/samza/contents/samza-api/src/main/java/org/apache/samza/checkpoint/CheckpointId.java?ref=f010e3429c1b8670cd4fa5d7b13b8f75b3462c7b",
    "patch": "@@ -36,11 +36,19 @@\n   private final long millis;\n   private final long nanos;\n \n-  public CheckpointId(long millis, long nanos) {\n+  private CheckpointId(long millis, long nanos) {\n     this.millis = millis;\n     this.nanos = nanos;\n   }\n \n+  /**\n+   * Default placeholder checkpointId for backwards compatibility\n+   * @return Default placeholder checkpoint id\n+   */\n+  public static CheckpointId getPlaceholderCheckpointId() {\n+    return new CheckpointId(-1, -1);\n+  }\n+\n   public static CheckpointId create() {\n     return new CheckpointId(System.currentTimeMillis(), System.nanoTime() % 1000000);\n   }"
  },
  {
    "sha": "8a093d95afa492fe1a97878b39325a8e5b108533",
    "filename": "samza-api/src/main/java/org/apache/samza/checkpoint/CheckpointV1.java",
    "status": "added",
    "additions": 77,
    "deletions": 0,
    "changes": 77,
    "blob_url": "https://github.com/dxichen/samza/blob/f010e3429c1b8670cd4fa5d7b13b8f75b3462c7b/samza-api/src/main/java/org/apache/samza/checkpoint/CheckpointV1.java",
    "raw_url": "https://github.com/dxichen/samza/raw/f010e3429c1b8670cd4fa5d7b13b8f75b3462c7b/samza-api/src/main/java/org/apache/samza/checkpoint/CheckpointV1.java",
    "contents_url": "https://api.github.com/repos/dxichen/samza/contents/samza-api/src/main/java/org/apache/samza/checkpoint/CheckpointV1.java?ref=f010e3429c1b8670cd4fa5d7b13b8f75b3462c7b",
    "patch": "@@ -0,0 +1,77 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.samza.checkpoint;\n+\n+import org.apache.samza.system.SystemStreamPartition;\n+\n+import java.util.Collections;\n+import java.util.Map;\n+import java.util.Objects;\n+\n+/**\n+ * A checkpoint is a mapping of all the streams a job is consuming and the most recent current offset for each.\n+ * It is used to restore a {@link org.apache.samza.task.StreamTask}, either as part of a job restart or as part\n+ * of restarting a failed container within a running job.\n+ */\n+public class CheckpointV1 implements Checkpoint {\n+  public static final short CHECKPOINT_VERSION = 1;\n+\n+  private final Map<SystemStreamPartition, String> offsets;\n+\n+  /**\n+   * Constructs a new checkpoint based off a map of Samza stream offsets.\n+   * @param offsets Map of Samza streams to their current offset.\n+   */\n+  public CheckpointV1(Map<SystemStreamPartition, String> offsets) {\n+    this.offsets = offsets;\n+  }\n+\n+  public short getVersion() {\n+    return CHECKPOINT_VERSION;\n+  }\n+\n+  /**\n+   * Gets a unmodifiable view of the current Samza stream offsets.\n+   * @return A unmodifiable view of a Map of Samza streams to their recorded offsets.\n+   */\n+  public Map<SystemStreamPartition, String> getOffsets() {\n+    return Collections.unmodifiableMap(offsets);\n+  }\n+\n+  @Override\n+  public boolean equals(Object o) {\n+    if (this == o) return true;\n+    if (!(o instanceof CheckpointV1)) return false;\n+\n+    CheckpointV1 that = (CheckpointV1) o;\n+\n+    return Objects.equals(offsets, that.offsets);\n+  }\n+\n+  @Override\n+  public int hashCode() {\n+    return offsets != null ? offsets.hashCode() : 0;\n+  }\n+\n+  @Override\n+  public String toString() {\n+    return \"CheckpointV1 [offsets=\" + offsets + \"]\";\n+  }\n+}"
  },
  {
    "sha": "07985204be04a11e1a0124438d0a5076f63b3fa6",
    "filename": "samza-api/src/main/java/org/apache/samza/checkpoint/CheckpointV2.java",
    "status": "added",
    "additions": 106,
    "deletions": 0,
    "changes": 106,
    "blob_url": "https://github.com/dxichen/samza/blob/f010e3429c1b8670cd4fa5d7b13b8f75b3462c7b/samza-api/src/main/java/org/apache/samza/checkpoint/CheckpointV2.java",
    "raw_url": "https://github.com/dxichen/samza/raw/f010e3429c1b8670cd4fa5d7b13b8f75b3462c7b/samza-api/src/main/java/org/apache/samza/checkpoint/CheckpointV2.java",
    "contents_url": "https://api.github.com/repos/dxichen/samza/contents/samza-api/src/main/java/org/apache/samza/checkpoint/CheckpointV2.java?ref=f010e3429c1b8670cd4fa5d7b13b8f75b3462c7b",
    "patch": "@@ -0,0 +1,106 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.samza.checkpoint;\n+\n+import com.google.common.collect.ImmutableMap;\n+import java.util.List;\n+import java.util.Objects;\n+import org.apache.samza.system.SystemStreamPartition;\n+\n+import java.util.Map;\n+\n+/**\n+ * A checkpoint is a mapping of all the streams a job is consuming and the most recent current offset for each.\n+ * It is used to restore a {@link org.apache.samza.task.StreamTask}, either as part of a job restart or as part\n+ * of restarting a failed container within a running job.\n+ */\n+\n+public class CheckpointV2 implements Checkpoint {\n+  public static final short CHECKPOINT_VERSION = 2;\n+\n+  private final CheckpointId checkpointId;\n+  private final Map<SystemStreamPartition, String> inputOffsets;\n+  private final Map<String, List<StateCheckpointMarker>> stateCheckpointMarkers;\n+\n+  /**\n+   * Constructs the checkpoint with separated input and state offsets\n+   * @param checkpointId CheckpointId associated with this checkpoint\n+   * @param inputOffsets Map of Samza system stream partition to offset of the checkpoint\n+   * @param stateCheckpointMarkers Map of local state store names and StateCheckpointMarkers for each state backend system\n+   */\n+  public CheckpointV2(CheckpointId checkpointId,\n+      Map<SystemStreamPartition, String> inputOffsets,\n+      Map<String, List<StateCheckpointMarker>> stateCheckpointMarkers) {\n+    this.checkpointId = checkpointId;\n+    this.inputOffsets = ImmutableMap.copyOf(inputOffsets);\n+    this.stateCheckpointMarkers = ImmutableMap.copyOf(stateCheckpointMarkers);\n+  }\n+\n+  public short getVersion() {\n+    return CHECKPOINT_VERSION;\n+  }\n+\n+  /**\n+   * Gets the checkpoint id for the checkpoint\n+   * @return The timestamp based checkpoint identifier associated with the checkpoint\n+   */\n+  public CheckpointId getCheckpointId() {\n+    return checkpointId;\n+  }\n+\n+  /**\n+   * Gets a unmodifiable view of the current Samza stream offsets.\n+   * @return A unmodifiable view of a Map of Samza streams to their recorded offsets.\n+   */\n+  public Map<SystemStreamPartition, String> getInputOffsets() {\n+    return inputOffsets;\n+  }\n+\n+  /**\n+   * Gets the stateCheckpointMarkers\n+   * @return The state checkpoint markers for the checkpoint\n+   */\n+  public Map<String, List<StateCheckpointMarker>> getStateCheckpointMarkers() {\n+    return stateCheckpointMarkers;\n+  }\n+\n+  @Override\n+  public boolean equals(Object o) {\n+    if (this == o) return true;\n+    if (!(o instanceof CheckpointV2)) return false;\n+\n+    CheckpointV2 that = (CheckpointV2) o;\n+\n+    return checkpointId.equals(that.checkpointId) &&\n+        Objects.equals(inputOffsets, that.inputOffsets) &&\n+        Objects.equals(stateCheckpointMarkers, that.stateCheckpointMarkers);\n+  }\n+\n+  @Override\n+  public int hashCode() {\n+    return Objects.hash(checkpointId, inputOffsets, stateCheckpointMarkers);\n+  }\n+\n+  @Override\n+  public String toString() {\n+    return \"CheckpointV2 [SCHEMA_VERSION=\" + CHECKPOINT_VERSION + \", checkpointId=\" + checkpointId +\n+        \", inputOffsets=\" + inputOffsets + \", stateCheckpoint=\" + stateCheckpointMarkers + \"]\";\n+  }\n+}"
  },
  {
    "sha": "35fbf5d2798196dbc17e7f791f87aa701352a00e",
    "filename": "samza-api/src/main/java/org/apache/samza/checkpoint/KafkaStateChangelogOffset.java",
    "status": "renamed",
    "additions": 15,
    "deletions": 13,
    "changes": 28,
    "blob_url": "https://github.com/dxichen/samza/blob/f010e3429c1b8670cd4fa5d7b13b8f75b3462c7b/samza-api/src/main/java/org/apache/samza/checkpoint/KafkaStateChangelogOffset.java",
    "raw_url": "https://github.com/dxichen/samza/raw/f010e3429c1b8670cd4fa5d7b13b8f75b3462c7b/samza-api/src/main/java/org/apache/samza/checkpoint/KafkaStateChangelogOffset.java",
    "contents_url": "https://api.github.com/repos/dxichen/samza/contents/samza-api/src/main/java/org/apache/samza/checkpoint/KafkaStateChangelogOffset.java?ref=f010e3429c1b8670cd4fa5d7b13b8f75b3462c7b",
    "patch": "@@ -25,23 +25,24 @@\n /**\n  * Checkpointed changelog offset has the format: [checkpointId, offset], separated by a colon.\n  */\n+// TODO HIGH dchen use this when creating CheckpointV1 from KafkaSCM in TaskCommitManager\n @InterfaceStability.Unstable\n-public class CheckpointedChangelogOffset {\n+public class KafkaStateChangelogOffset {\n   public static final String SEPARATOR = \":\";\n \n   private final CheckpointId checkpointId;\n-  private final String offset;\n+  private final String changelogOffset;\n \n-  public CheckpointedChangelogOffset(CheckpointId checkpointId, String offset) {\n+  public KafkaStateChangelogOffset(CheckpointId checkpointId, String changelogOffset) {\n     this.checkpointId = checkpointId;\n-    this.offset = offset;\n+    this.changelogOffset = changelogOffset;\n   }\n \n-  public static CheckpointedChangelogOffset fromString(String message) {\n+  public static KafkaStateChangelogOffset fromString(String message) {\n     if (StringUtils.isBlank(message)) {\n       throw new IllegalArgumentException(\"Invalid checkpointed changelog message: \" + message);\n     }\n-    String[] checkpointIdAndOffset = message.split(\":\");\n+    String[] checkpointIdAndOffset = message.split(SEPARATOR);\n     if (checkpointIdAndOffset.length != 2) {\n       throw new IllegalArgumentException(\"Invalid checkpointed changelog offset: \" + message);\n     }\n@@ -50,33 +51,34 @@ public static CheckpointedChangelogOffset fromString(String message) {\n     if (!\"null\".equals(checkpointIdAndOffset[1])) {\n       offset = checkpointIdAndOffset[1];\n     }\n-    return new CheckpointedChangelogOffset(checkpointId, offset);\n+\n+    return new KafkaStateChangelogOffset(checkpointId, offset);\n   }\n \n   public CheckpointId getCheckpointId() {\n     return checkpointId;\n   }\n \n-  public String getOffset() {\n-    return offset;\n+  public String getChangelogOffset() {\n+    return changelogOffset;\n   }\n \n   @Override\n   public String toString() {\n-    return String.format(\"%s%s%s\", checkpointId, SEPARATOR, offset);\n+    return String.format(\"%s%s%s\", checkpointId, SEPARATOR, changelogOffset);\n   }\n \n   @Override\n   public boolean equals(Object o) {\n     if (this == o) return true;\n     if (o == null || getClass() != o.getClass()) return false;\n-    CheckpointedChangelogOffset that = (CheckpointedChangelogOffset) o;\n+    KafkaStateChangelogOffset that = (KafkaStateChangelogOffset) o;\n     return Objects.equals(checkpointId, that.checkpointId) &&\n-        Objects.equals(offset, that.offset);\n+        Objects.equals(changelogOffset, that.changelogOffset);\n   }\n \n   @Override\n   public int hashCode() {\n-    return Objects.hash(checkpointId, offset);\n+    return Objects.hash(checkpointId, changelogOffset);\n   }\n }",
    "previous_filename": "samza-api/src/main/java/org/apache/samza/checkpoint/CheckpointedChangelogOffset.java"
  },
  {
    "sha": "4c4527f1c8392d11331d4c1197c86f78e82a0686",
    "filename": "samza-api/src/main/java/org/apache/samza/checkpoint/StateCheckpointMarker.java",
    "status": "added",
    "additions": 28,
    "deletions": 0,
    "changes": 28,
    "blob_url": "https://github.com/dxichen/samza/blob/f010e3429c1b8670cd4fa5d7b13b8f75b3462c7b/samza-api/src/main/java/org/apache/samza/checkpoint/StateCheckpointMarker.java",
    "raw_url": "https://github.com/dxichen/samza/raw/f010e3429c1b8670cd4fa5d7b13b8f75b3462c7b/samza-api/src/main/java/org/apache/samza/checkpoint/StateCheckpointMarker.java",
    "contents_url": "https://api.github.com/repos/dxichen/samza/contents/samza-api/src/main/java/org/apache/samza/checkpoint/StateCheckpointMarker.java?ref=f010e3429c1b8670cd4fa5d7b13b8f75b3462c7b",
    "patch": "@@ -0,0 +1,28 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.samza.checkpoint;\n+\n+\n+/**\n+ * Interface for State Checkpoint Marker for all TaskStorageBackupManagers\n+ */\n+public interface StateCheckpointMarker {\n+  String getFactoryName();\n+}"
  },
  {
    "sha": "52701736a3c7b6ad611e70248b6b1ae1709228d8",
    "filename": "samza-api/src/main/java/org/apache/samza/checkpoint/StateCheckpointMarkerSerde.java",
    "status": "added",
    "additions": 83,
    "deletions": 0,
    "changes": 83,
    "blob_url": "https://github.com/dxichen/samza/blob/f010e3429c1b8670cd4fa5d7b13b8f75b3462c7b/samza-api/src/main/java/org/apache/samza/checkpoint/StateCheckpointMarkerSerde.java",
    "raw_url": "https://github.com/dxichen/samza/raw/f010e3429c1b8670cd4fa5d7b13b8f75b3462c7b/samza-api/src/main/java/org/apache/samza/checkpoint/StateCheckpointMarkerSerde.java",
    "contents_url": "https://api.github.com/repos/dxichen/samza/contents/samza-api/src/main/java/org/apache/samza/checkpoint/StateCheckpointMarkerSerde.java?ref=f010e3429c1b8670cd4fa5d7b13b8f75b3462c7b",
    "patch": "@@ -0,0 +1,83 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.samza.checkpoint;\n+\n+import org.apache.commons.lang3.StringUtils;\n+import org.apache.samza.SamzaException;\n+import org.apache.samza.storage.StateBackendFactory;\n+\n+\n+public class StateCheckpointMarkerSerde<T extends StateCheckpointMarker> {\n+  private static final short SCHEMA_VERSION = 1;\n+  private static final String SEPARATOR = \":\";\n+  private static final int PARTS_COUNT = 3; // protocol_version, serde_class, payload\n+\n+  /**\n+   * Serializes the {@link StateCheckpointMarker} according to the {@link StateCheckpointPayloadSerde} provided by\n+   * the {@link StateBackendFactory}\n+   * @param payload of type StateCheckpointMarker to be serialized into String\n+   * @return serialized StateCheckpointMarker\n+   */\n+  public String serialize(T payload) {\n+    try {\n+      StateBackendFactory stateBackendFactory =\n+          (StateBackendFactory) Class.forName(payload.getFactoryName()).newInstance();\n+      StateCheckpointPayloadSerde<T> payloadSerde = stateBackendFactory.getStateCheckpointPayloadSerde();\n+      return SCHEMA_VERSION + SEPARATOR +\n+          payloadSerde.getClass().getName() + SEPARATOR +\n+          payloadSerde.serialize(payload);\n+    } catch (ClassNotFoundException | IllegalAccessException | InstantiationException e) {\n+      throw new SamzaException(\"State backend factory serde not found for class name: \" + payload.getFactoryName(), e);\n+    }\n+  }\n+\n+  /**\n+   * Deserializes the serialized {@link StateCheckpointMarker} with the {@link StateCheckpointPayloadSerde} provided in\n+   * the serializedSCM\n+   * @param serializedSCM serialized version of a {@link StateCheckpointMarker}\n+   * @return {@link StateCheckpointMarker} object deserialized\n+   */\n+  public T deserialize(String serializedSCM) {\n+    if (StringUtils.isBlank(serializedSCM)) {\n+      throw new IllegalArgumentException(\"Invalid remote store checkpoint message: \" + serializedSCM);\n+    }\n+    String[] parts = serializedSCM.split(SEPARATOR, PARTS_COUNT);\n+    if (parts.length != PARTS_COUNT) {\n+      throw new IllegalArgumentException(\"Invalid state checkpoint marker: \" + serializedSCM);\n+    }\n+    short scmSchemaVersion = Short.parseShort(parts[0]);\n+    if (SCHEMA_VERSION != scmSchemaVersion) {\n+      throw new SamzaException(\n+          String.format(\"StateCheckpointMarker supported schema version does not match serialized \" +\n+              \"state checkpoint marker schema version. Supported version: %d. Found version: %d\",\n+              SCHEMA_VERSION, scmSchemaVersion));\n+    }\n+    String payloadSerdeClassName = parts[1];\n+    try {\n+      StateCheckpointPayloadSerde<T> serde =\n+          (StateCheckpointPayloadSerde<T>) Class.forName(payloadSerdeClassName).newInstance();\n+      return serde.deserialize(parts[2]);\n+    } catch (Exception e) {\n+      throw new SamzaException(\n+          String.format(\"Error deserializing state checkpoint marker: %s with payload serde class: %s\",\n+              serializedSCM, payloadSerdeClassName), e);\n+    }\n+  }\n+}"
  },
  {
    "sha": "ef4badf74b034163dd7f02e8e4e09148226efa35",
    "filename": "samza-api/src/main/java/org/apache/samza/checkpoint/StateCheckpointPayloadSerde.java",
    "status": "added",
    "additions": 27,
    "deletions": 0,
    "changes": 27,
    "blob_url": "https://github.com/dxichen/samza/blob/f010e3429c1b8670cd4fa5d7b13b8f75b3462c7b/samza-api/src/main/java/org/apache/samza/checkpoint/StateCheckpointPayloadSerde.java",
    "raw_url": "https://github.com/dxichen/samza/raw/f010e3429c1b8670cd4fa5d7b13b8f75b3462c7b/samza-api/src/main/java/org/apache/samza/checkpoint/StateCheckpointPayloadSerde.java",
    "contents_url": "https://api.github.com/repos/dxichen/samza/contents/samza-api/src/main/java/org/apache/samza/checkpoint/StateCheckpointPayloadSerde.java?ref=f010e3429c1b8670cd4fa5d7b13b8f75b3462c7b",
    "patch": "@@ -0,0 +1,27 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.samza.checkpoint;\n+\n+public interface StateCheckpointPayloadSerde<T extends StateCheckpointMarker> {\n+  // TODO HIGH dchen add javadocs\n+  String serialize(T payload);\n+\n+  T deserialize(String data);\n+}"
  },
  {
    "sha": "a1e1265408b65862f56fb2eefd48bd68d4c86040",
    "filename": "samza-api/src/main/java/org/apache/samza/storage/StateBackendFactory.java",
    "status": "added",
    "additions": 51,
    "deletions": 0,
    "changes": 51,
    "blob_url": "https://github.com/dxichen/samza/blob/f010e3429c1b8670cd4fa5d7b13b8f75b3462c7b/samza-api/src/main/java/org/apache/samza/storage/StateBackendFactory.java",
    "raw_url": "https://github.com/dxichen/samza/raw/f010e3429c1b8670cd4fa5d7b13b8f75b3462c7b/samza-api/src/main/java/org/apache/samza/storage/StateBackendFactory.java",
    "contents_url": "https://api.github.com/repos/dxichen/samza/contents/samza-api/src/main/java/org/apache/samza/storage/StateBackendFactory.java?ref=f010e3429c1b8670cd4fa5d7b13b8f75b3462c7b",
    "patch": "@@ -0,0 +1,51 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.samza.storage;\n+\n+import java.util.Map;\n+import org.apache.samza.checkpoint.StateCheckpointPayloadSerde;\n+import org.apache.samza.config.Config;\n+import org.apache.samza.job.model.ContainerModel;\n+import org.apache.samza.job.model.JobModel;\n+import org.apache.samza.job.model.TaskModel;\n+import org.apache.samza.util.Clock;\n+\n+\n+public interface StateBackendFactory {\n+  TaskBackupManager getBackupManager(JobModel jobModel,\n+      ContainerModel containerModel,\n+      TaskModel taskModel,\n+      Map<String, StorageEngine> taskStores,\n+      Config config,\n+      Clock clock);\n+\n+  TaskRestoreManager getRestoreManager(JobModel jobModel,\n+      ContainerModel containerModel,\n+      TaskModel taskModel,\n+      Map<String, StorageEngine> taskStores,\n+      Config config,\n+      Clock clock);\n+\n+  TaskStorageAdmin getAdmin();\n+\n+  // TODO HIGH dchen check why this needs to be part of this interface\n+  // Can the backup and restore managers do the serde for SCM payloads themselves?\n+  StateCheckpointPayloadSerde getStateCheckpointPayloadSerde();\n+}"
  },
  {
    "sha": "0d62ca4c10cb3eceb40f0fa5ba0c9229dbabb0da",
    "filename": "samza-api/src/main/java/org/apache/samza/storage/StorageEngine.java",
    "status": "modified",
    "additions": 8,
    "deletions": 0,
    "changes": 8,
    "blob_url": "https://github.com/dxichen/samza/blob/f010e3429c1b8670cd4fa5d7b13b8f75b3462c7b/samza-api/src/main/java/org/apache/samza/storage/StorageEngine.java",
    "raw_url": "https://github.com/dxichen/samza/raw/f010e3429c1b8670cd4fa5d7b13b8f75b3462c7b/samza-api/src/main/java/org/apache/samza/storage/StorageEngine.java",
    "contents_url": "https://api.github.com/repos/dxichen/samza/contents/samza-api/src/main/java/org/apache/samza/storage/StorageEngine.java?ref=f010e3429c1b8670cd4fa5d7b13b8f75b3462c7b",
    "patch": "@@ -24,6 +24,9 @@\n import java.util.Optional;\n import org.apache.samza.annotation.InterfaceStability;\n import org.apache.samza.checkpoint.CheckpointId;\n+import org.apache.samza.context.ContainerContext;\n+import org.apache.samza.context.ExternalContext;\n+import org.apache.samza.context.JobContext;\n import org.apache.samza.system.ChangelogSSPIterator;\n \n /**\n@@ -38,6 +41,11 @@\n  */\n public interface StorageEngine {\n \n+  /**\n+   * Initialize the storage engine\n+   */\n+  default void init(ExternalContext externalContext, JobContext jobContext, ContainerContext containerContext) { };\n+\n   /**\n    * Restore the content of this StorageEngine from the changelog. Messages are\n    * provided in one {@link java.util.Iterator} and not deserialized for"
  },
  {
    "sha": "2b1b8316fb04e7ed9d5ee0bb52435c77d13d28d4",
    "filename": "samza-api/src/main/java/org/apache/samza/storage/TaskBackupManager.java",
    "status": "added",
    "additions": 90,
    "deletions": 0,
    "changes": 90,
    "blob_url": "https://github.com/dxichen/samza/blob/f010e3429c1b8670cd4fa5d7b13b8f75b3462c7b/samza-api/src/main/java/org/apache/samza/storage/TaskBackupManager.java",
    "raw_url": "https://github.com/dxichen/samza/raw/f010e3429c1b8670cd4fa5d7b13b8f75b3462c7b/samza-api/src/main/java/org/apache/samza/storage/TaskBackupManager.java",
    "contents_url": "https://api.github.com/repos/dxichen/samza/contents/samza-api/src/main/java/org/apache/samza/storage/TaskBackupManager.java?ref=f010e3429c1b8670cd4fa5d7b13b8f75b3462c7b",
    "patch": "@@ -0,0 +1,90 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.samza.storage;\n+\n+import java.util.Map;\n+import java.util.concurrent.CompletableFuture;\n+\n+import org.apache.samza.checkpoint.Checkpoint;\n+import org.apache.samza.checkpoint.CheckpointId;\n+import org.apache.samza.checkpoint.StateCheckpointMarker;\n+\n+/**\n+ * <p>\n+ * TaskBackupManager is the interface that must be implemented for\n+ * any remote system that Samza persists its state to. The interface will be\n+ * evoked in the following way:\n+ * </p>\n+ *\n+ * <ul>\n+ *   <li>Snapshot will be called before Upload.</li>\n+ *   <li>persistToFilesystem will be called after Upload is completed</li>\n+ *   <li>Cleanup is only called after Upload and persistToFilesystem has successfully completed</li>\n+ * </ul>\n+ */\n+public interface TaskBackupManager {\n+\n+  /**\n+   * Initializes the TaskBackupManager instance\n+   * @param checkpoint Last recorded checkpoint from the CheckpointManager or null if no checkpoint was found\n+   */\n+  // TODO HIGH dchen why is this default while stop isn't?\n+  // TODO HIGH dchen explictly mark and document as nullaable and verify all impls handle it correctly\n+  default void init(Checkpoint checkpoint) {}\n+\n+  /**\n+   * Commit operation that is synchronous to processing\n+   * @param checkpointId Checkpoint id of the current commit\n+   * @return The store name to checkpoint of the snapshotted local store\n+   */\n+  Map<String, StateCheckpointMarker> snapshot(CheckpointId checkpointId);\n+\n+  /**\n+   * Commit operation that is asynchronous to message processing,\n+   * @param checkpointId Checkpoint id of the current commit\n+   * @param stateCheckpointMarkers The map of storename to checkpoint makers returned by the snapshot\n+   * @return The future of storename to checkpoint map of the uploaded local store\n+   */\n+  CompletableFuture<Map<String, StateCheckpointMarker>> upload(CheckpointId checkpointId,\n+      Map<String, StateCheckpointMarker> stateCheckpointMarkers);\n+\n+  /**\n+   * Persist the state locally to the file system\n+   * @param checkpointId The id of the checkpoint to be committed\n+   * @param stateCheckpointMarkers Uploaded storename to checkpoints markers to be persisted locally\n+   */\n+  // TODO HIGH dchen fix misleading method name + javadoc + logs. This should only be writing the SCM / OFFSET-V2 files to disk,\n+  // this is too late to \"persist the state\" (store flush), which should have happened in snapshot.\n+  void persistToFilesystem(CheckpointId checkpointId, Map<String, StateCheckpointMarker> stateCheckpointMarkers);\n+\n+  /**\n+   * Cleanup any local or remote state for obsolete checkpoint information that are older than checkpointId\n+   * @param checkpointId The id of the latest successfully committed checkpoint\n+   */\n+  // TODO HIGH dchen can we pass SCMs here as well so that impls don't have to cache that information after upload\n+  //  or during startup?\n+  void cleanUp(CheckpointId checkpointId);\n+\n+  /**\n+   * Shutdown hook the backup manager to cleanup any allocated resources\n+   */\n+  void stop();\n+\n+}\n\\ No newline at end of file"
  },
  {
    "sha": "8f42ba71494ebf1e0a956bc6408746ed3aa0c39b",
    "filename": "samza-api/src/main/java/org/apache/samza/storage/TaskRestoreManager.java",
    "status": "renamed",
    "additions": 5,
    "deletions": 5,
    "changes": 10,
    "blob_url": "https://github.com/dxichen/samza/blob/f010e3429c1b8670cd4fa5d7b13b8f75b3462c7b/samza-api/src/main/java/org/apache/samza/storage/TaskRestoreManager.java",
    "raw_url": "https://github.com/dxichen/samza/raw/f010e3429c1b8670cd4fa5d7b13b8f75b3462c7b/samza-api/src/main/java/org/apache/samza/storage/TaskRestoreManager.java",
    "contents_url": "https://api.github.com/repos/dxichen/samza/contents/samza-api/src/main/java/org/apache/samza/storage/TaskRestoreManager.java?ref=f010e3429c1b8670cd4fa5d7b13b8f75b3462c7b",
    "patch": "@@ -19,8 +19,7 @@\n \n package org.apache.samza.storage;\n \n-import java.util.Map;\n-import org.apache.samza.system.SystemStreamPartition;\n+import org.apache.samza.checkpoint.Checkpoint;\n \n \n /**\n@@ -29,12 +28,12 @@\n public interface TaskRestoreManager {\n \n   /**\n-   * Init state resources such as file directories.\n+   * Initialize state resources such as store directories.\n    */\n-  void init(Map<SystemStreamPartition, String> checkpointedChangelogSSPOffsets);\n+  void init(Checkpoint checkpoint);\n \n   /**\n-   * Restore state from checkpoints, state snapshots and changelog.\n+   * Restore state from checkpoints, state snapshots and changelogs.\n    * Currently, store restoration happens on a separate thread pool within {@code ContainerStorageManager}. In case of\n    * interrupt/shutdown signals from {@code SamzaContainer}, {@code ContainerStorageManager} may interrupt the restore\n    * thread.\n@@ -52,4 +51,5 @@\n    */\n   void stopPersistentStores();\n \n+  // TODO HIGH pmaheshw add close to mirror init? What's the difference b/w close and stopPersistentStores()?\n }",
    "previous_filename": "samza-core/src/main/java/org/apache/samza/storage/TaskRestoreManager.java"
  },
  {
    "sha": "83255f2bbaddda964770c76ba6be593d341c3a90",
    "filename": "samza-api/src/main/java/org/apache/samza/storage/TaskStorageAdmin.java",
    "status": "renamed",
    "additions": 5,
    "deletions": 15,
    "changes": 20,
    "blob_url": "https://github.com/dxichen/samza/blob/f010e3429c1b8670cd4fa5d7b13b8f75b3462c7b/samza-api/src/main/java/org/apache/samza/storage/TaskStorageAdmin.java",
    "raw_url": "https://github.com/dxichen/samza/raw/f010e3429c1b8670cd4fa5d7b13b8f75b3462c7b/samza-api/src/main/java/org/apache/samza/storage/TaskStorageAdmin.java",
    "contents_url": "https://api.github.com/repos/dxichen/samza/contents/samza-api/src/main/java/org/apache/samza/storage/TaskStorageAdmin.java?ref=f010e3429c1b8670cd4fa5d7b13b8f75b3462c7b",
    "patch": "@@ -17,21 +17,11 @@\n  * under the License.\n  */\n \n-package org.apache.samza.storage\n+package org.apache.samza.storage;\n \n-import org.apache.samza.checkpoint.CheckpointId\n-import org.apache.samza.system.SystemStreamPartition\n+public interface TaskStorageAdmin {\n \n-trait TaskStorageManager {\n+  void createResources();\n \n-  def getStore(storeName: String): Option[StorageEngine]\n-\n-  def flush(): Map[SystemStreamPartition, Option[String]]\n-\n-  def checkpoint(checkpointId: CheckpointId, newestChangelogOffsets: Map[SystemStreamPartition, Option[String]]): Unit\n-\n-  def removeOldCheckpoints(checkpointId: CheckpointId): Unit\n-\n-  def stop(): Unit\n-\n-}\n\\ No newline at end of file\n+  void validateResources();\n+}",
    "previous_filename": "samza-core/src/main/scala/org/apache/samza/storage/TaskStorageManager.scala"
  },
  {
    "sha": "a3552f08b908fcec9379fa292b211d4ca901bbed",
    "filename": "samza-api/src/main/java/org/apache/samza/storage/kv/KeyValueStore.java",
    "status": "modified",
    "additions": 13,
    "deletions": 0,
    "changes": 13,
    "blob_url": "https://github.com/dxichen/samza/blob/f010e3429c1b8670cd4fa5d7b13b8f75b3462c7b/samza-api/src/main/java/org/apache/samza/storage/kv/KeyValueStore.java",
    "raw_url": "https://github.com/dxichen/samza/raw/f010e3429c1b8670cd4fa5d7b13b8f75b3462c7b/samza-api/src/main/java/org/apache/samza/storage/kv/KeyValueStore.java",
    "contents_url": "https://api.github.com/repos/dxichen/samza/contents/samza-api/src/main/java/org/apache/samza/storage/kv/KeyValueStore.java?ref=f010e3429c1b8670cd4fa5d7b13b8f75b3462c7b",
    "patch": "@@ -26,6 +26,9 @@\n import java.util.Optional;\n import org.apache.samza.annotation.InterfaceStability;\n import org.apache.samza.checkpoint.CheckpointId;\n+import org.apache.samza.context.ContainerContext;\n+import org.apache.samza.context.ExternalContext;\n+import org.apache.samza.context.JobContext;\n \n \n /**\n@@ -35,6 +38,16 @@\n  * @param <V> the type of values maintained by this key-value store.\n  */\n public interface KeyValueStore<K, V> {\n+\n+  /**\n+   * Initializes the KeyValueStore\n+   *\n+   * @param externalContext any external store required for initialization\n+   * @param jobContext context of the job the KeyValueStore is in\n+   * @param containerContext context of the KeyValueStore's container\n+   */\n+  default void init(ExternalContext externalContext, JobContext jobContext, ContainerContext containerContext) { }\n+\n   /**\n    * Gets the value associated with the specified {@code key}.\n    *"
  },
  {
    "sha": "6fae7e7c35da83e47f4f59fe2d0d4f903c9c6b29",
    "filename": "samza-api/src/test/java/org/apache/samza/checkpoint/MockStateCheckpointMarker.java",
    "status": "added",
    "additions": 56,
    "deletions": 0,
    "changes": 56,
    "blob_url": "https://github.com/dxichen/samza/blob/f010e3429c1b8670cd4fa5d7b13b8f75b3462c7b/samza-api/src/test/java/org/apache/samza/checkpoint/MockStateCheckpointMarker.java",
    "raw_url": "https://github.com/dxichen/samza/raw/f010e3429c1b8670cd4fa5d7b13b8f75b3462c7b/samza-api/src/test/java/org/apache/samza/checkpoint/MockStateCheckpointMarker.java",
    "contents_url": "https://api.github.com/repos/dxichen/samza/contents/samza-api/src/test/java/org/apache/samza/checkpoint/MockStateCheckpointMarker.java?ref=f010e3429c1b8670cd4fa5d7b13b8f75b3462c7b",
    "patch": "@@ -0,0 +1,56 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.samza.checkpoint;\n+\n+import java.util.Objects;\n+import org.apache.samza.system.SystemStreamPartition;\n+\n+\n+public class MockStateCheckpointMarker implements StateCheckpointMarker {\n+  public static final String MOCK_FACTORY_NAME = MockStateCheckpointMarkerFactory.class.getName();\n+\n+  public final SystemStreamPartition ssp;\n+  public final String offset;\n+\n+  public MockStateCheckpointMarker(SystemStreamPartition ssp, String offset) {\n+    this.ssp = ssp;\n+    this.offset = offset;\n+  }\n+\n+  @Override\n+  public String getFactoryName() {\n+    return MOCK_FACTORY_NAME;\n+  }\n+\n+  @Override\n+  public boolean equals(Object other) {\n+    if (this == other) return true;\n+    if (other == null || getClass() != other.getClass()) return false;\n+    MockStateCheckpointMarker that = (MockStateCheckpointMarker) other;\n+    return Objects.equals(ssp, that.ssp) &&\n+        Objects.equals(offset, that.offset);\n+  }\n+\n+  @Override\n+  public int hashCode() {\n+    return Objects.hash(ssp, offset);\n+  }\n+\n+}"
  },
  {
    "sha": "3ed026498b921f0b8abd11812b3a8e6c8e3b1420",
    "filename": "samza-api/src/test/java/org/apache/samza/checkpoint/MockStateCheckpointMarkerFactory.java",
    "status": "added",
    "additions": 58,
    "deletions": 0,
    "changes": 58,
    "blob_url": "https://github.com/dxichen/samza/blob/f010e3429c1b8670cd4fa5d7b13b8f75b3462c7b/samza-api/src/test/java/org/apache/samza/checkpoint/MockStateCheckpointMarkerFactory.java",
    "raw_url": "https://github.com/dxichen/samza/raw/f010e3429c1b8670cd4fa5d7b13b8f75b3462c7b/samza-api/src/test/java/org/apache/samza/checkpoint/MockStateCheckpointMarkerFactory.java",
    "contents_url": "https://api.github.com/repos/dxichen/samza/contents/samza-api/src/test/java/org/apache/samza/checkpoint/MockStateCheckpointMarkerFactory.java?ref=f010e3429c1b8670cd4fa5d7b13b8f75b3462c7b",
    "patch": "@@ -0,0 +1,58 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.samza.checkpoint;\n+\n+import java.util.Map;\n+import org.apache.samza.config.Config;\n+import org.apache.samza.job.model.ContainerModel;\n+import org.apache.samza.job.model.JobModel;\n+import org.apache.samza.job.model.TaskModel;\n+import org.apache.samza.storage.StateBackendFactory;\n+import org.apache.samza.storage.StorageEngine;\n+import org.apache.samza.storage.TaskBackupManager;\n+import org.apache.samza.storage.TaskRestoreManager;\n+import org.apache.samza.storage.TaskStorageAdmin;\n+import org.apache.samza.util.Clock;\n+\n+\n+public class MockStateCheckpointMarkerFactory implements StateBackendFactory {\n+\n+  @Override\n+  public TaskBackupManager getBackupManager(JobModel jobModel, ContainerModel containerModel, TaskModel taskModel,\n+      Map<String, StorageEngine> taskStores, Config config, Clock clock) {\n+    return null;\n+  }\n+\n+  @Override\n+  public TaskRestoreManager getRestoreManager(JobModel jobModel, ContainerModel containerModel, TaskModel taskModel,\n+      Map<String, StorageEngine> taskStores, Config config, Clock clock) {\n+    return null;\n+  }\n+\n+  @Override\n+  public TaskStorageAdmin getAdmin() {\n+    return null;\n+  }\n+\n+  @Override\n+  public StateCheckpointPayloadSerde getStateCheckpointPayloadSerde() {\n+    return new MockStateCheckpointPayloadSerde();\n+  }\n+}"
  },
  {
    "sha": "8bb130bbcff5a5d0ed62f355b9bb057496a3aa86",
    "filename": "samza-api/src/test/java/org/apache/samza/checkpoint/MockStateCheckpointPayloadSerde.java",
    "status": "added",
    "additions": 42,
    "deletions": 0,
    "changes": 42,
    "blob_url": "https://github.com/dxichen/samza/blob/f010e3429c1b8670cd4fa5d7b13b8f75b3462c7b/samza-api/src/test/java/org/apache/samza/checkpoint/MockStateCheckpointPayloadSerde.java",
    "raw_url": "https://github.com/dxichen/samza/raw/f010e3429c1b8670cd4fa5d7b13b8f75b3462c7b/samza-api/src/test/java/org/apache/samza/checkpoint/MockStateCheckpointPayloadSerde.java",
    "contents_url": "https://api.github.com/repos/dxichen/samza/contents/samza-api/src/test/java/org/apache/samza/checkpoint/MockStateCheckpointPayloadSerde.java?ref=f010e3429c1b8670cd4fa5d7b13b8f75b3462c7b",
    "patch": "@@ -0,0 +1,42 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.samza.checkpoint;\n+\n+import org.apache.samza.Partition;\n+import org.apache.samza.system.SystemStreamPartition;\n+\n+\n+public class MockStateCheckpointPayloadSerde implements StateCheckpointPayloadSerde<MockStateCheckpointMarker> {\n+  private static final String SEPARATOR = \";\";\n+\n+  @Override\n+  public String serialize(MockStateCheckpointMarker payload) {\n+    return payload.ssp.getSystem() + SEPARATOR + payload.ssp.getStream() + SEPARATOR + payload.ssp.getPartition()\n+        .getPartitionId() + SEPARATOR + payload.offset;\n+  }\n+\n+  @Override\n+  public MockStateCheckpointMarker deserialize(String data) {\n+    String[] parts = data.split(SEPARATOR);\n+    return new MockStateCheckpointMarker(\n+        new SystemStreamPartition(parts[0], parts[1], new Partition(Integer.parseInt(parts[2]))),\n+        parts[3]);\n+  }\n+}"
  },
  {
    "sha": "6ddf3493e19e8be32ff351d4289eb2aa991e01a2",
    "filename": "samza-azure/src/main/java/org/apache/samza/checkpoint/azure/AzureCheckpointManager.java",
    "status": "modified",
    "additions": 4,
    "deletions": 2,
    "changes": 6,
    "blob_url": "https://github.com/dxichen/samza/blob/f010e3429c1b8670cd4fa5d7b13b8f75b3462c7b/samza-azure/src/main/java/org/apache/samza/checkpoint/azure/AzureCheckpointManager.java",
    "raw_url": "https://github.com/dxichen/samza/raw/f010e3429c1b8670cd4fa5d7b13b8f75b3462c7b/samza-azure/src/main/java/org/apache/samza/checkpoint/azure/AzureCheckpointManager.java",
    "contents_url": "https://api.github.com/repos/dxichen/samza/contents/samza-azure/src/main/java/org/apache/samza/checkpoint/azure/AzureCheckpointManager.java?ref=f010e3429c1b8670cd4fa5d7b13b8f75b3462c7b",
    "patch": "@@ -28,6 +28,7 @@\n import org.apache.samza.SamzaException;\n import org.apache.samza.checkpoint.Checkpoint;\n import org.apache.samza.checkpoint.CheckpointManager;\n+import org.apache.samza.checkpoint.CheckpointV1;\n import org.apache.samza.config.AzureConfig;\n import org.apache.samza.container.TaskName;\n import org.apache.samza.serializers.JsonSerdeV2;\n@@ -119,7 +120,8 @@ public void writeCheckpoint(TaskName taskName, Checkpoint checkpoint) {\n \n     TableBatchOperation batchOperation = new TableBatchOperation();\n \n-    Iterator<Map.Entry<SystemStreamPartition, String>> iterator = checkpoint.getOffsets().entrySet().iterator();\n+    Iterator<Map.Entry<SystemStreamPartition, String>> iterator =\n+        ((CheckpointV1) checkpoint).getOffsets().entrySet().iterator();\n     while (iterator.hasNext()) {\n       Map.Entry<SystemStreamPartition, String> entry = iterator.next();\n       SystemStreamPartition ssp = entry.getKey();\n@@ -205,7 +207,7 @@ public Checkpoint readLastCheckpoint(TaskName taskName) {\n       return null;\n     }\n     LOG.debug(\"Received checkpoint state for taskName=%s\", taskName);\n-    return new Checkpoint(builder.build());\n+    return new CheckpointV1(builder.build());\n   }\n \n   @Override"
  },
  {
    "sha": "2240e654346a77d3eaee8ee7770585d53202433a",
    "filename": "samza-azure/src/test/java/org/apache/samza/checkpoint/azure/ITestAzureCheckpointManager.java",
    "status": "modified",
    "additions": 8,
    "deletions": 7,
    "changes": 15,
    "blob_url": "https://github.com/dxichen/samza/blob/f010e3429c1b8670cd4fa5d7b13b8f75b3462c7b/samza-azure/src/test/java/org/apache/samza/checkpoint/azure/ITestAzureCheckpointManager.java",
    "raw_url": "https://github.com/dxichen/samza/raw/f010e3429c1b8670cd4fa5d7b13b8f75b3462c7b/samza-azure/src/test/java/org/apache/samza/checkpoint/azure/ITestAzureCheckpointManager.java",
    "contents_url": "https://api.github.com/repos/dxichen/samza/contents/samza-azure/src/test/java/org/apache/samza/checkpoint/azure/ITestAzureCheckpointManager.java?ref=f010e3429c1b8670cd4fa5d7b13b8f75b3462c7b",
    "patch": "@@ -22,6 +22,7 @@\n import org.apache.samza.Partition;\n import org.apache.samza.checkpoint.Checkpoint;\n import org.apache.samza.checkpoint.CheckpointManager;\n+import org.apache.samza.checkpoint.CheckpointV1;\n import org.apache.samza.config.AzureConfig;\n import org.apache.samza.config.Config;\n import org.apache.samza.config.MapConfig;\n@@ -69,10 +70,10 @@ public void testStoringAndReadingCheckpointsSamePartition() {\n     Map<SystemStreamPartition, String> sspMap = new HashMap<>();\n \n     sspMap.put(ssp, \"12345\");\n-    Checkpoint cp0 = new Checkpoint(sspMap);\n+    Checkpoint cp0 = new CheckpointV1(sspMap);\n \n     sspMap.put(ssp, \"54321\");\n-    Checkpoint cp1 = new Checkpoint(sspMap);\n+    Checkpoint cp1 = new CheckpointV1(sspMap);\n \n     checkpointManager.register(taskName);\n \n@@ -96,12 +97,12 @@ public void testStoringAndReadingCheckpointsMultiPartitions() {\n     Map<SystemStreamPartition, String> sspMap = new HashMap<>();\n     sspMap.put(ssp, \"12345\");\n     sspMap.put(ssp1, \"54321\");\n-    Checkpoint cp1 = new Checkpoint(sspMap);\n+    Checkpoint cp1 = new CheckpointV1(sspMap);\n \n     Map<SystemStreamPartition, String> sspMap2 = new HashMap<>();\n     sspMap2.put(ssp, \"12347\");\n     sspMap2.put(ssp1, \"54323\");\n-    Checkpoint cp2 = new Checkpoint(sspMap2);\n+    Checkpoint cp2 = new CheckpointV1(sspMap2);\n \n     checkpointManager.register(taskName);\n \n@@ -126,12 +127,12 @@ public void testStoringAndReadingCheckpointsMultiTasks() {\n     Map<SystemStreamPartition, String> sspMap = new HashMap<>();\n     sspMap.put(ssp, \"12345\");\n     sspMap.put(ssp1, \"54321\");\n-    Checkpoint cp1 = new Checkpoint(sspMap);\n+    Checkpoint cp1 = new CheckpointV1(sspMap);\n \n     Map<SystemStreamPartition, String> sspMap2 = new HashMap<>();\n     sspMap2.put(ssp, \"12347\");\n     sspMap2.put(ssp1, \"54323\");\n-    Checkpoint cp2 = new Checkpoint(sspMap2);\n+    Checkpoint cp2 = new CheckpointV1(sspMap2);\n \n     checkpointManager.register(taskName);\n     checkpointManager.register(taskName1);\n@@ -171,7 +172,7 @@ public void testMultipleBatchWrites() {\n       sspMap.put(ssp, String.valueOf(i));\n     }\n \n-    Checkpoint cp0 = new Checkpoint(sspMap);\n+    Checkpoint cp0 = new CheckpointV1(sspMap);\n     checkpointManager.register(taskName);\n     checkpointManager.writeCheckpoint(taskName, cp0);\n     Checkpoint readCp = checkpointManager.readLastCheckpoint(taskName);"
  },
  {
    "sha": "5371d6bb2455fc5aa019c4c63483f89b65b7f567",
    "filename": "samza-core/src/main/java/org/apache/samza/config/StorageConfig.java",
    "status": "modified",
    "additions": 15,
    "deletions": 0,
    "changes": 15,
    "blob_url": "https://github.com/dxichen/samza/blob/f010e3429c1b8670cd4fa5d7b13b8f75b3462c7b/samza-core/src/main/java/org/apache/samza/config/StorageConfig.java",
    "raw_url": "https://github.com/dxichen/samza/raw/f010e3429c1b8670cd4fa5d7b13b8f75b3462c7b/samza-core/src/main/java/org/apache/samza/config/StorageConfig.java",
    "contents_url": "https://api.github.com/repos/dxichen/samza/contents/samza-core/src/main/java/org/apache/samza/config/StorageConfig.java?ref=f010e3429c1b8670cd4fa5d7b13b8f75b3462c7b",
    "patch": "@@ -22,13 +22,16 @@\n import java.util.ArrayList;\n import java.util.Collections;\n import java.util.List;\n+import java.util.Map;\n import java.util.Optional;\n import java.util.concurrent.TimeUnit;\n+import java.util.function.Function;\n import java.util.stream.Collectors;\n import java.util.stream.Stream;\n import org.apache.commons.lang3.StringUtils;\n import org.apache.samza.SamzaException;\n import org.apache.samza.execution.StreamManager;\n+import org.apache.samza.system.SystemStream;\n import org.apache.samza.util.StreamUtil;\n \n import static com.google.common.base.Preconditions.*;\n@@ -60,6 +63,8 @@\n   public static final String MIN_COMPACTION_LAG_MS = \"min.compaction.lag.ms\";\n   public static final String CHANGELOG_MIN_COMPACTION_LAG_MS = STORE_PREFIX + \"%s.changelog.\" + MIN_COMPACTION_LAG_MS;\n   public static final long DEFAULT_CHANGELOG_MIN_COMPACTION_LAG_MS = TimeUnit.HOURS.toMillis(4);\n+  public static final String STATE_BACKUP_MANAGER_FACTORY = STORE_PREFIX + \"state.backup.manager\" + FACTORY_SUFFIX;\n+  public static final String DEFAULT_STATE_BACKUP_MANAGER_FACTORY = \"org.apache.samza.storage.KafkaChangelogStateBackendFactory\";\n \n   static final String CHANGELOG_SYSTEM = \"job.changelog.system\";\n   static final String CHANGELOG_DELETE_RETENTION_MS = STORE_PREFIX + \"%s.changelog.delete.retention.ms\";\n@@ -94,6 +99,11 @@ public StorageConfig(Config config) {\n     return storeNames;\n   }\n \n+  public Map<String, SystemStream> getStoreChangelogs() {\n+    return getStoreNames().stream().filter(store -> getChangelogStream(store).isPresent())\n+        .collect(Collectors.toMap(Function.identity(), n -> StreamUtil.getSystemStreamFromNames(getChangelogStream(n).get())));\n+  }\n+\n   /**\n    * If the config specifies 'stores.&lt;storename&gt;.changelog' as '&lt;system&gt;.&lt;stream&gt;' combination - it will take\n    * precedence.\n@@ -240,6 +250,11 @@ public long getChangelogMinCompactionLagMs(String storeName) {\n     return getLong(minCompactLagConfigName, getDefaultChangelogMinCompactionLagMs());\n   }\n \n+  // TODO HIGH dchen change everything to State Backend Factory\n+  public String getStateBackupManager() {\n+    return get(STATE_BACKUP_MANAGER_FACTORY, DEFAULT_STATE_BACKUP_MANAGER_FACTORY);\n+  }\n+\n   /**\n    * Helper method to check if a system has a changelog attached to it.\n    */"
  },
  {
    "sha": "da38698cf9a4a444d75b0781eafc882b623520eb",
    "filename": "samza-core/src/main/java/org/apache/samza/config/TaskConfig.java",
    "status": "modified",
    "additions": 21,
    "deletions": 0,
    "changes": 21,
    "blob_url": "https://github.com/dxichen/samza/blob/f010e3429c1b8670cd4fa5d7b13b8f75b3462c7b/samza-core/src/main/java/org/apache/samza/config/TaskConfig.java",
    "raw_url": "https://github.com/dxichen/samza/raw/f010e3429c1b8670cd4fa5d7b13b8f75b3462c7b/samza-core/src/main/java/org/apache/samza/config/TaskConfig.java",
    "contents_url": "https://api.github.com/repos/dxichen/samza/contents/samza-core/src/main/java/org/apache/samza/config/TaskConfig.java?ref=f010e3429c1b8670cd4fa5d7b13b8f75b3462c7b",
    "patch": "@@ -19,6 +19,8 @@\n \n package org.apache.samza.config;\n \n+import com.google.common.collect.ImmutableList;\n+\n import java.util.Collections;\n import java.util.HashSet;\n import java.util.List;\n@@ -108,6 +110,14 @@\n   // standby containers use this flag to indicate that checkpoints will be polled continually, rather than only once at startup like in an active container\n   public static final String INTERNAL_CHECKPOINT_MANAGER_CONSUMER_STOP_AFTER_FIRST_READ = \"samza.internal.task.checkpoint.consumer.stop.after.first.read\";\n \n+  // list of checkpoint versions to write during processing\n+  public static final String CHECKPOINT_WRITE_VERSIONS = \"task.checkpoint.write.versions\";\n+  public static final List<String> DEFAULT_CHECKPOINT_WRITE_VERSIONS = ImmutableList.of(\"1\", \"2\");\n+\n+  // checkpoint version to read during container startup\n+  public static final String CHECKPOINT_READ_VERSION = \"task.checkpoint.read.version\";\n+  public static final short DEFAULT_CHECKPOINT_READ_VERSION = 1;\n+\n   public static final String TRANSACTIONAL_STATE_CHECKPOINT_ENABLED = \"task.transactional.state.checkpoint.enabled\";\n   private static final boolean DEFAULT_TRANSACTIONAL_STATE_CHECKPOINT_ENABLED = true;\n   public static final String TRANSACTIONAL_STATE_RESTORE_ENABLED = \"task.transactional.state.restore.enabled\";\n@@ -315,6 +325,17 @@ public long getShutdownMs() {\n     }\n   }\n \n+  public List<Short> getCheckpointWriteVersions() {\n+    return getList(CHECKPOINT_WRITE_VERSIONS, DEFAULT_CHECKPOINT_WRITE_VERSIONS)\n+        .stream().map(Short::valueOf).collect(Collectors.toList());\n+  }\n+\n+  // TODO HIGH dchen add separate configs for checkpointV2.write.enabled (default true)\n+  //  and checkpointV2.read.enabled (default false).\n+  public short getCheckpointReadVersion() {\n+    return getShort(CHECKPOINT_READ_VERSION, DEFAULT_CHECKPOINT_READ_VERSION);\n+  }\n+\n   public boolean getTransactionalStateCheckpointEnabled() {\n     return getBoolean(TRANSACTIONAL_STATE_CHECKPOINT_ENABLED, DEFAULT_TRANSACTIONAL_STATE_CHECKPOINT_ENABLED);\n   }"
  },
  {
    "sha": "0871d8d8354eda83e7917e45f35eafd0e05922c5",
    "filename": "samza-core/src/main/java/org/apache/samza/serializers/CheckpointV2Serde.java",
    "status": "added",
    "additions": 176,
    "deletions": 0,
    "changes": 176,
    "blob_url": "https://github.com/dxichen/samza/blob/f010e3429c1b8670cd4fa5d7b13b8f75b3462c7b/samza-core/src/main/java/org/apache/samza/serializers/CheckpointV2Serde.java",
    "raw_url": "https://github.com/dxichen/samza/raw/f010e3429c1b8670cd4fa5d7b13b8f75b3462c7b/samza-core/src/main/java/org/apache/samza/serializers/CheckpointV2Serde.java",
    "contents_url": "https://api.github.com/repos/dxichen/samza/contents/samza-core/src/main/java/org/apache/samza/serializers/CheckpointV2Serde.java?ref=f010e3429c1b8670cd4fa5d7b13b8f75b3462c7b",
    "patch": "@@ -0,0 +1,176 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.samza.serializers;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.samza.Partition;\n+import org.apache.samza.SamzaException;\n+import org.apache.samza.checkpoint.CheckpointId;\n+import org.apache.samza.checkpoint.CheckpointV2;\n+import org.apache.samza.checkpoint.StateCheckpointMarker;\n+import org.apache.samza.checkpoint.StateCheckpointMarkerSerde;\n+import org.apache.samza.system.SystemStreamPartition;\n+\n+import static com.google.common.base.Preconditions.*;\n+\n+\n+/**\n+ * // TODO HIGH dchen the JSON serialization format is secondary to the fact that this serdes SCMs and CheckpointIDs.\n+ * // Clarify class name, docs, and relationship to the regular CheckpointSerde.\n+ * JSON Serde for the {@link CheckpointV2} using the {@link JsonSerdeV2} by converting the Checkpoint to a {@link JsonCheckpoint}\n+ * The following will be the representation of the data format:\n+ * <code>\n+ * {\n+ *   \"checkpointId\" : \"1614147487244-33577\",\n+ *   \"inputOffsets\" : {\n+ *     \"SystemStreamPartition [test-system, test-stream, 777]\" : {\n+ *       \"system\" : \"SystemName\",\n+ *       \"stream\" : \"StreamName\"\n+ *       \"partition\" : \"777\",\n+ *       \"offset\" : \"1\",\n+ *     }\n+ *   },\n+ *   \"stateCheckpointMarkers\" : {\n+ *     \"store1\" : [ StateCheckpointMarker...]\n+ *     \"store2\": [...]\n+ *   }\n+ * }\n+ * </code>\n+ *\n+ */\n+public class CheckpointV2Serde implements Serde<CheckpointV2> {\n+  private static final StateCheckpointMarkerSerde SCM_SERDE = new StateCheckpointMarkerSerde();\n+\n+  private final Serde<JsonCheckpoint> jsonCheckpointSerde;\n+\n+  public CheckpointV2Serde() {\n+    this.jsonCheckpointSerde = new JsonSerdeV2<>(JsonCheckpoint.class);\n+  }\n+\n+  @Override\n+  public CheckpointV2 fromBytes(byte[] bytes) {\n+    try {\n+      JsonCheckpoint jsonCheckpoint = jsonCheckpointSerde.fromBytes(bytes);\n+      Map<SystemStreamPartition, String> sspOffsets = new HashMap<>();\n+      Map<String, List<StateCheckpointMarker>> stateCheckpoints = new HashMap<>();\n+\n+      // TODO HIGH dchen include original message in error messages\n+      jsonCheckpoint.getInputOffsets().forEach((sspName, m) -> {\n+        String system = m.get(\"system\");\n+        checkNotNull(system, \"System must be present in JSON-encoded SystemStreamPartition\");\n+        String stream = m.get(\"stream\");\n+        checkNotNull(stream, \"Stream must be present in JSON-encoded SystemStreamPartition\");\n+        String partition = m.get(\"partition\");\n+        checkNotNull(partition, \"Partition must be present in JSON-encoded SystemStreamPartition\");\n+        String offset = m.get(\"offset\");\n+        checkNotNull(offset, \"Offset must be present in JSON-encoded SystemStreamPartition\");\n+        sspOffsets.put(new SystemStreamPartition(system, stream, new Partition(Integer.parseInt(partition))), offset);\n+      });\n+\n+      jsonCheckpoint.getStateCheckpointMarkers().forEach((storeName, scms) -> {\n+        List<StateCheckpointMarker> stateCheckpointMarkers = new ArrayList<>();\n+        checkArgument(!scms.isEmpty(), \"StateCheckpointMarker must be present in Stateful checkpoint\");\n+        scms.forEach((scm) -> {\n+          stateCheckpointMarkers.add(SCM_SERDE.deserialize(scm));\n+        });\n+        stateCheckpoints.put(storeName, stateCheckpointMarkers);\n+      });\n+\n+      return new CheckpointV2(CheckpointId.fromString(jsonCheckpoint.getCheckpointId()), sspOffsets, stateCheckpoints);\n+    } catch (Exception e) {\n+      throw new SamzaException(String.format(\"Exception while deserializing checkpoint: %s\", Arrays.toString(bytes)), e);\n+    }\n+  }\n+\n+  @Override\n+  public byte[] toBytes(CheckpointV2 checkpoint) {\n+    try {\n+      String checkpointId = checkpoint.getCheckpointId().toString();\n+      Map<String, Map<String, String>> inputOffsets = new HashMap<>();\n+      Map<String, List<String>> storeStateCheckpointMarkers = new HashMap<>();\n+\n+      // TODO HIGH dchen why does this need to be similar to checkpoint serde when we're doing dual writes?\n+      // Create input offsets map similar to CheckpointSerde\n+      // (ssp -> (system, stream, partition, offset))\n+      checkpoint.getInputOffsets().forEach((ssp, offset) -> {\n+        Map<String, String> sspOffsetsMap = new HashMap<>();\n+        sspOffsetsMap.put(\"system\", ssp.getSystem());\n+        sspOffsetsMap.put(\"stream\", ssp.getStream());\n+        sspOffsetsMap.put(\"partition\", Integer.toString(ssp.getPartition().getPartitionId()));\n+        sspOffsetsMap.put(\"offset\", offset);\n+\n+        inputOffsets.put(ssp.toString(), sspOffsetsMap);\n+      });\n+\n+      // Create mapping for state checkpoint markers\n+      // (storeName -> (StateCheckpointMarkerFactory -> StateCheckpointMarker))\n+      checkpoint.getStateCheckpointMarkers().forEach((storeName, stateCheckpointMarkers) -> {\n+        List<String> stateCheckpointMarkerByFactory = new ArrayList<>();\n+        stateCheckpointMarkers.forEach(stateCheckpointMarker -> {\n+          // Serialize the StateCheckpointMarker according to StateBackendFactory\n+          stateCheckpointMarkerByFactory.add(SCM_SERDE.serialize(stateCheckpointMarker));\n+        });\n+        storeStateCheckpointMarkers.put(storeName, stateCheckpointMarkerByFactory);\n+      });\n+\n+      return jsonCheckpointSerde.toBytes(new JsonCheckpoint(checkpointId, inputOffsets, storeStateCheckpointMarkers));\n+    } catch (Exception e) {\n+      throw new SamzaException(String.format(\"Exception while serializing checkpoint: %s\", checkpoint.toString()), e);\n+    }\n+  }\n+\n+  /**\n+   * Used for Json serialization of the {@link CheckpointV2} class by the\n+   * {@link CheckpointV2Serde}\n+   */\n+  // TODO add documentation for fields and the string-string map contents.\n+  private class JsonCheckpoint {\n+    private String checkpointId;\n+    private Map<String, Map<String, String>> inputOffsets;\n+    private Map<String, List<String>> stateCheckpointMarkers;\n+\n+    // Default constructor required for Jackson ObjectMapper\n+    public JsonCheckpoint() {}\n+\n+    public JsonCheckpoint(String checkpointId,\n+        Map<String, Map<String, String>> inputOffsets,\n+        Map<String, List<String>> stateCheckpointMakers) {\n+      this.checkpointId = checkpointId;\n+      this.inputOffsets = inputOffsets;\n+      this.stateCheckpointMarkers = stateCheckpointMakers;\n+    }\n+\n+    public String getCheckpointId() {\n+      return checkpointId;\n+    }\n+\n+    public Map<String, Map<String, String>> getInputOffsets() {\n+      return inputOffsets;\n+    }\n+\n+    public Map<String, List<String>> getStateCheckpointMarkers() {\n+      return stateCheckpointMarkers;\n+    }\n+  }\n+}"
  },
  {
    "sha": "c22d810c281f1c269f26f59cd882ff60cbdbc6a0",
    "filename": "samza-core/src/main/java/org/apache/samza/storage/NonTransactionalStateTaskRestoreManager.java",
    "status": "modified",
    "additions": 2,
    "deletions": 1,
    "changes": 3,
    "blob_url": "https://github.com/dxichen/samza/blob/f010e3429c1b8670cd4fa5d7b13b8f75b3462c7b/samza-core/src/main/java/org/apache/samza/storage/NonTransactionalStateTaskRestoreManager.java",
    "raw_url": "https://github.com/dxichen/samza/raw/f010e3429c1b8670cd4fa5d7b13b8f75b3462c7b/samza-core/src/main/java/org/apache/samza/storage/NonTransactionalStateTaskRestoreManager.java",
    "contents_url": "https://api.github.com/repos/dxichen/samza/contents/samza-core/src/main/java/org/apache/samza/storage/NonTransactionalStateTaskRestoreManager.java?ref=f010e3429c1b8670cd4fa5d7b13b8f75b3462c7b",
    "patch": "@@ -28,6 +28,7 @@\n import java.util.stream.Collectors;\n import org.apache.samza.Partition;\n import org.apache.samza.SamzaException;\n+import org.apache.samza.checkpoint.Checkpoint;\n import org.apache.samza.config.Config;\n import org.apache.samza.config.StorageConfig;\n import org.apache.samza.job.model.TaskModel;\n@@ -109,7 +110,7 @@\n    * and registers SSPs with the respective consumers.\n    */\n   @Override\n-  public void init(Map<SystemStreamPartition, String> checkpointedChangelogSSPOffsets) {\n+  public void init(Checkpoint checkpoint) {\n     cleanBaseDirsAndReadOffsetFiles();\n     setupBaseDirs();\n     validateChangelogStreams();"
  },
  {
    "sha": "d5127afce86ae4fc8ba900762c1f576f37d498e7",
    "filename": "samza-core/src/main/java/org/apache/samza/storage/TransactionalStateTaskRestoreManager.java",
    "status": "modified",
    "additions": 41,
    "deletions": 7,
    "changes": 48,
    "blob_url": "https://github.com/dxichen/samza/blob/f010e3429c1b8670cd4fa5d7b13b8f75b3462c7b/samza-core/src/main/java/org/apache/samza/storage/TransactionalStateTaskRestoreManager.java",
    "raw_url": "https://github.com/dxichen/samza/raw/f010e3429c1b8670cd4fa5d7b13b8f75b3462c7b/samza-core/src/main/java/org/apache/samza/storage/TransactionalStateTaskRestoreManager.java",
    "contents_url": "https://api.github.com/repos/dxichen/samza/contents/samza-core/src/main/java/org/apache/samza/storage/TransactionalStateTaskRestoreManager.java?ref=f010e3429c1b8670cd4fa5d7b13b8f75b3462c7b",
    "patch": "@@ -34,7 +34,11 @@\n import org.apache.commons.lang3.StringUtils;\n import org.apache.samza.Partition;\n import org.apache.samza.SamzaException;\n-import org.apache.samza.checkpoint.CheckpointedChangelogOffset;\n+import org.apache.samza.checkpoint.Checkpoint;\n+import org.apache.samza.checkpoint.CheckpointV1;\n+import org.apache.samza.checkpoint.CheckpointV2;\n+import org.apache.samza.checkpoint.KafkaStateChangelogOffset;\n+import org.apache.samza.checkpoint.StateCheckpointMarker;\n import org.apache.samza.config.Config;\n import org.apache.samza.config.StorageConfig;\n import org.apache.samza.config.TaskConfig;\n@@ -104,7 +108,8 @@ public TransactionalStateTaskRestoreManager(\n   }\n \n   @Override\n-  public void init(Map<SystemStreamPartition, String> checkpointedChangelogOffsets) {\n+  public void init(Checkpoint checkpoint) {\n+    Map<String, String> checkpointedChangelogOffsets = getCheckpointedChangelogOffsets(checkpoint);\n     currentChangelogOffsets = getCurrentChangelogOffsets(taskModel, storeChangelogs, sspMetadataCache);\n \n     this.storeActions = getStoreActions(taskModel, storeEngines, storeChangelogs,\n@@ -194,7 +199,7 @@ static StoreActions getStoreActions(\n       TaskModel taskModel,\n       Map<String, StorageEngine> storeEngines,\n       Map<String, SystemStream> storeChangelogs,\n-      Map<SystemStreamPartition, String> checkpointedChangelogOffsets,\n+      Map<String, String> storeOffset,\n       Map<SystemStreamPartition, SystemStreamPartitionMetadata> currentChangelogOffsets,\n       SystemAdmins systemAdmins,\n       StorageManagerUtil storageManagerUtil,\n@@ -236,14 +241,15 @@ static StoreActions getStoreActions(\n       String oldestOffset = changelogSSPMetadata.getOldestOffset();\n       String newestOffset = changelogSSPMetadata.getNewestOffset();\n \n-      String checkpointMessage = checkpointedChangelogOffsets.get(changelogSSP);\n+      String checkpointMessage = storeOffset.get(storeName);\n       String checkpointedOffset = null;  // can be null if no message, or message has null offset\n       long timeSinceLastCheckpointInMs = Long.MAX_VALUE;\n       if (StringUtils.isNotBlank(checkpointMessage)) {\n-        CheckpointedChangelogOffset checkpointedChangelogOffset = CheckpointedChangelogOffset.fromString(checkpointMessage);\n-        checkpointedOffset = checkpointedChangelogOffset.getOffset();\n+        // TODO HIGH dchen fix Checkpoint version handling\n+        KafkaStateChangelogOffset kafkaStateCheckpointMarker = KafkaStateChangelogOffset.fromString(checkpointMessage);\n+        checkpointedOffset = kafkaStateCheckpointMarker.getChangelogOffset();\n         timeSinceLastCheckpointInMs = System.currentTimeMillis() -\n-            checkpointedChangelogOffset.getCheckpointId().getMillis();\n+            kafkaStateCheckpointMarker.getCheckpointId().getMillis(); //TODO change for KafkaStateCheckpointMarker\n       }\n \n       // if the clean.store.start config is set, delete current and checkpoint dirs, restore from oldest offset to checkpointed\n@@ -557,6 +563,34 @@ private static void validateRestoreOffsets(RestoreOffsets restoreOffsets, System\n     }\n   }\n \n+  private Map<String, String> getCheckpointedChangelogOffsets(Checkpoint checkpoint) {\n+    Map<String, String> checkpointedChangelogOffsets = new HashMap<>();\n+    if (checkpoint == null) return checkpointedChangelogOffsets;\n+\n+    if (checkpoint instanceof CheckpointV2) {\n+      Map<String, List<StateCheckpointMarker>> storeSCMs = ((CheckpointV2) checkpoint).getStateCheckpointMarkers();\n+      storeSCMs.forEach((storeName, scms) -> {\n+        String offsetMessage = null;\n+        // TODO HIGH dchen why would deserialization happen here? Shouldn't it already be deserialized at this point?\n+        // we should just pick the deserialized SCM with the right factory name\n+        // TODO dchen1 deserialize this with KafkaStateCheckpointMarker after moving modules\n+        checkpointedChangelogOffsets.put(storeName, null);\n+      });\n+    } else if (checkpoint instanceof CheckpointV1) {\n+      // If the checkpoint v1 is used, we need to fetch the changelog SSPs in the inputOffsets in order to get the\n+      // store offset.\n+      Map<SystemStreamPartition, String> checkpointedOffsets = ((CheckpointV1) checkpoint).getOffsets();\n+      storeChangelogs.forEach((storeName, systemStream) -> {\n+        SystemStreamPartition storeChangelogSSP = new SystemStreamPartition(systemStream, taskModel.getChangelogPartition());\n+        checkpointedChangelogOffsets.put(storeName, checkpointedOffsets.get(storeChangelogSSP));\n+      });\n+    } else {\n+      throw new SamzaException(\"Unsupported checkpoint version: \" + checkpoint.getVersion());\n+    }\n+\n+    return checkpointedChangelogOffsets;\n+  }\n+\n   @VisibleForTesting\n   static class StoreActions {\n     final Map<String, File> storeDirsToRetain;"
  },
  {
    "sha": "8ff681204795f7b6b1a80f0e7663c054b2e8fd25",
    "filename": "samza-core/src/main/scala/org/apache/samza/checkpoint/CheckpointTool.scala",
    "status": "modified",
    "additions": 20,
    "deletions": 19,
    "changes": 39,
    "blob_url": "https://github.com/dxichen/samza/blob/f010e3429c1b8670cd4fa5d7b13b8f75b3462c7b/samza-core/src/main/scala/org/apache/samza/checkpoint/CheckpointTool.scala",
    "raw_url": "https://github.com/dxichen/samza/raw/f010e3429c1b8670cd4fa5d7b13b8f75b3462c7b/samza-core/src/main/scala/org/apache/samza/checkpoint/CheckpointTool.scala",
    "contents_url": "https://api.github.com/repos/dxichen/samza/contents/samza-core/src/main/scala/org/apache/samza/checkpoint/CheckpointTool.scala?ref=f010e3429c1b8670cd4fa5d7b13b8f75b3462c7b",
    "patch": "@@ -185,25 +185,26 @@ class CheckpointTool(newOffsets: TaskNameToCheckpointMap, coordinatorStreamStore\n       taskNames.foreach(checkpointManager.register)\n       checkpointManager.start()\n \n-      val lastCheckpoints = taskNames.map(taskName => {\n-        taskName -> Option(checkpointManager.readLastCheckpoint(taskName))\n-          .getOrElse(new Checkpoint(new java.util.HashMap[SystemStreamPartition, String]()))\n-          .getOffsets\n-          .asScala\n-          .toMap\n-      }).toMap\n-\n-      lastCheckpoints.foreach(lcp => logCheckpoint(lcp._1, lcp._2, \"Current checkpoint for task: \"+ lcp._1))\n-\n-      if (newOffsets != null) {\n-        newOffsets.foreach {\n-          case (taskName: TaskName, offsets: Map[SystemStreamPartition, String]) =>\n-            logCheckpoint(taskName, offsets, \"New offset to be written for task: \" + taskName)\n-            val checkpoint = new Checkpoint(offsets.asJava)\n-            checkpointManager.writeCheckpoint(taskName, checkpoint)\n-            info(s\"Updated the checkpoint of the task: $taskName to: $offsets\")\n-        }\n-      }\n+      // TODO BLOCKER dchen fix this\n+//      val lastCheckpoints = taskNames.map(taskName => {\n+//        taskName -> Option(checkpointManager.readLastCheckpoint(taskName))\n+//          .getOrElse(new CheckpointV1(new java.util.HashMap[SystemStreamPartition, String]()))\n+//          .getOffsets\n+//          .asScala\n+//          .toMap\n+//      }).toMap\n+//\n+//      lastCheckpoints.foreach(lcp => logCheckpoint(lcp._1, lcp._2, \"Current checkpoint for task: \"+ lcp._1))\n+//\n+//      if (newOffsets != null) {\n+//        newOffsets.foreach {\n+//          case (taskName: TaskName, offsets: Map[SystemStreamPartition, String]) =>\n+//            logCheckpoint(taskName, offsets, \"New offset to be written for task: \" + taskName)\n+//            val checkpoint = new CheckpointV1(offsets.asJava)\n+//            checkpointManager.writeCheckpoint(taskName, checkpoint)\n+//            info(s\"Updated the checkpoint of the task: $taskName to: $offsets\")\n+//        }\n+//      }\n     } finally {\n       checkpointManager.stop()\n       coordinatorStreamStore.close()"
  },
  {
    "sha": "a0c46cd8cbcee052a0d27126f1c29cc9b4cfc3e5",
    "filename": "samza-core/src/main/scala/org/apache/samza/checkpoint/OffsetManager.scala",
    "status": "modified",
    "additions": 20,
    "deletions": 10,
    "changes": 30,
    "blob_url": "https://github.com/dxichen/samza/blob/f010e3429c1b8670cd4fa5d7b13b8f75b3462c7b/samza-core/src/main/scala/org/apache/samza/checkpoint/OffsetManager.scala",
    "raw_url": "https://github.com/dxichen/samza/raw/f010e3429c1b8670cd4fa5d7b13b8f75b3462c7b/samza-core/src/main/scala/org/apache/samza/checkpoint/OffsetManager.scala",
    "contents_url": "https://api.github.com/repos/dxichen/samza/contents/samza-core/src/main/scala/org/apache/samza/checkpoint/OffsetManager.scala?ref=f010e3429c1b8670cd4fa5d7b13b8f75b3462c7b",
    "patch": "@@ -19,6 +19,7 @@\n \n package org.apache.samza.checkpoint\n \n+import java.util\n import java.util.HashMap\n import java.util.concurrent.ConcurrentHashMap\n \n@@ -267,9 +268,9 @@ class OffsetManager(\n     * ensure there are no concurrent updates to the offsets between when this method is\n     * invoked and the corresponding call to [[OffsetManager.writeCheckpoint()]]\n     */\n-  def buildCheckpoint(taskName: TaskName): Checkpoint = {\n+  def getLastProcessedOffsets(taskName: TaskName): util.HashMap[SystemStreamPartition, String] = {\n     if (checkpointManager != null || checkpointListeners.nonEmpty) {\n-      debug(\"Getting checkpoint offsets for taskName %s.\" format taskName)\n+      debug(\"Getting last processed offsets to checkpoint for taskName %s.\" format taskName)\n \n       val taskStartingOffsets = startingOffsets.getOrElse(taskName,\n         throw new SamzaException(\"Couldn't find starting offsets for task: \" + taskName))\n@@ -283,10 +284,10 @@ class OffsetManager(\n           .filterKeys(taskSSPs.contains)\n \n       val modifiedTaskOffsets = getModifiedOffsets(taskStartingOffsets, taskLastProcessedOffsets)\n-      new Checkpoint(new HashMap(modifiedTaskOffsets)) // Copy into new Map to prevent mutation\n+      new util.HashMap(modifiedTaskOffsets)\n     } else {\n-      debug(\"Returning null checkpoint for taskName %s because no checkpoint manager/callback is defined.\" format taskName)\n-      null\n+      debug(\"Returning empty offsets for taskName %s because no checkpoint manager/callback is defined.\" format taskName)\n+      new util.HashMap()\n     }\n   }\n \n@@ -336,11 +337,17 @@ class OffsetManager(\n     */\n   def writeCheckpoint(taskName: TaskName, checkpoint: Checkpoint) {\n     if (checkpoint != null && (checkpointManager != null || checkpointListeners.nonEmpty)) {\n-      debug(\"Writing checkpoint for taskName %s with offsets %s.\" format (taskName, checkpoint))\n+      debug(\"Writing checkpoint for taskName: %s as: %s.\" format (taskName, checkpoint))\n+\n+      val sspToOffsets = checkpoint match {\n+        case checkpointV1: CheckpointV1 => checkpointV1.getOffsets\n+        case checkpointV2: CheckpointV2 => checkpointV2.getInputOffsets\n+        case _ => throw new SamzaException(\"Unknown checkpoint version: \" + checkpoint.getVersion)\n+      }\n \n       if(checkpointManager != null) {\n         checkpointManager.writeCheckpoint(taskName, checkpoint)\n-        val sspToOffsets = checkpoint.getOffsets\n+\n         if(sspToOffsets != null) {\n           sspToOffsets.asScala.foreach {\n             case (ssp, cp) => {\n@@ -357,7 +364,7 @@ class OffsetManager(\n       // changelog SSPs are not registered but may be present in the Checkpoint if transactional state checkpointing\n       // is enabled.\n       val registeredSSPs = systemStreamPartitions.getOrElse(taskName, Set[SystemStreamPartition]())\n-      checkpoint.getOffsets.asScala\n+      sspToOffsets.asScala\n         .filterKeys(registeredSSPs.contains)\n         .groupBy { case (ssp, _) => ssp.getSystem }.foreach {\n           case (systemName:String, offsets: Map[SystemStreamPartition, String]) => {\n@@ -449,10 +456,13 @@ class OffsetManager(\n     val checkpoint = checkpointManager.readLastCheckpoint(taskName)\n \n     if (checkpoint != null) {\n-      Map(taskName -> checkpoint.getOffsets.asScala.toMap)\n+      checkpoint match {\n+        case checkpointV1: CheckpointV1 => Map(taskName -> checkpointV1.getOffsets.asScala.toMap)\n+        case checkpointV2: CheckpointV2 => Map(taskName -> checkpointV2.getInputOffsets.asScala.toMap)\n+        case _ => throw new SamzaException(\"Unknown checkpoint version: \" + checkpoint.getVersion)\n+      }\n     } else {\n       info(\"Did not receive a checkpoint for taskName %s. Proceeding without a checkpoint.\" format taskName)\n-\n       Map(taskName -> Map())\n     }\n   }"
  },
  {
    "sha": "b740a130e963882e1d47103d66611dd8a439b777",
    "filename": "samza-core/src/main/scala/org/apache/samza/checkpoint/file/FileSystemCheckpointManager.scala",
    "status": "modified",
    "additions": 4,
    "deletions": 6,
    "changes": 10,
    "blob_url": "https://github.com/dxichen/samza/blob/f010e3429c1b8670cd4fa5d7b13b8f75b3462c7b/samza-core/src/main/scala/org/apache/samza/checkpoint/file/FileSystemCheckpointManager.scala",
    "raw_url": "https://github.com/dxichen/samza/raw/f010e3429c1b8670cd4fa5d7b13b8f75b3462c7b/samza-core/src/main/scala/org/apache/samza/checkpoint/file/FileSystemCheckpointManager.scala",
    "contents_url": "https://api.github.com/repos/dxichen/samza/contents/samza-core/src/main/scala/org/apache/samza/checkpoint/file/FileSystemCheckpointManager.scala?ref=f010e3429c1b8670cd4fa5d7b13b8f75b3462c7b",
    "patch": "@@ -24,28 +24,26 @@ import java.io.FileNotFoundException\n import java.io.FileOutputStream\n \n import org.apache.samza.SamzaException\n-import org.apache.samza.checkpoint.Checkpoint\n-import org.apache.samza.checkpoint.CheckpointManager\n-import org.apache.samza.checkpoint.CheckpointManagerFactory\n+import org.apache.samza.checkpoint.{Checkpoint, CheckpointManager, CheckpointManagerFactory, CheckpointV1}\n import org.apache.samza.config.{Config, FileSystemCheckpointManagerConfig, JobConfig}\n import org.apache.samza.container.TaskName\n import org.apache.samza.metrics.MetricsRegistry\n-import org.apache.samza.serializers.CheckpointSerde\n+import org.apache.samza.serializers.CheckpointV1Serde\n import org.apache.samza.util.ScalaJavaUtil.JavaOptionals\n \n import scala.io.Source\n \n class FileSystemCheckpointManager(\n                                    jobName: String,\n                                    root: File,\n-                                   serde: CheckpointSerde = new CheckpointSerde) extends CheckpointManager {\n+                                   serde: CheckpointV1Serde = new CheckpointV1Serde) extends CheckpointManager {\n \n   override def register(taskName: TaskName):Unit = Unit\n \n   def getCheckpointFile(taskName: TaskName) = getFile(jobName, taskName, \"checkpoints\")\n \n   def writeCheckpoint(taskName: TaskName, checkpoint: Checkpoint) {\n-    val bytes = serde.toBytes(checkpoint)\n+    val bytes = serde.toBytes(checkpoint.asInstanceOf[CheckpointV1])\n     val fos = new FileOutputStream(getCheckpointFile(taskName))\n \n     fos.write(bytes)"
  },
  {
    "sha": "c5a04b80d208c43cc28a1a9cfdfb834b20643887",
    "filename": "samza-core/src/main/scala/org/apache/samza/container/SamzaContainer.scala",
    "status": "modified",
    "additions": 29,
    "deletions": 22,
    "changes": 51,
    "blob_url": "https://github.com/dxichen/samza/blob/f010e3429c1b8670cd4fa5d7b13b8f75b3462c7b/samza-core/src/main/scala/org/apache/samza/container/SamzaContainer.scala",
    "raw_url": "https://github.com/dxichen/samza/raw/f010e3429c1b8670cd4fa5d7b13b8f75b3462c7b/samza-core/src/main/scala/org/apache/samza/container/SamzaContainer.scala",
    "contents_url": "https://api.github.com/repos/dxichen/samza/contents/samza-core/src/main/scala/org/apache/samza/container/SamzaContainer.scala?ref=f010e3429c1b8670cd4fa5d7b13b8f75b3462c7b",
    "patch": "@@ -52,7 +52,7 @@ import org.apache.samza.util.{Util, _}\n import org.apache.samza.SamzaException\n import org.apache.samza.clustermanager.StandbyTaskUtil\n \n-import scala.collection.JavaConversions\n+import scala.collection.JavaConversions.mapAsScalaMap\n import scala.collection.JavaConverters._\n \n object SamzaContainer extends Logging {\n@@ -343,11 +343,7 @@ object SamzaContainer extends Logging {\n \n     debug(\"Got system stream message serdes: %s\" format systemStreamMessageSerdes)\n \n-    val storeChangelogs = storageConfig\n-      .getStoreNames.asScala\n-      .filter(storageConfig.getChangelogStream(_).isPresent)\n-      .map(name => (name, storageConfig.getChangelogStream(name).get)).toMap\n-      .mapValues(StreamUtil.getSystemStreamFromNames(_))\n+    val storeChangelogs = storageConfig.getStoreChangelogs\n \n     info(\"Got change log system streams: %s\" format storeChangelogs)\n \n@@ -398,7 +394,7 @@ object SamzaContainer extends Logging {\n       systemMessageSerdes = systemMessageSerdes,\n       systemStreamKeySerdes = systemStreamKeySerdes,\n       systemStreamMessageSerdes = systemStreamMessageSerdes,\n-      changeLogSystemStreams = storeChangelogs.values.toSet,\n+      changeLogSystemStreams = storeChangelogs.asScala.values.toSet,\n       controlMessageKeySerdes = controlMessageKeySerdes,\n       intermediateMessageSerdes = intermediateStreamMessageSerdes)\n \n@@ -499,7 +495,7 @@ object SamzaContainer extends Logging {\n \n     val timerExecutor = Executors.newSingleThreadScheduledExecutor\n \n-    var taskStorageManagers : Map[TaskName, TaskStorageManager] = Map()\n+    var taskStorageManagers : Map[TaskName, TaskBackupManager] = Map()\n \n     val taskInstanceMetrics: Map[TaskName, TaskInstanceMetrics] = taskModels.map(taskModel => {\n       (taskModel.getTaskName, new TaskInstanceMetrics(\"TaskName-%s\" format taskModel.getTaskName))\n@@ -524,7 +520,7 @@ object SamzaContainer extends Logging {\n       streamMetadataCache,\n       changelogSSPMetadataCache,\n       systemAdmins,\n-      storeChangelogs.asJava,\n+      storeChangelogs,\n       sideInputStoresToSystemStreams.mapValues(systemStreamSet => systemStreamSet.toSet.asJava).asJava,\n       storageEngineFactories.asJava,\n       systemFactories.asJava,\n@@ -543,6 +539,8 @@ object SamzaContainer extends Logging {\n \n     storeWatchPaths.addAll(containerStorageManager.getStoreDirectoryPaths)\n \n+    val stateStorageBackendFactory = ReflectionUtil.getObj(storageConfig.getStateBackupManager, classOf[StateBackendFactory])\n+\n     // Create taskInstances\n     val taskInstances: Map[TaskName, TaskInstance] = taskModels\n       .filter(taskModel => taskModel.getTaskMode.eq(TaskMode.Active)).map(taskModel => {\n@@ -564,15 +562,10 @@ object SamzaContainer extends Logging {\n       val taskSideInputSSPs = sideInputStoresToSSPs.values.flatMap(_.asScala).toSet\n       info (\"Got task side input SSPs: %s\" format taskSideInputSSPs)\n \n-      val storageManager = TaskStorageManagerFactory.create(\n-        taskName,\n-        containerStorageManager,\n-        storeChangelogs,\n-        systemAdmins,\n-        loggedStorageBaseDir,\n-        taskModel.getChangelogPartition,\n-        config,\n-        taskModel.getTaskMode)\n+      val taskBackupManager = stateStorageBackendFactory.getBackupManager(jobModel, containerModel,\n+        taskModel, containerStorageManager.getAllStores(taskName), config, new SystemClock)\n+\n+      val commitManager = new TaskStorageCommitManager(taskName, taskBackupManager, checkpointManager)\n \n       val tableManager = new TableManager(config)\n \n@@ -586,9 +579,10 @@ object SamzaContainer extends Logging {\n           consumerMultiplexer = consumerMultiplexer,\n           collector = taskCollectors.get(taskName).get,\n           offsetManager = offsetManager,\n-          storageManager = storageManager,\n+          commitManager = commitManager,\n+          containerStorageManager = containerStorageManager,\n           tableManager = tableManager,\n-          systemStreamPartitions = JavaConversions.setAsJavaSet(taskSSPs -- taskSideInputSSPs),\n+          systemStreamPartitions = (taskSSPs -- taskSideInputSSPs).asJava,\n           exceptionHandler = TaskInstanceExceptionHandler(taskInstanceMetrics.get(taskName).get, taskConfig),\n           jobModel = jobModel,\n           streamMetadataCache = streamMetadataCache,\n@@ -602,7 +596,7 @@ object SamzaContainer extends Logging {\n \n       val taskInstance = createTaskInstance(task)\n \n-      taskStorageManagers += taskInstance.taskName -> storageManager\n+      taskStorageManagers += taskInstance.taskName -> taskBackupManager\n       (taskName, taskInstance)\n     }).toMap\n \n@@ -684,7 +678,7 @@ object SamzaContainer extends Logging {\n     */\n   @VisibleForTesting\n   private[container] def getChangelogSSPsForContainer(containerModel: ContainerModel,\n-    changeLogSystemStreams: Map[String, SystemStream]): Set[SystemStreamPartition] = {\n+    changeLogSystemStreams: util.Map[String, SystemStream]): Set[SystemStreamPartition] = {\n     containerModel.getTasks.values().asScala\n       .map(taskModel => taskModel.getChangelogPartition)\n       .flatMap(changelogPartition => changeLogSystemStreams.map { case (_, systemStream) =>\n@@ -764,6 +758,7 @@ class SamzaContainer(\n       startProducers\n       startStores\n       startTableManager\n+      startCommitManagers\n       startDiskSpaceMonitor\n       startHostStatisticsMonitor\n       startTask\n@@ -974,6 +969,13 @@ class SamzaContainer(\n     })\n   }\n \n+  def startCommitManagers: Unit = {\n+    taskInstances.values.foreach(taskInstance  => {\n+      info(\"Starting commit manager in task instance %s\" format taskInstance.taskName)\n+      taskInstance.startCommitManager\n+    })\n+  }\n+\n   def startTask {\n     info(\"Initializing stream tasks.\")\n \n@@ -1074,6 +1076,11 @@ class SamzaContainer(\n     taskInstances.values.foreach(_.shutdownTableManager)\n   }\n \n+  def shutdownCommitManager: Unit = {\n+    info(\"Shutting down task instance commit manager\")\n+    taskInstances.values.foreach(_.shutdownCommitManager)\n+  }\n+\n   def shutdownOffsetManager {\n     info(\"Shutting down offset manager.\")\n "
  },
  {
    "sha": "7ef54f19f74a155d7c13d2e120e15019a7fcadc2",
    "filename": "samza-core/src/main/scala/org/apache/samza/container/TaskInstance.scala",
    "status": "modified",
    "additions": 64,
    "deletions": 46,
    "changes": 110,
    "blob_url": "https://github.com/dxichen/samza/blob/f010e3429c1b8670cd4fa5d7b13b8f75b3462c7b/samza-core/src/main/scala/org/apache/samza/container/TaskInstance.scala",
    "raw_url": "https://github.com/dxichen/samza/raw/f010e3429c1b8670cd4fa5d7b13b8f75b3462c7b/samza-core/src/main/scala/org/apache/samza/container/TaskInstance.scala",
    "contents_url": "https://api.github.com/repos/dxichen/samza/contents/samza-core/src/main/scala/org/apache/samza/container/TaskInstance.scala?ref=f010e3429c1b8670cd4fa5d7b13b8f75b3462c7b",
    "patch": "@@ -24,16 +24,17 @@ import java.util.{Collections, Objects, Optional}\n import java.util.concurrent.ScheduledExecutorService\n \n import org.apache.samza.SamzaException\n-import org.apache.samza.checkpoint.{Checkpoint, CheckpointId, CheckpointedChangelogOffset, OffsetManager}\n+import org.apache.samza.checkpoint.{Checkpoint, CheckpointId, CheckpointV1, CheckpointV2, OffsetManager, StateCheckpointMarker}\n import org.apache.samza.config.{Config, StreamConfig, TaskConfig}\n import org.apache.samza.context._\n import org.apache.samza.job.model.{JobModel, TaskModel}\n import org.apache.samza.scheduler.{CallbackSchedulerImpl, EpochTimeScheduler, ScheduledCallback}\n import org.apache.samza.storage.kv.KeyValueStore\n-import org.apache.samza.storage.TaskStorageManager\n+import org.apache.samza.storage.{ContainerStorageManager, TaskStorageCommitManager}\n import org.apache.samza.system._\n import org.apache.samza.table.TableManager\n import org.apache.samza.task._\n+import org.apache.samza.util.ScalaJavaUtil.JavaOptionals.toRichOptional\n import org.apache.samza.util.{Logging, ScalaJavaUtil}\n \n import scala.collection.JavaConversions._\n@@ -48,7 +49,8 @@ class TaskInstance(\n   consumerMultiplexer: SystemConsumers,\n   collector: TaskInstanceCollector,\n   override val offsetManager: OffsetManager = new OffsetManager,\n-  storageManager: TaskStorageManager = null,\n+  commitManager: TaskStorageCommitManager = null,\n+  containerStorageManager: ContainerStorageManager = null,\n   tableManager: TableManager = null,\n   val systemStreamPartitions: java.util.Set[SystemStreamPartition] = Collections.emptySet(),\n   val exceptionHandler: TaskInstanceExceptionHandler = new TaskInstanceExceptionHandler,\n@@ -73,8 +75,9 @@ class TaskInstance(\n \n   private val kvStoreSupplier = ScalaJavaUtil.toJavaFunction(\n     (storeName: String) => {\n-      if (storageManager != null && storageManager.getStore(storeName).isDefined) {\n-        storageManager.getStore(storeName).get.asInstanceOf[KeyValueStore[_, _]]\n+      if (containerStorageManager != null) {\n+        val storeOption = containerStorageManager.getStore(taskName, storeName).toOption\n+        if (storeOption.isDefined) storeOption.get.asInstanceOf[KeyValueStore[_, _]] else null\n       } else {\n         null\n       }\n@@ -103,6 +106,8 @@ class TaskInstance(\n \n   val streamsToDeleteCommittedMessages: Set[String] = streamConfig.getStreamIds.filter(streamConfig.getDeleteCommittedMessages).map(streamConfig.getPhysicalName).toSet\n \n+  val checkpointWriteVersions = new TaskConfig(config).getCheckpointWriteVersions\n+\n   def registerOffsets {\n     debug(\"Registering offsets for taskName: %s\" format taskName)\n     offsetManager.register(taskName, systemStreamPartitions)\n@@ -118,6 +123,15 @@ class TaskInstance(\n     }\n   }\n \n+  def startCommitManager: Unit = {\n+    if (commitManager != null) {\n+      debug(\"Starting commit manager for taskName: %s\" format taskName)\n+      commitManager.start()\n+    } else {\n+      debug(\"Skipping commit manager initialization for taskName: %s\" format taskName)\n+    }\n+  }\n+\n   def initTask {\n     initCaughtUpMapping()\n \n@@ -221,12 +235,8 @@ class TaskInstance(\n   def commit {\n     metrics.commits.inc\n \n-    val allCheckpointOffsets = new java.util.HashMap[SystemStreamPartition, String]()\n-    val inputCheckpoint = offsetManager.buildCheckpoint(taskName)\n-    if (inputCheckpoint != null) {\n-      trace(\"Got input offsets for taskName: %s as: %s\" format(taskName, inputCheckpoint.getOffsets))\n-      allCheckpointOffsets.putAll(inputCheckpoint.getOffsets)\n-    }\n+    val inputOffsets = offsetManager.getLastProcessedOffsets(taskName)\n+    trace(\"Got input offsets for taskName: %s as: %s\" format(taskName, inputOffsets))\n \n     trace(\"Flushing producers for taskName: %s\" format taskName)\n     collector.flush\n@@ -236,48 +246,47 @@ class TaskInstance(\n       tableManager.flush()\n     }\n \n-    var newestChangelogOffsets: Map[SystemStreamPartition, Option[String]] = null\n-    if (storageManager != null) {\n-      trace(\"Flushing state stores for taskName: %s\" format taskName)\n-      newestChangelogOffsets = storageManager.flush()\n-      trace(\"Got newest changelog offsets for taskName: %s as: %s \" format(taskName, newestChangelogOffsets))\n-    }\n-\n     val checkpointId = CheckpointId.create()\n-    if (storageManager != null && newestChangelogOffsets != null) {\n-      trace(\"Checkpointing stores for taskName: %s with checkpoint id: %s\" format (taskName, checkpointId))\n-      storageManager.checkpoint(checkpointId, newestChangelogOffsets.toMap)\n-    }\n \n-    if (newestChangelogOffsets != null) {\n-      newestChangelogOffsets.foreach {case (ssp, newestOffsetOption) =>\n-        val offset = new CheckpointedChangelogOffset(checkpointId, newestOffsetOption.orNull).toString\n-        allCheckpointOffsets.put(ssp, offset)\n+    // Perform state commit\n+    trace(\"Committing state stores for taskName: %s\" format taskName)\n+    val stateCheckpointMarkers = commitManager.commit(taskName, checkpointId)\n+    trace(\"Got state checkpoint markers for taskName: %s as: %s \" format(taskName, stateCheckpointMarkers))\n+\n+    // TODO BLOCKER dchen where are the SCMs returned by KafkaBackupManagers being serialized as part of the\n+    // input offsets for backwards compatibility? Previously they were being merged in the \"allCheckpointOffsets\" map\n+    // which was used to create the Checkpoint#offsets map, now they are not being included anymore.\n+    checkpointWriteVersions.foreach(checkpointWriteVersion => {\n+      val checkpoint = if (checkpointWriteVersion == 1) {\n+        new CheckpointV1(inputOffsets)\n+      } else if (checkpointWriteVersion == 2) {\n+        new CheckpointV2(checkpointId, inputOffsets, stateCheckpointMarkers)\n+      } else {\n+        throw new SamzaException(\"Unsupported checkpoint write version: \" + checkpointWriteVersion)\n       }\n-    }\n-    val checkpoint = new Checkpoint(allCheckpointOffsets)\n-    trace(\"Got combined checkpoint offsets for taskName: %s as: %s\" format (taskName, allCheckpointOffsets))\n \n-    offsetManager.writeCheckpoint(taskName, checkpoint)\n+      trace(\"Got combined checkpoint offsets for taskName: %s as: %s\" format (taskName, checkpoint))\n \n-    if (storageManager != null) {\n-      trace(\"Remove old checkpoint stores for taskName: %s\" format taskName)\n-      try {\n-        storageManager.removeOldCheckpoints(checkpointId)\n-      } catch {\n-        case e: Exception => error(\"Failed to remove old checkpoints for task: %s. Current checkpointId: %s\" format (taskName, checkpointId), e)\n-      }\n-    }\n+      // Write input offsets and state checkpoint markers to the checkpoint topic atomically\n+      offsetManager.writeCheckpoint(taskName, checkpoint)\n+    })\n \n-    if (inputCheckpoint != null) {\n-      trace(\"Deleting committed input offsets for taskName: %s\" format taskName)\n-      inputCheckpoint.getOffsets.asScala\n-        .filter { case (ssp, _) => streamsToDeleteCommittedMessages.contains(ssp.getStream) } // Only delete data of intermediate streams\n-        .groupBy { case (ssp, _) => ssp.getSystem }\n-        .foreach { case (systemName: String, offsets: Map[SystemStreamPartition, String]) =>\n-          systemAdmins.getSystemAdmin(systemName).deleteMessages(offsets.asJava)\n-        }\n+    // Perform cleanup on unused checkpoints\n+    trace(\"Cleaning up old checkpoint state for taskName: %s. Current checkpointId: %s\" format (taskName, checkpointId))\n+    try {\n+      // TODO BLOCKER dchen cleanup should also be called in init on container startup.\n+      commitManager.cleanUp(checkpointId)\n+    } catch {\n+      case e: Exception => error(\"Failed to remove old checkpoint state for task: %s. Current checkpointId: %s\" format (taskName, checkpointId), e)\n     }\n+\n+    trace(\"Deleting committed input offsets from intermediate topics for taskName: %s\" format taskName)\n+    inputOffsets.asScala\n+      .filter { case (ssp, _) => streamsToDeleteCommittedMessages.contains(ssp.getStream) } // Only delete data of intermediate streams\n+      .groupBy { case (ssp, _) => ssp.getSystem }\n+      .foreach { case (systemName: String, offsets: Map[SystemStreamPartition, String]) =>\n+        systemAdmins.getSystemAdmin(systemName).deleteMessages(offsets.asJava)\n+      }\n   }\n \n   def shutdownTask {\n@@ -304,6 +313,15 @@ class TaskInstance(\n     }\n   }\n \n+  def shutdownCommitManager: Unit = {\n+    if (commitManager != null) {\n+      debug(\"Shutting down commit manager for taskName: %s\" format taskName)\n+      commitManager.close()\n+    } else {\n+      debug(\"Skipping commit manager shutdown for taskName: %s\" format taskName)\n+    }\n+  }\n+\n   override def toString() = \"TaskInstance for class %s and taskName %s.\" format (task.getClass.getName, taskName)\n \n   def toDetailedString() = \"TaskInstance [taskName = %s, windowable=%s, closable=%s endofstreamlistener=%s]\" format"
  }
]
