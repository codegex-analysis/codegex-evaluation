[
  {
    "sha": "3febc47b2b8dae3f3efae4d08d689114048fa0ac",
    "filename": "athena-dynamodb/README.md",
    "status": "modified",
    "additions": 17,
    "deletions": 3,
    "changes": 20,
    "blob_url": "https://github.com/awslabs/aws-athena-query-federation/blob/95973aa9a0faf2c9ea39679cb63d50058a35268e/athena-dynamodb/README.md",
    "raw_url": "https://github.com/awslabs/aws-athena-query-federation/raw/95973aa9a0faf2c9ea39679cb63d50058a35268e/athena-dynamodb/README.md",
    "contents_url": "https://api.github.com/repos/awslabs/aws-athena-query-federation/contents/athena-dynamodb/README.md?ref=95973aa9a0faf2c9ea39679cb63d50058a35268e",
    "patch": "@@ -51,14 +51,28 @@ Review the \"Policies\" section of the athena-dynamodb.yaml file for full details\n 4. CloudWatch Logs - This is a somewhat implicit permission when deploying a Lambda function but it needs access to cloudwatch logs for storing logs.\n 1. Athena GetQueryExecution - The connector uses this access to fast-fail when the upstream Athena query has terminated.\n \n+### Running Integration Tests\n+\n+The integration tests in this module are designed to run without the prior need for deploying the connector. Nevertheless,\n+the integration tests will not run straight out-of-the-box. Certain build-dependencies are required for them to execute correctly.\n+For build commands and step-by-step instructions on building and running the integration tests see the\n+[Running Integration Tests](https://github.com/awslabs/aws-athena-query-federation/blob/master/athena-federation-integ-test/README.md#running-integration-tests) README section in the **athena-federation-integ-test** module.\n+\n+In addition to the build-dependencies, certain test configuration attributes must also be provided in the connector's [test-config.json](./etc/test-config.json) JSON file.\n+For additional information about the test configuration file, see the [Test Configuration](https://github.com/awslabs/aws-athena-query-federation/blob/master/athena-federation-integ-test/README.md#test-configuration) README section in the **athena-federation-integ-test** module.\n+\n+Once all prerequisites have been satisfied, the integration tests can be executed by specifying the following command: `mvn failsafe:integration-test` from the connector's root directory.\n+\n ### Deploying The Connector\n \n To use this connector in your queries, navigate to AWS Serverless Application Repository and deploy a pre-built version of this connector. Alternatively, you can build and deploy this connector from\n source follow the below steps or use the more detailed tutorial in the athena-example module:\n \n-1. From the athena-federation-sdk dir, run `mvn clean install` if you haven't already.\n-2. From the athena-dynamodb dir, run `mvn clean install`.\n-3. From the athena-dynamodb dir, run  `../tools/publish.sh S3_BUCKET_NAME athena-dynamodb` to publish the connector to your private AWS Serverless Application Repository. The S3_BUCKET in the command\n+1. From the **athena-federation-sdk** dir, run `mvn clean install` if you haven't already.\n+2. From the **athena-federation-integ-test** dir, run `mvn clean install` if you haven't already\n+   (**Note: failure to follow this step will result in compilation errors**).\n+3. From the **athena-dynamodb** dir, run `mvn clean install`.\n+4. From the **athena-dynamodb** dir, run  `../tools/publish.sh S3_BUCKET_NAME athena-dynamodb` to publish the connector to your private AWS Serverless Application Repository. The S3_BUCKET in the command\n is where a copy of the connector's code will be stored for Serverless Application Repository to retrieve it. This will allow users with permission to do so, the ability to deploy instances of the\n connector via 1-Click form. Then navigate to [Serverless Application Repository](https://aws.amazon.com/serverless/serverlessrepo)\n "
  },
  {
    "sha": "e55da14504bb0305e9067d1a3c960e5dafd84d0d",
    "filename": "athena-dynamodb/etc/test-config.json",
    "status": "added",
    "additions": 18,
    "deletions": 0,
    "changes": 18,
    "blob_url": "https://github.com/awslabs/aws-athena-query-federation/blob/95973aa9a0faf2c9ea39679cb63d50058a35268e/athena-dynamodb/etc/test-config.json",
    "raw_url": "https://github.com/awslabs/aws-athena-query-federation/raw/95973aa9a0faf2c9ea39679cb63d50058a35268e/athena-dynamodb/etc/test-config.json",
    "contents_url": "https://api.github.com/repos/awslabs/aws-athena-query-federation/contents/athena-dynamodb/etc/test-config.json?ref=95973aa9a0faf2c9ea39679cb63d50058a35268e",
    "patch": "@@ -0,0 +1,18 @@\n+{\n+  \"athena_work_group\" : \"FederationIntegrationTests\", /* The Athena Workgroup used for running integration tests (default: FederationIntegrationTests) */\n+  \"secrets_manager_secret\" : \"<secret name>\",         /* Secret name used to retrieve user credentials from SecretsManager. */\n+  \"environment_vars\" : {                  /* Parameters used by the connector's internal logic */\n+    \"spill_bucket\" : \"<spill bucket>\",    /* The S3 bucket used for spilling excess data */\n+    \"spill_prefix\" : \"athena-spill\",      /* The prefix within the S3 spill bucket (default: athena-spill) */\n+    \"disable_spill_encryption\" : \"false\"  /* If set to true encryption for spilled data is disabled (default: false) */\n+  },\n+  \"vpc_configuration\" : {           /* This connector does not use a VPC configuration */\n+    \"vpc_id\": \"\",                   /* Leave empty */\n+    \"security_group_id\": \"\",        /* Leave empty */\n+    \"subnet_ids\": [],               /* Leave empty */\n+    \"availability_zones\": []        /* Leave empty */\n+  },\n+  \"user_settings\" : {               /* User customizable settings */\n+    \"dynamodb_db_name\": \"default\"   /* Name of DynamoDb instance used by the integration tests */\n+  }\n+}\n\\ No newline at end of file"
  },
  {
    "sha": "ad27b4fe70f3d2fdfdff580ef9451a600f7ec6c1",
    "filename": "athena-dynamodb/src/test/java/com/amazonaws/athena/connectors/dynamodb/DynamoDbIntegTest.java",
    "status": "modified",
    "additions": 15,
    "deletions": 7,
    "changes": 22,
    "blob_url": "https://github.com/awslabs/aws-athena-query-federation/blob/95973aa9a0faf2c9ea39679cb63d50058a35268e/athena-dynamodb/src/test/java/com/amazonaws/athena/connectors/dynamodb/DynamoDbIntegTest.java",
    "raw_url": "https://github.com/awslabs/aws-athena-query-federation/raw/95973aa9a0faf2c9ea39679cb63d50058a35268e/athena-dynamodb/src/test/java/com/amazonaws/athena/connectors/dynamodb/DynamoDbIntegTest.java",
    "contents_url": "https://api.github.com/repos/awslabs/aws-athena-query-federation/contents/athena-dynamodb/src/test/java/com/amazonaws/athena/connectors/dynamodb/DynamoDbIntegTest.java?ref=95973aa9a0faf2c9ea39679cb63d50058a35268e",
    "patch": "@@ -33,6 +33,7 @@\n import java.util.ArrayList;\n import java.util.List;\n import java.util.Map;\n+import java.util.Optional;\n import java.util.UUID;\n \n import static org.junit.Assert.assertEquals;\n@@ -43,14 +44,17 @@\n  */\n public class DynamoDbIntegTest extends IntegrationTestBase {\n     private static final Logger logger = LoggerFactory.getLogger(DynamoDbIntegTest.class);\n-    private static final String DATABASE_NAME = \"default\";\n \n+    private final String dynamodbDbName;\n     private final String lambdaFunctionName;\n     private final String tableName;\n     private final DdbTableUtils ddbTableUtils;\n \n     public DynamoDbIntegTest()\n     {\n+        Map<String, Object> userSettings = getUserSettings().orElseThrow(() ->\n+                new RuntimeException(\"user_settings attribute must be provided in test-config.json.\"));\n+        dynamodbDbName = (String) userSettings.get(\"dynamodb_db_name\");\n         lambdaFunctionName = getLambdaFunctionName();\n         tableName = String.format(\"dynamodbit_%s\", UUID.randomUUID().toString().replace('-', '_'));\n         ddbTableUtils = new DdbTableUtils(tableName);\n@@ -62,21 +66,23 @@ public DynamoDbIntegTest()\n      * Elasticsearch etc...)\n      * @return A policy document object.\n      */\n-    protected PolicyDocument getConnectorAccessPolicy()\n+    @Override\n+    protected Optional<PolicyDocument> getConnectorAccessPolicy()\n     {\n-        return PolicyDocument.Builder.create()\n+        return Optional.of(PolicyDocument.Builder.create()\n                 .statements(ImmutableList.of(PolicyStatement.Builder.create()\n                         .actions(ImmutableList.of(\"dynamodb:DescribeTable\", \"dynamodb:ListSchemas\",\n                                 \"dynamodb:ListTables\", \"dynamodb:Query\", \"dynamodb:Scan\"))\n                         .resources(ImmutableList.of(\"*\"))\n                         .effect(Effect.ALLOW)\n                         .build()))\n-                .build();\n+                .build());\n     }\n \n     /**\n      * Sets the environment variables for the Lambda function.\n      */\n+    @Override\n     protected void setConnectorEnvironmentVars(final Map environmentVars)\n     {\n         // This is a no-op for this connector.\n@@ -86,6 +92,7 @@ protected void setConnectorEnvironmentVars(final Map environmentVars)\n      * Sets up the DDB Table's CloudFormation stack.\n      * @param stack The current CloudFormation stack.\n      */\n+    @Override\n     protected void setUpStackData(final Stack stack)\n     {\n         ddbTableUtils.setupTableStack(stack);\n@@ -94,6 +101,7 @@ protected void setUpStackData(final Stack stack)\n     /**\n      * Insert rows into the newly created DDB table.\n      */\n+    @Override\n     protected void setUpTableData()\n     {\n         logger.info(\"----------------------------------------------------\");\n@@ -122,7 +130,7 @@ public void listTablesIntegTest()\n         logger.info(\"Executing listTablesIntegTest\");\n         logger.info(\"-----------------------------------\");\n \n-        List tableNames = listTables(DATABASE_NAME);\n+        List tableNames = listTables(dynamodbDbName);\n         logger.info(\"Tables: {}\", tableNames);\n         assertTrue(String.format(\"Table not found: %s.\", tableName), tableNames.contains(tableName));\n     }\n@@ -134,7 +142,7 @@ public void describeTableIntegTest()\n         logger.info(\"Executing describeTableIntegTest\");\n         logger.info(\"--------------------------------------\");\n \n-        Map schema = describeTable(DATABASE_NAME, tableName);\n+        Map schema = describeTable(dynamodbDbName, tableName);\n         logger.info(\"Schema: {}\", schema);\n         assertEquals(\"Wrong number of columns found.\", 3, schema.size());\n         assertTrue(\"Column not found: title\", schema.containsKey(\"title\"));\n@@ -154,7 +162,7 @@ public void selectColumnWithPredicateIntegTest()\n         logger.info(\"--------------------------------------------------\");\n \n         String query = String.format(\"select title from %s.%s.%s where year > 2000;\",\n-                lambdaFunctionName, DATABASE_NAME, tableName);\n+                lambdaFunctionName, dynamodbDbName, tableName);\n         List<Row> rows = startQueryExecution(query).getResultSet().getRows();\n         if (!rows.isEmpty()) {\n             // Remove the column-header row"
  },
  {
    "sha": "26c739193842523ce3a8fd1488c289fd8f0871dc",
    "filename": "athena-federation-integ-test/README.md",
    "status": "modified",
    "additions": 113,
    "deletions": 21,
    "changes": 134,
    "blob_url": "https://github.com/awslabs/aws-athena-query-federation/blob/95973aa9a0faf2c9ea39679cb63d50058a35268e/athena-federation-integ-test/README.md",
    "raw_url": "https://github.com/awslabs/aws-athena-query-federation/raw/95973aa9a0faf2c9ea39679cb63d50058a35268e/athena-federation-integ-test/README.md",
    "contents_url": "https://api.github.com/repos/awslabs/aws-athena-query-federation/contents/athena-federation-integ-test/README.md?ref=95973aa9a0faf2c9ea39679cb63d50058a35268e",
    "patch": "@@ -1,17 +1,17 @@\n-# Integration-Test Module\n+# Integration-Test Framework\n \n-The Integration-Test module provides end-to-end testing capabilities, and is available\n+The Integration-Test framework provides end-to-end testing capabilities, and is available\n to all lambda connectors developed using the Athena Federation SDK.\n \n ## How It Works\n \n In order to test the connectors end-to-end, several infrastructure resources need to be\n-provisioned and deployed (e.g. DB instance, Lambda function, etc...) This module accomplishes\n+provisioned and deployed (e.g. DB instance, Lambda function, etc...) The framework accomplishes\n that by allowing AWS CloudFormation to manage the infrastructure resources. All an\n integration-test writer needs to do is provide an implementation for a handful of functions,\n-and the Integration-Test module will do the rest.\n+and the Integration-Test framework will do the rest.\n \n-This module provides the following benefits:\n+The framework provides the following benefits:\n * Automatically provisions all infrastructure resources prior to testing, and de-provisions\n them immediately after.\n * Provides a set of public APIs that can be used to send queries via Athena using the lambda\n@@ -20,19 +20,21 @@ connector.\n ## Writing Integration Tests\n \n This section explains the steps necessary to create integration tests using the\n-Integration-Test module. For an actual code example, see the DynamoDB connector\n-[DynamoDbIntegTest integration-test class](https://github.com/awslabs/aws-athena-query-federation/blob/master/athena-dynamodb/src/test/java/com/amazonaws/athena/connectors/dynamodb/DynamoDbIntegTest.java).\n+Integration-Test framework. For actual code examples, see the DynamoDB connector\n+([DynamoDbIntegTest](https://github.com/awslabs/aws-athena-query-federation/blob/master/athena-dynamodb/src/test/java/com/amazonaws/athena/connectors/dynamodb/DynamoDbIntegTest.java)),\n+and the Redshift (JDBC) connector\n+([RedshiftIntegTest](https://github.com/awslabs/aws-athena-query-federation/blob/master/athena-jdbc/src/test/java/com/amazonaws/connectors/athena/jdbc/integ/RedshiftIntegTest.java)).\n \n ### Dependencies\n \n-Add the Integration-Test module as a test dependency in the specific connector's `pom.xml` file (replace `2020.46.1`\n-with current version):\n+Add the Integration-Test module (athena-federation-integ-test) as a test dependency in the specific connector's\n+`pom.xml` file (replace `version` with current version on the module):\n \n ```xml\n         <dependency>\n             <groupId>com.amazonaws</groupId>\n             <artifactId>athena-federation-integ-test</artifactId>\n-            <version>2020.46.1</version>\n+            <version>version</version>\n             <scope>test</scope>\n         </dependency>\n ```\n@@ -76,10 +78,10 @@ Provide implementation for the following 4 abstract methods in the test class:\n     protected abstract void setUpStackData(final Stack stack);\n \n     /**\n-     * Must be overridden in the extending class to set the lambda function's environment variables key-value pairs\n-     * (e.g. \"spill_bucket\":\"myspillbucket\"). See individual connector for expected environment variables. This method\n-     * can be a no-op in the extending class since some environment variables are set by default (spill_bucket,\n-     * spill_prefix, and disable_spill_encryption).\n+     * Must be overridden in the extending class (can be a no-op) to set the lambda function's environment variables\n+     * key-value pairs (e.g. \"connection_string\":\"redshift://jdbc:redshift://...\"). See individual connector for the\n+     * expected environment variables. This method is intended to supplement the test-config.json file environment_vars\n+     * attribute (see below) for cases where the environment variable cannot be hardcoded.\n      */\n     protected abstract void setConnectorEnvironmentVars(final Map<String, String> environmentVars);\n \n@@ -88,17 +90,104 @@ Provide implementation for the following 4 abstract methods in the test class:\n      * access to multiple connector-specific AWS services (e.g. DynamoDB, Elasticsearch etc...)\n      * @return A policy document object.\n      */\n-    protected abstract PolicyDocument getConnectorAccessPolicy();\n+    protected abstract Optional<PolicyDocument> getConnectorAccessPolicy();\n+```\n+\n+### Test Configuration\n+\n+The Integration-Test framework uses several configurable attributes to set up the test resources (e.g. a spill bucket,\n+Athena work-group, etc...) Those attributes must be placed in the connectors' `test-config.json` JSON file available\n+in each connector's **etc** directory. The following is an example of a test configuration file used for the Redshift\n+integration tests:\n+```json\n+{\n+  \"athena_work_group\" : \"FederationIntegrationTests\",\n+  \"secrets_manager_secret\" : \"redshift-integ1\",\n+  \"environment_vars\" : {\n+    \"spill_bucket\" : \"athena-results\",\n+    \"spill_prefix\" : \"athena-spill\",\n+    \"disable_spill_encryption\" : \"false\"\n+  },\n+  \"vpc_configuration\" : {\n+    \"vpc_id\": \"vpc-569cdc2c\",\n+    \"security_group_id\": \"sg-2bc8117a\",\n+    \"subnet_ids\": [\"subnet-a3017a9d\", \"subnet-bb894ef6\", \"subnet-7b6f5f27\", \"subnet-d55361fb\",\n+      \"subnet-da5db3d4\", \"subnet-88d6e2ef\"],\n+    \"availability_zones\": [\"us-east-1a\", \"us-east-1b\", \"us-east-1c\", \"us-east-1d\", \"us-east-1e\",\n+      \"us-ease-1f\"]\n+  },\n+  \"user_settings\" : {\n+    \"redshift_db_name\": \"public\",\n+    \"redshift_db_port\": \"5439\",\n+    \"redshift_table_movies\": \"movies\",\n+    \"redshift_table_bday\": \"bday\"\n+  }\n+}\n+```\n+General attributes needed for the tests' execution:\n+* **athena_work_group** - The Athena Workgroup used for running integration tests (default:\n+  `FederationIntegrationTests`).\n+* **secrets_manager_secret** - Secret name used to retrieve user credentials from SecretsManager.\n+\n+Since secret credentials may be needed when creating resources specific to the tests' execution (e.g. DB cluster), the\n+Integration-Test framework provides the following public API allowing access to the SecretsManager secret credentials:\n+```java\n+    /**\n+     * Public accessor for the SecretsManager credentials obtained using the secrets_manager_secret attribute entered\n+     * in the config file.\n+     * @return Optional SecretsManager credentials object.\n+     */\n+    public Optional<SecretsManagerCredentials> getSecretCredentials()\n+    {\n+        return secretCredentials;\n+    }\n+```\n+\n+**Environment variables** - Parameters used by the connectors' internal logic:\n+* **spill_bucket** - The S3 bucket used for spilling excess data.\n+* **spill_prefix** - The prefix within the S3 spill bucket (default: `athena-spill`).\n+* **disable_spill_encryption** - If set to `true` encryption for spilled data is disabled (default: `false`).\n+\n+**VPC configuration** (Optional) - Parameters needed to configure resources within a VPC (e.g. DB cluster):\n+* **vpc_id** - The VPC Id (e.g. `\"vpc_id\": \"vpc-xxx\"`).\n+* **security_group_id** - The Security Group Id (e.g. `\"security_group_id\": \"sg-xxx\"`).\n+* **subnet_ids** - A list consisting of at least one Subnet Id (e.g. `\"subnet_ids\": [\"subnet-xxx1\", \"subnet-xxx2\"]`).\n+* **availability_zones** - A list consisting of at least one AZ (e.g. `\"availability_zones\": [\"us-east-1a\", \"us-east-1b\"]`).\n+\n+The framework uses the aforementioned attributes to configure the connector. In order for the latter to be able to connect\n+to the data source, however, the same VPC configuration must be set when provisioning the DB instance. To that end, the\n+Integration-Test framework provides the following public API allowing access to the VPC attributes:\n+```java\n+    /**\n+     * Public accessor for the VPC attributes used in generating the lambda function.\n+     * @return Optional VPC attributes object.\n+     */\n+    public Optional<ConnectorVpcAttributes> getVpcAttributes()\n+```\n+\n+**User settings**: (Optional)\n+User customizable Map that contains user-specific attributes (e.g. `\"user_settings\": {\"redshift_table_movies\": \"movies\"}`). Because the Map\n+is constructed from a JSON structure and returned as Map<String, Object>, it can contain different type of attributes\n+ranging from a single value, a list of values, to even a nested structure. the Integration-Test framework provides the\n+following public API allowing access to the `user_settings` attribute:\n+```java\n+    /**\n+     * Public accessor for the user_settings attribute (stored in the test-config.json file) that are customizable to\n+     * any user-specific purpose.\n+     * @return Optional Map(String, Object) containing all the user attributes as defined in the test configuration file,\n+     * or an empty Optional if the user_settings attribute does not exist in the file.\n+     */\n+    public Optional<Map> getUserSettings()\n ```\n \n ### Integration-Test Public APIs\n \n-The Integration-Test module provides the following 5 public APIs that can be used to send DB\n+The Integration-Test framework provides the following 5 public APIs that can be used to send DB\n queries as part of the tests' execution:\n \n ```java\n     /**\n-     * Gets the name of the lambda function generated by the Integration-Test module.\n+     * Gets the name of the lambda function generated by the Integration-Test framework.\n      * @return The name of the lambda function.\n      */\n     public String getLambdaFunctionName()\n@@ -145,11 +234,14 @@ locally from the terminal.\n The following commands should be sent after cloning the Federation GitHub repository for\n the first time, and each time the connector's code changes:\n \n-1. Build the SDK and connector (SDK only needs to build once): `mvn clean install`\n-2. Export the IAM credentials for the AWS account used for testing purposes.\n-3. Package the connector (from the connector's directory):\n+1. From the **athena-federation-sdk** dir, run `mvn clean install` if you haven't done so already.\n+2. From the **athena-federation-integ-test** dir, run `mvn clean install` if you haven't done so already\n+   (**Note: failure to follow this step will result in compilation errors**).\n+3. From your connector's dir, run `mvn clean install`.\n+4. Export the IAM credentials for the AWS account used for testing purposes.\n+5. Package the connector (from the connector's directory):\n `sam package --template-file <connector.yaml> --output-template-file packaged.yaml\n---s3-bucket <spill-bucket> --region <region> --force-upload`\n+--s3-bucket <s3-bucket> --region <region> --force-upload`\n \n ### Running Integration Tests\n "
  },
  {
    "sha": "727809b3e849c6362b71777a5653b7caef9b6772",
    "filename": "athena-federation-integ-test/pom.xml",
    "status": "modified",
    "additions": 11,
    "deletions": 0,
    "changes": 11,
    "blob_url": "https://github.com/awslabs/aws-athena-query-federation/blob/95973aa9a0faf2c9ea39679cb63d50058a35268e/athena-federation-integ-test/pom.xml",
    "raw_url": "https://github.com/awslabs/aws-athena-query-federation/raw/95973aa9a0faf2c9ea39679cb63d50058a35268e/athena-federation-integ-test/pom.xml",
    "contents_url": "https://api.github.com/repos/awslabs/aws-athena-query-federation/contents/athena-federation-integ-test/pom.xml?ref=95973aa9a0faf2c9ea39679cb63d50058a35268e",
    "patch": "@@ -82,6 +82,12 @@\n             <artifactId>aws-java-sdk-cloudformation</artifactId>\n             <version>${aws-sdk.version}</version>\n         </dependency>\n+        <!-- https://mvnrepository.com/artifact/com.amazonaws/aws-java-sdk-secretsmanager -->\n+        <dependency>\n+            <groupId>com.amazonaws</groupId>\n+            <artifactId>aws-java-sdk-secretsmanager</artifactId>\n+            <version>${aws-sdk.version}</version>\n+        </dependency>\n         <!-- https://mvnrepository.com/artifact/software.amazon.awscdk/core -->\n         <dependency>\n             <groupId>software.amazon.awscdk</groupId>\n@@ -112,6 +118,11 @@\n             <artifactId>jackson-annotations</artifactId>\n             <version>${fasterxml.jackson.version}</version>\n         </dependency>\n+        <dependency>\n+            <groupId>org.apache.commons</groupId>\n+            <artifactId>commons-lang3</artifactId>\n+            <version>3.9</version>\n+        </dependency>\n     </dependencies>\n \n     <build>"
  },
  {
    "sha": "e6c57e750eec653b9a8614c53aef6faae978cacf",
    "filename": "athena-federation-integ-test/src/main/java/com/amazonaws/athena/connector/integ/CloudFormationTemplateProvider.java",
    "status": "removed",
    "additions": 0,
    "deletions": 213,
    "changes": 213,
    "blob_url": "https://github.com/awslabs/aws-athena-query-federation/blob/e2f9c876e73d162fe63e54bc0caa6de894a838ae/athena-federation-integ-test/src/main/java/com/amazonaws/athena/connector/integ/CloudFormationTemplateProvider.java",
    "raw_url": "https://github.com/awslabs/aws-athena-query-federation/raw/e2f9c876e73d162fe63e54bc0caa6de894a838ae/athena-federation-integ-test/src/main/java/com/amazonaws/athena/connector/integ/CloudFormationTemplateProvider.java",
    "contents_url": "https://api.github.com/repos/awslabs/aws-athena-query-federation/contents/athena-federation-integ-test/src/main/java/com/amazonaws/athena/connector/integ/CloudFormationTemplateProvider.java?ref=e2f9c876e73d162fe63e54bc0caa6de894a838ae",
    "patch": "@@ -1,213 +0,0 @@\n-/*-\n- * #%L\n- * Amazon Athena Query Federation Integ Test\n- * %%\n- * Copyright (C) 2019 - 2020 Amazon Web Services\n- * %%\n- * Licensed under the Apache License, Version 2.0 (the \"License\");\n- * you may not use this file except in compliance with the License.\n- * You may obtain a copy of the License at\n- * \n- *      http://www.apache.org/licenses/LICENSE-2.0\n- * \n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- * #L%\n- */\n-package com.amazonaws.athena.connector.integ;\n-\n-import com.fasterxml.jackson.databind.ObjectMapper;\n-import com.fasterxml.jackson.databind.SerializationFeature;\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-import software.amazon.awscdk.core.App;\n-import software.amazon.awscdk.core.Stack;\n-import software.amazon.awscdk.services.iam.PolicyDocument;\n-\n-import java.io.IOException;\n-import java.nio.charset.StandardCharsets;\n-import java.nio.file.Files;\n-import java.nio.file.Paths;\n-import java.util.HashMap;\n-import java.util.Map;\n-import java.util.UUID;\n-\n-public abstract class CloudFormationTemplateProvider\n-{\n-    private static final Logger logger = LoggerFactory.getLogger(CloudFormationTemplateProvider.class);\n-\n-    private static final String CF_TEMPLATE_NAME = \"packaged.yaml\";\n-    private static final String LAMBDA_CODE_URI_TAG = \"CodeUri:\";\n-    private static final String LAMBDA_SPILL_BUCKET_PREFIX = \"s3://\";\n-    private static final String LAMBDA_HANDLER_TAG = \"Handler:\";\n-    private static final String LAMBDA_HANDLER_PREFIX = \"Handler: \";\n-    private static final String LAMBDA_SPILL_BUCKET_TAG = \"spill_bucket\";\n-    private static final String LAMBDA_SPILL_PREFIX_TAG = \"spill_prefix\";\n-    private static final String LAMBDA_DISABLE_SPILL_ENCRYPTION_TAG = \"disable_spill_encryption\";\n-    private static final int MAX_LAMBDA_FUNCTION_NAME = 64;\n-\n-    private final String cloudFormationStackName;\n-    private final App theApp;\n-    private final ObjectMapper objectMapper;\n-    private final String lambdaFunctionName;\n-    private final PolicyDocument accessPolicy;\n-    private final Map environmentVars;\n-\n-    private String lambdaFunctionHandler;\n-    private String spillBucket;\n-    private String s3Key;\n-\n-    public CloudFormationTemplateProvider(String stackName)\n-    {\n-        setupLambdaFunctionInfo();\n-\n-        final String randomUuidStr = UUID.randomUUID().toString();\n-        theApp = new App();\n-        objectMapper = new ObjectMapper().configure(SerializationFeature.INDENT_OUTPUT, true);\n-        cloudFormationStackName = String.format(\"integration-%s-%s\", stackName, randomUuidStr);\n-        // Lambda Function's name cannot exceed 64 bytes.\n-        lambdaFunctionName = String.format(\"%s_%s\", stackName.toLowerCase(), randomUuidStr\n-                .replace('-', '_'))\n-                .substring(0, Math.min(MAX_LAMBDA_FUNCTION_NAME, stackName.length() + randomUuidStr.length() + 1));\n-        environmentVars = getEnvironmentVars();\n-        accessPolicy = getAccessPolicy();\n-    }\n-\n-    /**\n-     * Sets several variables needed in the creation of the CF Stack (e.g. spillBucket, s3Key, lambdaFunctionHandler).\n-     * @throws RuntimeException CloudFormation template (packaged.yaml) was not found.\n-     */\n-    private void setupLambdaFunctionInfo()\n-            throws RuntimeException\n-    {\n-        try {\n-            for (String line : Files.readAllLines(Paths.get(CF_TEMPLATE_NAME), StandardCharsets.UTF_8)) {\n-                if (line.contains(LAMBDA_CODE_URI_TAG)) {\n-                    spillBucket = line.substring(line.indexOf(LAMBDA_SPILL_BUCKET_PREFIX) +\n-                            LAMBDA_SPILL_BUCKET_PREFIX.length(), line.lastIndexOf('/'));\n-                    s3Key = line.substring(line.lastIndexOf('/') + 1);\n-                }\n-                else if (line.contains(LAMBDA_HANDLER_TAG)) {\n-                    lambdaFunctionHandler = line.substring(line.indexOf(LAMBDA_HANDLER_PREFIX) +\n-                            LAMBDA_HANDLER_PREFIX.length());\n-                }\n-            }\n-        }\n-        catch (IOException e) {\n-            throw new RuntimeException(\"Lambda connector has not been packaged via `sam package` (see README).\", e);\n-        }\n-\n-        logger.info(\"Spill Bucket: [{}], S3 Key: [{}], Handler: [{}]\", spillBucket, s3Key, lambdaFunctionHandler);\n-    }\n-\n-    /**\n-     * Gets the specific connectors' environment variables.\n-     * @return A Map containing the environment variables key-value pairs.\n-     */\n-    private Map getEnvironmentVars()\n-    {\n-        final Map<String, String> environmentVars = new HashMap<>();\n-        // Have the connector set specific environment variables first.\n-        setEnvironmentVars(environmentVars);\n-\n-        // Check for missing spill_bucket\n-        if (!environmentVars.containsKey(LAMBDA_SPILL_BUCKET_TAG)) {\n-            // Add missing spill_bucket environment variable\n-            environmentVars.put(LAMBDA_SPILL_BUCKET_TAG, spillBucket);\n-        }\n-\n-        // Check for missing spill_prefix\n-        if (!environmentVars.containsKey(LAMBDA_SPILL_PREFIX_TAG)) {\n-            // Add missing spill_prefix environment variable\n-            environmentVars.put(LAMBDA_SPILL_PREFIX_TAG, \"athena-spill\");\n-        }\n-\n-        // Check for missing disable_spill_encryption environment variable\n-        if (!environmentVars.containsKey(LAMBDA_DISABLE_SPILL_ENCRYPTION_TAG)) {\n-            // Add missing disable_spill_encryption environment variable\n-            environmentVars.put(LAMBDA_DISABLE_SPILL_ENCRYPTION_TAG, \"false\");\n-        }\n-\n-        return environmentVars;\n-    }\n-\n-    /**\n-     * Must be overridden to facilitate getting the lambda function's IAM access policy. The latter sets up\n-     * access to multiple connector-specific AWS services (e.g. DynamoDB, Elasticsearch etc...)\n-     * @return A policy document object.\n-     */\n-    protected abstract PolicyDocument getAccessPolicy();\n-\n-    /**\n-     * Must be overridden to facilitate the setting of the lambda function's environment variables key-value pairs\n-     * (e.g. \"spill_bucket\":\"myspillbucket\"). See individual connector for expected environment variables. This method\n-     * can be a no-op in the extending class since some environment variables are set by default (spill_bucket,\n-     * spill_prefix, and disable_spill_encryption).\n-     */\n-    protected abstract void setEnvironmentVars(final Map environmentVars);\n-\n-    /**\n-     * Must be overridden (can be a no-op) to facilitate the creation of a connector-specific CloudFormation stack\n-     * resource (e.g. DB table) using AWS CDK.\n-     * @param stack The current CloudFormation stack.\n-     */\n-    protected abstract void setSpecificResource(final Stack stack);\n-\n-    /**\n-     * Gets the CloudFormation stack name.\n-     * @return The stack's name.\n-     */\n-    protected String getStackName()\n-    {\n-        return cloudFormationStackName;\n-    }\n-\n-    /**\n-     * Gets the name of the lambda function generated by the Integration-Test module.\n-     * @return The name of the lambda function.\n-     */\n-    protected String getLambdaFunctionName()\n-    {\n-        return lambdaFunctionName;\n-    }\n-\n-    /**\n-     * Gets the CloudFormation stack template.\n-     * @return The stack template as String.\n-     */\n-    protected String getTemplate()\n-    {\n-        return generateTemplate();\n-    }\n-\n-    /**\n-     * Gets the CloudFormation template (generated programmatically using AWS CDK).\n-     * @return CloudFormation stack template.\n-     */\n-    private String generateTemplate()\n-    {\n-        final Stack stack = generateStack();\n-        final String stackTemplate = objectMapper\n-                .valueToTree(theApp.synth().getStackArtifact(stack.getArtifactId()).getTemplate())\n-                .toPrettyString();\n-        logger.info(\"CloudFormation Template:\\n{}: {}\", cloudFormationStackName, stackTemplate);\n-\n-        return stackTemplate;\n-    }\n-\n-    /**\n-     * Generate the CloudFormation stack programmatically using AWS CDK.\n-     * @return CloudFormation stack object.\n-     */\n-    private Stack generateStack()\n-    {\n-        final Stack stack = new ConnectorStack(theApp, cloudFormationStackName, spillBucket, s3Key,\n-                lambdaFunctionName, lambdaFunctionHandler, accessPolicy, environmentVars);\n-        setSpecificResource(stack);\n-\n-        return stack;\n-    }\n-}"
  },
  {
    "sha": "61e48c347a8ad24c4baed0e5c9358fbca679e0b1",
    "filename": "athena-federation-integ-test/src/main/java/com/amazonaws/athena/connector/integ/ConnectorStackAttributesProvider.java",
    "status": "added",
    "additions": 75,
    "deletions": 0,
    "changes": 75,
    "blob_url": "https://github.com/awslabs/aws-athena-query-federation/blob/95973aa9a0faf2c9ea39679cb63d50058a35268e/athena-federation-integ-test/src/main/java/com/amazonaws/athena/connector/integ/ConnectorStackAttributesProvider.java",
    "raw_url": "https://github.com/awslabs/aws-athena-query-federation/raw/95973aa9a0faf2c9ea39679cb63d50058a35268e/athena-federation-integ-test/src/main/java/com/amazonaws/athena/connector/integ/ConnectorStackAttributesProvider.java",
    "contents_url": "https://api.github.com/repos/awslabs/aws-athena-query-federation/contents/athena-federation-integ-test/src/main/java/com/amazonaws/athena/connector/integ/ConnectorStackAttributesProvider.java?ref=95973aa9a0faf2c9ea39679cb63d50058a35268e",
    "patch": "@@ -0,0 +1,75 @@\n+/*-\n+ * #%L\n+ * Amazon Athena Query Federation Integ Test\n+ * %%\n+ * Copyright (C) 2019 - 2020 Amazon Web Services\n+ * %%\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * \n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ * \n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ * #L%\n+ */\n+package com.amazonaws.athena.connector.integ;\n+\n+import com.amazonaws.athena.connector.integ.data.ConnectorPackagingAttributes;\n+import com.amazonaws.athena.connector.integ.data.ConnectorStackAttributes;\n+import com.amazonaws.athena.connector.integ.data.ConnectorVpcAttributes;\n+import com.amazonaws.athena.connector.integ.data.TestConfig;\n+import com.amazonaws.athena.connector.integ.providers.ConnectorEnvironmentVarsProvider;\n+import com.amazonaws.athena.connector.integ.providers.ConnectorPackagingAttributesProvider;\n+import com.amazonaws.athena.connector.integ.providers.ConnectorVpcAttributesProvider;\n+import software.amazon.awscdk.core.Construct;\n+import software.amazon.awscdk.services.iam.PolicyDocument;\n+\n+import java.util.Map;\n+import java.util.Optional;\n+\n+/**\n+ * Responsible for providing the Connector's stack attributes used in creating the Connector's stack (Lambda function,\n+ * Athena catalog, etc...)\n+ */\n+public class ConnectorStackAttributesProvider\n+{\n+    private final Construct scope;\n+    private final String id;\n+    private final String lambdaFunctionName;\n+    private final TestConfig testConfig;\n+    private final Optional<PolicyDocument> connectorAccessPolicy;\n+    private final Map<String, String> environmentVariables;\n+    private final ConnectorPackagingAttributes connectorPackagingAttributes;\n+    private final Optional<ConnectorVpcAttributes> connectorVpcAttributes;\n+\n+    protected ConnectorStackAttributesProvider(final Construct scope, final String id, final String lambdaFunctionName,\n+                                               final TestConfig testConfig,\n+                                               final Optional<PolicyDocument> connectorAccessPolicy,\n+                                               final Map<String, String> environmentVariables)\n+    {\n+        this.scope = scope;\n+        this.id = id;\n+        this.lambdaFunctionName = lambdaFunctionName;\n+        this.testConfig = testConfig;\n+        this.connectorAccessPolicy = connectorAccessPolicy;\n+        this.connectorPackagingAttributes = ConnectorPackagingAttributesProvider.getAttributes();\n+        this.connectorVpcAttributes = ConnectorVpcAttributesProvider.getAttributes(testConfig);\n+        this.environmentVariables = ConnectorEnvironmentVarsProvider.getVars(testConfig);\n+        this.environmentVariables.putAll(environmentVariables);\n+    }\n+\n+    /**\n+     * Provides the Connector's attributes needed to create the connector's CloudFormation stack template.\n+     * @return Connector attributes object.\n+     */\n+    protected ConnectorStackAttributes getAttributes()\n+    {\n+        return new ConnectorStackAttributes(scope, id, lambdaFunctionName, connectorAccessPolicy,\n+                environmentVariables, connectorPackagingAttributes, connectorVpcAttributes);\n+    }\n+}"
  },
  {
    "sha": "c11f0a394a1e6f12b7be628c87c3e163a4646789",
    "filename": "athena-federation-integ-test/src/main/java/com/amazonaws/athena/connector/integ/ConnectorStackFactory.java",
    "status": "added",
    "additions": 60,
    "deletions": 0,
    "changes": 60,
    "blob_url": "https://github.com/awslabs/aws-athena-query-federation/blob/95973aa9a0faf2c9ea39679cb63d50058a35268e/athena-federation-integ-test/src/main/java/com/amazonaws/athena/connector/integ/ConnectorStackFactory.java",
    "raw_url": "https://github.com/awslabs/aws-athena-query-federation/raw/95973aa9a0faf2c9ea39679cb63d50058a35268e/athena-federation-integ-test/src/main/java/com/amazonaws/athena/connector/integ/ConnectorStackFactory.java",
    "contents_url": "https://api.github.com/repos/awslabs/aws-athena-query-federation/contents/athena-federation-integ-test/src/main/java/com/amazonaws/athena/connector/integ/ConnectorStackFactory.java?ref=95973aa9a0faf2c9ea39679cb63d50058a35268e",
    "patch": "@@ -0,0 +1,60 @@\n+/*-\n+ * #%L\n+ * Amazon Athena Query Federation Integ Test\n+ * %%\n+ * Copyright (C) 2019 - 2020 Amazon Web Services\n+ * %%\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * \n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ * \n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ * #L%\n+ */\n+package com.amazonaws.athena.connector.integ;\n+\n+import com.amazonaws.athena.connector.integ.data.ConnectorStackAttributes;\n+import com.amazonaws.athena.connector.integ.stacks.ConnectorStack;\n+import com.amazonaws.athena.connector.integ.stacks.ConnectorWithVpcStack;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import software.amazon.awscdk.core.Stack;\n+\n+/**\n+ * Responsible for creating different types of Connector CloudFormation stacks depending on whether the connector\n+ * supports a VPC config or not.\n+ */\n+public class ConnectorStackFactory\n+{\n+    private static final Logger logger = LoggerFactory.getLogger(ConnectorStackFactory.class);\n+\n+    private final ConnectorStackAttributes attributes;\n+    private final boolean isSupportedVpcConfig;\n+\n+    public ConnectorStackFactory(final ConnectorStackAttributes attributes)\n+    {\n+        this.attributes = attributes;\n+        this.isSupportedVpcConfig = attributes.getConnectorVpcAttributes().isPresent();\n+    }\n+\n+    /**\n+     * Creates the Connector's CloudFormation stack.\n+     * @return Connector's stack: ConnectorWithVpcStack (supports a VPC config), or ConnectorStack (default).\n+     */\n+    public Stack createStack()\n+    {\n+        if (isSupportedVpcConfig) {\n+            logger.info(\"Creating stack: ConnectorWithVpcStack\");\n+            return ConnectorWithVpcStack.buildWithAttributes(attributes);\n+        }\n+\n+        logger.info(\"Creating stack: ConnectorStack\");\n+        return ConnectorStack.buildWithAttributes(attributes);\n+    }\n+}"
  },
  {
    "sha": "40b32aab7ee446c6338b1b9e6d07b8947cf85aa2",
    "filename": "athena-federation-integ-test/src/main/java/com/amazonaws/athena/connector/integ/ConnectorStackProvider.java",
    "status": "added",
    "additions": 114,
    "deletions": 0,
    "changes": 114,
    "blob_url": "https://github.com/awslabs/aws-athena-query-federation/blob/95973aa9a0faf2c9ea39679cb63d50058a35268e/athena-federation-integ-test/src/main/java/com/amazonaws/athena/connector/integ/ConnectorStackProvider.java",
    "raw_url": "https://github.com/awslabs/aws-athena-query-federation/raw/95973aa9a0faf2c9ea39679cb63d50058a35268e/athena-federation-integ-test/src/main/java/com/amazonaws/athena/connector/integ/ConnectorStackProvider.java",
    "contents_url": "https://api.github.com/repos/awslabs/aws-athena-query-federation/contents/athena-federation-integ-test/src/main/java/com/amazonaws/athena/connector/integ/ConnectorStackProvider.java?ref=95973aa9a0faf2c9ea39679cb63d50058a35268e",
    "patch": "@@ -0,0 +1,114 @@\n+/*-\n+ * #%L\n+ * Amazon Athena Query Federation Integ Test\n+ * %%\n+ * Copyright (C) 2019 - 2020 Amazon Web Services\n+ * %%\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * \n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ * \n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ * #L%\n+ */\n+package com.amazonaws.athena.connector.integ;\n+\n+import com.amazonaws.athena.connector.integ.data.TestConfig;\n+import org.testng.internal.collections.Pair;\n+import software.amazon.awscdk.core.App;\n+import software.amazon.awscdk.core.Stack;\n+import software.amazon.awscdk.services.iam.PolicyDocument;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.UUID;\n+\n+/**\n+ * Responsible for providing a CloudFormation stack for the connector being tested.\n+ */\n+public abstract class ConnectorStackProvider\n+{\n+    private static final int LAMBDA_FUNCTION_MAX_LENGTH = 64;\n+\n+    private final String cloudFormationStackName;\n+    private final TestConfig testConfig;\n+    private final App theApp;\n+    private final String lambdaFunctionName;\n+\n+    public ConnectorStackProvider(String stackName, TestConfig testConfig)\n+    {\n+        final String randomUuidStr = UUID.randomUUID().toString();\n+        theApp = new App();\n+        cloudFormationStackName = String.format(\"integration-%s-%s\", stackName, randomUuidStr);\n+        // Lambda Function's name cannot exceed 64 bytes.\n+        lambdaFunctionName = String.format(\"%s_%s\", stackName.toLowerCase(), randomUuidStr\n+                .replace('-', '_'))\n+                .substring(0, Math.min(LAMBDA_FUNCTION_MAX_LENGTH, stackName.length() + randomUuidStr.length() + 1));\n+        this.testConfig = testConfig;\n+    }\n+\n+    /**\n+     * Must be overridden to facilitate getting the lambda function's IAM access policy. The latter sets up\n+     * access to multiple connector-specific AWS services (e.g. DynamoDB, Elasticsearch etc...)\n+     * @return A policy document object.\n+     */\n+    protected abstract Optional<PolicyDocument> getAccessPolicy();\n+\n+    /**\n+     * Must be overridden to facilitate the setting of the lambda function's environment variables key-value pairs\n+     * (e.g. \"connection_string\":\"redshift://jdbc:redshift://...\"). See individual connector for the expected list of\n+     * environment variables.\n+     */\n+    protected abstract void setEnvironmentVars(final Map environmentVars);\n+\n+    /**\n+     * Must be overridden (can be a no-op) to facilitate the creation of a connector-specific CloudFormation stack\n+     * resource (e.g. DB table) using AWS CDK.\n+     * @param stack The current CloudFormation stack.\n+     */\n+    protected abstract void setSpecificResource(final Stack stack);\n+\n+    /**\n+     * Gets the name of the lambda function generated by the Integration-Test module.\n+     * @return The name of the lambda function.\n+     */\n+    protected String getLambdaFunctionName()\n+    {\n+        return lambdaFunctionName;\n+    }\n+\n+    /**\n+     * Gets the CloudFormation stack programmatically using AWS CDK.\n+     * @return CloudFormation stack object.\n+     */\n+    protected Pair<App, Stack> getStack()\n+    {\n+        ConnectorStackAttributesProvider attributesProvider = new ConnectorStackAttributesProvider(theApp,\n+                cloudFormationStackName, lambdaFunctionName, testConfig, getAccessPolicy(), getEnvironmentVars());\n+        ConnectorStackFactory stackFactory = new ConnectorStackFactory(attributesProvider.getAttributes());\n+        final Stack theStack = stackFactory.createStack();\n+        setSpecificResource(theStack);\n+\n+        return new Pair<>(theApp, theStack);\n+    }\n+\n+    /**\n+     * Gets the specific connectors' environment variables.\n+     * @return A Map containing the environment variables key-value pairs.\n+     */\n+    private Map<String, String> getEnvironmentVars()\n+    {\n+        final Map<String, String> environmentVars = new HashMap<>();\n+        // Set connector-specific environment variables.\n+        setEnvironmentVars(environmentVars);\n+\n+        return environmentVars;\n+    }\n+}"
  },
  {
    "sha": "fa4bcff2bbeabd489b46e832954287bdfc844e31",
    "filename": "athena-federation-integ-test/src/main/java/com/amazonaws/athena/connector/integ/IntegrationTestBase.java",
    "status": "modified",
    "additions": 81,
    "deletions": 19,
    "changes": 100,
    "blob_url": "https://github.com/awslabs/aws-athena-query-federation/blob/95973aa9a0faf2c9ea39679cb63d50058a35268e/athena-federation-integ-test/src/main/java/com/amazonaws/athena/connector/integ/IntegrationTestBase.java",
    "raw_url": "https://github.com/awslabs/aws-athena-query-federation/raw/95973aa9a0faf2c9ea39679cb63d50058a35268e/athena-federation-integ-test/src/main/java/com/amazonaws/athena/connector/integ/IntegrationTestBase.java",
    "contents_url": "https://api.github.com/repos/awslabs/aws-athena-query-federation/contents/athena-federation-integ-test/src/main/java/com/amazonaws/athena/connector/integ/IntegrationTestBase.java?ref=95973aa9a0faf2c9ea39679cb63d50058a35268e",
    "patch": "@@ -19,6 +19,12 @@\n  */\n package com.amazonaws.athena.connector.integ;\n \n+import com.amazonaws.athena.connector.integ.clients.CloudFormationClient;\n+import com.amazonaws.athena.connector.integ.data.ConnectorVpcAttributes;\n+import com.amazonaws.athena.connector.integ.data.SecretsManagerCredentials;\n+import com.amazonaws.athena.connector.integ.data.TestConfig;\n+import com.amazonaws.athena.connector.integ.providers.ConnectorVpcAttributesProvider;\n+import com.amazonaws.athena.connector.integ.providers.SecretsManagerCredentialsProvider;\n import com.amazonaws.services.athena.AmazonAthena;\n import com.amazonaws.services.athena.AmazonAthenaClientBuilder;\n import com.amazonaws.services.athena.model.GetQueryExecutionRequest;\n@@ -39,6 +45,7 @@\n import java.util.HashMap;\n import java.util.List;\n import java.util.Map;\n+import java.util.Optional;\n \n /**\n  * The Integration-Tests base class from which all connector-specific integration test modules should subclass.\n@@ -47,24 +54,31 @@\n {\n     private static final Logger logger = LoggerFactory.getLogger(IntegrationTestBase.class);\n \n+    private static final String TEST_CONFIG_WORK_GROUP = \"athena_work_group\";\n+    private static final String TEST_CONFIG_USER_SETTINGS = \"user_settings\";\n     private static final String ATHENA_QUERY_QUEUED_STATE = \"QUEUED\";\n     private static final String ATHENA_QUERY_RUNNING_STATE = \"RUNNING\";\n     private static final String ATHENA_QUERY_FAILED_STATE = \"FAILED\";\n     private static final String ATHENA_QUERY_CANCELLED_STATE = \"CANCELLED\";\n-    private static final String ATHENA_FEDERATION_WORK_GROUP = \"AmazonAthenaPreviewFunctionality\";\n     private static final long sleepTimeMillis = 5000L;\n \n-    private final CloudFormationTemplateProvider templateProvider;\n-    private final String cloudFormationStackName;\n+    private final ConnectorStackProvider connectorStackProvider;\n     private final String lambdaFunctionName;\n-    private final CloudFormationClient cloudFormationClient;\n     private final AmazonAthena athenaClient;\n+    private final TestConfig testConfig;\n+    private final Optional<ConnectorVpcAttributes> vpcAttributes;\n+    private final Optional<SecretsManagerCredentials> secretCredentials;\n+    private final String athenaWorkgroup;\n+    private CloudFormationClient cloudFormationClient;\n \n     public IntegrationTestBase()\n     {\n-        templateProvider = new CloudFormationTemplateProvider(this.getClass().getSimpleName()) {\n+        testConfig = new TestConfig();\n+        vpcAttributes = ConnectorVpcAttributesProvider.getAttributes(testConfig);\n+        secretCredentials = SecretsManagerCredentialsProvider.getCredentials(testConfig);\n+        connectorStackProvider = new ConnectorStackProvider(this.getClass().getSimpleName(), testConfig) {\n             @Override\n-            protected PolicyDocument getAccessPolicy()\n+            protected Optional<PolicyDocument> getAccessPolicy()\n             {\n                 return getConnectorAccessPolicy();\n             }\n@@ -82,21 +96,66 @@ protected void setSpecificResource(final Stack stack)\n             }\n         };\n \n-        cloudFormationStackName = templateProvider.getStackName();\n-        lambdaFunctionName = templateProvider.getLambdaFunctionName();\n-        cloudFormationClient = new CloudFormationClient(cloudFormationStackName);\n+        lambdaFunctionName = connectorStackProvider.getLambdaFunctionName();\n         athenaClient = AmazonAthenaClientBuilder.defaultClient();\n+        athenaWorkgroup = getAthenaWorkgroup();\n     }\n \n     /**\n-     * Gets the name of the lambda function generated by the Integration-Test module.\n+     * Gets the athena_work_group from the test-config.json JSON file.\n+     * @return A String containing the name of the workgroup.\n+     * @throws RuntimeException The athena_work_group is missing from test-config.json, or its value is empty.\n+     */\n+    private String getAthenaWorkgroup()\n+            throws RuntimeException\n+    {\n+        String athenaWorkgroup = testConfig.getStringItem(TEST_CONFIG_WORK_GROUP).orElseThrow(() ->\n+                new RuntimeException(TEST_CONFIG_WORK_GROUP + \" must be specified in test-config.json.\"));\n+\n+        logger.info(\"Athena Workgroup: {}\", athenaWorkgroup);\n+\n+        return athenaWorkgroup;\n+    }\n+\n+    /**\n+     * Public accessor for the framework generate lambda function name used in generating the lambda function.\n      * @return The name of the lambda function.\n      */\n     public String getLambdaFunctionName()\n     {\n         return lambdaFunctionName;\n     }\n \n+    /**\n+     * Public accessor for the VPC attributes used in generating the lambda function.\n+     * @return Optional VPC attributes object.\n+     */\n+    public Optional<ConnectorVpcAttributes> getVpcAttributes()\n+    {\n+        return vpcAttributes;\n+    }\n+\n+    /**\n+     * Public accessor for the user_settings attribute (stored in the test-config.json file) that are customizable to\n+     * any user-specific purpose.\n+     * @return Optional Map(String, Object) containing all the user attributes as defined in the test configuration file,\n+     * or an empty Optional if the user_settings attribute does not exist in the file.\n+     */\n+    public Optional<Map<String, Object>> getUserSettings()\n+    {\n+        return testConfig.getMap(TEST_CONFIG_USER_SETTINGS);\n+    }\n+\n+    /**\n+     * Public accessor for the SecretsManager credentials obtained using the secrets_manager_secret attribute entered\n+     * in the config file.\n+     * @return Optional SecretsManager credentials object.\n+     */\n+    public Optional<SecretsManagerCredentials> getSecretCredentials()\n+    {\n+        return secretCredentials;\n+    }\n+\n     /**\n      * Must be overridden in the extending class to setup the DB table (i.e. insert rows into table, etc...)\n      */\n@@ -110,10 +169,10 @@ public String getLambdaFunctionName()\n     protected abstract void setUpStackData(final Stack stack);\n \n     /**\n-     * Must be overridden in the extending class to set the lambda function's environment variables key-value pairs\n-     * (e.g. \"spill_bucket\":\"myspillbucket\"). See individual connector for expected environment variables. This method\n-     * can be a no-op in the extending class since some environment variables are set by default (spill_bucket,\n-     * spill_prefix, and disable_spill_encryption).\n+     * Must be overridden in the extending class (can be a no-op) to set the lambda function's environment variables\n+     * key-value pairs (e.g. \"connection_string\":\"redshift://jdbc:redshift://...\"). See individual connector for the\n+     * expected environment variables. This method is intended to supplement the test-config.json file environment_vars\n+     * attribute (see below) for cases where the environment variable cannot be hardcoded.\n      */\n     protected abstract void setConnectorEnvironmentVars(final Map<String, String> environmentVars);\n \n@@ -122,7 +181,7 @@ public String getLambdaFunctionName()\n      * access to multiple connector-specific AWS services (e.g. DynamoDB, Elasticsearch etc...)\n      * @return A policy document object.\n      */\n-    protected abstract PolicyDocument getConnectorAccessPolicy();\n+    protected abstract Optional<PolicyDocument> getConnectorAccessPolicy();\n \n     /**\n      * Creates a CloudFormation stack to build the infrastructure needed to run the integration tests (e.g., Database\n@@ -132,8 +191,9 @@ public String getLambdaFunctionName()\n     @BeforeClass\n     protected void setUp()\n     {\n+        cloudFormationClient = new CloudFormationClient(connectorStackProvider.getStack());\n         try {\n-            cloudFormationClient.createStack(templateProvider.getTemplate());\n+            cloudFormationClient.createStack();\n             setUpTableData();\n         }\n         catch (Exception e) {\n@@ -203,8 +263,10 @@ protected void cleanUp()\n         startQueryExecution(query).getResultSet().getRows()\n                 .forEach(row -> {\n                     String property = row.getData().get(0).getVarCharValue();\n-                    schema.put(property.substring(0, property.indexOf('\\t')),\n-                            property.substring(property.indexOf('\\t') + 1));\n+                    String[] columnProperties = property.split(\"\\t\");\n+                    if (columnProperties.length == 2) {\n+                        schema.put(columnProperties[0], columnProperties[1]);\n+                    }\n                 });\n \n         return schema;\n@@ -220,7 +282,7 @@ public GetQueryResultsResult startQueryExecution(String query)\n             throws RuntimeException\n     {\n         StartQueryExecutionRequest startQueryExecutionRequest = new StartQueryExecutionRequest()\n-                .withWorkGroup(ATHENA_FEDERATION_WORK_GROUP)\n+                .withWorkGroup(athenaWorkgroup)\n                 .withQueryString(query);\n \n         String queryExecutionId = sendAthenaQuery(startQueryExecutionRequest);"
  },
  {
    "sha": "af5a92f9b74bb457c819f3e841cf43949b3b3f9f",
    "filename": "athena-federation-integ-test/src/main/java/com/amazonaws/athena/connector/integ/clients/CloudFormationClient.java",
    "status": "renamed",
    "additions": 31,
    "deletions": 9,
    "changes": 40,
    "blob_url": "https://github.com/awslabs/aws-athena-query-federation/blob/95973aa9a0faf2c9ea39679cb63d50058a35268e/athena-federation-integ-test/src/main/java/com/amazonaws/athena/connector/integ/clients/CloudFormationClient.java",
    "raw_url": "https://github.com/awslabs/aws-athena-query-federation/raw/95973aa9a0faf2c9ea39679cb63d50058a35268e/athena-federation-integ-test/src/main/java/com/amazonaws/athena/connector/integ/clients/CloudFormationClient.java",
    "contents_url": "https://api.github.com/repos/awslabs/aws-athena-query-federation/contents/athena-federation-integ-test/src/main/java/com/amazonaws/athena/connector/integ/clients/CloudFormationClient.java?ref=95973aa9a0faf2c9ea39679cb63d50058a35268e",
    "patch": "@@ -17,7 +17,7 @@\n  * limitations under the License.\n  * #L%\n  */\n-package com.amazonaws.athena.connector.integ;\n+package com.amazonaws.athena.connector.integ.clients;\n \n import com.amazonaws.services.cloudformation.AmazonCloudFormation;\n import com.amazonaws.services.cloudformation.AmazonCloudFormationClientBuilder;\n@@ -28,11 +28,20 @@\n import com.amazonaws.services.cloudformation.model.DescribeStackEventsRequest;\n import com.amazonaws.services.cloudformation.model.DescribeStackEventsResult;\n import com.amazonaws.services.cloudformation.model.StackEvent;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.SerializationFeature;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n+import org.testng.internal.collections.Pair;\n+import software.amazon.awscdk.core.App;\n+import software.amazon.awscdk.core.Stack;\n \n import java.util.List;\n \n+/**\n+ * Responsible for creating the CloudFormation stack needed to test the connector, and unwinding it once testing is\n+ * done.\n+ */\n public class CloudFormationClient\n {\n     private static final Logger logger = LoggerFactory.getLogger(CloudFormationClient.class);\n@@ -42,27 +51,39 @@\n     private static final long sleepTimeMillis = 5000L;\n \n     private final String stackName;\n+    private final String stackTemplate;\n+    private final AmazonCloudFormation cloudFormationClient;\n \n-    public CloudFormationClient(String stackName)\n+    public CloudFormationClient(Pair<App, Stack> stackPair)\n     {\n-        this.stackName = stackName;\n+        this(stackPair.first(), stackPair.second());\n+    }\n+\n+    public CloudFormationClient(App theApp, Stack theStack)\n+    {\n+        stackName = theStack.getStackName();\n+        ObjectMapper objectMapper = new ObjectMapper().configure(SerializationFeature.INDENT_OUTPUT, true);\n+        stackTemplate = objectMapper\n+                .valueToTree(theApp.synth().getStackArtifact(theStack.getArtifactId()).getTemplate())\n+                .toPrettyString();\n+        this.cloudFormationClient = AmazonCloudFormationClientBuilder.defaultClient();\n     }\n \n     /**\n      * Creates a CloudFormation stack to build the infrastructure needed to run the integration tests (e.g., Database\n      * instance, Lambda function, etc...). Once the stack is created successfully, the lambda function is registered\n      * with Athena.\n-     * @param template\n      */\n-    protected void createStack(String template)\n+    public void createStack()\n     {\n         logger.info(\"------------------------------------------------------\");\n         logger.info(\"Create CloudFormation stack: {}\", stackName);\n         logger.info(\"------------------------------------------------------\");\n+        // logger.info(stackTemplate);\n \n         CreateStackRequest createStackRequest = new CreateStackRequest()\n                 .withStackName(stackName)\n-                .withTemplateBody(template)\n+                .withTemplateBody(stackTemplate)\n                 .withDisableRollback(true)\n                 .withCapabilities(Capability.CAPABILITY_NAMED_IAM);\n         processCreateStackRequest(createStackRequest);\n@@ -77,7 +98,6 @@ private void processCreateStackRequest(CreateStackRequest createStackRequest)\n             throws RuntimeException\n     {\n         // Create CloudFormation stack.\n-        AmazonCloudFormation cloudFormationClient = AmazonCloudFormationClientBuilder.defaultClient();\n         CreateStackResult result = cloudFormationClient.createStack(createStackRequest);\n         logger.info(\"Stack ID: {}\", result.getStackId());\n \n@@ -133,19 +153,21 @@ private String getCloudFormationErrorReasons(List<StackEvent> stackEvents)\n     /**\n      * Deletes a CloudFormation stack, and the lambda function registered with Athena.\n      */\n-    protected void deleteStack()\n+    public void deleteStack()\n     {\n         logger.info(\"------------------------------------------------------\");\n         logger.info(\"Delete CloudFormation stack: {}\", stackName);\n         logger.info(\"------------------------------------------------------\");\n \n         try {\n-            AmazonCloudFormation cloudFormationClient = AmazonCloudFormationClientBuilder.defaultClient();\n             DeleteStackRequest request = new DeleteStackRequest().withStackName(stackName);\n             cloudFormationClient.deleteStack(request);\n         }\n         catch (Exception e) {\n             logger.error(\"Something went wrong... Manual resource cleanup may be needed!!!\", e);\n         }\n+        finally {\n+            cloudFormationClient.shutdown();\n+        }\n     }\n }",
    "previous_filename": "athena-federation-integ-test/src/main/java/com/amazonaws/athena/connector/integ/CloudFormationClient.java"
  },
  {
    "sha": "ce18a74a75f98bc533d686def073698927e2c1d7",
    "filename": "athena-federation-integ-test/src/main/java/com/amazonaws/athena/connector/integ/data/ConnectorPackagingAttributes.java",
    "status": "added",
    "additions": 69,
    "deletions": 0,
    "changes": 69,
    "blob_url": "https://github.com/awslabs/aws-athena-query-federation/blob/95973aa9a0faf2c9ea39679cb63d50058a35268e/athena-federation-integ-test/src/main/java/com/amazonaws/athena/connector/integ/data/ConnectorPackagingAttributes.java",
    "raw_url": "https://github.com/awslabs/aws-athena-query-federation/raw/95973aa9a0faf2c9ea39679cb63d50058a35268e/athena-federation-integ-test/src/main/java/com/amazonaws/athena/connector/integ/data/ConnectorPackagingAttributes.java",
    "contents_url": "https://api.github.com/repos/awslabs/aws-athena-query-federation/contents/athena-federation-integ-test/src/main/java/com/amazonaws/athena/connector/integ/data/ConnectorPackagingAttributes.java?ref=95973aa9a0faf2c9ea39679cb63d50058a35268e",
    "patch": "@@ -0,0 +1,69 @@\n+/*-\n+ * #%L\n+ * Amazon Athena Query Federation Integ Test\n+ * %%\n+ * Copyright (C) 2019 - 2020 Amazon Web Services\n+ * %%\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * \n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ * \n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ * #L%\n+ */\n+package com.amazonaws.athena.connector.integ.data;\n+\n+/**\n+ * The Lambda's executable is packaged in an S3 bucket ready to be deployed by the CloudFormation stack (a result of\n+ * running `sam package` - see README). This class contains the attributes needed by CloudFormation to find and deploy\n+ * the Lambda function.\n+ * s3Bucket - The S3 bucket where the packaged Lambda resides.\n+ * s3Key - The folder within the s3Bucket.\n+ * lambdaFunctionHandler - the handler class for the Lambda (e.g. com.amazonaws.athena.connectors.dynamodb.DynamoDBCompositeHandler).\n+ */\n+public class ConnectorPackagingAttributes\n+{\n+    private final String s3Bucket;\n+    private final String s3Key;\n+    private final String lambdaFunctionHandler;\n+\n+    public ConnectorPackagingAttributes(String s3Bucket, String s3Key, String lambdaFunctionHandler)\n+    {\n+        this.s3Bucket = s3Bucket;\n+        this.s3Key = s3Key;\n+        this.lambdaFunctionHandler = lambdaFunctionHandler;\n+    }\n+\n+    /**\n+     * Public accessor for the Connector's S3 bucket.\n+     * @return Connector's S3 bucket\n+     */\n+    public String getS3Bucket()\n+    {\n+        return s3Bucket;\n+    }\n+\n+    /**\n+     * Public accessor for the location of the connector's artifact in the spill bucket (S3).\n+     * @return Artifact's S3 Key\n+     */\n+    public String getS3Key()\n+    {\n+        return s3Key;\n+    }\n+\n+    /**\n+     * Public accessor for the Connector's handler.\n+     * @return Connector's handler\n+     */\n+    public String getLambdaFunctionHandler()\n+    {\n+        return lambdaFunctionHandler;\n+    }\n+}"
  },
  {
    "sha": "c29eb17e05f9f64b57d13df30d9c840766469f5d",
    "filename": "athena-federation-integ-test/src/main/java/com/amazonaws/athena/connector/integ/data/ConnectorStackAttributes.java",
    "status": "added",
    "additions": 125,
    "deletions": 0,
    "changes": 125,
    "blob_url": "https://github.com/awslabs/aws-athena-query-federation/blob/95973aa9a0faf2c9ea39679cb63d50058a35268e/athena-federation-integ-test/src/main/java/com/amazonaws/athena/connector/integ/data/ConnectorStackAttributes.java",
    "raw_url": "https://github.com/awslabs/aws-athena-query-federation/raw/95973aa9a0faf2c9ea39679cb63d50058a35268e/athena-federation-integ-test/src/main/java/com/amazonaws/athena/connector/integ/data/ConnectorStackAttributes.java",
    "contents_url": "https://api.github.com/repos/awslabs/aws-athena-query-federation/contents/athena-federation-integ-test/src/main/java/com/amazonaws/athena/connector/integ/data/ConnectorStackAttributes.java?ref=95973aa9a0faf2c9ea39679cb63d50058a35268e",
    "patch": "@@ -0,0 +1,125 @@\n+/*-\n+ * #%L\n+ * Amazon Athena Query Federation Integ Test\n+ * %%\n+ * Copyright (C) 2019 - 2020 Amazon Web Services\n+ * %%\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * \n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ * \n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ * #L%\n+ */\n+package com.amazonaws.athena.connector.integ.data;\n+\n+import software.amazon.awscdk.core.Construct;\n+import software.amazon.awscdk.services.iam.PolicyDocument;\n+\n+import java.util.Map;\n+import java.util.Optional;\n+\n+/**\n+ * Contains the attributes needed to create the connector's CloudFormation stack template.\n+ */\n+public class ConnectorStackAttributes\n+{\n+    private final Construct scope;\n+    private final String id;\n+    private final String lambdaFunctionName;\n+    private final Optional<PolicyDocument> connectorAccessPolicy;\n+    private final Map<String, String> environmentVariables;\n+    private final ConnectorPackagingAttributes connectorPackagingAttributes;\n+    private final Optional<ConnectorVpcAttributes> connectorVpcAttributes;\n+\n+    public ConnectorStackAttributes(final Construct scope, final String id, final String lambdaFunctionName,\n+                                    final Optional<PolicyDocument> connectorAccessPolicy,\n+                                    final Map<String, String> environmentVariables,\n+                                    final ConnectorPackagingAttributes connectorPackagingAttributes,\n+                                    final Optional<ConnectorVpcAttributes> connectorVpcAttributes)\n+    {\n+        this.scope = scope;\n+        this.id = id;\n+        this.lambdaFunctionName = lambdaFunctionName;\n+        this.connectorAccessPolicy = connectorAccessPolicy;\n+        this.environmentVariables = environmentVariables;\n+        this.connectorPackagingAttributes = connectorPackagingAttributes;\n+        this.connectorVpcAttributes = connectorVpcAttributes;\n+    }\n+\n+    /**\n+     * Public accessor for the Stack's context scope.\n+     * @return Stack's context scope\n+     */\n+    public Construct getScope()\n+    {\n+        return scope;\n+    }\n+\n+    /**\n+     * Public accessor for the Stack's Id/name.\n+     * @return Stack's Id\n+     */\n+    public String getId()\n+    {\n+        return id;\n+    }\n+\n+    /**\n+     * Public accessor for the Lambda function's name.\n+     * @return Lambda function's name\n+     */\n+    public String getLambdaFunctionName()\n+    {\n+        return lambdaFunctionName;\n+    }\n+\n+    /**\n+     * Public accessor for the Connector-specific access policy.\n+     * @return Connector's access policy\n+     */\n+    public Optional<PolicyDocument> getConnectorAccessPolicy()\n+    {\n+        return connectorAccessPolicy;\n+    }\n+\n+    /**\n+     * Public accessor for the Connector's environment variables.\n+     * @return Connector's environment variables.\n+     */\n+    public Map<String, String> getEnvironmentVariables()\n+    {\n+        return environmentVariables;\n+    }\n+\n+    /**\n+     * Public accessor for the Connector's packaging attributes:\n+     * 1) S3 Bucket,\n+     * 2) S3 Key,\n+     * 3) Connector's Handler.\n+     * @return Packaging attributes\n+     */\n+    public ConnectorPackagingAttributes getConnectorPackagingAttributes()\n+    {\n+        return connectorPackagingAttributes;\n+    }\n+\n+    /**\n+     * Public accessor for the Connector's VPC attributes:\n+     * 1) VPC Id (e.g. vpc-xxxx),\n+     * 2) Security Group Id (e.g. sg-xxxx),\n+     * 3) Subnet Ids (e.g. subnet-xxxx),\n+     * 4) Subnet availability zones (e.g. us-east-1a)\n+     * @return VPC attributes\n+     */\n+    public Optional<ConnectorVpcAttributes> getConnectorVpcAttributes()\n+    {\n+        return connectorVpcAttributes;\n+    }\n+}"
  },
  {
    "sha": "ed23a5e1805d104bc57d40e003d96ac526ae58f8",
    "filename": "athena-federation-integ-test/src/main/java/com/amazonaws/athena/connector/integ/data/ConnectorVpcAttributes.java",
    "status": "added",
    "additions": 77,
    "deletions": 0,
    "changes": 77,
    "blob_url": "https://github.com/awslabs/aws-athena-query-federation/blob/95973aa9a0faf2c9ea39679cb63d50058a35268e/athena-federation-integ-test/src/main/java/com/amazonaws/athena/connector/integ/data/ConnectorVpcAttributes.java",
    "raw_url": "https://github.com/awslabs/aws-athena-query-federation/raw/95973aa9a0faf2c9ea39679cb63d50058a35268e/athena-federation-integ-test/src/main/java/com/amazonaws/athena/connector/integ/data/ConnectorVpcAttributes.java",
    "contents_url": "https://api.github.com/repos/awslabs/aws-athena-query-federation/contents/athena-federation-integ-test/src/main/java/com/amazonaws/athena/connector/integ/data/ConnectorVpcAttributes.java?ref=95973aa9a0faf2c9ea39679cb63d50058a35268e",
    "patch": "@@ -0,0 +1,77 @@\n+/*-\n+ * #%L\n+ * Amazon Athena Query Federation Integ Test\n+ * %%\n+ * Copyright (C) 2019 - 2020 Amazon Web Services\n+ * %%\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * \n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ * \n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ * #L%\n+ */\n+package com.amazonaws.athena.connector.integ.data;\n+\n+import java.util.List;\n+\n+/**\n+ * Contains the attributes for the connector's VPC configuration.\n+ */\n+public class ConnectorVpcAttributes\n+{\n+    private final String vpcId;\n+    private final String securityGroupId;\n+    private final List<String> privateSubnetIds;\n+    private final List<String> availabilityZones;\n+\n+    public ConnectorVpcAttributes(String vpcId, String securityGroupId, ConnectorVpcSubnetAttributes subnetAttributes)\n+    {\n+        this.vpcId = vpcId;\n+        this.securityGroupId = securityGroupId;\n+        this.privateSubnetIds = subnetAttributes.getPrivateSubnetIds();\n+        this.availabilityZones = subnetAttributes.getAvailabilityZones();\n+    }\n+\n+    /**\n+     * Public accessor for the VPC's Id.\n+     * @return VPC's Id\n+     */\n+    public String getVpcId()\n+    {\n+        return vpcId;\n+    }\n+\n+    /**\n+     * Public accessor for the VPC Security Group Id (e.g. sg-xxxx).\n+     * @return Security group Id\n+     */\n+    public String getSecurityGroupId()\n+    {\n+        return securityGroupId;\n+    }\n+\n+    /**\n+     * Public accessor for the Subnet Ids (e.g. subnet-xxxxx)\n+     * @return Subnet Ids\n+     */\n+    public List<String> getPrivateSubnetIds()\n+    {\n+        return privateSubnetIds;\n+    }\n+\n+    /**\n+     * Public accessor for the VPC Subnets' availability zones (e.g. us-east-1a).\n+     * @return Subnets' availability zones\n+     */\n+    public List<String> getAvailabilityZones()\n+    {\n+        return availabilityZones;\n+    }\n+}"
  },
  {
    "sha": "91883021ea4e5107e73e81a16506eec9e251819b",
    "filename": "athena-federation-integ-test/src/main/java/com/amazonaws/athena/connector/integ/data/ConnectorVpcSubnetAttributes.java",
    "status": "added",
    "additions": 61,
    "deletions": 0,
    "changes": 61,
    "blob_url": "https://github.com/awslabs/aws-athena-query-federation/blob/95973aa9a0faf2c9ea39679cb63d50058a35268e/athena-federation-integ-test/src/main/java/com/amazonaws/athena/connector/integ/data/ConnectorVpcSubnetAttributes.java",
    "raw_url": "https://github.com/awslabs/aws-athena-query-federation/raw/95973aa9a0faf2c9ea39679cb63d50058a35268e/athena-federation-integ-test/src/main/java/com/amazonaws/athena/connector/integ/data/ConnectorVpcSubnetAttributes.java",
    "contents_url": "https://api.github.com/repos/awslabs/aws-athena-query-federation/contents/athena-federation-integ-test/src/main/java/com/amazonaws/athena/connector/integ/data/ConnectorVpcSubnetAttributes.java?ref=95973aa9a0faf2c9ea39679cb63d50058a35268e",
    "patch": "@@ -0,0 +1,61 @@\n+/*-\n+ * #%L\n+ * Amazon Athena Query Federation Integ Test\n+ * %%\n+ * Copyright (C) 2019 - 2020 Amazon Web Services\n+ * %%\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * \n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ * \n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ * #L%\n+ */\n+package com.amazonaws.athena.connector.integ.data;\n+\n+import java.util.List;\n+\n+/**\n+ * Contains the attributes for the connector's VPC Subnet configuration.\n+ */\n+public class ConnectorVpcSubnetAttributes\n+{\n+    private final List<String> privateSubnetIds;\n+    private final List<String> availabilityZones;\n+\n+    public ConnectorVpcSubnetAttributes(List<String> privateSubnetIds, List<String> availabilityZones)\n+    {\n+        this.privateSubnetIds = privateSubnetIds;\n+        this.availabilityZones = availabilityZones;\n+    }\n+\n+    /**\n+     * Public accessor for the Subnet Ids (e.g. subnet-xxxxx)\n+     * @return Subnet Ids\n+     */\n+    public List<String> getPrivateSubnetIds()\n+    {\n+        return privateSubnetIds;\n+    }\n+\n+    /**\n+     * Public accessor for the VPC Subnets' availability zones (e.g. us-east-1a).\n+     * @return Subnets' availability zones\n+     */\n+    public List<String> getAvailabilityZones()\n+    {\n+        return availabilityZones;\n+    }\n+\n+    @Override\n+    public String toString()\n+    {\n+        return String.format(\"Subnet Ids: %s, AZs: %s\", privateSubnetIds, availabilityZones);\n+    }\n+}"
  },
  {
    "sha": "65343dfb17a29d5a898c08f432605301e359d745",
    "filename": "athena-federation-integ-test/src/main/java/com/amazonaws/athena/connector/integ/data/SecretsManagerCredentials.java",
    "status": "added",
    "additions": 77,
    "deletions": 0,
    "changes": 77,
    "blob_url": "https://github.com/awslabs/aws-athena-query-federation/blob/95973aa9a0faf2c9ea39679cb63d50058a35268e/athena-federation-integ-test/src/main/java/com/amazonaws/athena/connector/integ/data/SecretsManagerCredentials.java",
    "raw_url": "https://github.com/awslabs/aws-athena-query-federation/raw/95973aa9a0faf2c9ea39679cb63d50058a35268e/athena-federation-integ-test/src/main/java/com/amazonaws/athena/connector/integ/data/SecretsManagerCredentials.java",
    "contents_url": "https://api.github.com/repos/awslabs/aws-athena-query-federation/contents/athena-federation-integ-test/src/main/java/com/amazonaws/athena/connector/integ/data/SecretsManagerCredentials.java?ref=95973aa9a0faf2c9ea39679cb63d50058a35268e",
    "patch": "@@ -0,0 +1,77 @@\n+/*-\n+ * #%L\n+ * Amazon Athena Query Federation Integ Test\n+ * %%\n+ * Copyright (C) 2019 - 2021 Amazon Web Services\n+ * %%\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * \n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ * \n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ * #L%\n+ */\n+package com.amazonaws.athena.connector.integ.data;\n+\n+import org.apache.commons.lang3.Validate;\n+\n+/**\n+ * Holds the credentials retrieved from SecretsManager.\n+ */\n+public class SecretsManagerCredentials\n+{\n+    private final String secretName;\n+    private final String username;\n+    private final String password;\n+    private final String arn;\n+\n+    public SecretsManagerCredentials(String secretName, String username, String password, String arn)\n+    {\n+        this.secretName = Validate.notNull(secretName, \"secretName is null.\");\n+        this.username = Validate.notNull(username, \"username is null.\");\n+        this.password = Validate.notNull(password, \"password is null.\");\n+        this.arn = Validate.notNull(arn, \"arn is null.\");\n+    }\n+\n+    /**\n+     * Public accessor to the secret name used to retrieve the credentials from SecretsManager.\n+     * @return Secret name (String).\n+     */\n+    public String getSecretName()\n+    {\n+        return secretName;\n+    }\n+\n+    /**\n+     * Public accessor to the username retrieved from SecretsManager.\n+     * @return Username (String).\n+     */\n+    public String getUsername()\n+    {\n+        return username;\n+    }\n+\n+    /**\n+     * Public accessor to the password retrieved from SecretsManager.\n+     * @return Password (String).\n+     */\n+    public String getPassword()\n+    {\n+        return password;\n+    }\n+\n+    /**\n+     * Public accessor to the arn associated with the secret retrieved from SecretsManager.\n+     * @return Arn (String).\n+     */\n+    public String getArn()\n+    {\n+        return arn;\n+    }\n+}"
  },
  {
    "sha": "9d7a9e40fd11a72ae07f4b0355f841ab32b99dd3",
    "filename": "athena-federation-integ-test/src/main/java/com/amazonaws/athena/connector/integ/data/TestConfig.java",
    "status": "added",
    "additions": 140,
    "deletions": 0,
    "changes": 140,
    "blob_url": "https://github.com/awslabs/aws-athena-query-federation/blob/95973aa9a0faf2c9ea39679cb63d50058a35268e/athena-federation-integ-test/src/main/java/com/amazonaws/athena/connector/integ/data/TestConfig.java",
    "raw_url": "https://github.com/awslabs/aws-athena-query-federation/raw/95973aa9a0faf2c9ea39679cb63d50058a35268e/athena-federation-integ-test/src/main/java/com/amazonaws/athena/connector/integ/data/TestConfig.java",
    "contents_url": "https://api.github.com/repos/awslabs/aws-athena-query-federation/contents/athena-federation-integ-test/src/main/java/com/amazonaws/athena/connector/integ/data/TestConfig.java?ref=95973aa9a0faf2c9ea39679cb63d50058a35268e",
    "patch": "@@ -0,0 +1,140 @@\n+/*-\n+ * #%L\n+ * Amazon Athena Query Federation Integ Test\n+ * %%\n+ * Copyright (C) 2019 - 2021 Amazon Web Services\n+ * %%\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * \n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ * \n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ * #L%\n+ */\n+package com.amazonaws.athena.connector.integ.data;\n+\n+import com.fasterxml.jackson.core.JsonParser;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Optional;\n+\n+/**\n+ * This class is responsible for extracting the attributes from the test config file (test-config.json), and provides\n+ * simple extractors for the attributes within.\n+ */\n+public class TestConfig\n+{\n+    private static final String TEST_CONFIG_FILE_NAME = \"etc/test-config.json\";\n+\n+    private final Map<String, Object> config;\n+\n+    /**\n+     * The constructor loads the test configuration attributes from a file into a config Map.\n+     */\n+    public TestConfig()\n+    {\n+        config = setUpTestConfig();\n+    }\n+\n+    /**\n+     * Loads the test configuration attributes from a file into a Map.\n+     * @return Map(String, Object) containing the test configuration attributes.\n+     * @throws RuntimeException Error encountered while trying to access or parse the config file.\n+     */\n+    private Map<String, Object> setUpTestConfig()\n+            throws RuntimeException\n+    {\n+        try {\n+            ObjectMapper objectMapper = new ObjectMapper();\n+            objectMapper.configure(JsonParser.Feature.ALLOW_COMMENTS, true);\n+            return objectMapper.readValue(new File(TEST_CONFIG_FILE_NAME), HashMap.class);\n+        }\n+        catch (IOException e) {\n+            throw new RuntimeException(\"Unable to parse test-config.json: \" + e.getMessage(), e);\n+        }\n+    }\n+\n+    /**\n+     * Gets a single item from the config file.\n+     * @param attribute The name of the item being extracted from the config file.\n+     * @return Optional Object, or empty Optional if the retrieval of the attribute results in a null value.\n+     */\n+    public Optional<Object> getItem(String attribute)\n+    {\n+        return Optional.ofNullable(config.get(attribute));\n+    }\n+\n+    /**\n+     * Gets a String item from the config file.\n+     * @param attribute The name of the item being extracted from the config file.\n+     * @return An Optional String, or empty Optional if the attribute is either an empty String or not a String.\n+     * @throws RuntimeException The attribute does not exist in the config file.\n+     */\n+    public Optional<String> getStringItem(String attribute)\n+            throws RuntimeException\n+    {\n+        Object item = getItem(attribute).orElseThrow(() ->\n+                new RuntimeException(attribute + \" does not exist test-config.json file.\"));\n+\n+        if (!(item instanceof String) || ((String) item).isEmpty()) {\n+            return Optional.empty();\n+        }\n+\n+        return Optional.of((String) item);\n+    }\n+\n+    /**\n+     * Gets a map item from the config file.\n+     * @param attribute The name of the item being extracted from the config file.\n+     * @return Optional Map(String, Object) that can be further parsed, or an empty Optional if the map is empty or\n+     * not a Map.\n+     * @throws RuntimeException The attribute does not exist in the config file.\n+     */\n+    public Optional<Map<String, Object>> getMap(String attribute)\n+            throws RuntimeException\n+    {\n+        Object item = getItem(attribute).orElseThrow(() ->\n+                new RuntimeException(attribute + \" does not exist test-config.json file.\"));\n+\n+        if (!(item instanceof Map) || ((Map) item).isEmpty()) {\n+            return Optional.empty();\n+        }\n+\n+        return Optional.of((Map) item);\n+    }\n+\n+    /**\n+     * Gets a string map item from the config file.\n+     * @param attribute The name of the item being extracted from the config file.\n+     * @return Optional Map(String, String), or an empty Optional if the map is empty or not a Map.\n+     * @throws RuntimeException The attribute does not exist in the config file.\n+     */\n+    public Optional<Map<String, String>> getStringMap(String attribute)\n+            throws RuntimeException\n+    {\n+        Map<String, String> mapOfStrings = new HashMap<>();\n+\n+        Object item = getItem(attribute).orElseThrow(() ->\n+                new RuntimeException(attribute + \" does not exist test-config.json file.\"));\n+\n+        if (item instanceof Map) {\n+            ((Map) item).forEach((key, value) -> {\n+                if ((key instanceof String) && (value instanceof String)) {\n+                    mapOfStrings.put((String) key, (String) value);\n+                }\n+            });\n+        }\n+\n+        return mapOfStrings.isEmpty() ? Optional.empty() : Optional.of(mapOfStrings);\n+    }\n+}"
  },
  {
    "sha": "cbe2e510e68fc16c3c290063001deaf0e7991fe2",
    "filename": "athena-federation-integ-test/src/main/java/com/amazonaws/athena/connector/integ/providers/ConnectorEnvironmentVarsProvider.java",
    "status": "added",
    "additions": 56,
    "deletions": 0,
    "changes": 56,
    "blob_url": "https://github.com/awslabs/aws-athena-query-federation/blob/95973aa9a0faf2c9ea39679cb63d50058a35268e/athena-federation-integ-test/src/main/java/com/amazonaws/athena/connector/integ/providers/ConnectorEnvironmentVarsProvider.java",
    "raw_url": "https://github.com/awslabs/aws-athena-query-federation/raw/95973aa9a0faf2c9ea39679cb63d50058a35268e/athena-federation-integ-test/src/main/java/com/amazonaws/athena/connector/integ/providers/ConnectorEnvironmentVarsProvider.java",
    "contents_url": "https://api.github.com/repos/awslabs/aws-athena-query-federation/contents/athena-federation-integ-test/src/main/java/com/amazonaws/athena/connector/integ/providers/ConnectorEnvironmentVarsProvider.java?ref=95973aa9a0faf2c9ea39679cb63d50058a35268e",
    "patch": "@@ -0,0 +1,56 @@\n+/*-\n+ * #%L\n+ * Amazon Athena Query Federation Integ Test\n+ * %%\n+ * Copyright (C) 2019 - 2021 Amazon Web Services\n+ * %%\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * \n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ * \n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ * #L%\n+ */\n+package com.amazonaws.athena.connector.integ.providers;\n+\n+import com.amazonaws.athena.connector.integ.data.TestConfig;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.Map;\n+\n+/**\n+ * Responsible for providing the Connector's Environment vars added to the Connector's stack attributes and used\n+ * in the creation of the Lambda.\n+ */\n+public class ConnectorEnvironmentVarsProvider\n+{\n+    private static final Logger logger = LoggerFactory.getLogger(ConnectorEnvironmentVarsProvider.class);\n+\n+    private static final String TEST_CONFIG_ENVIRONMENT_VARS = \"environment_vars\";\n+\n+    private ConnectorEnvironmentVarsProvider() {}\n+\n+    /**\n+     * Gets the environment variables used for configuring the Lambda function (e.g. spill_bucket, etc...)\n+     * @param testConfig A Map containing the test configuration attributes extracted from a config file.\n+     * @return Map containing the Lambda's environment variables and their associated values if the vars\n+     * are included in test-config.json.\n+     */\n+    public static Map<String, String> getVars(TestConfig testConfig)\n+    {\n+        // Get environment vars.\n+        Map<String, String> environmentVars = testConfig.getStringMap(TEST_CONFIG_ENVIRONMENT_VARS).orElseThrow(() ->\n+                new RuntimeException(TEST_CONFIG_ENVIRONMENT_VARS + \" must be specified in test-config.json\"));\n+\n+        logger.info(\"Environment vars: {}\", environmentVars);\n+\n+        return environmentVars;\n+    }\n+}"
  },
  {
    "sha": "eddfb5198cbadd3d2543dbbb9f40fb136c12dbff",
    "filename": "athena-federation-integ-test/src/main/java/com/amazonaws/athena/connector/integ/providers/ConnectorPackagingAttributesProvider.java",
    "status": "added",
    "additions": 80,
    "deletions": 0,
    "changes": 80,
    "blob_url": "https://github.com/awslabs/aws-athena-query-federation/blob/95973aa9a0faf2c9ea39679cb63d50058a35268e/athena-federation-integ-test/src/main/java/com/amazonaws/athena/connector/integ/providers/ConnectorPackagingAttributesProvider.java",
    "raw_url": "https://github.com/awslabs/aws-athena-query-federation/raw/95973aa9a0faf2c9ea39679cb63d50058a35268e/athena-federation-integ-test/src/main/java/com/amazonaws/athena/connector/integ/providers/ConnectorPackagingAttributesProvider.java",
    "contents_url": "https://api.github.com/repos/awslabs/aws-athena-query-federation/contents/athena-federation-integ-test/src/main/java/com/amazonaws/athena/connector/integ/providers/ConnectorPackagingAttributesProvider.java?ref=95973aa9a0faf2c9ea39679cb63d50058a35268e",
    "patch": "@@ -0,0 +1,80 @@\n+/*-\n+ * #%L\n+ * Amazon Athena Query Federation Integ Test\n+ * %%\n+ * Copyright (C) 2019 - 2021 Amazon Web Services\n+ * %%\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * \n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ * \n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ * #L%\n+ */\n+package com.amazonaws.athena.connector.integ.providers;\n+\n+import com.amazonaws.athena.connector.integ.data.ConnectorPackagingAttributes;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.nio.file.Files;\n+import java.nio.file.Paths;\n+\n+/**\n+ * Responsible for providing the Connector's packaging attributes used in creating the Connector's stack attributes.\n+ */\n+public class ConnectorPackagingAttributesProvider\n+{\n+    private static final Logger logger = LoggerFactory.getLogger(ConnectorPackagingAttributesProvider.class);\n+\n+    private static final String CF_TEMPLATE_NAME = \"packaged.yaml\";\n+    private static final String LAMBDA_CODE_URI_TAG = \"CodeUri:\";\n+    private static final String LAMBDA_SPILL_BUCKET_PREFIX = \"s3://\";\n+    private static final String LAMBDA_HANDLER_TAG = \"Handler:\";\n+    private static final String LAMBDA_HANDLER_PREFIX = \"Handler: \";\n+\n+    private ConnectorPackagingAttributesProvider() {}\n+    \n+    /**\n+     * Extracts the packaging attributes needed in the creation of the CF Stack from packaged.yaml (S3 Bucket,\n+     * S3 Key, and lambdaFunctionHandler).\n+     * @return Connector's packaging attributes (S3 Bucket, S3 Key, and Lambda function handler).\n+     * @throws RuntimeException CloudFormation template (packaged.yaml) was not found.\n+     */\n+    public static ConnectorPackagingAttributes getAttributes()\n+            throws RuntimeException\n+    {\n+        String s3Bucket = \"\";\n+        String s3Key = \"\";\n+        String lambdaFunctionHandler = \"\";\n+\n+        try {\n+            for (String line : Files.readAllLines(Paths.get(CF_TEMPLATE_NAME), StandardCharsets.UTF_8)) {\n+                if (line.contains(LAMBDA_CODE_URI_TAG)) {\n+                    s3Bucket = line.substring(line.indexOf(LAMBDA_SPILL_BUCKET_PREFIX) +\n+                            LAMBDA_SPILL_BUCKET_PREFIX.length(), line.lastIndexOf('/'));\n+                    s3Key = line.substring(line.lastIndexOf('/') + 1);\n+                }\n+                else if (line.contains(LAMBDA_HANDLER_TAG)) {\n+                    lambdaFunctionHandler = line.substring(line.indexOf(LAMBDA_HANDLER_PREFIX) +\n+                            LAMBDA_HANDLER_PREFIX.length());\n+                }\n+            }\n+        }\n+        catch (IOException e) {\n+            throw new RuntimeException(\"Lambda connector has not been packaged via `sam package` (see README).\", e);\n+        }\n+\n+        logger.info(\"S3 Bucket: [{}], S3 Key: [{}], Handler: [{}]\", s3Bucket, s3Key, lambdaFunctionHandler);\n+\n+        return new ConnectorPackagingAttributes(s3Bucket, s3Key, lambdaFunctionHandler);\n+    }\n+}"
  },
  {
    "sha": "ac045ff526fdecbfc9a2d1d6e386644971dd1f7e",
    "filename": "athena-federation-integ-test/src/main/java/com/amazonaws/athena/connector/integ/providers/ConnectorVpcAttributesProvider.java",
    "status": "added",
    "additions": 97,
    "deletions": 0,
    "changes": 97,
    "blob_url": "https://github.com/awslabs/aws-athena-query-federation/blob/95973aa9a0faf2c9ea39679cb63d50058a35268e/athena-federation-integ-test/src/main/java/com/amazonaws/athena/connector/integ/providers/ConnectorVpcAttributesProvider.java",
    "raw_url": "https://github.com/awslabs/aws-athena-query-federation/raw/95973aa9a0faf2c9ea39679cb63d50058a35268e/athena-federation-integ-test/src/main/java/com/amazonaws/athena/connector/integ/providers/ConnectorVpcAttributesProvider.java",
    "contents_url": "https://api.github.com/repos/awslabs/aws-athena-query-federation/contents/athena-federation-integ-test/src/main/java/com/amazonaws/athena/connector/integ/providers/ConnectorVpcAttributesProvider.java?ref=95973aa9a0faf2c9ea39679cb63d50058a35268e",
    "patch": "@@ -0,0 +1,97 @@\n+/*-\n+ * #%L\n+ * Amazon Athena Query Federation Integ Test\n+ * %%\n+ * Copyright (C) 2019 - 2021 Amazon Web Services\n+ * %%\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * \n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ * \n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ * #L%\n+ */\n+package com.amazonaws.athena.connector.integ.providers;\n+\n+import com.amazonaws.athena.connector.integ.data.ConnectorVpcAttributes;\n+import com.amazonaws.athena.connector.integ.data.ConnectorVpcSubnetAttributes;\n+import com.amazonaws.athena.connector.integ.data.TestConfig;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+\n+/**\n+ * Responsible for providing the Connector's VPC attributes added to the Connector's stack attributes and used\n+ * in the creation of the Lambda.\n+ */\n+public class ConnectorVpcAttributesProvider\n+{\n+    private static final Logger logger = LoggerFactory.getLogger(ConnectorVpcAttributesProvider.class);\n+\n+    private static final String TEST_CONFIG_VPC_CONFIGURATION = \"vpc_configuration\";\n+    private static final String TEST_CONFIG_VPC_ID = \"vpc_id\";\n+    private static final String TEST_CONFIG_SECURITY_GROUP_ID = \"security_group_id\";\n+    private static final String TEST_CONFIG_SUBNET_IDS = \"subnet_ids\";\n+    private static final String TEST_CONFIG_AVAILABILITY_ZONES = \"availability_zones\";\n+\n+    private ConnectorVpcAttributesProvider() {}\n+\n+    /**\n+     * Gets the VPC attributes used for configuring the Lambda function.\n+     * @param testConfig A Map containing the test configuration attributes extracted from a config file.\n+     * @return Optional VPC attributes (VPC Id, Security group Id, Subnet Ids, and Availability zones) if the VPC\n+     * configurations are included in test-config.json.\n+     * @throws RuntimeException The VPC config attribute is missing from the test config file.\n+     */\n+    public static Optional<ConnectorVpcAttributes> getAttributes(TestConfig testConfig)\n+            throws RuntimeException\n+    {\n+        // Get VPC configuration.\n+        Map vpcConfig = testConfig.getMap(TEST_CONFIG_VPC_CONFIGURATION).orElseThrow(() ->\n+                new RuntimeException(TEST_CONFIG_VPC_CONFIGURATION + \" map must be specified in test-config.json\"));\n+\n+        // Get VPC Id.\n+        Object vpcId = vpcConfig.get(TEST_CONFIG_VPC_ID);\n+        if (!(vpcId instanceof String) || ((String) vpcId).isEmpty()) {\n+            logger.info(\"VPC Id is not set in test-config.json\");\n+            return Optional.empty();\n+        }\n+\n+        // Get Security Group Id.\n+        Object securityGroupId = vpcConfig.get(TEST_CONFIG_SECURITY_GROUP_ID);\n+        if (!(securityGroupId instanceof String) || ((String) securityGroupId).isEmpty()) {\n+            logger.info(\"Security Group Id is not set in test-config.json\");\n+            return Optional.empty();\n+        }\n+\n+        // Get Subnet Ids.\n+        Object subnetIds = vpcConfig.get(TEST_CONFIG_SUBNET_IDS);\n+        if (!(subnetIds instanceof List) || ((List) subnetIds).isEmpty()) {\n+            logger.info(\"Subnet Ids are not set in test-config.json\");\n+            return Optional.empty();\n+        }\n+\n+        // Get Availability Zones.\n+        Object availabilityZones = vpcConfig.get(TEST_CONFIG_AVAILABILITY_ZONES);\n+        if (!(availabilityZones instanceof List) || ((List) availabilityZones).isEmpty()) {\n+            logger.info(\"Availability Zones are not set in test-config.json\");\n+            return Optional.empty();\n+        }\n+\n+        ConnectorVpcSubnetAttributes subnetAttributes = new ConnectorVpcSubnetAttributes(\n+                (List) subnetIds, (List) availabilityZones);\n+\n+        logger.info(\"VPC Id: [{}], SG: [{}], {}\", vpcId, securityGroupId, subnetAttributes);\n+\n+        return Optional.of(new ConnectorVpcAttributes((String) vpcId, (String) securityGroupId, subnetAttributes));\n+    }\n+}"
  },
  {
    "sha": "cabc1afa66d883b3075e8b37a519fe64351228e7",
    "filename": "athena-federation-integ-test/src/main/java/com/amazonaws/athena/connector/integ/providers/SecretsManagerCredentialsProvider.java",
    "status": "added",
    "additions": 79,
    "deletions": 0,
    "changes": 79,
    "blob_url": "https://github.com/awslabs/aws-athena-query-federation/blob/95973aa9a0faf2c9ea39679cb63d50058a35268e/athena-federation-integ-test/src/main/java/com/amazonaws/athena/connector/integ/providers/SecretsManagerCredentialsProvider.java",
    "raw_url": "https://github.com/awslabs/aws-athena-query-federation/raw/95973aa9a0faf2c9ea39679cb63d50058a35268e/athena-federation-integ-test/src/main/java/com/amazonaws/athena/connector/integ/providers/SecretsManagerCredentialsProvider.java",
    "contents_url": "https://api.github.com/repos/awslabs/aws-athena-query-federation/contents/athena-federation-integ-test/src/main/java/com/amazonaws/athena/connector/integ/providers/SecretsManagerCredentialsProvider.java?ref=95973aa9a0faf2c9ea39679cb63d50058a35268e",
    "patch": "@@ -0,0 +1,79 @@\n+/*-\n+ * #%L\n+ * Amazon Athena Query Federation Integ Test\n+ * %%\n+ * Copyright (C) 2019 - 2021 Amazon Web Services\n+ * %%\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * \n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ * \n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ * #L%\n+ */\n+package com.amazonaws.athena.connector.integ.providers;\n+\n+import com.amazonaws.athena.connector.integ.data.SecretsManagerCredentials;\n+import com.amazonaws.athena.connector.integ.data.TestConfig;\n+import com.amazonaws.services.secretsmanager.AWSSecretsManager;\n+import com.amazonaws.services.secretsmanager.AWSSecretsManagerClientBuilder;\n+import com.amazonaws.services.secretsmanager.model.GetSecretValueRequest;\n+import com.amazonaws.services.secretsmanager.model.GetSecretValueResult;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Optional;\n+\n+/**\n+ * Responsible for providing user credentials from SecretsManager.\n+ */\n+public class SecretsManagerCredentialsProvider\n+{\n+    private static final String TEST_CONFIG_SECRETS_MANAGER_SECRET = \"secrets_manager_secret\";\n+\n+    private SecretsManagerCredentialsProvider() {}\n+\n+    /**\n+     * Gets the SecretManager credentials obtained using a secret name stored in the test-config.json file.\n+     * @param testConfig Contains the test configurations from the test-config.json file.\n+     * @return Optional credentials object, or empty Optional if the secrets_manager_secret attribute is not in the\n+     * configuration file or is empty.\n+     * @throws RuntimeException Error encountered attempting to parse the json string returned from SecretsManager.\n+     */\n+    public static Optional<SecretsManagerCredentials> getCredentials(TestConfig testConfig)\n+            throws RuntimeException\n+    {\n+        Optional<String> secretsManagerSecret = testConfig.getStringItem(TEST_CONFIG_SECRETS_MANAGER_SECRET);\n+\n+        if (secretsManagerSecret.isPresent()) {\n+            String secret = secretsManagerSecret.get();\n+            AWSSecretsManager secretsManager = AWSSecretsManagerClientBuilder.defaultClient();\n+            try {\n+                GetSecretValueResult secretValueResult = secretsManager.getSecretValue(new GetSecretValueRequest()\n+                        .withSecretId(secret));\n+                ObjectMapper objectMapper = new ObjectMapper();\n+                Map<String, String> credentials = objectMapper.readValue(secretValueResult.getSecretString(),\n+                        HashMap.class);\n+                return Optional.of(new SecretsManagerCredentials(secret, credentials.get(\"username\"),\n+                        credentials.get(\"password\"),  secretValueResult.getARN()));\n+            }\n+            catch (IOException e) {\n+                throw new RuntimeException(String.format(\"Unable to parse SecretsManager secret (%s): %s\",\n+                        secret, e.getMessage()), e);\n+            }\n+            finally {\n+                secretsManager.shutdown();\n+            }\n+        }\n+\n+        return Optional.empty();\n+    }\n+}"
  },
  {
    "sha": "ca63351b6d1f8b110972f48b7568baadd00b4fd7",
    "filename": "athena-federation-integ-test/src/main/java/com/amazonaws/athena/connector/integ/stacks/ConnectorStack.java",
    "status": "renamed",
    "additions": 128,
    "deletions": 36,
    "changes": 164,
    "blob_url": "https://github.com/awslabs/aws-athena-query-federation/blob/95973aa9a0faf2c9ea39679cb63d50058a35268e/athena-federation-integ-test/src/main/java/com/amazonaws/athena/connector/integ/stacks/ConnectorStack.java",
    "raw_url": "https://github.com/awslabs/aws-athena-query-federation/raw/95973aa9a0faf2c9ea39679cb63d50058a35268e/athena-federation-integ-test/src/main/java/com/amazonaws/athena/connector/integ/stacks/ConnectorStack.java",
    "contents_url": "https://api.github.com/repos/awslabs/aws-athena-query-federation/contents/athena-federation-integ-test/src/main/java/com/amazonaws/athena/connector/integ/stacks/ConnectorStack.java?ref=95973aa9a0faf2c9ea39679cb63d50058a35268e",
    "patch": "@@ -17,10 +17,14 @@\n  * limitations under the License.\n  * #L%\n  */\n-package com.amazonaws.athena.connector.integ;\n+package com.amazonaws.athena.connector.integ.stacks;\n \n+import com.amazonaws.athena.connector.integ.data.ConnectorPackagingAttributes;\n+import com.amazonaws.athena.connector.integ.data.ConnectorStackAttributes;\n import com.google.common.collect.ImmutableList;\n import com.google.common.collect.ImmutableMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n import software.amazon.awscdk.core.CfnParameter;\n import software.amazon.awscdk.core.Construct;\n import software.amazon.awscdk.core.Duration;\n@@ -37,49 +41,71 @@\n import software.amazon.awscdk.services.lambda.Runtime;\n \n import java.util.ArrayList;\n+import java.util.HashMap;\n import java.util.List;\n import java.util.Map;\n+import java.util.Optional;\n \n /**\n  * Sets up the CloudFormation stack necessary for a Lambda Connector.\n  */\n public class ConnectorStack extends Stack\n {\n-    private final String spillBucket;\n+    private static final Logger logger = LoggerFactory.getLogger(ConnectorStack.class);\n+\n+    private static final String LAMBDA_SPILL_BUCKET_TAG = \"spill_bucket\";\n+\n+    private final String s3Bucket;\n     private final String s3Key;\n-    private final String functionName;\n     private final String functionHandler;\n-    private final PolicyDocument connectorAccessPolicy;\n-    private final Map environmentVariables;\n+    private final String functionName;\n+    private final Optional<PolicyDocument> connectorAccessPolicy;\n+    private final Map<String, String> environmentVariables;\n+    private final String spillBucket;\n \n-    public ConnectorStack(final Construct scope, final String id, final String spillBucket, final String s3Key,\n-                          final String functionName, final String functionHandler,\n-                          final PolicyDocument connectorAccessPolicy, final Map environmentVariables)\n+    public ConnectorStack(Builder builder)\n     {\n-        super(scope, id);\n+        super(builder.scope, builder.id);\n \n-        this.spillBucket = spillBucket;\n-        this.s3Key = s3Key;\n-        this.functionName = functionName;\n-        this.functionHandler = functionHandler;\n-        this.connectorAccessPolicy = connectorAccessPolicy;\n-        this.environmentVariables = environmentVariables;\n+        s3Bucket = builder.connectorPackagingAttributes.getS3Bucket();\n+        s3Key = builder.connectorPackagingAttributes.getS3Key();\n+        functionHandler = builder.connectorPackagingAttributes.getLambdaFunctionHandler();\n+        functionName = builder.functionName;\n+        connectorAccessPolicy = builder.connectorAccessPolicy;\n+        environmentVariables = builder.environmentVariables;\n+        spillBucket = environmentVariables.get(LAMBDA_SPILL_BUCKET_TAG);\n+    }\n+\n+    /**\n+     * Initialize the stack by building the Lambda function and Athena data catalog.\n+     */\n+    protected void initialize()\n+    {\n+        logger.info(\"Initializing stack: {}\", this.getClass().getSimpleName());\n+        createLambdaFunction();\n+        createAthenaDataCatalog();\n+    }\n \n-        setupLambdaFunction();\n-        setupAthenaDataCatalog();\n+    /**\n+     * Creates the Connector's CloudFormation stack for the lambda function.\n+     */\n+    private void createLambdaFunction()\n+    {\n+        lambdaFunctionBuilder().build();\n     }\n \n     /**\n-     * Sets up the Connector's CloudFormation stack for the lambda function.\n+     * Builds the Lambda function stack resource.\n+     * @return Lambda function Builder.\n      */\n-    private void setupLambdaFunction()\n+    protected Function.Builder lambdaFunctionBuilder()\n     {\n-        Function.Builder.create(this, \"LambdaConnector\")\n+        return Function.Builder.create(this, \"LambdaConnector\")\n                 .functionName(functionName)\n-                .role(getIamRole())\n+                .role(createIamRole())\n                 .code(Code.fromCfnParameters(CfnParametersCodeProps.builder()\n                         .bucketNameParam(CfnParameter.Builder.create(this, \"BucketName\")\n-                                .defaultValue(spillBucket)\n+                                .defaultValue(s3Bucket)\n                                 .build())\n                         .objectKeyParam(CfnParameter.Builder.create(this, \"BucketKey\")\n                                 .defaultValue(s3Key)\n@@ -89,35 +115,62 @@ private void setupLambdaFunction()\n                 .runtime(new Runtime(\"java8\"))\n                 .memorySize(Integer.valueOf(3008))\n                 .timeout(Duration.seconds(Integer.valueOf(900)))\n-                .environment(environmentVariables)\n-                .build();\n+                .environment(environmentVariables);\n+    }\n+\n+    /**\n+     * Creates the Connector's Athena data catalog stack resource, and registers the lambda function with Athena.\n+     */\n+    private void createAthenaDataCatalog()\n+    {\n+        athenaDataCatalogBuilder().build();\n     }\n \n     /**\n-     * Sets up the Connector's CloudFormation stack to register the lambda function with Athena.\n+     * Builds the Athena data catalog stack resource.\n+     * @return Athena data catalog Builder.\n      */\n-    private void setupAthenaDataCatalog()\n+    protected CfnDataCatalog.Builder athenaDataCatalogBuilder()\n     {\n-        CfnDataCatalog.Builder.create(this, \"AthenaDataCatalog\")\n+        return CfnDataCatalog.Builder.create(this, \"AthenaDataCatalog\")\n                 .name(functionName)\n                 .type(\"LAMBDA\")\n-                .parameters(ImmutableMap.of(\"function\", \"arn:aws:lambda:function:\" + functionName))\n-                .build();\n+                .parameters(ImmutableMap.of(\"function\", \"arn:aws:lambda:function:\" + functionName));\n     }\n \n     /**\n-     * Sets up the IAM role for the Lambda function.\n+     * Creates the IAM role for the Lambda function.\n      * @return IAM Role object.\n      */\n-    private Role getIamRole()\n+    private Role createIamRole()\n     {\n+        return iamRoleBuilder().build();\n+    }\n+\n+    /**\n+     * Builds the IAM role stack resource.\n+     * @return IAM role Builder.\n+     */\n+    protected Role.Builder iamRoleBuilder()\n+    {\n+        Map<String, PolicyDocument> policies = new HashMap<>();\n+\n+        setAccessPolicies(policies);\n+\n         return Role.Builder.create(this, \"ConnectorConfigRole\")\n                 .assumedBy(ServicePrincipal.Builder.create(\"lambda.amazonaws.com\").build())\n-                .inlinePolicies(ImmutableMap.of(\n-                        \"ConnectorAccessPolicy\", connectorAccessPolicy,\n-                        \"GlueAthenaS3AccessPolicy\", getGlueAthenaS3AccessPolicy(),\n-                        \"S3SpillBucketAccessPolicy\", getS3SpillBucketAccessPolicy()))\n-                .build();\n+                .inlinePolicies(policies);\n+    }\n+\n+    /**\n+     * Sets the access policies used by the Lambda function.\n+     * @param policies A map of access policies.\n+     */\n+    protected void setAccessPolicies(Map<String, PolicyDocument> policies)\n+    {\n+        policies.put(\"GlueAthenaS3AccessPolicy\", getGlueAthenaS3AccessPolicy());\n+        policies.put(\"S3SpillBucketAccessPolicy\", getS3SpillBucketAccessPolicy());\n+        connectorAccessPolicy.ifPresent(policyDocument -> policies.put(\"ConnectorAccessPolicy\", policyDocument));\n     }\n \n     /**\n@@ -174,4 +227,43 @@ private PolicyDocument getS3SpillBucketAccessPolicy()\n                         .build()))\n                 .build();\n     }\n+\n+    public static Stack buildWithAttributes(ConnectorStackAttributes attributes)\n+    {\n+        return builder().withAttributes(attributes).build();\n+    }\n+\n+    public static Builder builder()\n+    {\n+        return new Builder();\n+    }\n+\n+    public static class Builder\n+    {\n+        private Construct scope;\n+        private String id;\n+        private String functionName;\n+        private Optional<PolicyDocument> connectorAccessPolicy;\n+        private Map<String, String> environmentVariables;\n+        private ConnectorPackagingAttributes connectorPackagingAttributes;\n+\n+        public Builder withAttributes(ConnectorStackAttributes attributes)\n+        {\n+            scope = attributes.getScope();\n+            id = attributes.getId();\n+            functionName = attributes.getLambdaFunctionName();\n+            connectorAccessPolicy = attributes.getConnectorAccessPolicy();\n+            environmentVariables = attributes.getEnvironmentVariables();\n+            connectorPackagingAttributes = attributes.getConnectorPackagingAttributes();\n+\n+            return this;\n+        }\n+\n+        public Stack build()\n+        {\n+            ConnectorStack stack = new ConnectorStack(this);\n+            stack.initialize();\n+            return stack;\n+        }\n+    }\n }",
    "previous_filename": "athena-federation-integ-test/src/main/java/com/amazonaws/athena/connector/integ/ConnectorStack.java"
  },
  {
    "sha": "6bb87ff337f973afd2a95304e2a1712da69837e6",
    "filename": "athena-federation-integ-test/src/main/java/com/amazonaws/athena/connector/integ/stacks/ConnectorWithVpcStack.java",
    "status": "added",
    "additions": 163,
    "deletions": 0,
    "changes": 163,
    "blob_url": "https://github.com/awslabs/aws-athena-query-federation/blob/95973aa9a0faf2c9ea39679cb63d50058a35268e/athena-federation-integ-test/src/main/java/com/amazonaws/athena/connector/integ/stacks/ConnectorWithVpcStack.java",
    "raw_url": "https://github.com/awslabs/aws-athena-query-federation/raw/95973aa9a0faf2c9ea39679cb63d50058a35268e/athena-federation-integ-test/src/main/java/com/amazonaws/athena/connector/integ/stacks/ConnectorWithVpcStack.java",
    "contents_url": "https://api.github.com/repos/awslabs/aws-athena-query-federation/contents/athena-federation-integ-test/src/main/java/com/amazonaws/athena/connector/integ/stacks/ConnectorWithVpcStack.java?ref=95973aa9a0faf2c9ea39679cb63d50058a35268e",
    "patch": "@@ -0,0 +1,163 @@\n+/*-\n+ * #%L\n+ * Amazon Athena Query Federation Integ Test\n+ * %%\n+ * Copyright (C) 2019 - 2020 Amazon Web Services\n+ * %%\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * \n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ * \n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ * #L%\n+ */\n+package com.amazonaws.athena.connector.integ.stacks;\n+\n+import com.amazonaws.athena.connector.integ.data.ConnectorStackAttributes;\n+import com.amazonaws.athena.connector.integ.data.ConnectorVpcAttributes;\n+import com.google.common.collect.ImmutableList;\n+import software.amazon.awscdk.core.Stack;\n+import software.amazon.awscdk.services.ec2.SecurityGroup;\n+import software.amazon.awscdk.services.ec2.Vpc;\n+import software.amazon.awscdk.services.ec2.VpcAttributes;\n+import software.amazon.awscdk.services.iam.Effect;\n+import software.amazon.awscdk.services.iam.PolicyDocument;\n+import software.amazon.awscdk.services.iam.PolicyStatement;\n+import software.amazon.awscdk.services.lambda.Function;\n+\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+\n+/**\n+ * Sets up the CloudFormation stack necessary for a Lambda Connector with a VPC configuration.\n+ */\n+public class ConnectorWithVpcStack extends ConnectorStack\n+{\n+    private final String vpcId;\n+    private final String securityGroupId;\n+    private final List<String> subnetIds;\n+    private final List<String> availabilityZones;\n+\n+    public ConnectorWithVpcStack(Builder builder)\n+    {\n+        super(builder);\n+\n+        vpcId = builder.vpcId;\n+        securityGroupId = builder.securityGroupId;\n+        subnetIds = builder.subnetIds;\n+        availabilityZones = builder.availabilityZones;\n+    }\n+\n+    /**\n+     * Builds the Lambda function stack resource injecting the VPC configuration.\n+     * @return Lambda function Builder.\n+     */\n+    @Override\n+    protected Function.Builder lambdaFunctionBuilder()\n+    {\n+        return super.lambdaFunctionBuilder()\n+                .vpc(Vpc.fromVpcAttributes(this, \"VpcConfig\", createVpcAttributes()))\n+                .securityGroups(Collections.singletonList(SecurityGroup\n+                        .fromSecurityGroupId(this, \"VpcSecurityGroup\", securityGroupId)));\n+    }\n+\n+    /**\n+     * Creates the VPC Attributes used in the VPC configuration.\n+     * @return VPC attributes object.\n+     */\n+    private VpcAttributes createVpcAttributes()\n+    {\n+        return vpcAttributesBuilder().build();\n+    }\n+\n+    /**\n+     * Builds the VPC Attributes.\n+     * @return VPC attributes Builder.\n+     */\n+    protected VpcAttributes.Builder vpcAttributesBuilder()\n+    {\n+        return VpcAttributes.builder()\n+                .vpcId(vpcId)\n+                .privateSubnetIds(subnetIds)\n+                .availabilityZones(availabilityZones);\n+    }\n+\n+    /**\n+     * Sets the access policies used by the Lambda function.\n+     * @param policies A map of access policies.\n+     */\n+    @Override\n+    protected void setAccessPolicies(Map<String, PolicyDocument> policies)\n+    {\n+        super.setAccessPolicies(policies);\n+        policies.put(\"VpcEc2AccessPolicy\", getVpcEc2AccessPolicy());\n+    }\n+\n+    /**\n+     * Sets up the EC2 access policy used to create the VPC configuration.\n+     * @return A policy document object.\n+     */\n+    private PolicyDocument getVpcEc2AccessPolicy()\n+    {\n+        List<String> statementActionsPolicy = ImmutableList.of(\n+                \"ec2:CreateNetworkInterface\",\n+                \"ec2:DescribeNetworkInterfaces\",\n+                \"ec2:DeleteNetworkInterface\");\n+\n+        return PolicyDocument.Builder.create()\n+                .statements(Collections.singletonList(PolicyStatement.Builder.create()\n+                        .actions(statementActionsPolicy)\n+                        .resources(Collections.singletonList(\"*\"))\n+                        .effect(Effect.ALLOW)\n+                        .build()))\n+                .build();\n+    }\n+\n+    public static Stack buildWithAttributes(ConnectorStackAttributes attributes)\n+    {\n+        return builder().withAttributes(attributes).build();\n+    }\n+\n+    public static Builder builder()\n+    {\n+        return new Builder();\n+    }\n+\n+    public static class Builder extends ConnectorStack.Builder\n+    {\n+        private String vpcId;\n+        private String securityGroupId;\n+        private List<String> subnetIds;\n+        private List<String> availabilityZones;\n+\n+        @Override\n+        public Builder withAttributes(ConnectorStackAttributes attributes)\n+        {\n+            super.withAttributes(attributes);\n+\n+            ConnectorVpcAttributes vpcAttributes = attributes.getConnectorVpcAttributes()\n+                .orElseThrow(() -> new RuntimeException(\"vpc_configuration must be provided in test-config.json\"));\n+            vpcId = vpcAttributes.getVpcId();\n+            securityGroupId = vpcAttributes.getSecurityGroupId();\n+            subnetIds = vpcAttributes.getPrivateSubnetIds();\n+            availabilityZones = vpcAttributes.getAvailabilityZones();\n+\n+            return this;\n+        }\n+\n+        @Override\n+        public Stack build()\n+        {\n+            ConnectorWithVpcStack stack = new ConnectorWithVpcStack(this);\n+            stack.initialize();\n+            return stack;\n+        }\n+    }\n+}"
  },
  {
    "sha": "7f175d8c5f2f23c37cabc1032dd02120d060e0f1",
    "filename": "athena-jdbc/README.md",
    "status": "modified",
    "additions": 19,
    "deletions": 4,
    "changes": 23,
    "blob_url": "https://github.com/awslabs/aws-athena-query-federation/blob/95973aa9a0faf2c9ea39679cb63d50058a35268e/athena-jdbc/README.md",
    "raw_url": "https://github.com/awslabs/aws-athena-query-federation/raw/95973aa9a0faf2c9ea39679cb63d50058a35268e/athena-jdbc/README.md",
    "contents_url": "https://api.github.com/repos/awslabs/aws-athena-query-federation/contents/athena-jdbc/README.md?ref=95973aa9a0faf2c9ea39679cb63d50058a35268e",
    "patch": "@@ -178,13 +178,28 @@ A partition is represented by two partition columns of type varchar. We leverage\n \n **Note:** In case of Redshift partition_schema and partition_name will always be '*'. It does not support external partitions. Performance with huge datasets is slow.\n \n+### Running Integration Tests\n+\n+The integration tests in this module are designed to run without the prior need for deploying the connector. Nevertheless,\n+the integration tests will not run straight out-of-the-box. Certain build-dependencies are required for them to execute correctly.\n+For build commands and step-by-step instructions on building and running the integration tests see the\n+[Running Integration Tests](https://github.com/awslabs/aws-athena-query-federation/blob/master/athena-federation-integ-test/README.md#running-integration-tests) README section in the **athena-federation-integ-test** module.\n+\n+In addition to the build-dependencies, certain test configuration attributes must also be provided in the connector's [test-config.json](./etc/test-config.json) JSON file.\n+For additional information about the test configuration file, see the [Test Configuration](https://github.com/awslabs/aws-athena-query-federation/blob/master/athena-federation-integ-test/README.md#test-configuration) README section in the **athena-federation-integ-test** module.\n+\n+Once all prerequisites have been satisfied, the integration tests can be executed by specifying the following command: `mvn failsafe:integration-test` from the connector's root directory.\n+\n ### Deploying The Connector\n \n-To use the Amazon Athena HBase Connector in your queries, navigate to AWS Serverless Application Repository and deploy a pre-built version of this connector. Alternatively, you can build and deploy this connector from source follow the below steps or use the more detailed tutorial in the athena-example module:\n+To use this connector in your queries, navigate to AWS Serverless Application Repository and deploy a pre-built version of this connector. Alternatively, you can build and deploy this connector from\n+source follow the below steps or use the more detailed tutorial in the athena-example module:\n \n-1. From the athena-federation-sdk dir, run `mvn clean install` if you haven't already.\n-2. From the athena-jdbc dir, run `mvn clean install`.\n-3. From the athena-jdbc dir, run  `../tools/publish.sh S3_BUCKET_NAME athena-jdbc` to publish the connector to your private AWS Serverless Application Repository. The S3_BUCKET in the command is where a copy of the connector's code will be stored for Serverless Application Repository to retrieve it. This will allow users with permission to do so, the ability to deploy instances of the connector via 1-Click form. Then navigate to [Serverless Application Repository](https://aws.amazon.com/serverless/serverlessrepo)\n+1. From the **athena-federation-sdk** dir, run `mvn clean install` if you haven't already.\n+2. From the **athena-federation-integ-test** dir, run `mvn clean install` if you haven't already\n+   (**Note: failure to follow this step will result in compilation errors**).\n+3. From the **athena-jdbc** dir, run `mvn clean install`.\n+4. From the **athena-jdbc** dir, run  `../tools/publish.sh S3_BUCKET_NAME athena-jdbc` to publish the connector to your private AWS Serverless Application Repository. The S3_BUCKET in the command is where a copy of the connector's code will be stored for Serverless Application Repository to retrieve it. This will allow users with permission to do so, the ability to deploy instances of the connector via 1-Click form. Then navigate to [Serverless Application Repository](https://aws.amazon.com/serverless/serverlessrepo)\n \n # JDBC Driver Versions\n "
  },
  {
    "sha": "bf6cc1e5b75cba36acb09490a96da6dc749054ae",
    "filename": "athena-jdbc/etc/test-config.json",
    "status": "added",
    "additions": 29,
    "deletions": 0,
    "changes": 29,
    "blob_url": "https://github.com/awslabs/aws-athena-query-federation/blob/95973aa9a0faf2c9ea39679cb63d50058a35268e/athena-jdbc/etc/test-config.json",
    "raw_url": "https://github.com/awslabs/aws-athena-query-federation/raw/95973aa9a0faf2c9ea39679cb63d50058a35268e/athena-jdbc/etc/test-config.json",
    "contents_url": "https://api.github.com/repos/awslabs/aws-athena-query-federation/contents/athena-jdbc/etc/test-config.json?ref=95973aa9a0faf2c9ea39679cb63d50058a35268e",
    "patch": "@@ -0,0 +1,29 @@\n+{\n+  \"athena_work_group\" : \"FederationIntegrationTests\", /* The Athena Workgroup used for running integration tests (default: FederationIntegrationTests) */\n+  \"secrets_manager_secret\" : \"<secret name>\",         /* Secret name used to retrieve user credentials from SecretsManager. */\n+  \"environment_vars\" : {                  /* Parameters used by the connector's internal logic */\n+    \"spill_bucket\" : \"<spill bucket>\",    /* The S3 bucket used for spilling excess data */\n+    \"spill_prefix\" : \"athena-spill\",      /* The prefix within the S3 spill bucket (default: athena-spill) */\n+    \"disable_spill_encryption\" : \"false\"  /* If set to true encryption for spilled data is disabled (default: false) */\n+  },\n+  \"vpc_configuration\" : {                 /* VPC configuration for DB instances within a VPC */\n+    \"vpc_id\": \"<VPC Id>\",                 /* The VPC Id (e.g. vpc-xxx) */\n+    \"security_group_id\": \"<SG Id>\",       /* The Security Group Id (e.g. sg-xxx) */\n+    \"subnet_ids\": [\"<Subnet 1>\", \"<Subnet 2>\"],     /* A list consisting of at least one Subnet Id (e.g. subnet-xxxx) */\n+    \"availability_zones\": [\"<Zone 1>\", \"<Zone 2>\"]  /* A list consisting of at least one AZ (e.g. us-east-1a) */\n+  },\n+  \"user_settings\" : {                     /* User customizable settings */\n+    \"redshift_db_name\": \"<DB Name>\",      /* Name of the Db used by the Redshift integration tests */\n+    \"redshift_db_port\": \"<DB Port>\",      /* Port number associated with the Redshift cluster endpoint */\n+    \"redshift_table_movies\": \"<Table Name>\",    /* Redshift table name */\n+    \"redshift_table_bday\": \"<Table Name>\",      /* Redshift table name */\n+    \"postgres_db_name\": \"<DB Name>\",      /* Name of the Db used by the PostGreSql integration tests */\n+    \"postgres_db_port\": <Port (Integer)>, /* Port number associated with the PostGreSql instance endpoint */\n+    \"postgres_table_movies\": \"<Table Name>\",    /* PostGreSql table name */\n+    \"postgres_table_bday\": \"<Table Name>\",      /* PostGreSql table name */\n+    \"mysql_db_name\": \"<DB Name>\",         /* Name of the Db used by the MySql integration tests */\n+    \"mysql_db_port\": <Port (Integer)>,    /* Port number associated with the MySql instance endpoint */\n+    \"mysql_table_movies\": \"<Table Name>\",       /* MySql table name */\n+    \"mysql_table_bday\": \"<Table Name>\"          /* MySql table name */\n+  }\n+}\n\\ No newline at end of file"
  },
  {
    "sha": "f76f0cfbbc22d59dcb79ee787a452b30f76df5f4",
    "filename": "athena-jdbc/pom.xml",
    "status": "modified",
    "additions": 34,
    "deletions": 0,
    "changes": 34,
    "blob_url": "https://github.com/awslabs/aws-athena-query-federation/blob/95973aa9a0faf2c9ea39679cb63d50058a35268e/athena-jdbc/pom.xml",
    "raw_url": "https://github.com/awslabs/aws-athena-query-federation/raw/95973aa9a0faf2c9ea39679cb63d50058a35268e/athena-jdbc/pom.xml",
    "contents_url": "https://api.github.com/repos/awslabs/aws-athena-query-federation/contents/athena-jdbc/pom.xml?ref=95973aa9a0faf2c9ea39679cb63d50058a35268e",
    "patch": "@@ -27,6 +27,12 @@\n                 </exclusion>\n             </exclusions>\n         </dependency>\n+        <dependency>\n+            <groupId>com.amazonaws</groupId>\n+            <artifactId>athena-federation-integ-test</artifactId>\n+            <version>2021.6.1</version>\n+            <scope>test</scope>\n+        </dependency>\n         <dependency>\n             <groupId>org.apache.commons</groupId>\n             <artifactId>commons-text</artifactId>\n@@ -91,6 +97,34 @@\n             <version>${log4j2Version}</version>\n             <scope>runtime</scope>\n         </dependency>\n+        <!-- https://mvnrepository.com/artifact/com.amazonaws/aws-java-sdk-redshift -->\n+        <dependency>\n+            <groupId>com.amazonaws</groupId>\n+            <artifactId>aws-java-sdk-redshift</artifactId>\n+            <version>${aws-sdk.version}</version>\n+            <scope>test</scope>\n+        </dependency>\n+        <!-- https://mvnrepository.com/artifact/software.amazon.awscdk/redshift -->\n+        <dependency>\n+            <groupId>software.amazon.awscdk</groupId>\n+            <artifactId>redshift</artifactId>\n+            <version>${aws-cdk.version}</version>\n+            <scope>test</scope>\n+        </dependency>\n+        <!-- https://mvnrepository.com/artifact/com.amazonaws/aws-java-sdk-rds -->\n+        <dependency>\n+            <groupId>com.amazonaws</groupId>\n+            <artifactId>aws-java-sdk-rds</artifactId>\n+            <version>${aws-sdk.version}</version>\n+            <scope>test</scope>\n+        </dependency>\n+        <!-- https://mvnrepository.com/artifact/software.amazon.awscdk/rds -->\n+        <dependency>\n+            <groupId>software.amazon.awscdk</groupId>\n+            <artifactId>rds</artifactId>\n+            <version>${aws-cdk.version}</version>\n+            <scope>test</scope>\n+        </dependency>\n     </dependencies>\n \n     <build>"
  },
  {
    "sha": "baf014c5f0797f3455ae404cbcbcc667814e0828",
    "filename": "athena-jdbc/src/test/java/com/amazonaws/connectors/athena/jdbc/integ/JdbcTableUtils.java",
    "status": "added",
    "additions": 160,
    "deletions": 0,
    "changes": 160,
    "blob_url": "https://github.com/awslabs/aws-athena-query-federation/blob/95973aa9a0faf2c9ea39679cb63d50058a35268e/athena-jdbc/src/test/java/com/amazonaws/connectors/athena/jdbc/integ/JdbcTableUtils.java",
    "raw_url": "https://github.com/awslabs/aws-athena-query-federation/raw/95973aa9a0faf2c9ea39679cb63d50058a35268e/athena-jdbc/src/test/java/com/amazonaws/connectors/athena/jdbc/integ/JdbcTableUtils.java",
    "contents_url": "https://api.github.com/repos/awslabs/aws-athena-query-federation/contents/athena-jdbc/src/test/java/com/amazonaws/connectors/athena/jdbc/integ/JdbcTableUtils.java?ref=95973aa9a0faf2c9ea39679cb63d50058a35268e",
    "patch": "@@ -0,0 +1,160 @@\n+/*-\n+ * #%L\n+ * athena-jdbc\n+ * %%\n+ * Copyright (C) 2019 - 2021 Amazon Web Services\n+ * %%\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * \n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ * \n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ * #L%\n+ */\n+package com.amazonaws.connectors.athena.jdbc.integ;\n+\n+import com.amazonaws.athena.connector.lambda.domain.TableName;\n+import com.amazonaws.connectors.athena.jdbc.connection.DatabaseConnectionConfig;\n+import com.amazonaws.connectors.athena.jdbc.connection.DatabaseConnectionConfigBuilder;\n+import com.amazonaws.connectors.athena.jdbc.connection.GenericJdbcConnectionFactory;\n+import com.amazonaws.connectors.athena.jdbc.connection.JdbcConnectionFactory;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.sql.Connection;\n+import java.sql.PreparedStatement;\n+import java.sql.SQLException;\n+import java.util.Map;\n+\n+/**\n+ * Facilitates the creation and management of a DB table using JDBC.\n+ */\n+public class JdbcTableUtils\n+{\n+    private static final Logger logger = LoggerFactory.getLogger(JdbcTableUtils.class);\n+\n+    private final String catalog;\n+    private final String schemaName;\n+    private final String tableName;\n+    private final Map environmentVars;\n+    private final Map properties;\n+\n+    public JdbcTableUtils(String catalog, TableName table, Map environmentVars)\n+    {\n+        this(catalog, table, environmentVars, null);\n+    }\n+\n+    public JdbcTableUtils(String catalog, TableName table, Map environmentVars, Map properties)\n+    {\n+        this.catalog = catalog;\n+        this.schemaName = table.getSchemaName();\n+        this.tableName = table.getTableName();\n+        this.environmentVars = environmentVars;\n+        this.properties = properties;\n+    }\n+\n+    /**\n+     * Creates a DB schema.\n+     * @throws RuntimeException The SQL statement failed.\n+     */\n+    public void createDbSchema()\n+            throws RuntimeException\n+    {\n+        try (Connection connection = getDbConnection()) {\n+            // Prepare create schema statement\n+            String createStatement = String.format(\"create schema %s;\", schemaName);\n+            PreparedStatement createSchema = connection.prepareStatement(createStatement);\n+            logger.info(\"Statement prepared: {}\", createStatement);\n+            // Execute statement\n+            createSchema.execute();\n+            logger.info(\"Created the DB schema: {}\", schemaName);\n+        }\n+        catch(SQLException e) {\n+            throw new RuntimeException(String.format(\"Unable to create DB schema (%s): %s\",\n+                    schemaName, e.getMessage()), e);\n+        }\n+    }\n+\n+    /**\n+     * Creates a DB table.\n+     * @param tableSchema String representing the table's schema (e.g. \"year int, first_name varchar\").\n+     * @throws RuntimeException The SQL statement failed.\n+     */\n+    public void createTable(String tableSchema)\n+            throws RuntimeException\n+    {\n+        try (Connection connection = getDbConnection()) {\n+            // Prepare create table statement\n+            String createStatement = String.format(\"create table %s.%s (%s);\", schemaName, tableName, tableSchema);\n+            PreparedStatement createTable = connection.prepareStatement(createStatement);\n+            logger.info(\"Statement prepared: {}\", createStatement);\n+            // Execute statement\n+            createTable.execute();\n+            logger.info(\"Created the '{}' table.\", tableName);\n+        }\n+        catch(SQLException e) {\n+            throw new RuntimeException(String.format(\"Unable to create table '%s' in DB '%s': %s\",\n+                    tableName, schemaName, e.getMessage()), e);\n+        }\n+    }\n+\n+    /**\n+     * Inserts a row into a DB table.\n+     * @param tableValues String representing the row's values (e.g. \"1992, 'James'\").\n+     * @throws RuntimeException The SQL statement failed.\n+     */\n+    public void insertRow(String tableValues)\n+            throws RuntimeException\n+    {\n+        try (Connection connection = getDbConnection()) {\n+\n+            // Prepare insert values statements\n+            String insertStatement = String.format(\"insert into %s.%s values(%s);\", schemaName, tableName, tableValues);\n+            PreparedStatement insertValues = connection.prepareStatement(insertStatement);\n+            logger.info(\"Statement prepared: {}\", insertStatement);\n+            // Execute statement\n+            insertValues.execute();\n+            logger.info(\"Inserted row into the '{}' table.\", tableName);\n+        }\n+        catch(SQLException e) {\n+            throw new RuntimeException(String.format(\"Unable to insert row into table '%s': %s\",\n+                    tableName, e.getMessage()), e);\n+        }\n+    }\n+\n+    /**\n+     * Gets a JDBC DB connection.\n+     * @return Connection object.\n+     */\n+    protected Connection getDbConnection()\n+    {\n+        DatabaseConnectionConfig connectionConfig = getDbConfig();\n+        JdbcConnectionFactory connectionFactory = new GenericJdbcConnectionFactory(connectionConfig, properties);\n+        return connectionFactory.getConnection(null);\n+    }\n+\n+    /**\n+     * Gets the DB connection configuration used to create a DB connection.\n+     * @return Connection Config object.\n+     * @throws RuntimeException If a configuration with the catalog (lambda function name) cannot be found in the\n+     * environmentVars map.\n+     */\n+    protected DatabaseConnectionConfig getDbConfig()\n+            throws RuntimeException\n+    {\n+        DatabaseConnectionConfigBuilder configBuilder = new DatabaseConnectionConfigBuilder();\n+        for (DatabaseConnectionConfig config : configBuilder.properties(environmentVars).build()) {\n+            if (config.getCatalog().equals(catalog)) {\n+                return config;\n+            }\n+        }\n+\n+        throw new RuntimeException(\"Unable to configure connection to DB.\");\n+    }\n+}"
  },
  {
    "sha": "375890639f324cdde226a59a165a6f49b08bf635",
    "filename": "athena-jdbc/src/test/java/com/amazonaws/connectors/athena/jdbc/integ/MySqlIntegTest.java",
    "status": "added",
    "additions": 398,
    "deletions": 0,
    "changes": 398,
    "blob_url": "https://github.com/awslabs/aws-athena-query-federation/blob/95973aa9a0faf2c9ea39679cb63d50058a35268e/athena-jdbc/src/test/java/com/amazonaws/connectors/athena/jdbc/integ/MySqlIntegTest.java",
    "raw_url": "https://github.com/awslabs/aws-athena-query-federation/raw/95973aa9a0faf2c9ea39679cb63d50058a35268e/athena-jdbc/src/test/java/com/amazonaws/connectors/athena/jdbc/integ/MySqlIntegTest.java",
    "contents_url": "https://api.github.com/repos/awslabs/aws-athena-query-federation/contents/athena-jdbc/src/test/java/com/amazonaws/connectors/athena/jdbc/integ/MySqlIntegTest.java?ref=95973aa9a0faf2c9ea39679cb63d50058a35268e",
    "patch": "@@ -0,0 +1,398 @@\n+/*-\n+ * #%L\n+ * athena-jdbc\n+ * %%\n+ * Copyright (C) 2019 - 2021 Amazon Web Services\n+ * %%\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * \n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ * \n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ * #L%\n+ */\n+package com.amazonaws.connectors.athena.jdbc.integ;\n+\n+import com.amazonaws.athena.connector.integ.IntegrationTestBase;\n+import com.amazonaws.athena.connector.integ.clients.CloudFormationClient;\n+import com.amazonaws.athena.connector.integ.data.ConnectorVpcAttributes;\n+import com.amazonaws.athena.connector.integ.data.SecretsManagerCredentials;\n+import com.amazonaws.athena.connector.lambda.domain.TableName;\n+import com.amazonaws.services.athena.model.Row;\n+import com.amazonaws.services.rds.AmazonRDS;\n+import com.amazonaws.services.rds.AmazonRDSClientBuilder;\n+import com.amazonaws.services.rds.model.DescribeDBInstancesRequest;\n+import com.amazonaws.services.rds.model.DescribeDBInstancesResult;\n+import com.amazonaws.services.rds.model.Endpoint;\n+import com.google.common.collect.ImmutableMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.testng.annotations.AfterClass;\n+import org.testng.annotations.BeforeClass;\n+import org.testng.annotations.Test;\n+import software.amazon.awscdk.core.App;\n+import software.amazon.awscdk.core.RemovalPolicy;\n+import software.amazon.awscdk.core.Stack;\n+import software.amazon.awscdk.services.ec2.InstanceType;\n+import software.amazon.awscdk.services.ec2.SecurityGroup;\n+import software.amazon.awscdk.services.ec2.Vpc;\n+import software.amazon.awscdk.services.ec2.VpcAttributes;\n+import software.amazon.awscdk.services.iam.PolicyDocument;\n+import software.amazon.awscdk.services.rds.Credentials;\n+import software.amazon.awscdk.services.rds.DatabaseInstance;\n+import software.amazon.awscdk.services.rds.DatabaseInstanceEngine;\n+import software.amazon.awscdk.services.rds.MySqlInstanceEngineProps;\n+import software.amazon.awscdk.services.rds.MysqlEngineVersion;\n+import software.amazon.awscdk.services.rds.StorageType;\n+import software.amazon.awscdk.services.secretsmanager.Secret;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.UUID;\n+\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+\n+/**\n+ * Integration-tests for the MySql (JDBC) connector using the Integration-test module.\n+ */\n+public class MySqlIntegTest extends IntegrationTestBase\n+{\n+    private static final Logger logger = LoggerFactory.getLogger(MySqlIntegTest.class);\n+\n+    private final App theApp;\n+    private final String secretArn;\n+    private final String username;\n+    private final String password;\n+    private final String mysqlDbName;\n+    private final Number mysqlDbPort;\n+    private final String mysqlTableMovies;\n+    private final String mysqlTableBday;\n+    private final String lambdaFunctionName;\n+    private final String dbInstanceName;\n+    private final Map<String, String> environmentVars;\n+    private final Map<String, String> jdbcProperties;\n+\n+    private CloudFormationClient cloudFormationClient;\n+\n+    public MySqlIntegTest()\n+    {\n+        theApp = new App();\n+        SecretsManagerCredentials secretsManagerCredentials = getSecretCredentials().orElseThrow(() ->\n+                new RuntimeException(\"secrets_manager_secret must be provided in test-config.json file.\"));\n+        secretArn = secretsManagerCredentials.getArn();\n+        username = secretsManagerCredentials.getUsername();\n+        password = secretsManagerCredentials.getPassword();\n+        Map<String, Object> userSettings = getUserSettings().orElseThrow(() ->\n+                new RuntimeException(\"user_settings attribute must be provided in test-config.json file.\"));\n+        mysqlDbName = (String) userSettings.get(\"mysql_db_name\");\n+        mysqlDbPort = (Number) userSettings.get(\"mysql_db_port\");\n+        mysqlTableMovies = (String) userSettings.get(\"mysql_table_movies\");\n+        mysqlTableBday = (String) userSettings.get(\"mysql_table_bday\");\n+        lambdaFunctionName = getLambdaFunctionName();\n+        dbInstanceName = \"integ-mysql-instance-\" + UUID.randomUUID();\n+        environmentVars = new HashMap<>();\n+        jdbcProperties = ImmutableMap.of(\"databaseTerm\", \"SCHEMA\");\n+    }\n+\n+    /**\n+     * Creates a MySql RDS Instance used for the integration tests.\n+     */\n+    @BeforeClass\n+    @Override\n+    protected void setUp()\n+    {\n+        cloudFormationClient = new CloudFormationClient(theApp, getMySqlStack());\n+        try {\n+            // Create the CloudFormation stack for the MySql DB instance.\n+            cloudFormationClient.createStack();\n+            // Get DB instance's host and port information and set the environment variables needed for the Lambda.\n+            setEnvironmentVars(getInstanceData());\n+            // Create the DB schema in the newly created DB instance used for the integration tests.\n+            createDbSchema();\n+            // Invoke the framework's setUp().\n+            super.setUp();\n+        }\n+        catch (Exception e) {\n+            // Delete the partially formed CloudFormation stack.\n+            cloudFormationClient.deleteStack();\n+            throw e;\n+        }\n+    }\n+\n+    /**\n+     * Deletes a CloudFormation stack for the MySql RDS Instance.\n+     */\n+    @AfterClass\n+    @Override\n+    protected void cleanUp()\n+    {\n+        // Invoke the framework's cleanUp().\n+        super.cleanUp();\n+        // Delete the CloudFormation stack for the MySql DB instance.\n+        cloudFormationClient.deleteStack();\n+    }\n+\n+    /**\n+     * Gets the CloudFormation stack for the MySql RDS Instance.\n+     * @return Stack object for the MySql RDS Instance.\n+     */\n+    private Stack getMySqlStack()\n+    {\n+        Stack stack = Stack.Builder.create(theApp, dbInstanceName).build();\n+\n+        ConnectorVpcAttributes vpcAttributes = getVpcAttributes()\n+                .orElseThrow(() -> new RuntimeException(\"vpc_configuration must be specified in test-config.json\"));\n+\n+        DatabaseInstance.Builder.create(stack, \"MySqlInstance\")\n+                .publiclyAccessible(Boolean.TRUE)\n+                .removalPolicy(RemovalPolicy.DESTROY)\n+                .deleteAutomatedBackups(Boolean.TRUE)\n+                .storageEncrypted(Boolean.FALSE)\n+                .port(mysqlDbPort)\n+                .instanceIdentifier(dbInstanceName)\n+                .engine(DatabaseInstanceEngine.mysql(MySqlInstanceEngineProps.builder()\n+                        .version(MysqlEngineVersion.VER_8_0_20)\n+                        .build()))\n+                .storageType(StorageType.GP2)\n+                .allocatedStorage(20)\n+                .instanceType(new InstanceType(\"t2.micro\"))\n+                .credentials(Credentials.fromSecret(Secret\n+                        .fromSecretCompleteArn(stack, \"MySqlSecret\", secretArn)))\n+                .vpc(Vpc.fromVpcAttributes(stack, \"MySqlVpcConfig\", VpcAttributes.builder()\n+                        .vpcId(vpcAttributes.getVpcId())\n+                        .privateSubnetIds(vpcAttributes.getPrivateSubnetIds())\n+                        .availabilityZones(vpcAttributes.getAvailabilityZones())\n+                        .build()))\n+                .securityGroups(Collections.singletonList(SecurityGroup\n+                        .fromSecurityGroupId(stack, \"MySqlVpcSecurityGroup\",\n+                                vpcAttributes.getSecurityGroupId())))\n+                .build();\n+\n+        return stack;\n+    }\n+\n+    /**\n+     * Gets the MySql RDS Instance endpoint information. All exceptions thrown here will be caught in the\n+     * calling function.\n+     * @return Endpoint object containing the DB instance's domain and port information.\n+     */\n+    private Endpoint getInstanceData()\n+    {\n+        AmazonRDS rdsClient = AmazonRDSClientBuilder.defaultClient();\n+        try {\n+            DescribeDBInstancesResult instancesResult = rdsClient.describeDBInstances(new DescribeDBInstancesRequest()\n+                    .withDBInstanceIdentifier(dbInstanceName));\n+            return instancesResult.getDBInstances().get(0).getEndpoint();\n+        }\n+        finally {\n+            rdsClient.shutdown();\n+        }\n+    }\n+\n+    /**\n+     * Sets the environment variables needed for the Lambda.\n+     * @param endpoint Contains the DB hostname and port information.\n+     */\n+    private void setEnvironmentVars(Endpoint endpoint)\n+    {\n+        String connectionString = String.format(\"mysql://jdbc:mysql://%s:%s/mysql?user=%s&password=%s\",\n+                endpoint.getAddress(), endpoint.getPort(), username, password);\n+        String connectionStringTag = lambdaFunctionName + \"_connection_string\";\n+        environmentVars.put(\"default\", connectionString);\n+        environmentVars.put(connectionStringTag, connectionString);\n+    }\n+\n+    /**\n+     * Creates the DB schema used for the integration tests.\n+     */\n+    private void createDbSchema()\n+    {\n+        logger.info(\"----------------------------------------------------\");\n+        logger.info(\"Setting up DB Schema: {}\", mysqlDbName);\n+        logger.info(\"----------------------------------------------------\");\n+\n+        JdbcTableUtils jdbcUtils =\n+                new JdbcTableUtils(lambdaFunctionName, new TableName(mysqlDbName, mysqlTableMovies),\n+                        environmentVars, jdbcProperties);\n+        jdbcUtils.createDbSchema();\n+    }\n+\n+    /**\n+     * Sets up the access policy for the Lambda connector to multiple connector-specific AWS services (e.g. DynamoDB,\n+     * Elasticsearch etc...)\n+     * @return A policy document object.\n+     */\n+    @Override\n+    protected Optional<PolicyDocument> getConnectorAccessPolicy()\n+    {\n+        // No connector-specific policy document needed\n+        return Optional.empty();\n+    }\n+\n+    /**\n+     * Sets the environment variables for the Lambda function.\n+     */\n+    @Override\n+    protected void setConnectorEnvironmentVars(final Map environmentVars)\n+    {\n+        environmentVars.putAll(this.environmentVars);\n+    }\n+\n+    /**\n+     * Sets up connector-specific Cloud Formation resource.\n+     * @param stack The current CloudFormation stack.\n+     */\n+    @Override\n+    protected void setUpStackData(final Stack stack)\n+    {\n+        // No-op.\n+    }\n+\n+    /**\n+     * Sets up the DB tables used by the tests.\n+     */\n+    @Override\n+    protected void setUpTableData()\n+    {\n+        setUpMoviesTable();\n+        setUpBdayTable();\n+    }\n+\n+    /**\n+     * Creates the 'movies' table and inserts rows.\n+     */\n+    private void setUpMoviesTable()\n+    {\n+        logger.info(\"----------------------------------------------------\");\n+        logger.info(\"Setting up DB table: {}\", mysqlTableMovies);\n+        logger.info(\"----------------------------------------------------\");\n+\n+        JdbcTableUtils moviesTable =\n+                new JdbcTableUtils(lambdaFunctionName, new TableName(mysqlDbName, mysqlTableMovies),\n+                        environmentVars, jdbcProperties);\n+        moviesTable.createTable(\"year INTEGER, title VARCHAR(25), director VARCHAR(25), lead_actor VARCHAR(25)\");\n+        moviesTable.insertRow(\"2014, 'Interstellar', 'Christopher Nolan', 'Matthew McConaughey'\");\n+        moviesTable.insertRow(\"1986, 'Aliens', 'James Cameron', 'Sigourney Weaver'\");\n+    }\n+\n+    /**\n+     * Creates the 'bday' table and inserts rows.\n+     */\n+    private void setUpBdayTable()\n+    {\n+        logger.info(\"----------------------------------------------------\");\n+        logger.info(\"Setting up DB table: {}\", mysqlTableBday);\n+        logger.info(\"----------------------------------------------------\");\n+\n+        JdbcTableUtils bdayTable =\n+                new JdbcTableUtils(lambdaFunctionName, new TableName(mysqlDbName, mysqlTableBday),\n+                        environmentVars, jdbcProperties);\n+        bdayTable.createTable(\"first_name VARCHAR(10), last_name VARCHAR(10), birthday DATE\");\n+        bdayTable.insertRow(\"'Joe', 'Schmoe', '2002-05-05'\");\n+        bdayTable.insertRow(\"'Jane', 'Doe', '2005-10-12'\");\n+        bdayTable.insertRow(\"'John', 'Smith', '2006-02-10'\");\n+    }\n+\n+    @Test\n+    public void listDatabasesIntegTest()\n+    {\n+        logger.info(\"--------------------------------------\");\n+        logger.info(\"Executing listDatabasesIntegTest\");\n+        logger.info(\"--------------------------------------\");\n+\n+        List dbNames = listDatabases();\n+        logger.info(\"Databases: {}\", dbNames);\n+        assertTrue(\"DB not found.\", dbNames.contains(mysqlDbName));\n+    }\n+\n+    @Test\n+    public void listTablesIntegTest()\n+    {\n+        logger.info(\"-----------------------------------\");\n+        logger.info(\"Executing listTablesIntegTest\");\n+        logger.info(\"-----------------------------------\");\n+\n+        List tableNames = listTables(mysqlDbName);\n+        logger.info(\"Tables: {}\", tableNames);\n+        assertEquals(\"Incorrect number of tables found.\", 2, tableNames.size());\n+        assertTrue(String.format(\"Table not found: %s.\", mysqlTableMovies),\n+                tableNames.contains(mysqlTableMovies));\n+        assertTrue(String.format(\"Table not found: %s.\", mysqlTableBday),\n+                tableNames.contains(mysqlTableBday));\n+    }\n+\n+    @Test\n+    public void listTableSchemaIntegTest()\n+    {\n+        logger.info(\"--------------------------------------\");\n+        logger.info(\"Executing listTableSchemaIntegTest\");\n+        logger.info(\"--------------------------------------\");\n+\n+        Map schema = describeTable(mysqlDbName, mysqlTableMovies);\n+        schema.remove(\"partition_name\");\n+        schema.remove(\"partition_schema_name\");\n+        logger.info(\"Schema: {}\", schema);\n+        assertEquals(\"Wrong number of columns found.\", 4, schema.size());\n+        assertTrue(\"Column not found: year\", schema.containsKey(\"year\"));\n+        assertEquals(\"Wrong column type for year.\", \"int\", schema.get(\"year\"));\n+        assertTrue(\"Column not found: title\", schema.containsKey(\"title\"));\n+        assertEquals(\"Wrong column type for title.\", \"varchar\", schema.get(\"title\"));\n+        assertTrue(\"Column not found: director\", schema.containsKey(\"director\"));\n+        assertEquals(\"Wrong column type for director.\", \"varchar\", schema.get(\"director\"));\n+        assertTrue(\"Column not found: lead_actor\", schema.containsKey(\"lead_actor\"));\n+        assertEquals(\"Wrong column type for lead_actor.\", \"varchar\", schema.get(\"lead_actor\"));\n+    }\n+\n+    @Test\n+    public void selectColumnWithPredicateIntegTest()\n+    {\n+        logger.info(\"--------------------------------------------------\");\n+        logger.info(\"Executing selectColumnWithPredicateIntegTest\");\n+        logger.info(\"--------------------------------------------------\");\n+\n+        String query = String.format(\"select title from %s.%s.%s where year > 2010;\",\n+                lambdaFunctionName, mysqlDbName, mysqlTableMovies);\n+        List<Row> rows = startQueryExecution(query).getResultSet().getRows();\n+        if (!rows.isEmpty()) {\n+            // Remove the column-header row\n+            rows.remove(0);\n+        }\n+        List<String> titles = new ArrayList<>();\n+        rows.forEach(row -> titles.add(row.getData().get(0).getVarCharValue()));\n+        logger.info(\"Titles: {}\", titles);\n+        assertEquals(\"Wrong number of DB records found.\", 1, titles.size());\n+        assertTrue(\"Movie title not found: Interstellar.\", titles.contains(\"Interstellar\"));\n+    }\n+\n+    @Test\n+    public void selectColumnBetweenDatesIntegTest() {\n+        logger.info(\"--------------------------------------------------\");\n+        logger.info(\"Executing selectColumnBetweenDatesIntegTest\");\n+        logger.info(\"--------------------------------------------------\");\n+\n+        String query = String.format(\n+                \"select first_name from %s.%s.%s where birthday between date('2005-10-01') and date('2005-10-31');\",\n+                lambdaFunctionName, mysqlDbName, mysqlTableBday);\n+        List<Row> rows = startQueryExecution(query).getResultSet().getRows();\n+        if (!rows.isEmpty()) {\n+            // Remove the column-header row\n+            rows.remove(0);\n+        }\n+        List<String> names = new ArrayList<>();\n+        rows.forEach(row -> names.add(row.getData().get(0).getVarCharValue()));\n+        logger.info(\"Names: {}\", names);\n+        assertEquals(\"Wrong number of DB records found.\", 1, names.size());\n+        assertTrue(\"Name not found: Jane.\", names.contains(\"Jane\"));\n+    }\n+}"
  },
  {
    "sha": "33100157e3ab43038cf1266bc973154f6fdaf83d",
    "filename": "athena-jdbc/src/test/java/com/amazonaws/connectors/athena/jdbc/integ/PostGreSqlIntegTest.java",
    "status": "added",
    "additions": 402,
    "deletions": 0,
    "changes": 402,
    "blob_url": "https://github.com/awslabs/aws-athena-query-federation/blob/95973aa9a0faf2c9ea39679cb63d50058a35268e/athena-jdbc/src/test/java/com/amazonaws/connectors/athena/jdbc/integ/PostGreSqlIntegTest.java",
    "raw_url": "https://github.com/awslabs/aws-athena-query-federation/raw/95973aa9a0faf2c9ea39679cb63d50058a35268e/athena-jdbc/src/test/java/com/amazonaws/connectors/athena/jdbc/integ/PostGreSqlIntegTest.java",
    "contents_url": "https://api.github.com/repos/awslabs/aws-athena-query-federation/contents/athena-jdbc/src/test/java/com/amazonaws/connectors/athena/jdbc/integ/PostGreSqlIntegTest.java?ref=95973aa9a0faf2c9ea39679cb63d50058a35268e",
    "patch": "@@ -0,0 +1,402 @@\n+/*-\n+ * #%L\n+ * athena-jdbc\n+ * %%\n+ * Copyright (C) 2019 - 2021 Amazon Web Services\n+ * %%\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * \n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ * \n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ * #L%\n+ */\n+package com.amazonaws.connectors.athena.jdbc.integ;\n+\n+import com.amazonaws.athena.connector.integ.IntegrationTestBase;\n+import com.amazonaws.athena.connector.integ.clients.CloudFormationClient;\n+import com.amazonaws.athena.connector.integ.data.ConnectorVpcAttributes;\n+import com.amazonaws.athena.connector.integ.data.SecretsManagerCredentials;\n+import com.amazonaws.athena.connector.lambda.domain.TableName;\n+import com.amazonaws.services.athena.model.Row;\n+import com.amazonaws.services.rds.AmazonRDS;\n+import com.amazonaws.services.rds.AmazonRDSClientBuilder;\n+import com.amazonaws.services.rds.model.DescribeDBInstancesRequest;\n+import com.amazonaws.services.rds.model.DescribeDBInstancesResult;\n+import com.amazonaws.services.rds.model.Endpoint;\n+import com.google.common.collect.ImmutableMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.testng.annotations.AfterClass;\n+import org.testng.annotations.BeforeClass;\n+import org.testng.annotations.Test;\n+import software.amazon.awscdk.core.App;\n+import software.amazon.awscdk.core.RemovalPolicy;\n+import software.amazon.awscdk.core.Stack;\n+import software.amazon.awscdk.services.ec2.InstanceType;\n+import software.amazon.awscdk.services.ec2.SecurityGroup;\n+import software.amazon.awscdk.services.ec2.Vpc;\n+import software.amazon.awscdk.services.ec2.VpcAttributes;\n+import software.amazon.awscdk.services.iam.PolicyDocument;\n+import software.amazon.awscdk.services.rds.Credentials;\n+import software.amazon.awscdk.services.rds.DatabaseInstance;\n+import software.amazon.awscdk.services.rds.DatabaseInstanceEngine;\n+import software.amazon.awscdk.services.rds.PostgresInstanceEngineProps;\n+import software.amazon.awscdk.services.rds.PostgresEngineVersion;\n+import software.amazon.awscdk.services.rds.StorageType;\n+import software.amazon.awscdk.services.secretsmanager.Secret;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.UUID;\n+\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+\n+/**\n+ * Integration-tests for the PostGreSql (JDBC) connector using the Integration-test module.\n+ */\n+public class PostGreSqlIntegTest extends IntegrationTestBase\n+{\n+    private static final Logger logger = LoggerFactory.getLogger(PostGreSqlIntegTest.class);\n+\n+    private final App theApp;\n+    private final String secretArn;\n+    private final String username;\n+    private final String password;\n+    private final String postgresDbName;\n+    private final Number postgresDbPort;\n+    private final String postgresTableMovies;\n+    private final String postgresTableBday;\n+    private final String lambdaFunctionName;\n+    private final String dbInstanceName;\n+    private final Map<String, String> environmentVars;\n+    private final Map<String, String> jdbcProperties;\n+\n+    private CloudFormationClient cloudFormationClient;\n+\n+    public PostGreSqlIntegTest()\n+    {\n+        theApp = new App();\n+        SecretsManagerCredentials secretsManagerCredentials = getSecretCredentials().orElseThrow(() ->\n+                new RuntimeException(\"secrets_manager_secret must be provided in test-config.json file.\"));\n+        secretArn = secretsManagerCredentials.getArn();\n+        username = secretsManagerCredentials.getUsername();\n+        password = secretsManagerCredentials.getPassword();\n+        Map<String, Object> userSettings = getUserSettings().orElseThrow(() ->\n+                new RuntimeException(\"user_settings attribute must be provided in test-config.json file.\"));\n+        postgresDbName = (String) userSettings.get(\"postgres_db_name\");\n+        postgresDbPort = (Number) userSettings.get(\"postgres_db_port\");\n+        postgresTableMovies = (String) userSettings.get(\"postgres_table_movies\");\n+        postgresTableBday = (String) userSettings.get(\"postgres_table_bday\");\n+        lambdaFunctionName = getLambdaFunctionName();\n+        dbInstanceName = \"integ-postgres-instance-\" + UUID.randomUUID();\n+        environmentVars = new HashMap<>();\n+        jdbcProperties = ImmutableMap.of(\"databaseTerm\", \"SCHEMA\");\n+    }\n+\n+    /**\n+     * Creates a PostGreSql RDS Instance used for the integration tests.\n+     */\n+    @BeforeClass\n+    @Override\n+    protected void setUp()\n+    {\n+        cloudFormationClient = new CloudFormationClient(theApp, getPostGreSqlStack());\n+        try {\n+            // Create the CloudFormation stack for the PostGreSql DB instance.\n+            cloudFormationClient.createStack();\n+            // Get DB instance's host and port information and set the environment variables needed for the Lambda.\n+            setEnvironmentVars(getInstanceData());\n+            // Create the DB schema in the newly created DB instance used for the integration tests.\n+            createDbSchema();\n+            // Invoke the framework's setUp().\n+            super.setUp();\n+        }\n+        catch (Exception e) {\n+            // Delete the partially formed CloudFormation stack.\n+            cloudFormationClient.deleteStack();\n+            throw e;\n+        }\n+    }\n+\n+    /**\n+     * Deletes a CloudFormation stack for the PostGreSql RDS Instance.\n+     */\n+    @AfterClass\n+    @Override\n+    protected void cleanUp()\n+    {\n+        // Invoke the framework's cleanUp().\n+        super.cleanUp();\n+        // Delete the CloudFormation stack for the PostGreSql DB instance.\n+        cloudFormationClient.deleteStack();\n+    }\n+\n+    /**\n+     * Gets the CloudFormation stack for the PostGreSql RDS Instance.\n+     * @return Stack object for the PostGreSql RDS Instance.\n+     */\n+    private Stack getPostGreSqlStack()\n+    {\n+        Stack stack = Stack.Builder.create(theApp, dbInstanceName).build();\n+\n+        ConnectorVpcAttributes vpcAttributes = getVpcAttributes()\n+                .orElseThrow(() -> new RuntimeException(\"vpc_configuration must be specified in test-config.json\"));\n+\n+        DatabaseInstance.Builder.create(stack, \"PostGreSqlInstance\")\n+                .publiclyAccessible(Boolean.TRUE)\n+                .removalPolicy(RemovalPolicy.DESTROY)\n+                .deleteAutomatedBackups(Boolean.TRUE)\n+                .storageEncrypted(Boolean.FALSE)\n+                .port(postgresDbPort)\n+                .instanceIdentifier(dbInstanceName)\n+                .engine(DatabaseInstanceEngine.postgres(PostgresInstanceEngineProps.builder()\n+                        .version(PostgresEngineVersion.VER_12_4)\n+                        .build()))\n+                .storageType(StorageType.GP2)\n+                .allocatedStorage(20)\n+                .instanceType(new InstanceType(\"t2.micro\"))\n+                .credentials(Credentials.fromSecret(Secret\n+                        .fromSecretCompleteArn(stack, \"PostGreSqlSecret\", secretArn)))\n+                .vpc(Vpc.fromVpcAttributes(stack, \"PostGreSqlVpcConfig\", VpcAttributes.builder()\n+                        .vpcId(vpcAttributes.getVpcId())\n+                        .privateSubnetIds(vpcAttributes.getPrivateSubnetIds())\n+                        .availabilityZones(vpcAttributes.getAvailabilityZones())\n+                        .build()))\n+                .securityGroups(Collections.singletonList(SecurityGroup\n+                        .fromSecurityGroupId(stack, \"PostGreSqlVpcSecurityGroup\",\n+                                vpcAttributes.getSecurityGroupId())))\n+                .build();\n+\n+        return stack;\n+    }\n+\n+    /**\n+     * Gets the PostGreSql RDS Instance endpoint information and generates the environment variables needed for the\n+     * Lambda. All exceptions thrown here will be caught in the calling function.\n+     */\n+    private Endpoint getInstanceData()\n+    {\n+        AmazonRDS rdsClient = AmazonRDSClientBuilder.defaultClient();\n+        try {\n+            DescribeDBInstancesResult instancesResult = rdsClient.describeDBInstances(new DescribeDBInstancesRequest()\n+                    .withDBInstanceIdentifier(dbInstanceName));\n+            return instancesResult.getDBInstances().get(0).getEndpoint();\n+        }\n+        finally {\n+            rdsClient.shutdown();\n+        }\n+    }\n+\n+    /**\n+     * Sets the environment variables needed for the Lambda.\n+     * @param endpoint Contains the DB hostname and port information.\n+     */\n+    private void setEnvironmentVars(Endpoint endpoint)\n+    {\n+        String connectionString = String.format(\"postgres://jdbc:postgresql://%s:%s/postgres?user=%s&password=%s\",\n+                endpoint.getAddress(), endpoint.getPort(), username, password);\n+        String connectionStringTag = lambdaFunctionName + \"_connection_string\";\n+        environmentVars.put(\"default\", connectionString);\n+        environmentVars.put(connectionStringTag, connectionString);\n+    }\n+\n+    /**\n+     * Creates the DB schema used for the integration tests.\n+     */\n+    private void createDbSchema()\n+    {\n+        logger.info(\"----------------------------------------------------\");\n+        logger.info(\"Setting up DB Schema: {}\", postgresDbName);\n+        logger.info(\"----------------------------------------------------\");\n+\n+        JdbcTableUtils jdbcUtils =\n+                new JdbcTableUtils(lambdaFunctionName, new TableName(postgresDbName, postgresTableMovies),\n+                        environmentVars, jdbcProperties);\n+        jdbcUtils.createDbSchema();\n+    }\n+\n+    /**\n+     * Sets up the access policy for the Lambda connector to multiple connector-specific AWS services (e.g. DynamoDB,\n+     * Elasticsearch etc...)\n+     * @return A policy document object.\n+     */\n+    @Override\n+    protected Optional<PolicyDocument> getConnectorAccessPolicy()\n+    {\n+        // No connector-specific policy document needed\n+        return Optional.empty();\n+    }\n+\n+    /**\n+     * Sets the environment variables for the Lambda function.\n+     */\n+    @Override\n+    protected void setConnectorEnvironmentVars(final Map environmentVars)\n+    {\n+        environmentVars.putAll(this.environmentVars);\n+    }\n+\n+    /**\n+     * Sets up connector-specific Cloud Formation resource.\n+     * @param stack The current CloudFormation stack.\n+     */\n+    @Override\n+    protected void setUpStackData(final Stack stack)\n+    {\n+        // No-op.\n+    }\n+\n+    /**\n+     * Sets up the DB tables used by the tests.\n+     */\n+    @Override\n+    protected void setUpTableData()\n+    {\n+        setUpMoviesTable();\n+        setUpBdayTable();\n+    }\n+\n+    /**\n+     * Creates the 'movies' table and inserts rows.\n+     */\n+    private void setUpMoviesTable()\n+    {\n+        logger.info(\"----------------------------------------------------\");\n+        logger.info(\"Setting up DB table: {}\", postgresTableMovies);\n+        logger.info(\"----------------------------------------------------\");\n+\n+        JdbcTableUtils moviesTable =\n+                new JdbcTableUtils(lambdaFunctionName, new TableName(postgresDbName, postgresTableMovies),\n+                        environmentVars, jdbcProperties);\n+        moviesTable.createTable(\"year int, title varchar, director varchar, actors varchar[]\");\n+        moviesTable.insertRow(\"2014, 'Interstellar', 'Christopher Nolan', \" +\n+                \"'{Matthew McConaughey, John Lithgow, Ann Hathaway, David Gyasi, Michael Caine, \" +\n+                \"Jessica Chastain, Matt Damon, Casey Affleck}'\");\n+        moviesTable.insertRow(\"1986, 'Aliens', 'James Cameron', \" +\n+                \"'{Sigourney Weaver, Paul Reiser, Lance Henriksen, Bill Paxton}'\");\n+\n+    }\n+\n+    /**\n+     * Creates the 'bday' table and inserts rows.\n+     */\n+    private void setUpBdayTable()\n+    {\n+        logger.info(\"----------------------------------------------------\");\n+        logger.info(\"Setting up DB table: {}\", postgresTableBday);\n+        logger.info(\"----------------------------------------------------\");\n+\n+        JdbcTableUtils bdayTable =\n+                new JdbcTableUtils(lambdaFunctionName, new TableName(postgresDbName, postgresTableBday),\n+                        environmentVars, jdbcProperties);\n+        bdayTable.createTable(\"first_name varchar, last_name varchar, birthday date\");\n+        bdayTable.insertRow(\"'Joe', 'Schmoe', date('2002-05-05')\");\n+        bdayTable.insertRow(\"'Jane', 'Doe', date('2005-10-12')\");\n+        bdayTable.insertRow(\"'John', 'Smith', date('2006-02-10')\");\n+    }\n+\n+    @Test\n+    public void listDatabasesIntegTest()\n+    {\n+        logger.info(\"--------------------------------------\");\n+        logger.info(\"Executing listDatabasesIntegTest\");\n+        logger.info(\"--------------------------------------\");\n+\n+        List dbNames = listDatabases();\n+        logger.info(\"Databases: {}\", dbNames);\n+        assertTrue(\"DB not found.\", dbNames.contains(postgresDbName));\n+    }\n+\n+    @Test\n+    public void listTablesIntegTest()\n+    {\n+        logger.info(\"-----------------------------------\");\n+        logger.info(\"Executing listTablesIntegTest\");\n+        logger.info(\"-----------------------------------\");\n+\n+        List tableNames = listTables(postgresDbName);\n+        logger.info(\"Tables: {}\", tableNames);\n+        assertEquals(\"Incorrect number of tables found.\", 2, tableNames.size());\n+        assertTrue(String.format(\"Table not found: %s.\", postgresTableMovies),\n+                tableNames.contains(postgresTableMovies));\n+        assertTrue(String.format(\"Table not found: %s.\", postgresTableBday),\n+                tableNames.contains(postgresTableBday));\n+    }\n+\n+    @Test\n+    public void listTableSchemaIntegTest()\n+    {\n+        logger.info(\"--------------------------------------\");\n+        logger.info(\"Executing listTableSchemaIntegTest\");\n+        logger.info(\"--------------------------------------\");\n+\n+        Map schema = describeTable(postgresDbName, postgresTableMovies);\n+        schema.remove(\"partition_name\");\n+        schema.remove(\"partition_schema_name\");\n+        logger.info(\"Schema: {}\", schema);\n+        assertEquals(\"Wrong number of columns found.\", 4, schema.size());\n+        assertTrue(\"Column not found: year\", schema.containsKey(\"year\"));\n+        assertEquals(\"Wrong column type for year.\", \"int\", schema.get(\"year\"));\n+        assertTrue(\"Column not found: title\", schema.containsKey(\"title\"));\n+        assertEquals(\"Wrong column type for title.\", \"varchar\", schema.get(\"title\"));\n+        assertTrue(\"Column not found: director\", schema.containsKey(\"director\"));\n+        assertEquals(\"Wrong column type for director.\", \"varchar\", schema.get(\"director\"));\n+        assertTrue(\"Column not found: actors\", schema.containsKey(\"actors\"));\n+        assertEquals(\"Wrong column type for actors.\", \"array<varchar>\", schema.get(\"actors\"));\n+    }\n+\n+    @Test\n+    public void selectColumnWithPredicateIntegTest()\n+    {\n+        logger.info(\"--------------------------------------------------\");\n+        logger.info(\"Executing selectColumnWithPredicateIntegTest\");\n+        logger.info(\"--------------------------------------------------\");\n+\n+        String query = String.format(\"select title from %s.%s.%s where year > 2010;\",\n+                lambdaFunctionName, postgresDbName, postgresTableMovies);\n+        List<Row> rows = startQueryExecution(query).getResultSet().getRows();\n+        if (!rows.isEmpty()) {\n+            // Remove the column-header row\n+            rows.remove(0);\n+        }\n+        List<String> titles = new ArrayList<>();\n+        rows.forEach(row -> titles.add(row.getData().get(0).getVarCharValue()));\n+        logger.info(\"Titles: {}\", titles);\n+        assertEquals(\"Wrong number of DB records found.\", 1, titles.size());\n+        assertTrue(\"Movie title not found: Interstellar.\", titles.contains(\"Interstellar\"));\n+    }\n+\n+    @Test\n+    public void selectColumnBetweenDatesIntegTest()\n+    {\n+        logger.info(\"--------------------------------------------------\");\n+        logger.info(\"Executing selectColumnBetweenDatesIntegTest\");\n+        logger.info(\"--------------------------------------------------\");\n+\n+        String query = String.format(\n+                \"select first_name from %s.%s.%s where birthday between date('2005-10-01') and date('2005-10-31');\",\n+                lambdaFunctionName, postgresDbName, postgresTableBday);\n+        List<Row> rows = startQueryExecution(query).getResultSet().getRows();\n+        if (!rows.isEmpty()) {\n+            // Remove the column-header row\n+            rows.remove(0);\n+        }\n+        List<String> names = new ArrayList<>();\n+        rows.forEach(row -> names.add(row.getData().get(0).getVarCharValue()));\n+        logger.info(\"Names: {}\", names);\n+        assertEquals(\"Wrong number of DB records found.\", 1, names.size());\n+        assertTrue(\"Name not found: Jane.\", names.contains(\"Jane\"));\n+    }\n+}"
  },
  {
    "sha": "95e88b9c5af00822eec3f6874441a83fd9fd09ef",
    "filename": "athena-jdbc/src/test/java/com/amazonaws/connectors/athena/jdbc/integ/RedshiftIntegTest.java",
    "status": "added",
    "additions": 396,
    "deletions": 0,
    "changes": 396,
    "blob_url": "https://github.com/awslabs/aws-athena-query-federation/blob/95973aa9a0faf2c9ea39679cb63d50058a35268e/athena-jdbc/src/test/java/com/amazonaws/connectors/athena/jdbc/integ/RedshiftIntegTest.java",
    "raw_url": "https://github.com/awslabs/aws-athena-query-federation/raw/95973aa9a0faf2c9ea39679cb63d50058a35268e/athena-jdbc/src/test/java/com/amazonaws/connectors/athena/jdbc/integ/RedshiftIntegTest.java",
    "contents_url": "https://api.github.com/repos/awslabs/aws-athena-query-federation/contents/athena-jdbc/src/test/java/com/amazonaws/connectors/athena/jdbc/integ/RedshiftIntegTest.java?ref=95973aa9a0faf2c9ea39679cb63d50058a35268e",
    "patch": "@@ -0,0 +1,396 @@\n+/*-\n+ * #%L\n+ * athena-jdbc\n+ * %%\n+ * Copyright (C) 2019 - 2020 Amazon Web Services\n+ * %%\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ * \n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ * \n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ * #L%\n+ */\n+package com.amazonaws.connectors.athena.jdbc.integ;\n+\n+import com.amazonaws.athena.connector.integ.clients.CloudFormationClient;\n+import com.amazonaws.athena.connector.integ.data.ConnectorVpcAttributes;\n+import com.amazonaws.athena.connector.integ.IntegrationTestBase;\n+import com.amazonaws.athena.connector.integ.data.SecretsManagerCredentials;\n+import com.amazonaws.athena.connector.lambda.domain.TableName;\n+import com.amazonaws.services.athena.model.Row;\n+import com.amazonaws.services.redshift.AmazonRedshift;\n+import com.amazonaws.services.redshift.AmazonRedshiftClientBuilder;\n+import com.amazonaws.services.redshift.model.DescribeClustersRequest;\n+import com.amazonaws.services.redshift.model.DescribeClustersResult;\n+import com.amazonaws.services.redshift.model.Endpoint;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.testng.annotations.AfterClass;\n+import org.testng.annotations.BeforeClass;\n+import org.testng.annotations.Test;\n+import software.amazon.awscdk.core.App;\n+import software.amazon.awscdk.core.RemovalPolicy;\n+import software.amazon.awscdk.core.SecretValue;\n+import software.amazon.awscdk.core.Stack;\n+import software.amazon.awscdk.services.ec2.SecurityGroup;\n+import software.amazon.awscdk.services.ec2.Vpc;\n+import software.amazon.awscdk.services.ec2.VpcAttributes;\n+import software.amazon.awscdk.services.iam.PolicyDocument;\n+import software.amazon.awscdk.services.redshift.Cluster;\n+import software.amazon.awscdk.services.redshift.ClusterType;\n+import software.amazon.awscdk.services.redshift.Login;\n+import software.amazon.awscdk.services.redshift.NodeType;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.UUID;\n+\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+\n+/**\n+ * Integration-tests for the Redshift (JDBC) connector using the Integration-test module.\n+ */\n+public class RedshiftIntegTest extends IntegrationTestBase\n+{\n+    private static final Logger logger = LoggerFactory.getLogger(RedshiftIntegTest.class);\n+\n+    private static final long sleepDelayMillis = 60_000L;\n+\n+    private final App theApp;\n+    private final String username;\n+    private final String password;\n+    private final String redshiftDbName;\n+    private final String redshiftDbPort;\n+    private final String redshiftTableMovies;\n+    private final String redshiftTableBday;\n+    private final String lambdaFunctionName;\n+    private final String clusterName;\n+    private final Map<String, String> environmentVars;\n+\n+    private CloudFormationClient cloudFormationClient;\n+\n+    public RedshiftIntegTest()\n+    {\n+        theApp = new App();\n+        SecretsManagerCredentials secretsManagerCredentials = getSecretCredentials().orElseThrow(() ->\n+                new RuntimeException(\"secrets_manager_secret must be provided in test-config.json file.\"));\n+        username = secretsManagerCredentials.getUsername();\n+        password = secretsManagerCredentials.getPassword();\n+        Map<String, Object> userSettings = getUserSettings().orElseThrow(() ->\n+                new RuntimeException(\"user_settings attribute must be provided in test-config.json file.\"));\n+        redshiftDbName = (String) userSettings.get(\"redshift_db_name\");\n+        redshiftDbPort = (String) userSettings.get(\"redshift_db_port\");\n+        redshiftTableMovies = (String) userSettings.get(\"redshift_table_movies\");\n+        redshiftTableBday = (String) userSettings.get(\"redshift_table_bday\");\n+        lambdaFunctionName = getLambdaFunctionName();\n+        clusterName = \"integ-redshift-cluster-\" + UUID.randomUUID();\n+        environmentVars = new HashMap<>();\n+    }\n+\n+    /**\n+     * Creates a Redshift cluster used for the integration tests.\n+     */\n+    @BeforeClass\n+    @Override\n+    protected void setUp()\n+    {\n+        cloudFormationClient = new CloudFormationClient(theApp, getRedshiftStack());\n+        try {\n+            // Create the CloudFormation stack for the Redshift cluster.\n+            cloudFormationClient.createStack();\n+            // Get DB cluster's host and port information and set the environment variables needed for the Lambda.\n+            setEnvironmentVars(getClusterData());\n+            // Create the DB schema in the newly created DB cluster used for the integration tests.\n+            createDbSchema();\n+            // Invoke the framework's setUp().\n+            super.setUp();\n+        }\n+        catch (Exception e) {\n+            // Delete the partially formed CloudFormation stack.\n+            cloudFormationClient.deleteStack();\n+            throw e;\n+        }\n+    }\n+\n+    /**\n+     * Deletes a CloudFormation stack for the Redshift cluster.\n+     */\n+    @AfterClass\n+    @Override\n+    protected void cleanUp()\n+    {\n+        // Invoke the framework's cleanUp().\n+        super.cleanUp();\n+        // Delete the CloudFormation stack for the Redshift cluster.\n+        cloudFormationClient.deleteStack();\n+    }\n+\n+    /**\n+     * Gets the CloudFormation stack for the Redshift cluster.\n+     * @return Stack object for the Redshift cluster.\n+     */\n+    private Stack getRedshiftStack()\n+    {\n+        Stack stack = Stack.Builder.create(theApp, clusterName).build();\n+\n+        ConnectorVpcAttributes vpcAttributes = getVpcAttributes()\n+                .orElseThrow(() -> new RuntimeException(\"vpc_configuration must be specified in test-config.json\"));\n+\n+        Cluster.Builder.create(stack, \"RedshiftCluster\")\n+                .publiclyAccessible(Boolean.TRUE)\n+                .removalPolicy(RemovalPolicy.DESTROY)\n+                .encrypted(Boolean.FALSE)\n+                .port(Integer.parseInt(redshiftDbPort))\n+                .clusterName(clusterName)\n+                .clusterType(ClusterType.SINGLE_NODE)\n+                .nodeType(NodeType.DC2_LARGE)\n+                .numberOfNodes(1)\n+                .defaultDatabaseName(\"public\")\n+                .masterUser(Login.builder()\n+                        .masterUsername(username)\n+                        .masterPassword(SecretValue.plainText(password))\n+                        .build())\n+                .vpc(Vpc.fromVpcAttributes(stack, \"RedshiftVpcConfig\", VpcAttributes.builder()\n+                        .vpcId(vpcAttributes.getVpcId())\n+                        .privateSubnetIds(vpcAttributes.getPrivateSubnetIds())\n+                        .availabilityZones(vpcAttributes.getAvailabilityZones())\n+                        .build()))\n+                .securityGroups(Collections.singletonList(SecurityGroup\n+                        .fromSecurityGroupId(stack, \"RedshiftVpcSecurityGroup\", vpcAttributes.getSecurityGroupId())))\n+                .build();\n+\n+        return stack;\n+    }\n+\n+    /**\n+     * Gets the Redshift cluster endpoint information needed for the Lambda.\n+     * All exceptions thrown here will be caught in the calling function.\n+     */\n+    private Endpoint getClusterData()\n+    {\n+        AmazonRedshift redshiftClient = AmazonRedshiftClientBuilder.defaultClient();\n+        try {\n+            DescribeClustersResult clustersResult = redshiftClient.describeClusters(new DescribeClustersRequest()\n+                    .withClusterIdentifier(clusterName));\n+            return clustersResult.getClusters().get(0).getEndpoint();\n+        }\n+        finally {\n+            redshiftClient.shutdown();\n+        }\n+    }\n+\n+    /**\n+     * Sets the environment variables needed for the Lambda.\n+     * @param endpoint Contains the DB hostname and port information.\n+     */\n+    private void setEnvironmentVars(Endpoint endpoint)\n+    {\n+        String connectionString = String.format(\"redshift://jdbc:redshift://%s:%s/public?user=%s&password=%s\",\n+                endpoint.getAddress(), endpoint.getPort(), username, password);\n+        String connectionStringTag = lambdaFunctionName + \"_connection_string\";\n+        environmentVars.put(\"default\", connectionString);\n+        environmentVars.put(connectionStringTag, connectionString);\n+    }\n+\n+    /**\n+     * Creates the DB schema used for the integration tests.\n+     */\n+    private void createDbSchema()\n+    {\n+        logger.info(\"----------------------------------------------------\");\n+        logger.info(\"Setting up DB Schema: {}\", redshiftDbName);\n+        logger.info(\"----------------------------------------------------\");\n+\n+        JdbcTableUtils jdbcUtils =\n+                new JdbcTableUtils(lambdaFunctionName, new TableName(redshiftDbName, redshiftTableMovies),\n+                        environmentVars);\n+        jdbcUtils.createDbSchema();\n+    }\n+\n+    /**\n+     * Sets up the access policy for the Lambda connector to multiple connector-specific AWS services (e.g. DynamoDB,\n+     * Elasticsearch etc...)\n+     * @return A policy document object.\n+     */\n+    @Override\n+    protected Optional<PolicyDocument> getConnectorAccessPolicy()\n+    {\n+        // No connector-specific policy document needed\n+        return Optional.empty();\n+    }\n+\n+    /**\n+     * Sets the environment variables for the Lambda function.\n+     */\n+    @Override\n+    protected void setConnectorEnvironmentVars(final Map environmentVars)\n+    {\n+        environmentVars.putAll(this.environmentVars);\n+    }\n+\n+    /**\n+     * Sets up connector-specific Cloud Formation resource.\n+     * @param stack The current CloudFormation stack.\n+     */\n+    @Override\n+    protected void setUpStackData(final Stack stack)\n+    {\n+        // No-op.\n+    }\n+\n+    /**\n+     * Sets up the DB tables used by the tests.\n+     */\n+    @Override\n+    protected void setUpTableData()\n+    {\n+        try {\n+            logger.info(\"Allowing Redshift cluster to fully warm up - Sleeping for 1 min...\");\n+            Thread.sleep(sleepDelayMillis);\n+        }\n+        catch (InterruptedException e) {\n+            throw new RuntimeException(\"Thread.sleep interrupted: \" + e.getMessage(), e);\n+        }\n+        setUpMoviesTable();\n+        setUpBdayTable();\n+    }\n+\n+    /**\n+     * Creates the 'movies' table and inserts rows.\n+     */\n+    private void setUpMoviesTable()\n+    {\n+        logger.info(\"----------------------------------------------------\");\n+        logger.info(\"Setting up DB table: {}\", redshiftTableMovies);\n+        logger.info(\"----------------------------------------------------\");\n+\n+        JdbcTableUtils moviesTable = new JdbcTableUtils(lambdaFunctionName,\n+                new TableName(redshiftDbName, redshiftTableMovies), environmentVars);\n+        moviesTable.createTable(\"year int, title varchar, director varchar, lead varchar\");\n+        moviesTable.insertRow(\"2014, 'Interstellar', 'Christopher Nolan', 'Matthew McConaughey'\");\n+        moviesTable.insertRow(\"1986, 'Aliens', 'James Cameron', 'Sigourney Weaver'\");\n+\n+    }\n+\n+    /**\n+     * Creates the 'bday' table and inserts rows.\n+     */\n+    private void setUpBdayTable()\n+    {\n+        logger.info(\"----------------------------------------------------\");\n+        logger.info(\"Setting up DB table: {}\", redshiftTableBday);\n+        logger.info(\"----------------------------------------------------\");\n+\n+        JdbcTableUtils bdayTable = new JdbcTableUtils(lambdaFunctionName,\n+                new TableName(redshiftDbName, redshiftTableBday), environmentVars);\n+        bdayTable.createTable(\"first_name varchar, last_name varchar, birthday date\");\n+        bdayTable.insertRow(\"'Joe', 'Schmoe', date('2002-05-05')\");\n+        bdayTable.insertRow(\"'Jane', 'Doe', date('2005-10-12')\");\n+        bdayTable.insertRow(\"'John', 'Smith', date('2006-02-10')\");\n+    }\n+\n+    @Test\n+    public void listDatabasesIntegTest()\n+    {\n+        logger.info(\"--------------------------------------\");\n+        logger.info(\"Executing listDatabasesIntegTest\");\n+        logger.info(\"--------------------------------------\");\n+\n+        List dbNames = listDatabases();\n+        logger.info(\"Databases: {}\", dbNames);\n+        assertTrue(\"DB not found.\", dbNames.contains(redshiftDbName));\n+    }\n+\n+    @Test\n+    public void listTablesIntegTest()\n+    {\n+        logger.info(\"-----------------------------------\");\n+        logger.info(\"Executing listTablesIntegTest\");\n+        logger.info(\"-----------------------------------\");\n+\n+        List tableNames = listTables(redshiftDbName);\n+        logger.info(\"Tables: {}\", tableNames);\n+        assertEquals(\"Incorrect number of tables found.\", 2, tableNames.size());\n+        assertTrue(String.format(\"Table not found: %s.\", redshiftTableMovies),\n+                tableNames.contains(redshiftTableMovies));\n+        assertTrue(String.format(\"Table not found: %s.\", redshiftTableBday),\n+                tableNames.contains(redshiftTableBday));\n+    }\n+\n+    @Test\n+    public void listTableSchemaIntegTest()\n+    {\n+        logger.info(\"--------------------------------------\");\n+        logger.info(\"Executing listTableSchemaIntegTest\");\n+        logger.info(\"--------------------------------------\");\n+\n+        Map schema = describeTable(redshiftDbName, redshiftTableMovies);\n+        schema.remove(\"partition_name\");\n+        schema.remove(\"partition_schema_name\");\n+        logger.info(\"Schema: {}\", schema);\n+        assertEquals(\"Wrong number of columns found.\", 4, schema.size());\n+        assertTrue(\"Column not found: year\", schema.containsKey(\"year\"));\n+        assertEquals(\"Wrong column type for year.\", \"int\", schema.get(\"year\"));\n+        assertTrue(\"Column not found: title\", schema.containsKey(\"title\"));\n+        assertEquals(\"Wrong column type for title.\", \"varchar\", schema.get(\"title\"));\n+        assertTrue(\"Column not found: director\", schema.containsKey(\"director\"));\n+        assertEquals(\"Wrong column type for director.\", \"varchar\", schema.get(\"director\"));\n+        assertTrue(\"Column not found: lead\", schema.containsKey(\"lead\"));\n+        assertEquals(\"Wrong column type for lead.\", \"varchar\", schema.get(\"lead\"));\n+    }\n+\n+    @Test\n+    public void selectColumnWithPredicateIntegTest()\n+    {\n+        logger.info(\"--------------------------------------------------\");\n+        logger.info(\"Executing selectColumnWithPredicateIntegTest\");\n+        logger.info(\"--------------------------------------------------\");\n+\n+        String query = String.format(\"select title from %s.%s.%s where year > 2000;\",\n+                lambdaFunctionName, redshiftDbName, redshiftTableMovies);\n+        List<Row> rows = startQueryExecution(query).getResultSet().getRows();\n+        if (!rows.isEmpty()) {\n+            // Remove the column-header row\n+            rows.remove(0);\n+        }\n+        List<String> titles = new ArrayList<>();\n+        rows.forEach(row -> titles.add(row.getData().get(0).getVarCharValue()));\n+        logger.info(\"Titles: {}\", titles);\n+        assertEquals(\"Wrong number of DB records found.\", 1, titles.size());\n+        assertTrue(\"Movie title not found: Interstellar.\", titles.contains(\"Interstellar\"));\n+    }\n+\n+    @Test\n+    public void selectColumnBetweenDatesIntegTest()\n+    {\n+        logger.info(\"--------------------------------------------------\");\n+        logger.info(\"Executing selectColumnBetweenDatesIntegTest\");\n+        logger.info(\"--------------------------------------------------\");\n+\n+        String query = String.format(\n+                \"select first_name from %s.%s.%s where birthday between date('2003-1-1') and date('2005-12-31');\",\n+                lambdaFunctionName, redshiftDbName, redshiftTableBday);\n+        List<Row> rows = startQueryExecution(query).getResultSet().getRows();\n+        if (!rows.isEmpty()) {\n+            // Remove the column-header row\n+            rows.remove(0);\n+        }\n+        List<String> names = new ArrayList<>();\n+        rows.forEach(row -> names.add(row.getData().get(0).getVarCharValue()));\n+        logger.info(\"Names: {}\", names);\n+        assertEquals(\"Wrong number of DB records found.\", 1, names.size());\n+        assertTrue(\"Name not found: Jane.\", names.contains(\"Jane\"));\n+    }\n+}"
  }
]
